{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Project: Portfolio Management Using Multi-Agent Reinforcement Learning "
      ],
      "metadata": {
        "id": "MKIG9MBixxX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Reinfocement Learning Model"
      ],
      "metadata": {
        "id": "qC_9nFXzxxS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Step 1: Import Libraries and Install Packages\n",
        "> - Step 1.1: Install required packages if not already installed\n",
        "> - Step 1.2: Import the necessary libraries\n",
        "- Step 2: Define Constants\n",
        "> - Step 2.1: Define start and end dates for training data\n",
        "> - Step 2.2: Define start and end dates for testing data\n",
        "- Step 3: Load and Merge Dataframes\n",
        "> - Step 3.1: Load YahooFinance and sentiment dataframes\n",
        "> - Step 3.2: Create GDP dataframe\n",
        "> - Step 3.3: Merge all dataframes into one\n",
        "- Step 4: Incorporate Technical Indicators\n",
        "> - Step 4.1: Use historical data to calculate technical indicators\n",
        "- Step 5: Design Environment Constants\n",
        "> - Step 5.1: Define environment parameters\n",
        "> - Step 5.2: Define A2C model parameters\n",
        "> - Step 5.3: Define PPO model parameters\n",
        "> - Step 5.4: Define DDPG model parameters\n",
        "> - Step 5.5: Define timesteps\n",
        "> - Step 5.6: Define ensemble agent parameters.\n",
        "- Step 6: Implement Deep Reinforcement Learning Model\n",
        "> - Step 6.1: Build and train a deep reinforcement learning model using the environment and data\n",
        "- Step 7: Analyze Results\n",
        "> - Step 7.1: Calcualte Sharpe ratio\n",
        "> - Step 7.2: Backtest results\n",
        "> - Step 7.3: Baseline Statistics\n",
        "> - Step 7.4: Compare with Index\n",
        "> - Step 7.5: Vizualise the comparision with Index\n",
        "- Step 8: Conclusion\n",
        "> - Step 8.1: Summarize the results and provide insights on the effectiveness of the model"
      ],
      "metadata": {
        "id": "8lFG0XxoofZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Import Libraries and Install Packages"
      ],
      "metadata": {
        "id": "EpIgm2TyyP8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 1.1: Install required packages if not already installed"
      ],
      "metadata": {
        "id": "kgYaDWpZpY2I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FBPaPwCTxoZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20062cdf-f35f-4e40-f157-f74697525ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyportfolioopt in /usr/local/lib/python3.9/site-packages (1.5.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.9/site-packages (from pyportfolioopt) (2.0.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.9/site-packages (from pyportfolioopt) (1.24.2)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.1.10 in /usr/local/lib/python3.9/site-packages (from pyportfolioopt) (1.3.1)\n",
            "Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.9/site-packages (from pyportfolioopt) (1.10.1)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.9/site-packages (from cvxpy<2.0.0,>=1.1.10->pyportfolioopt) (3.2.3)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.9/site-packages (from cvxpy<2.0.0,>=1.1.10->pyportfolioopt) (2.0.12)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.9/site-packages (from cvxpy<2.0.0,>=1.1.10->pyportfolioopt) (0.6.2.post8)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.9/site-packages (from cvxpy<2.0.0,>=1.1.10->pyportfolioopt) (65.6.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas>=0.19->pyportfolioopt) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/site-packages (from pandas>=0.19->pyportfolioopt) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from pandas>=0.19->pyportfolioopt) (2.8.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.9/site-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.10->pyportfolioopt) (0.1.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=0.19->pyportfolioopt) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell installs the yfinance package if only unable to import, indicating the package is not installed.\n",
        "This avoids isntalling the packages again.\n",
        "\"\"\"\n",
        "import importlib\n",
        "\n",
        "# gym Library\n",
        "try:\n",
        "    importlib.import_module('gym')\n",
        "except ImportError:\n",
        "    !pip install gym\n",
        "\n",
        "\n",
        "# swig Library\n",
        "try:\n",
        "    importlib.import_module('swig')\n",
        "except ImportError:\n",
        "    !pip install swig\n",
        "\n",
        "\n",
        "# wrds Library\n",
        "try:\n",
        "    importlib.import_module('wrds')\n",
        "except ImportError:\n",
        "    !pip install wrds\n",
        "\n",
        "\n",
        "# pyportfolioopt Library\n",
        "try:\n",
        "    importlib.import_module('pyportfolioopt')\n",
        "except ImportError:\n",
        "    !pip install pyportfolioopt\n",
        "\n",
        "# condacolab Library\n",
        "try:\n",
        "    importlib.import_module('condacolab')\n",
        "except ImportError:\n",
        "    !pip install -q condacolab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "# !apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ],
      "metadata": {
        "id": "7XPXudiz0-jW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edacba8f-afaa-434c-bd8b-b1b937fab3c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-llkf55ph\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-llkf55ph\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 2ed2207c926608d559789624df26ef26682d2e14\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-4rgkj86j/elegantrl_76f05241a98949748f750cac8a09e1b7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-4rgkj86j/elegantrl_76f05241a98949748f750cac8a09e1b7\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 5db9257f8f26784aaa68f2adf58b92642b191f49\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-4rgkj86j/pyfolio_1b6ee486269941729fb07b6c194f3fcf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/quantopian/pyfolio.git /tmp/pip-install-4rgkj86j/pyfolio_1b6ee486269941729fb07b6c194f3fcf\n",
            "  Resolved https://github.com/quantopian/pyfolio.git to commit 4b901f6d73aa02ceb6d04b7d83502e5c6f2e81aa\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ray[default,tune]>=2.0.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.3.1)\n",
            "Requirement already satisfied: exchange_calendars==3.6.3 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.6.3)\n",
            "Requirement already satisfied: stable-baselines3<2.0.0,>=1.6.2 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.8.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.2.14)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.24.2)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.21.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.7.1)\n",
            "Requirement already satisfied: stockstats>=0.4.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.5.2)\n",
            "Requirement already satisfied: alpaca_trade_api>=2.1.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.0.0)\n",
            "Requirement already satisfied: jqdatasdk in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.8.11)\n",
            "Requirement already satisfied: importlib-metadata==4.13.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (4.13.0)\n",
            "Requirement already satisfied: ccxt>=1.66.32 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.0.56)\n",
            "Requirement already satisfied: wrds>=3.1.6 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.1.6)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.0.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (4.3.2)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.3.1)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2.2.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2023.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2.8.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata==4.13.0->finrl==0.3.5) (3.15.0)\n",
            "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (6.0)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.5.1)\n",
            "Requirement already satisfied: aiohttp==3.8.1 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (3.8.1)\n",
            "Requirement already satisfied: websockets<11,>=9.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (10.4)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.1.0)\n",
            "Requirement already satisfied: msgpack==1.0.3 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.0.3)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.26.15)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.28.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (6.0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from deprecation==2.1.0->alpaca_trade_api>=2.1.0->finrl==0.3.5) (23.0)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (65.6.3)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (39.0.2)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (3.0.0)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (2022.12.7)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.2.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/site-packages (from pandas>=1.1.5->finrl==0.3.5) (2023.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (8.1.3)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (3.20.3)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.53.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (3.11.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (4.17.3)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (20.21.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.7.0)\n",
            "Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.10.7)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.3.14)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.16.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.11.2)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.5.5)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (6.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.9.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (3.1.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/site-packages (from stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.0.0)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.9/site-packages (from wrds>=3.1.6->finrl==0.3.5) (1.4.47)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.9/site-packages (from wrds>=3.1.6->finrl==0.3.5) (2.9.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (1.16.0)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (1.0.3)\n",
            "Requirement already satisfied: thriftpy2>=0.3.9 in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (0.4.16)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (9.5.0)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (8.12.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.12.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.5.5)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (4.12.2)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (4.9.2)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (0.0.11)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (2.3.6)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (1.1)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.9/site-packages (from aiodns>=1.1.1->ccxt>=1.66.32->finrl==0.3.5) (4.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance->finrl==0.3.5) (2.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/site-packages (from cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (1.15.1)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.9/site-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.10.0)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (5.9.4)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (1.20.0)\n",
            "Requirement already satisfied: nvidia-ml-py>=11.450.129 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (11.525.112)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance->finrl==0.3.5) (0.5.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.8.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.1.6)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.18.2)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.14.0)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.9.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (3.0.38)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.6.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api>=2.1.0->finrl==0.3.5) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/site-packages (from sqlalchemy<2->wrds>=3.1.6->finrl==0.3.5) (2.0.2)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.9/site-packages (from thriftpy2>=0.3.9->jqdatasdk->finrl==0.3.5) (3.11)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.99)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.99)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.101)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (1.11.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.14.3)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.0.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.10.3.66)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (0.38.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.26.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.3.6)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[default,tune]>=2.0.0->finrl==0.3.5) (3.2.0)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.3.5)\n",
            "Requirement already satisfied: pyglet>=1.4.0 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.0.5)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/site-packages (from jsonschema->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.19.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (2.11.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.9/site-packages (from opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.1.3)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.9/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (2.21)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (2.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (1.59.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.1.2)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.2)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.2.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/site-packages (from sympy->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.2.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.4.8)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 1.2: Import the necessary libraries"
      ],
      "metadata": {
        "id": "aUGJByMKzzc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import SP_500_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent, DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "import pandas_datareader.data as web\n",
        "\n",
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwDHd5-3xvqj",
        "outputId": "88f5206e-fb18-45e9-9d1e-15639afbfa44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2:  Define the constants."
      ],
      "metadata": {
        "id": "MmyY-7qW6_wR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 2.1: Define start and end dates for training data"
      ],
      "metadata": {
        "id": "3-ba72B_7Hz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_START_DATE = '2010-01-01'\n",
        "TRAIN_END_DATE = '2017-12-31'"
      ],
      "metadata": {
        "id": "M-ngtJv1z39l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 2.2: Define start and end dates for testing data"
      ],
      "metadata": {
        "id": "igAw-Ypp7SQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_START_DATE = '2018-01-01'\n",
        "TEST_END_DATE = '2020-12-30'"
      ],
      "metadata": {
        "id": "DehYPXWy7SzN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Load and Merge Dataframes"
      ],
      "metadata": {
        "id": "074-8Duk7rAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "import gdown\n",
        "# The link for the data folder in Google drive. \n",
        "data_url = \"https://drive.google.com/drive/folders/1zQGlgh5kHTXSq7eoyXf6i_uAWYFJ5xzx?usp=share_link\"\n",
        "\n",
        "current_path = os.getcwd() # Get the current working directory.\n",
        "\n",
        "data_folder_path = os.path.join(os.getcwd(),\"genie_data\") # Generate data folder path. \n",
        "\n",
        "# Check if the folder already exists locally\n",
        "\n",
        "if not os.path.exists(data_folder_path):\n",
        "    \n",
        "    os.makedirs(data_folder_path)\n",
        "    print(f\"Downloading data from Google Drive to: {data_folder_path}\")\n",
        "    gdown.download_folder(data_url,output=data_folder_path, quiet=True, use_cookies=False) # Download the data from Google Drive.\n",
        "    \n",
        "else:\n",
        "    print(f\"Directory already exists: {data_folder_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKh-XbTi8A1q",
        "outputId": "1d8ed1d7-231a-415d-af32-c56ce2b24a37"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/site-packages (4.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/site-packages (from gdown) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from gdown) (3.11.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/site-packages (from gdown) (2.28.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests[socks]->gdown) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mDirectory already exists: /content/genie_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 3.1: Load YahooFinance and sentiment dataframes"
      ],
      "metadata": {
        "id": "Uo4koJ9SF0l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yf_df = pd.read_csv('./genie_data/yf-data.csv',index_col='Unnamed: 0')\n",
        "yf_df[\"date\"] = pd.to_datetime(yf_df[\"date\"])\n",
        "\n",
        "yf_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zx2WEURa7qGH",
        "outputId": "90245c32-9d09-402a-87a1-57cb4f4decf3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            date        open        high         low       close    volume   \n",
              "0     2010-01-04   39.099998   39.419998   38.840000   22.922108   2175500  \\\n",
              "1     2010-01-04   11.220000   11.430000   10.950000    9.966131  14482500   \n",
              "2     2010-01-04    5.660000    5.970000    5.650000    4.164575  14901600   \n",
              "3     2010-01-04   25.320000   25.910000   24.930000   19.833185   3811400   \n",
              "4     2010-01-04   15.245000   15.350000   15.120000    9.583809   1332800   \n",
              "...          ...         ...         ...         ...         ...       ...   \n",
              "28549 2020-12-30   50.520000   51.000000   50.360001   47.424179    563800   \n",
              "28550 2020-12-30  147.470001  147.990005  147.009995  138.462997   2224900   \n",
              "28551 2020-12-30  138.600006  138.919998  137.550003  130.316620   3261400   \n",
              "28552 2020-12-30  372.339996  373.100006  371.570007  359.862762  49455300   \n",
              "28553 2020-12-30   65.519997   65.849998   65.389999   61.628376   1296400   \n",
              "\n",
              "       tic  day  \n",
              "0        D    0  \n",
              "1      DAL    0  \n",
              "2      KEY    0  \n",
              "3      LNC    0  \n",
              "4      LNT    0  \n",
              "...    ...  ...  \n",
              "28549  LNT    2  \n",
              "28550  PEP    2  \n",
              "28551   PG    2  \n",
              "28552  SPY    2  \n",
              "28553  XEL    2  \n",
              "\n",
              "[28554 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55f5100b-fe21-4ce4-88b6-155a8eb2bf02\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>39.099998</td>\n",
              "      <td>39.419998</td>\n",
              "      <td>38.840000</td>\n",
              "      <td>22.922108</td>\n",
              "      <td>2175500</td>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>11.220000</td>\n",
              "      <td>11.430000</td>\n",
              "      <td>10.950000</td>\n",
              "      <td>9.966131</td>\n",
              "      <td>14482500</td>\n",
              "      <td>DAL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>5.660000</td>\n",
              "      <td>5.970000</td>\n",
              "      <td>5.650000</td>\n",
              "      <td>4.164575</td>\n",
              "      <td>14901600</td>\n",
              "      <td>KEY</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>25.320000</td>\n",
              "      <td>25.910000</td>\n",
              "      <td>24.930000</td>\n",
              "      <td>19.833185</td>\n",
              "      <td>3811400</td>\n",
              "      <td>LNC</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>15.245000</td>\n",
              "      <td>15.350000</td>\n",
              "      <td>15.120000</td>\n",
              "      <td>9.583809</td>\n",
              "      <td>1332800</td>\n",
              "      <td>LNT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28549</th>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>50.520000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>50.360001</td>\n",
              "      <td>47.424179</td>\n",
              "      <td>563800</td>\n",
              "      <td>LNT</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28550</th>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>147.470001</td>\n",
              "      <td>147.990005</td>\n",
              "      <td>147.009995</td>\n",
              "      <td>138.462997</td>\n",
              "      <td>2224900</td>\n",
              "      <td>PEP</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28551</th>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>138.600006</td>\n",
              "      <td>138.919998</td>\n",
              "      <td>137.550003</td>\n",
              "      <td>130.316620</td>\n",
              "      <td>3261400</td>\n",
              "      <td>PG</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28552</th>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>372.339996</td>\n",
              "      <td>373.100006</td>\n",
              "      <td>371.570007</td>\n",
              "      <td>359.862762</td>\n",
              "      <td>49455300</td>\n",
              "      <td>SPY</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28553</th>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>65.519997</td>\n",
              "      <td>65.849998</td>\n",
              "      <td>65.389999</td>\n",
              "      <td>61.628376</td>\n",
              "      <td>1296400</td>\n",
              "      <td>XEL</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28554 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55f5100b-fe21-4ce4-88b6-155a8eb2bf02')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55f5100b-fe21-4ce4-88b6-155a8eb2bf02 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55f5100b-fe21-4ce4-88b6-155a8eb2bf02');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments_df = pd.read_csv('./genie_data/sentiments_df.csv',index_col='Unnamed: 0')\n",
        "sentiments_df[\"date\"] = pd.to_datetime(sentiments_df[\"date\"])\n",
        "\n",
        "sentiments_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "wEDzfKjTJP2X",
        "outputId": "5d5938ed-f7e5-4865-aa62-120e812f3fde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           date  SentimentScore   tic\n",
              "1036 2005-01-01             0.0   LNC\n",
              "1003 2005-01-01             0.0   XEL\n",
              "1762 2005-01-01             0.0    PG\n",
              "2431 2005-01-01             0.0     D\n",
              "155  2005-01-01             0.0  ETSY\n",
              "...         ...             ...   ...\n",
              "7427 2020-12-31             0.0   KEY\n",
              "5943 2020-12-31             0.0  ETSY\n",
              "7021 2020-12-31             0.0    PG\n",
              "6010 2020-12-31             0.0  ENPH\n",
              "7022 2020-12-31             0.0     D\n",
              "\n",
              "[71721 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e386bb61-8730-4588-9027-a5b0fda38396\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>SentimentScore</th>\n",
              "      <th>tic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1036</th>\n",
              "      <td>2005-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>LNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>2005-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XEL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1762</th>\n",
              "      <td>2005-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2431</th>\n",
              "      <td>2005-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>2005-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ETSY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7427</th>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>KEY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5943</th>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ETSY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7021</th>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6010</th>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ENPH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7022</th>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71721 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e386bb61-8730-4588-9027-a5b0fda38396')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e386bb61-8730-4588-9027-a5b0fda38396 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e386bb61-8730-4588-9027-a5b0fda38396');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 3.2: Create GDP dataframe."
      ],
      "metadata": {
        "id": "VcEoLB0IFk2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdp = web.DataReader(\"GDP\", 'fred', 2010, 2020)\n",
        "gdp = gdp.reset_index()"
      ],
      "metadata": {
        "id": "RACEQNl_7xxL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date = pd.date_range(start='2010-01-01', end='2020-12-30')\n",
        "date_df = pd.DataFrame()\n",
        "date_df['date'] = date"
      ],
      "metadata": {
        "id": "njSxHpMhG9eN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdp['date']=pd.to_datetime(gdp['DATE'])\n",
        "gdp.rename(columns = {'GDP':'gdp'}, inplace = True)\n",
        "gdp = gdp.drop(['DATE'], axis=1)\n",
        "gdp_df=gdp.merge(date_df, on='date', how='right')\n",
        "gdp_df = gdp_df.fillna(method='ffill')\n",
        "gdp_df = gdp_df.merge(pd.DataFrame({\"tic\":yf_df.tic.unique()}),how=\"cross\")"
      ],
      "metadata": {
        "id": "-VEpZbu3HS-U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " > - #### Step 3.3:  Merge all dataframes into one"
      ],
      "metadata": {
        "id": "BITc6ro3L_Dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(pd.merge(yf_df, sentiments_df, how='left', left_on=['date','tic'], right_on = ['date','tic']),\n",
        "              gdp_df, how='left', left_on=['date','tic'], right_on = ['date','tic'])"
      ],
      "metadata": {
        "id": "CZa_G1ffI0yj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "uAaslu54h3aF",
        "outputId": "3f04ee36-ed0d-41f6-d69e-89ee58f3a0f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            date        open        high         low       close    volume   \n",
              "0     2010-01-04   39.099998   39.419998   38.840000   22.922108   2175500  \\\n",
              "1     2010-01-04   11.220000   11.430000   10.950000    9.966131  14482500   \n",
              "2     2010-01-04    5.660000    5.970000    5.650000    4.164575  14901600   \n",
              "3     2010-01-04   25.320000   25.910000   24.930000   19.833185   3811400   \n",
              "4     2010-01-04   15.245000   15.350000   15.120000    9.583809   1332800   \n",
              "...          ...         ...         ...         ...         ...       ...   \n",
              "41102 2020-12-30   50.520000   51.000000   50.360001   47.424179    563800   \n",
              "41103 2020-12-30  147.470001  147.990005  147.009995  138.462997   2224900   \n",
              "41104 2020-12-30  138.600006  138.919998  137.550003  130.316620   3261400   \n",
              "41105 2020-12-30  372.339996  373.100006  371.570007  359.862762  49455300   \n",
              "41106 2020-12-30   65.519997   65.849998   65.389999   61.628376   1296400   \n",
              "\n",
              "       tic  day  SentimentScore        gdp  \n",
              "0        D    0             0.0  14764.611  \n",
              "1      DAL    0             0.0  14764.611  \n",
              "2      KEY    0             0.0  14764.611  \n",
              "3      LNC    0             0.0  14764.611  \n",
              "4      LNT    0             0.0  14764.611  \n",
              "...    ...  ...             ...        ...  \n",
              "41102  LNT    2             0.0  21538.032  \n",
              "41103  PEP    2             0.0  21538.032  \n",
              "41104   PG    2             0.0  21538.032  \n",
              "41105  SPY    2             NaN  21538.032  \n",
              "41106  XEL    2             0.0  21538.032  \n",
              "\n",
              "[41107 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7358d7d0-bac0-4c64-9095-480a677eab38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>SentimentScore</th>\n",
              "      <th>gdp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>39.099998</td>\n",
              "      <td>39.419998</td>\n",
              "      <td>38.840000</td>\n",
              "      <td>22.922108</td>\n",
              "      <td>2175500</td>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>11.220000</td>\n",
              "      <td>11.430000</td>\n",
              "      <td>10.950000</td>\n",
              "      <td>9.966131</td>\n",
              "      <td>14482500</td>\n",
              "      <td>DAL</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>5.660000</td>\n",
              "      <td>5.970000</td>\n",
              "      <td>5.650000</td>\n",
              "      <td>4.164575</td>\n",
              "      <td>14901600</td>\n",
              "      <td>KEY</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>25.320000</td>\n",
              "      <td>25.910000</td>\n",
              "      <td>24.930000</td>\n",
              "      <td>19.833185</td>\n",
              "      <td>3811400</td>\n",
              "      <td>LNC</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>15.245000</td>\n",
              "      <td>15.350000</td>\n",
              "      <td>15.120000</td>\n",
              "      <td>9.583809</td>\n",
              "      <td>1332800</td>\n",
              "      <td>LNT</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41102</th>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>50.520000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>50.360001</td>\n",
              "      <td>47.424179</td>\n",
              "      <td>563800</td>\n",
              "      <td>LNT</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21538.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41103</th>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>147.470001</td>\n",
              "      <td>147.990005</td>\n",
              "      <td>147.009995</td>\n",
              "      <td>138.462997</td>\n",
              "      <td>2224900</td>\n",
              "      <td>PEP</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21538.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41104</th>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>138.600006</td>\n",
              "      <td>138.919998</td>\n",
              "      <td>137.550003</td>\n",
              "      <td>130.316620</td>\n",
              "      <td>3261400</td>\n",
              "      <td>PG</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21538.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41105</th>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>372.339996</td>\n",
              "      <td>373.100006</td>\n",
              "      <td>371.570007</td>\n",
              "      <td>359.862762</td>\n",
              "      <td>49455300</td>\n",
              "      <td>SPY</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21538.032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41106</th>\n",
              "      <td>2020-12-30</td>\n",
              "      <td>65.519997</td>\n",
              "      <td>65.849998</td>\n",
              "      <td>65.389999</td>\n",
              "      <td>61.628376</td>\n",
              "      <td>1296400</td>\n",
              "      <td>XEL</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21538.032</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41107 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7358d7d0-bac0-4c64-9095-480a677eab38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7358d7d0-bac0-4c64-9095-480a677eab38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7358d7d0-bac0-4c64-9095-480a677eab38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"SentimentScore\"] = df[\"SentimentScore\"].fillna(0)"
      ],
      "metadata": {
        "id": "rsKVwwfMRp3e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "peiE61-qRrzU",
        "outputId": "93905ffe-3087-4e44-9995-2986af67f097"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date        open        high         low      close     volume  tic   \n",
              "0  2010-01-04   39.099998   39.419998   38.840000  22.922108    2175500    D  \\\n",
              "1  2010-01-04   11.220000   11.430000   10.950000   9.966131   14482500  DAL   \n",
              "2  2010-01-04    5.660000    5.970000    5.650000   4.164575   14901600  KEY   \n",
              "3  2010-01-04   25.320000   25.910000   24.930000  19.833185    3811400  LNC   \n",
              "4  2010-01-04   15.245000   15.350000   15.120000   9.583809    1332800  LNT   \n",
              "5  2010-01-04   61.189999   61.520000   60.639999  41.632233    6585900  PEP   \n",
              "6  2010-01-04   61.110001   61.310001   60.630001  41.181229    9190800   PG   \n",
              "7  2010-01-04  112.370003  113.389999  111.510002  88.117897  118944600  SPY   \n",
              "8  2010-01-04   21.379999   21.379999   21.040001  13.396955    2670400  XEL   \n",
              "9  2010-01-05   38.860001   39.020000   38.080002  22.639708    2802200    D   \n",
              "10 2010-01-05   11.320000   12.340000   11.290000  10.747787   25066000  DAL   \n",
              "11 2010-01-05    5.880000    6.190000    5.880000   4.325830   16660800  KEY   \n",
              "12 2010-01-05   25.799999   26.610001   25.719999  20.247015    4839200  LNC   \n",
              "13 2010-01-05   15.185000   15.555000   15.155000   9.808012    3684600  LNT   \n",
              "14 2010-01-05   61.000000   62.099998   60.900002  42.135311    8886000  PEP   \n",
              "15 2010-01-05   61.130001   61.279999   60.599998  41.194714    8649400   PG   \n",
              "16 2010-01-05  113.260002  113.680000  112.849998  88.351143  111579900  SPY   \n",
              "17 2010-01-05   20.950001   21.000000   20.410000  13.238071    4321400  XEL   \n",
              "18 2010-01-06   38.500000   38.730000   38.290001  22.663235    2882500    D   \n",
              "19 2010-01-06   11.990000   12.240000   11.850000  10.756669   14980700  DAL   \n",
              "\n",
              "    day  SentimentScore        gdp  \n",
              "0     0             0.0  14764.611  \n",
              "1     0             0.0  14764.611  \n",
              "2     0             0.0  14764.611  \n",
              "3     0             0.0  14764.611  \n",
              "4     0             0.0  14764.611  \n",
              "5     0             0.0  14764.611  \n",
              "6     0             0.0  14764.611  \n",
              "7     0             0.0  14764.611  \n",
              "8     0             0.0  14764.611  \n",
              "9     1             0.0  14764.611  \n",
              "10    1             0.0  14764.611  \n",
              "11    1             0.0  14764.611  \n",
              "12    1             0.0  14764.611  \n",
              "13    1             0.0  14764.611  \n",
              "14    1             0.0  14764.611  \n",
              "15    1             0.0  14764.611  \n",
              "16    1             0.0  14764.611  \n",
              "17    1             0.0  14764.611  \n",
              "18    2             0.0  14764.611  \n",
              "19    2             0.0  14764.611  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b280972e-34d6-494d-91af-3a787a0bdecc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>SentimentScore</th>\n",
              "      <th>gdp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>39.099998</td>\n",
              "      <td>39.419998</td>\n",
              "      <td>38.840000</td>\n",
              "      <td>22.922108</td>\n",
              "      <td>2175500</td>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>11.220000</td>\n",
              "      <td>11.430000</td>\n",
              "      <td>10.950000</td>\n",
              "      <td>9.966131</td>\n",
              "      <td>14482500</td>\n",
              "      <td>DAL</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>5.660000</td>\n",
              "      <td>5.970000</td>\n",
              "      <td>5.650000</td>\n",
              "      <td>4.164575</td>\n",
              "      <td>14901600</td>\n",
              "      <td>KEY</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>25.320000</td>\n",
              "      <td>25.910000</td>\n",
              "      <td>24.930000</td>\n",
              "      <td>19.833185</td>\n",
              "      <td>3811400</td>\n",
              "      <td>LNC</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>15.245000</td>\n",
              "      <td>15.350000</td>\n",
              "      <td>15.120000</td>\n",
              "      <td>9.583809</td>\n",
              "      <td>1332800</td>\n",
              "      <td>LNT</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>61.189999</td>\n",
              "      <td>61.520000</td>\n",
              "      <td>60.639999</td>\n",
              "      <td>41.632233</td>\n",
              "      <td>6585900</td>\n",
              "      <td>PEP</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>61.110001</td>\n",
              "      <td>61.310001</td>\n",
              "      <td>60.630001</td>\n",
              "      <td>41.181229</td>\n",
              "      <td>9190800</td>\n",
              "      <td>PG</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>112.370003</td>\n",
              "      <td>113.389999</td>\n",
              "      <td>111.510002</td>\n",
              "      <td>88.117897</td>\n",
              "      <td>118944600</td>\n",
              "      <td>SPY</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>21.379999</td>\n",
              "      <td>21.379999</td>\n",
              "      <td>21.040001</td>\n",
              "      <td>13.396955</td>\n",
              "      <td>2670400</td>\n",
              "      <td>XEL</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>38.860001</td>\n",
              "      <td>39.020000</td>\n",
              "      <td>38.080002</td>\n",
              "      <td>22.639708</td>\n",
              "      <td>2802200</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>11.320000</td>\n",
              "      <td>12.340000</td>\n",
              "      <td>11.290000</td>\n",
              "      <td>10.747787</td>\n",
              "      <td>25066000</td>\n",
              "      <td>DAL</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>6.190000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>4.325830</td>\n",
              "      <td>16660800</td>\n",
              "      <td>KEY</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>25.799999</td>\n",
              "      <td>26.610001</td>\n",
              "      <td>25.719999</td>\n",
              "      <td>20.247015</td>\n",
              "      <td>4839200</td>\n",
              "      <td>LNC</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>15.185000</td>\n",
              "      <td>15.555000</td>\n",
              "      <td>15.155000</td>\n",
              "      <td>9.808012</td>\n",
              "      <td>3684600</td>\n",
              "      <td>LNT</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>62.099998</td>\n",
              "      <td>60.900002</td>\n",
              "      <td>42.135311</td>\n",
              "      <td>8886000</td>\n",
              "      <td>PEP</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>61.130001</td>\n",
              "      <td>61.279999</td>\n",
              "      <td>60.599998</td>\n",
              "      <td>41.194714</td>\n",
              "      <td>8649400</td>\n",
              "      <td>PG</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>113.260002</td>\n",
              "      <td>113.680000</td>\n",
              "      <td>112.849998</td>\n",
              "      <td>88.351143</td>\n",
              "      <td>111579900</td>\n",
              "      <td>SPY</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>20.950001</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>20.410000</td>\n",
              "      <td>13.238071</td>\n",
              "      <td>4321400</td>\n",
              "      <td>XEL</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2010-01-06</td>\n",
              "      <td>38.500000</td>\n",
              "      <td>38.730000</td>\n",
              "      <td>38.290001</td>\n",
              "      <td>22.663235</td>\n",
              "      <td>2882500</td>\n",
              "      <td>D</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2010-01-06</td>\n",
              "      <td>11.990000</td>\n",
              "      <td>12.240000</td>\n",
              "      <td>11.850000</td>\n",
              "      <td>10.756669</td>\n",
              "      <td>14980700</td>\n",
              "      <td>DAL</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14764.611</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b280972e-34d6-494d-91af-3a787a0bdecc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b280972e-34d6-494d-91af-3a787a0bdecc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b280972e-34d6-494d-91af-3a787a0bdecc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset=['date', 'tic'], inplace=True)\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF2mO-m5hpMw",
        "outputId": "23571701-ee28-4cdd-8574-a925ce4c6a5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28554, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Incorporate Technical Indicators."
      ],
      "metadata": {
        "id": "jejabAiBTfmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 4.1: Use historical data to calculate technical indicators"
      ],
      "metadata": {
        "id": "7GpfYW-sqDLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "technical_indicators = ['macd', 'rsi_30', 'cci_30', 'dx_30']"
      ],
      "metadata": {
        "id": "6nrmtBVGSdgs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fe_pipeline = FeatureEngineer(use_technical_indicator=True, \n",
        "                              tech_indicator_list = technical_indicators, \n",
        "                              use_turbulence=True, \n",
        "                              user_defined_feature = True\n",
        "                              )"
      ],
      "metadata": {
        "id": "pusTbgzUTqHJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_processed = fe_pipeline.preprocess_data(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWolIyIaT_BV",
        "outputId": "30160e41-2ce7-4f62-b2b6-2e8d11f653aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n",
            "Successfully added user defined features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5:  Design Environment constants."
      ],
      "metadata": {
        "id": "RDR3MHqFlcUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 5.1: Define environment parameters"
      ],
      "metadata": {
        "id": "ztF9rZzOqSy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stock_dimension = len(df_processed.tic.unique())\n",
        "\n",
        "udfs = 2 # Sentiment Scores, GDP\n",
        "\n",
        "state_space = 1 + 2 * stock_dimension + len(technical_indicators)*stock_dimension + udfs*stock_dimension\n",
        "\n",
        "print(f\"Stock Dimension: {stock_dimension}, state Space: {state_space}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6J0lQWUUFZ3",
        "outputId": "f3b46b7e-53b6-4ff2-9525-bd346abc8b23"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 9, state Space: 73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "technical_indicators.extend([\"SentimentScore\",\"gdp\"])"
      ],
      "metadata": {
        "id": "1-0s3GHBl-FQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a dictionary containing environment arguments\n",
        "\n",
        "env_variables = { \"hmax\": 100,                        # Maximum number of shares that can be traded at a time\n",
        "                  \"buy_cost_pct\": 0.001,              # Transaction cost for buying\n",
        "                  \"sell_cost_pct\": 0.001,             # Transaction cost for selling\n",
        "                  \"state_space\": state_space,         # State space for the environment\n",
        "                  \"tech_indicator_list\": technical_indicators,  # List of technical indicators used\n",
        "                  \"action_space\": stock_dimension,    # Action space for the environment\n",
        "                  \"reward_scaling\": 1e-4,             # Scaling factor for rewards\n",
        "                  \"print_verbosity\": 5                # Level of detail for logging during training\n",
        "                  }"
      ],
      "metadata": {
        "id": "EJNQ1TXGmqnp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 5.2: Define A2C model parameters"
      ],
      "metadata": {
        "id": "MGZ4QnPLrW_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A2C_model_kwargs = {'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}"
      ],
      "metadata": {
        "id": "GvzaGen2r4CE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> -  #### Step 5.3: Define PPO model parameters"
      ],
      "metadata": {
        "id": "6yHV8PBWrWun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PPO_model_kwargs = { \"ent_coef\": 0.01, \"n_steps\": 2048, \"learning_rate\": 0.00025, \"batch_size\": 128 }"
      ],
      "metadata": {
        "id": "uxptBXIar91A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 5.4: Define DDPG model parameters"
      ],
      "metadata": {
        "id": "KyDKWItvrWlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DDPG_model_kwargs = { \"buffer_size\": 10_000, \"learning_rate\": 0.0005, \"batch_size\":64 }"
      ],
      "metadata": {
        "id": "7Znj3spJsFYI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 5.5: Define timesteps"
      ],
      "metadata": {
        "id": "R2z-ad2wrWS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps_dict = { 'a2c': 10_000, 'ppo': 10_000, 'ddpg': 10_000 }"
      ],
      "metadata": {
        "id": "aH3Nots0sLDq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 5.6: Define ensemble agent parameters."
      ],
      "metadata": {
        "id": "7_UaT149r1Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rebalance_window = 63\n",
        "validation_window = 63"
      ],
      "metadata": {
        "id": "m4YLBeq8sQGc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_agent = DRLEnsembleAgent(initial_amount = 10000,\n",
        "                                  stock_dim = stock_dimension,\n",
        "                                  df = df_processed,\n",
        "                                  train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                                  val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
        "                                  rebalance_window=rebalance_window,\n",
        "                                  validation_window=validation_window,\n",
        "                                  **env_variables)"
      ],
      "metadata": {
        "id": "DLvv-dSjsVv-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6: Implement Deep Reinforcement Learning Model"
      ],
      "metadata": {
        "id": "iXPiP6ybqZh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 6.1: Build and train a deep reinforcement learning model using the environment and data"
      ],
      "metadata": {
        "id": "7nGsa7SltetS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs, PPO_model_kwargs, DDPG_model_kwargs, timesteps_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPjSkaADm4lF",
        "outputId": "9eeb1d11-c118-414f-9227-ecd009ce9271"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  45.85564342289035\n",
            "======Model training from:  2010-01-01 to  2018-01-02 00:00:00\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_126_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 208          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0751      |\n",
            "|    reward             | -0.006231971 |\n",
            "|    std                | 1.03         |\n",
            "|    value_loss         | 6.47e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 219         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | 0.334       |\n",
            "|    reward             | 0.018966738 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.000807    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 210           |\n",
            "|    iterations         | 300           |\n",
            "|    time_elapsed       | 7             |\n",
            "|    total_timesteps    | 1500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.4         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 299           |\n",
            "|    policy_loss        | -0.265        |\n",
            "|    reward             | -0.0031671964 |\n",
            "|    std                | 1.08          |\n",
            "|    value_loss         | 0.00111       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 214           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 9             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.6         |\n",
            "|    explained_variance | -0.137        |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.117        |\n",
            "|    reward             | -0.0058770254 |\n",
            "|    std                | 1.1           |\n",
            "|    value_loss         | 0.000129      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 197           |\n",
            "|    iterations         | 500           |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 2500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.9         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 499           |\n",
            "|    policy_loss        | 0.176         |\n",
            "|    reward             | -0.0008483628 |\n",
            "|    std                | 1.13          |\n",
            "|    value_loss         | 0.000161      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 186          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.2        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | -0.0183      |\n",
            "|    reward             | 0.0013749419 |\n",
            "|    std                | 1.18         |\n",
            "|    value_loss         | 3.44e-06     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 180            |\n",
            "|    iterations         | 700            |\n",
            "|    time_elapsed       | 19             |\n",
            "|    total_timesteps    | 3500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -14.7          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 699            |\n",
            "|    policy_loss        | 0.0993         |\n",
            "|    reward             | -0.00046961647 |\n",
            "|    std                | 1.23           |\n",
            "|    value_loss         | 5.08e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 177          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 22           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | 0.0405       |\n",
            "|    reward             | -0.001076559 |\n",
            "|    std                | 1.3          |\n",
            "|    value_loss         | 6.93e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 181           |\n",
            "|    iterations         | 900           |\n",
            "|    time_elapsed       | 24            |\n",
            "|    total_timesteps    | 4500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -15.6         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 899           |\n",
            "|    policy_loss        | -0.0664       |\n",
            "|    reward             | -0.0034354026 |\n",
            "|    std                | 1.37          |\n",
            "|    value_loss         | 2.2e-05       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 184           |\n",
            "|    iterations         | 1000          |\n",
            "|    time_elapsed       | 27            |\n",
            "|    total_timesteps    | 5000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -16           |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 999           |\n",
            "|    policy_loss        | -0.0598       |\n",
            "|    reward             | 0.00076700107 |\n",
            "|    std                | 1.44          |\n",
            "|    value_loss         | 1.58e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 187         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 29          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.5       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -0.0323     |\n",
            "|    reward             | 0.005882751 |\n",
            "|    std                | 1.51        |\n",
            "|    value_loss         | 2.36e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 191         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -0.0173     |\n",
            "|    reward             | 0.006793895 |\n",
            "|    std                | 1.6         |\n",
            "|    value_loss         | 2.21e-06    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 188          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 34           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.315        |\n",
            "|    reward             | -0.014666072 |\n",
            "|    std                | 1.66         |\n",
            "|    value_loss         | 0.00046      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 184           |\n",
            "|    iterations         | 1400          |\n",
            "|    time_elapsed       | 37            |\n",
            "|    total_timesteps    | 7000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -17.6         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1399          |\n",
            "|    policy_loss        | 0.365         |\n",
            "|    reward             | -0.0008558901 |\n",
            "|    std                | 1.72          |\n",
            "|    value_loss         | 0.000554      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 180         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 41          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.9       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 0.434       |\n",
            "|    reward             | 0.025379792 |\n",
            "|    std                | 1.76        |\n",
            "|    value_loss         | 0.000629    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 179         |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -18.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | 0.361       |\n",
            "|    reward             | 0.010420655 |\n",
            "|    std                | 1.8         |\n",
            "|    value_loss         | 0.000421    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 181           |\n",
            "|    iterations         | 1700          |\n",
            "|    time_elapsed       | 46            |\n",
            "|    total_timesteps    | 8500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -18.3         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1699          |\n",
            "|    policy_loss        | -0.0314       |\n",
            "|    reward             | 0.00084823533 |\n",
            "|    std                | 1.84          |\n",
            "|    value_loss         | 1.45e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 177          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -18.6        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | 0.00911      |\n",
            "|    reward             | 0.0019717359 |\n",
            "|    std                | 1.9          |\n",
            "|    value_loss         | 1.26e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 178          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -18.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | 0.00965      |\n",
            "|    reward             | 0.0018186199 |\n",
            "|    std                | 1.99         |\n",
            "|    value_loss         | 5.25e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 178          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 56           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -19.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | -0.153       |\n",
            "|    reward             | 0.0031479825 |\n",
            "|    std                | 2.09         |\n",
            "|    value_loss         | 8.37e-05     |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2018-01-02 00:00:00 to  2018-04-04 00:00:00\n",
            "A2C Sharpe Ratio:  -0.34484367275248884\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_126_1\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    fps             | 168          |\n",
            "|    iterations      | 1            |\n",
            "|    time_elapsed    | 12           |\n",
            "|    total_timesteps | 2048         |\n",
            "| train/             |              |\n",
            "|    reward          | 0.0017945921 |\n",
            "-------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 183          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00733928   |\n",
            "|    clip_fraction        | 0.0793       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | -1.65        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.137       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00556     |\n",
            "|    reward               | -0.002341966 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.000812     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 171          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 35           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006138456  |\n",
            "|    clip_fraction        | 0.0759       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | -1.89        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.136       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00695     |\n",
            "|    reward               | -0.008761004 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.000641     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 182          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 44           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071625654 |\n",
            "|    clip_fraction        | 0.0708       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.463        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.121       |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00595     |\n",
            "|    reward               | 0.008577127  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.000128     |\n",
            "------------------------------------------\n",
            "day: 2012, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 2473.04\n",
            "total_reward: -7526.96\n",
            "total_cost: 4411.14\n",
            "total_trades: 12148\n",
            "Sharpe: -0.349\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 167          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 61           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006451433  |\n",
            "|    clip_fraction        | 0.0692       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.669        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.13        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00593     |\n",
            "|    reward               | 0.0011663691 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 9.54e-05     |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2018-01-02 00:00:00 to  2018-04-04 00:00:00\n",
            "PPO Sharpe Ratio:  -0.2858207325669781\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_126_1\n",
            "day: 2012, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9990.01\n",
            "total_reward: -9.99\n",
            "total_cost: 9.99\n",
            "total_trades: 10060\n",
            "Sharpe: 0.224\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    episodes        | 4            |\n",
            "|    fps             | 57           |\n",
            "|    time_elapsed    | 139          |\n",
            "|    total_timesteps | 8052         |\n",
            "| train/             |              |\n",
            "|    actor_loss      | 84.6         |\n",
            "|    critic_loss     | 90.2         |\n",
            "|    learning_rate   | 0.0005       |\n",
            "|    n_updates       | 6039         |\n",
            "|    reward          | -0.001907798 |\n",
            "-------------------------------------\n",
            "======DDPG Validation from:  2018-01-02 00:00:00 to  2018-04-04 00:00:00\n",
            "======Best Model Retraining from:  2010-01-01 to  2018-04-04 00:00:00\n",
            "======Trading from:  2018-04-04 00:00:00 to  2018-07-03 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  45.85564342289035\n",
            "======Model training from:  2010-01-01 to  2018-04-04 00:00:00\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_189_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 223          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.2        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.137       |\n",
            "|    reward             | -0.011882934 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.000433     |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 222       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 0.225     |\n",
            "|    reward             | 0.0166008 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.00035   |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 228          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.173       |\n",
            "|    reward             | -0.041260418 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 0.000702     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 224           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 8             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.8         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.129        |\n",
            "|    reward             | -0.0040851207 |\n",
            "|    std                | 1.12          |\n",
            "|    value_loss         | 0.000115      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 187         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 13          |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.0928      |\n",
            "|    reward             | -0.00250395 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 7.28e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 172          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 17           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.3        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | -0.0469      |\n",
            "|    reward             | 0.0004394062 |\n",
            "|    std                | 1.18         |\n",
            "|    value_loss         | 2.03e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 168           |\n",
            "|    iterations         | 700           |\n",
            "|    time_elapsed       | 20            |\n",
            "|    total_timesteps    | 3500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.7         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 699           |\n",
            "|    policy_loss        | -0.276        |\n",
            "|    reward             | -0.0023235325 |\n",
            "|    std                | 1.24          |\n",
            "|    value_loss         | 0.000411      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 174           |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 22            |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -15.1         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | -0.0252       |\n",
            "|    reward             | -0.0009831387 |\n",
            "|    std                | 1.3           |\n",
            "|    value_loss         | 3.91e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 178           |\n",
            "|    iterations         | 900           |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 4500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -15.6         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 899           |\n",
            "|    policy_loss        | -0.0618       |\n",
            "|    reward             | -0.0067339176 |\n",
            "|    std                | 1.36          |\n",
            "|    value_loss         | 1.86e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -0.0545     |\n",
            "|    reward             | 0.009388282 |\n",
            "|    std                | 1.43        |\n",
            "|    value_loss         | 2.1e-05     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 186          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 29           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | -0.161       |\n",
            "|    reward             | 0.0012092848 |\n",
            "|    std                | 1.5          |\n",
            "|    value_loss         | 0.000119     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 186          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 32           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | -0.245       |\n",
            "|    reward             | -0.007216993 |\n",
            "|    std                | 1.55         |\n",
            "|    value_loss         | 0.000227     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 182         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 0.0522      |\n",
            "|    reward             | 0.014667226 |\n",
            "|    std                | 1.6         |\n",
            "|    value_loss         | 3.1e-05     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 179         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | 0.113       |\n",
            "|    reward             | 0.005861218 |\n",
            "|    std                | 1.66        |\n",
            "|    value_loss         | 4.56e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 177          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 42           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | 0.0173       |\n",
            "|    reward             | 0.0018441754 |\n",
            "|    std                | 1.72         |\n",
            "|    value_loss         | 6.37e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 178          |\n",
            "|    iterations         | 1600         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 8000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1599         |\n",
            "|    policy_loss        | -0.119       |\n",
            "|    reward             | 0.0062179845 |\n",
            "|    std                | 1.78         |\n",
            "|    value_loss         | 7.72e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 180          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 47           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -18.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | -0.0642      |\n",
            "|    reward             | 0.0018901533 |\n",
            "|    std                | 1.84         |\n",
            "|    value_loss         | 1.3e-05      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 182           |\n",
            "|    iterations         | 1800          |\n",
            "|    time_elapsed       | 49            |\n",
            "|    total_timesteps    | 9000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -18.6         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1799          |\n",
            "|    policy_loss        | 0.0277        |\n",
            "|    reward             | -0.0036643085 |\n",
            "|    std                | 1.91          |\n",
            "|    value_loss         | 1.11e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 184         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -19         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -0.0655     |\n",
            "|    reward             | 0.004656599 |\n",
            "|    std                | 2           |\n",
            "|    value_loss         | 2e-05       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 185          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -19.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | 0.582        |\n",
            "|    reward             | -0.005311545 |\n",
            "|    std                | 2.09         |\n",
            "|    value_loss         | 0.000793     |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2018-04-04 00:00:00 to  2018-07-03 00:00:00\n",
            "A2C Sharpe Ratio:  0.3337634048497701\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_189_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 182        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 11         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.00514953 |\n",
            "-----------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 204           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 20            |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0064015803  |\n",
            "|    clip_fraction        | 0.0635        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | 0.0125        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.13         |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | -0.00627      |\n",
            "|    reward               | -0.0019503741 |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 0.000608      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 195          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00806378   |\n",
            "|    clip_fraction        | 0.106        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.154        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.122       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00633     |\n",
            "|    reward               | 0.0022590705 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.000978     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 204          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 40           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073409    |\n",
            "|    clip_fraction        | 0.0733       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.241        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.134       |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00469     |\n",
            "|    reward               | 0.0005548033 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.000615     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 205           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 49            |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.008670165   |\n",
            "|    clip_fraction        | 0.105         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | 0.362         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.138        |\n",
            "|    n_updates            | 40            |\n",
            "|    policy_gradient_loss | -0.00832      |\n",
            "|    reward               | -0.0020803092 |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 0.00043       |\n",
            "-------------------------------------------\n",
            "======PPO Validation from:  2018-04-04 00:00:00 to  2018-07-03 00:00:00\n",
            "PPO Sharpe Ratio:  0.245513867435113\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_189_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 4           |\n",
            "|    fps             | 65          |\n",
            "|    time_elapsed    | 126         |\n",
            "|    total_timesteps | 8304        |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -183        |\n",
            "|    critic_loss     | 165         |\n",
            "|    learning_rate   | 0.0005      |\n",
            "|    n_updates       | 6228        |\n",
            "|    reward          | 0.006153313 |\n",
            "------------------------------------\n",
            "day: 2075, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 10042.08\n",
            "total_reward: 42.08\n",
            "total_cost: 9.99\n",
            "total_trades: 8300\n",
            "Sharpe: 0.244\n",
            "=================================\n",
            "======DDPG Validation from:  2018-04-04 00:00:00 to  2018-07-03 00:00:00\n",
            "======Best Model Retraining from:  2010-01-01 to  2018-07-03 00:00:00\n",
            "======Trading from:  2018-07-03 00:00:00 to  2018-10-02 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  45.85564342289035\n",
            "======Model training from:  2010-01-01 to  2018-07-03 00:00:00\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_252_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 149          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0526      |\n",
            "|    reward             | 0.0124011235 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 4.22e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 149           |\n",
            "|    iterations         | 200           |\n",
            "|    time_elapsed       | 6             |\n",
            "|    total_timesteps    | 1000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.4         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 199           |\n",
            "|    policy_loss        | 0.105         |\n",
            "|    reward             | -0.0120306285 |\n",
            "|    std                | 1.07          |\n",
            "|    value_loss         | 8.4e-05       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 162           |\n",
            "|    iterations         | 300           |\n",
            "|    time_elapsed       | 9             |\n",
            "|    total_timesteps    | 1500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.6         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 299           |\n",
            "|    policy_loss        | -0.246        |\n",
            "|    reward             | -0.0009005638 |\n",
            "|    std                | 1.09          |\n",
            "|    value_loss         | 0.000596      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 178          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -0.304       |\n",
            "|    reward             | -0.023007575 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 0.000598     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 187          |\n",
            "|    iterations         | 500          |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 2500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 499          |\n",
            "|    policy_loss        | -0.0354      |\n",
            "|    reward             | 0.0024001575 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 1.03e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 193         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 15          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | -0.107      |\n",
            "|    reward             | 0.005815648 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 9.62e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 198          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 17           |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.5        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | -0.106       |\n",
            "|    reward             | -0.004797423 |\n",
            "|    std                | 1.21         |\n",
            "|    value_loss         | 5.77e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 194          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.9        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | -0.00855     |\n",
            "|    reward             | 0.0077542057 |\n",
            "|    std                | 1.27         |\n",
            "|    value_loss         | 9.81e-06     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 189         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -0.0541     |\n",
            "|    reward             | 0.005268597 |\n",
            "|    std                | 1.32        |\n",
            "|    value_loss         | 1.64e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 183          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 27           |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | -0.193       |\n",
            "|    reward             | -0.005136601 |\n",
            "|    std                | 1.38         |\n",
            "|    value_loss         | 0.000123     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 181          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.1        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 0.0997       |\n",
            "|    reward             | 0.0021818418 |\n",
            "|    std                | 1.45         |\n",
            "|    value_loss         | 5.45e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 185           |\n",
            "|    iterations         | 1200          |\n",
            "|    time_elapsed       | 32            |\n",
            "|    total_timesteps    | 6000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -16.6         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1199          |\n",
            "|    policy_loss        | -0.00187      |\n",
            "|    reward             | -0.0002742008 |\n",
            "|    std                | 1.53          |\n",
            "|    value_loss         | 6.7e-06       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 188          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 34           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | -0.167       |\n",
            "|    reward             | -0.008608897 |\n",
            "|    std                | 1.6          |\n",
            "|    value_loss         | 9.23e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 191           |\n",
            "|    iterations         | 1400          |\n",
            "|    time_elapsed       | 36            |\n",
            "|    total_timesteps    | 7000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -17.4         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1399          |\n",
            "|    policy_loss        | -0.0157       |\n",
            "|    reward             | 0.00053891155 |\n",
            "|    std                | 1.68          |\n",
            "|    value_loss         | 5.05e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 195          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 38           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.9        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | 0.156        |\n",
            "|    reward             | 0.0025550807 |\n",
            "|    std                | 1.76         |\n",
            "|    value_loss         | 0.000104     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 197          |\n",
            "|    iterations         | 1600         |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 8000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -18.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1599         |\n",
            "|    policy_loss        | 0.0346       |\n",
            "|    reward             | 0.0020459243 |\n",
            "|    std                | 1.85         |\n",
            "|    value_loss         | 1.47e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 194          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -18.7        |\n",
            "|    explained_variance | -2.38e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | -0.00221     |\n",
            "|    reward             | 0.0017020511 |\n",
            "|    std                | 1.94         |\n",
            "|    value_loss         | 3.32e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 191         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 47          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -19.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 0.0864      |\n",
            "|    reward             | 0.006391683 |\n",
            "|    std                | 2.02        |\n",
            "|    value_loss         | 5.96e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 188         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -19.5       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -0.115      |\n",
            "|    reward             | -0.00861179 |\n",
            "|    std                | 2.12        |\n",
            "|    value_loss         | 4.21e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 187           |\n",
            "|    iterations         | 2000          |\n",
            "|    time_elapsed       | 53            |\n",
            "|    total_timesteps    | 10000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -20           |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1999          |\n",
            "|    policy_loss        | -0.194        |\n",
            "|    reward             | 0.00034222894 |\n",
            "|    std                | 2.24          |\n",
            "|    value_loss         | 0.000126      |\n",
            "-----------------------------------------\n",
            "======A2C Validation from:  2018-07-03 00:00:00 to  2018-10-02 00:00:00\n",
            "A2C Sharpe Ratio:  0.35891195715485485\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_252_1\n",
            "---------------------------------------\n",
            "| time/              |                |\n",
            "|    fps             | 310            |\n",
            "|    iterations      | 1              |\n",
            "|    time_elapsed    | 6              |\n",
            "|    total_timesteps | 2048           |\n",
            "| train/             |                |\n",
            "|    reward          | -4.1405227e-05 |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 245          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004863411  |\n",
            "|    clip_fraction        | 0.0421       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | -1.02        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.121       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00324     |\n",
            "|    reward               | 0.0013701872 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.000423     |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 235            |\n",
            "|    iterations           | 3              |\n",
            "|    time_elapsed         | 26             |\n",
            "|    total_timesteps      | 6144           |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0075274664   |\n",
            "|    clip_fraction        | 0.0705         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -12.8          |\n",
            "|    explained_variance   | 0.112          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | -0.132         |\n",
            "|    n_updates            | 20             |\n",
            "|    policy_gradient_loss | -0.0045        |\n",
            "|    reward               | -4.0876268e-05 |\n",
            "|    std                  | 1.01           |\n",
            "|    value_loss           | 0.000578       |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 236           |\n",
            "|    iterations           | 4             |\n",
            "|    time_elapsed         | 34            |\n",
            "|    total_timesteps      | 8192          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.008388793   |\n",
            "|    clip_fraction        | 0.0843        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | -0.0134       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.135        |\n",
            "|    n_updates            | 30            |\n",
            "|    policy_gradient_loss | -0.00521      |\n",
            "|    reward               | -0.0012589671 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.000429      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 224          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 45           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007103589  |\n",
            "|    clip_fraction        | 0.0916       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.9        |\n",
            "|    explained_variance   | 0.302        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.131       |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.0067      |\n",
            "|    reward               | 0.0058208276 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.000312     |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2018-07-03 00:00:00 to  2018-10-02 00:00:00\n",
            "PPO Sharpe Ratio:  0.12473460903922125\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_252_1\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    episodes        | 4            |\n",
            "|    fps             | 64           |\n",
            "|    time_elapsed    | 131          |\n",
            "|    total_timesteps | 8556         |\n",
            "| train/             |              |\n",
            "|    actor_loss      | -289         |\n",
            "|    critic_loss     | 188          |\n",
            "|    learning_rate   | 0.0005       |\n",
            "|    n_updates       | 6417         |\n",
            "|    reward          | 0.0025421586 |\n",
            "-------------------------------------\n",
            "day: 2138, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 10002.01\n",
            "total_reward: 2.01\n",
            "total_cost: 9.99\n",
            "total_trades: 10690\n",
            "Sharpe: 0.128\n",
            "=================================\n",
            "======DDPG Validation from:  2018-07-03 00:00:00 to  2018-10-02 00:00:00\n",
            "======Best Model Retraining from:  2010-01-01 to  2018-10-02 00:00:00\n",
            "======Trading from:  2018-10-02 00:00:00 to  2019-01-03 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  45.85564342289035\n",
            "======Model training from:  2010-01-01 to  2018-10-02 00:00:00\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_315_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 228         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 2           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -0.153      |\n",
            "|    reward             | -0.00208732 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.000135    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 205         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | 0.221       |\n",
            "|    reward             | 0.013357124 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.000361    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 184           |\n",
            "|    iterations         | 300           |\n",
            "|    time_elapsed       | 8             |\n",
            "|    total_timesteps    | 1500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.3         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 299           |\n",
            "|    policy_loss        | -0.236        |\n",
            "|    reward             | -0.0031970837 |\n",
            "|    std                | 1.07          |\n",
            "|    value_loss         | 0.00034       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 176          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.6        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -0.0776      |\n",
            "|    reward             | -0.015862169 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.000151     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 171          |\n",
            "|    iterations         | 500          |\n",
            "|    time_elapsed       | 14           |\n",
            "|    total_timesteps    | 2500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.8        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 499          |\n",
            "|    policy_loss        | 0.143        |\n",
            "|    reward             | -0.015052922 |\n",
            "|    std                | 1.12         |\n",
            "|    value_loss         | 0.000137     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 176           |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 16            |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.1         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | 0.00238       |\n",
            "|    reward             | -0.0007905667 |\n",
            "|    std                | 1.16          |\n",
            "|    value_loss         | 3.26e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 185           |\n",
            "|    iterations         | 700           |\n",
            "|    time_elapsed       | 18            |\n",
            "|    total_timesteps    | 3500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.4         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 699           |\n",
            "|    policy_loss        | 0.0376        |\n",
            "|    reward             | 0.00055524823 |\n",
            "|    std                | 1.2           |\n",
            "|    value_loss         | 8.33e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 190           |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 21            |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.8         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | 0.182         |\n",
            "|    reward             | -0.0031818948 |\n",
            "|    std                | 1.26          |\n",
            "|    value_loss         | 0.000291      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 195         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -0.0859     |\n",
            "|    reward             | 0.029408546 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 0.000739    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 199           |\n",
            "|    iterations         | 1000          |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 5000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -15.4         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 999           |\n",
            "|    policy_loss        | -0.138        |\n",
            "|    reward             | -0.0075571095 |\n",
            "|    std                | 1.33          |\n",
            "|    value_loss         | 0.000239      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 197           |\n",
            "|    iterations         | 1100          |\n",
            "|    time_elapsed       | 27            |\n",
            "|    total_timesteps    | 5500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -15.5         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1099          |\n",
            "|    policy_loss        | -0.441        |\n",
            "|    reward             | -0.0060302317 |\n",
            "|    std                | 1.36          |\n",
            "|    value_loss         | 0.000821      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 193          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | -0.336       |\n",
            "|    reward             | 0.0017910992 |\n",
            "|    std                | 1.38         |\n",
            "|    value_loss         | 0.000537     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 189          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 34           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.179        |\n",
            "|    reward             | -0.017665219 |\n",
            "|    std                | 1.41         |\n",
            "|    value_loss         | 0.000189     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 185           |\n",
            "|    iterations         | 1400          |\n",
            "|    time_elapsed       | 37            |\n",
            "|    total_timesteps    | 7000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -16           |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1399          |\n",
            "|    policy_loss        | 0.1           |\n",
            "|    reward             | -0.0056131375 |\n",
            "|    std                | 1.43          |\n",
            "|    value_loss         | 4.84e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 186          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | -0.047       |\n",
            "|    reward             | -0.001444906 |\n",
            "|    std                | 1.48         |\n",
            "|    value_loss         | 1.33e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 189         |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 42          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | 0.0615      |\n",
            "|    reward             | 0.000604017 |\n",
            "|    std                | 1.54        |\n",
            "|    value_loss         | 1.68e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 191           |\n",
            "|    iterations         | 1700          |\n",
            "|    time_elapsed       | 44            |\n",
            "|    total_timesteps    | 8500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -17           |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1699          |\n",
            "|    policy_loss        | -0.00896      |\n",
            "|    reward             | -0.0010271522 |\n",
            "|    std                | 1.61          |\n",
            "|    value_loss         | 4.28e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 193           |\n",
            "|    iterations         | 1800          |\n",
            "|    time_elapsed       | 46            |\n",
            "|    total_timesteps    | 9000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -17.5         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1799          |\n",
            "|    policy_loss        | -0.0772       |\n",
            "|    reward             | 0.00082290353 |\n",
            "|    std                | 1.7           |\n",
            "|    value_loss         | 2.21e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 190           |\n",
            "|    iterations         | 1900          |\n",
            "|    time_elapsed       | 49            |\n",
            "|    total_timesteps    | 9500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -18           |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1899          |\n",
            "|    policy_loss        | -0.0199       |\n",
            "|    reward             | 2.3216248e-06 |\n",
            "|    std                | 1.79          |\n",
            "|    value_loss         | 2.85e-06      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 188            |\n",
            "|    iterations         | 2000           |\n",
            "|    time_elapsed       | 53             |\n",
            "|    total_timesteps    | 10000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -18.5          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1999           |\n",
            "|    policy_loss        | 0.0457         |\n",
            "|    reward             | -0.00096430606 |\n",
            "|    std                | 1.89           |\n",
            "|    value_loss         | 6.62e-06       |\n",
            "------------------------------------------\n",
            "======A2C Validation from:  2018-10-02 00:00:00 to  2019-01-03 00:00:00\n",
            "A2C Sharpe Ratio:  -0.2215757309576589\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_315_1\n",
            "--------------------------------------\n",
            "| time/              |               |\n",
            "|    fps             | 217           |\n",
            "|    iterations      | 1             |\n",
            "|    time_elapsed    | 9             |\n",
            "|    total_timesteps | 2048          |\n",
            "| train/             |               |\n",
            "|    reward          | -0.0025463013 |\n",
            "--------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 237           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 17            |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0063387547  |\n",
            "|    clip_fraction        | 0.0542        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | -0.381        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.134        |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | -0.00268      |\n",
            "|    reward               | 0.00015395433 |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 0.000653      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 205           |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 29            |\n",
            "|    total_timesteps      | 6144          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.006472559   |\n",
            "|    clip_fraction        | 0.0613        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | -0.000682     |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.121        |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -0.00443      |\n",
            "|    reward               | -0.0072392183 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.000431      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 217          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006272069  |\n",
            "|    clip_fraction        | 0.0601       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.9        |\n",
            "|    explained_variance   | 2.44e-06     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.134       |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00623     |\n",
            "|    reward               | 0.0019639793 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.000384     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 210          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004598487  |\n",
            "|    clip_fraction        | 0.0275       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.9        |\n",
            "|    explained_variance   | -1.79e-06    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.134       |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00334     |\n",
            "|    reward               | 0.0032076302 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.000401     |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2018-10-02 00:00:00 to  2019-01-03 00:00:00\n",
            "PPO Sharpe Ratio:  -0.15074549343323962\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_315_1\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    episodes        | 4            |\n",
            "|    fps             | 56           |\n",
            "|    time_elapsed    | 154          |\n",
            "|    total_timesteps | 8808         |\n",
            "| train/             |              |\n",
            "|    actor_loss      | 105          |\n",
            "|    critic_loss     | 63           |\n",
            "|    learning_rate   | 0.0005       |\n",
            "|    n_updates       | 6606         |\n",
            "|    reward          | 0.0012286651 |\n",
            "-------------------------------------\n",
            "day: 2201, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 10018.41\n",
            "total_reward: 18.41\n",
            "total_cost: 9.99\n",
            "total_trades: 11005\n",
            "Sharpe: 0.229\n",
            "=================================\n",
            "======DDPG Validation from:  2018-10-02 00:00:00 to  2019-01-03 00:00:00\n",
            "======Best Model Retraining from:  2010-01-01 to  2019-01-03 00:00:00\n",
            "======Trading from:  2019-01-03 00:00:00 to  2019-04-04 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  45.85564342289035\n",
            "======Model training from:  2010-01-01 to  2019-01-03 00:00:00\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_378_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 134         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.1       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -0.0166     |\n",
            "|    reward             | 0.007751382 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 2.24e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 135           |\n",
            "|    iterations         | 200           |\n",
            "|    time_elapsed       | 7             |\n",
            "|    total_timesteps    | 1000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.4         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 199           |\n",
            "|    policy_loss        | -0.0127       |\n",
            "|    reward             | -0.0037286077 |\n",
            "|    std                | 1.07          |\n",
            "|    value_loss         | 0.000111      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 142          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | 0.0582       |\n",
            "|    reward             | -0.014357922 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 0.000291     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 157           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.8         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | 0.195         |\n",
            "|    reward             | -0.0054429583 |\n",
            "|    std                | 1.13          |\n",
            "|    value_loss         | 0.000403      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 166         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 15          |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.144       |\n",
            "|    reward             | 0.011772787 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 0.000125    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 171            |\n",
            "|    iterations         | 600            |\n",
            "|    time_elapsed       | 17             |\n",
            "|    total_timesteps    | 3000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -14.3          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 599            |\n",
            "|    policy_loss        | 0.000588       |\n",
            "|    reward             | -0.00076064334 |\n",
            "|    std                | 1.19           |\n",
            "|    value_loss         | 5.47e-06       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 171           |\n",
            "|    iterations         | 700           |\n",
            "|    time_elapsed       | 20            |\n",
            "|    total_timesteps    | 3500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.7         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 699           |\n",
            "|    policy_loss        | 0.022         |\n",
            "|    reward             | -0.0010971745 |\n",
            "|    std                | 1.23          |\n",
            "|    value_loss         | 7.25e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 166          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 24           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | 0.0777       |\n",
            "|    reward             | 0.0005185547 |\n",
            "|    std                | 1.29         |\n",
            "|    value_loss         | 2.67e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 163         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 0.253       |\n",
            "|    reward             | 0.001013152 |\n",
            "|    std                | 1.36        |\n",
            "|    value_loss         | 0.000343    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 161          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.9        |\n",
            "|    explained_variance | -2.38e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | -0.0807      |\n",
            "|    reward             | 0.0066011413 |\n",
            "|    std                | 1.41         |\n",
            "|    value_loss         | 0.000128     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 165         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -0.127      |\n",
            "|    reward             | 0.013930424 |\n",
            "|    std                | 1.48        |\n",
            "|    value_loss         | 9.94e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 169          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 35           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.7        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | 0.193        |\n",
            "|    reward             | 0.0002882429 |\n",
            "|    std                | 1.54         |\n",
            "|    value_loss         | 0.000144     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 172          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 37           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.0328       |\n",
            "|    reward             | -0.002625855 |\n",
            "|    std                | 1.61         |\n",
            "|    value_loss         | 1.02e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 175          |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 39           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | -0.0847      |\n",
            "|    reward             | -0.002894636 |\n",
            "|    std                | 1.67         |\n",
            "|    value_loss         | 2.67e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 174            |\n",
            "|    iterations         | 1500           |\n",
            "|    time_elapsed       | 42             |\n",
            "|    total_timesteps    | 7500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -17.7          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1499           |\n",
            "|    policy_loss        | -0.142         |\n",
            "|    reward             | -0.00043534016 |\n",
            "|    std                | 1.73           |\n",
            "|    value_loss         | 8.96e-05       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 171         |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 46          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -18.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -0.0894     |\n",
            "|    reward             | 0.013702912 |\n",
            "|    std                | 1.81        |\n",
            "|    value_loss         | 5.7e-05     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 167          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -18.5        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | -0.0827      |\n",
            "|    reward             | -0.008202686 |\n",
            "|    std                | 1.89         |\n",
            "|    value_loss         | 3.05e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 166          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -18.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | -0.125       |\n",
            "|    reward             | -0.002528775 |\n",
            "|    std                | 1.97         |\n",
            "|    value_loss         | 6.75e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 168          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 56           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -19.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -0.261       |\n",
            "|    reward             | -0.008338854 |\n",
            "|    std                | 2.05         |\n",
            "|    value_loss         | 0.000302     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 170           |\n",
            "|    iterations         | 2000          |\n",
            "|    time_elapsed       | 58            |\n",
            "|    total_timesteps    | 10000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -19.6         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1999          |\n",
            "|    policy_loss        | -0.118        |\n",
            "|    reward             | -0.0032988037 |\n",
            "|    std                | 2.14          |\n",
            "|    value_loss         | 4.25e-05      |\n",
            "-----------------------------------------\n",
            "======A2C Validation from:  2019-01-03 00:00:00 to  2019-04-04 00:00:00\n",
            "A2C Sharpe Ratio:  0.5715659230013131\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_378_1\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    fps             | 237          |\n",
            "|    iterations      | 1            |\n",
            "|    time_elapsed    | 8            |\n",
            "|    total_timesteps | 2048         |\n",
            "| train/             |              |\n",
            "|    reward          | 0.0024224704 |\n",
            "-------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 198           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 20            |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.008068154   |\n",
            "|    clip_fraction        | 0.0909        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | -5.69         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.144        |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | -0.00695      |\n",
            "|    reward               | 0.00065460586 |\n",
            "|    std                  | 0.999         |\n",
            "|    value_loss           | 0.00105       |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 197           |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 31            |\n",
            "|    total_timesteps      | 6144          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.008222429   |\n",
            "|    clip_fraction        | 0.147         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | 0.096         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.143        |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -0.00523      |\n",
            "|    reward               | -0.0012305909 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.00142       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 188          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 43           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006495333  |\n",
            "|    clip_fraction        | 0.0878       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.9        |\n",
            "|    explained_variance   | 0.252        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.12        |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00439     |\n",
            "|    reward               | -0.005612042 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.000803     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 181          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 56           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.008029637  |\n",
            "|    clip_fraction        | 0.129        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.9        |\n",
            "|    explained_variance   | 0.223        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.139       |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00662     |\n",
            "|    reward               | 0.0007800919 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.000575     |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2019-01-03 00:00:00 to  2019-04-04 00:00:00\n",
            "PPO Sharpe Ratio:  0.38114179686129124\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_378_1\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    episodes        | 4            |\n",
            "|    fps             | 56           |\n",
            "|    time_elapsed    | 161          |\n",
            "|    total_timesteps | 9060         |\n",
            "| train/             |              |\n",
            "|    actor_loss      | -22.9        |\n",
            "|    critic_loss     | 86.9         |\n",
            "|    learning_rate   | 0.0005       |\n",
            "|    n_updates       | 6795         |\n",
            "|    reward          | -0.008874495 |\n",
            "-------------------------------------\n",
            "day: 2264, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9990.01\n",
            "total_reward: -9.99\n",
            "total_cost: 9.99\n",
            "total_trades: 18112\n",
            "Sharpe: 0.210\n",
            "=================================\n",
            "======DDPG Validation from:  2019-01-03 00:00:00 to  2019-04-04 00:00:00\n",
            "======Best Model Retraining from:  2010-01-01 to  2019-04-04 00:00:00\n",
            "======Trading from:  2019-04-04 00:00:00 to  2019-07-05 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  45.85564342289035\n",
            "======Model training from:  2010-01-01 to  2019-04-04 00:00:00\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_441_1\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 155           |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 3             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.1         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -0.0648       |\n",
            "|    reward             | -0.0045286617 |\n",
            "|    std                | 1.04          |\n",
            "|    value_loss         | 0.000301      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 159          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | -0.495       |\n",
            "|    reward             | 0.0017530884 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 0.00268      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 179         |\n",
            "|    iterations         | 300         |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 1500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 299         |\n",
            "|    policy_loss        | 0.618       |\n",
            "|    reward             | -0.04691237 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.00403     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 189          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -0.223       |\n",
            "|    reward             | -0.031091249 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 0.000688     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 193          |\n",
            "|    iterations         | 500          |\n",
            "|    time_elapsed       | 12           |\n",
            "|    total_timesteps    | 2500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 499          |\n",
            "|    policy_loss        | 0.185        |\n",
            "|    reward             | 0.0022119714 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 0.000241     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 185          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | -0.0721      |\n",
            "|    reward             | 0.0018956772 |\n",
            "|    std                | 1.14         |\n",
            "|    value_loss         | 3.87e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 171          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.2        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | 0.00497      |\n",
            "|    reward             | 0.0026212886 |\n",
            "|    std                | 1.17         |\n",
            "|    value_loss         | 9.81e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 153           |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 26            |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.5         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | 0.0291        |\n",
            "|    reward             | 0.00012985259 |\n",
            "|    std                | 1.22          |\n",
            "|    value_loss         | 1.87e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 158         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 28          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -0.144      |\n",
            "|    reward             | 0.008120957 |\n",
            "|    std                | 1.26        |\n",
            "|    value_loss         | 0.000135    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 163         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 30          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.2       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | 0.0473      |\n",
            "|    reward             | 0.010476936 |\n",
            "|    std                | 1.31        |\n",
            "|    value_loss         | 0.000142    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 166          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 33           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.5        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 0.285        |\n",
            "|    reward             | -0.007060301 |\n",
            "|    std                | 1.35         |\n",
            "|    value_loss         | 0.000524     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 169         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -0.656      |\n",
            "|    reward             | 0.036412526 |\n",
            "|    std                | 1.39        |\n",
            "|    value_loss         | 0.00237     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 162         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 0.471       |\n",
            "|    reward             | 0.057334036 |\n",
            "|    std                | 1.42        |\n",
            "|    value_loss         | 0.00129     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 157          |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | 0.077        |\n",
            "|    reward             | 0.0010966967 |\n",
            "|    std                | 1.45         |\n",
            "|    value_loss         | 2.87e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 151          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 49           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | 0.156        |\n",
            "|    reward             | 0.0018630533 |\n",
            "|    std                | 1.49         |\n",
            "|    value_loss         | 0.000116     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 153          |\n",
            "|    iterations         | 1600         |\n",
            "|    time_elapsed       | 52           |\n",
            "|    total_timesteps    | 8000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1599         |\n",
            "|    policy_loss        | 0.0603       |\n",
            "|    reward             | 0.0016206678 |\n",
            "|    std                | 1.54         |\n",
            "|    value_loss         | 2.36e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 155          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 54           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | -0.293       |\n",
            "|    reward             | 0.0017081364 |\n",
            "|    std                | 1.6          |\n",
            "|    value_loss         | 0.000416     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 157         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | -0.0291     |\n",
            "|    reward             | 0.002163758 |\n",
            "|    std                | 1.68        |\n",
            "|    value_loss         | 4.87e-06    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 157          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 60           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | 0.0685       |\n",
            "|    reward             | 0.0062269596 |\n",
            "|    std                | 1.75         |\n",
            "|    value_loss         | 3e-05        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 155           |\n",
            "|    iterations         | 2000          |\n",
            "|    time_elapsed       | 64            |\n",
            "|    total_timesteps    | 10000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -18.2         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1999          |\n",
            "|    policy_loss        | -0.151        |\n",
            "|    reward             | -0.0020519427 |\n",
            "|    std                | 1.83          |\n",
            "|    value_loss         | 5.62e-05      |\n",
            "-----------------------------------------\n",
            "======A2C Validation from:  2019-04-04 00:00:00 to  2019-07-05 00:00:00\n",
            "A2C Sharpe Ratio:  0.29737689438708254\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_441_1\n",
            "--------------------------------------\n",
            "| time/              |               |\n",
            "|    fps             | 174           |\n",
            "|    iterations      | 1             |\n",
            "|    time_elapsed    | 11            |\n",
            "|    total_timesteps | 2048          |\n",
            "| train/             |               |\n",
            "|    reward          | -0.0010398374 |\n",
            "--------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 164          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.008532802  |\n",
            "|    clip_fraction        | 0.112        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | -4.66        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.142       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00458     |\n",
            "|    reward               | 0.0011268089 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.000947     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 173          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 35           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072268397 |\n",
            "|    clip_fraction        | 0.0755       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | -0.00558     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.139       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.0032      |\n",
            "|    reward               | 0.0025923825 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.0012       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 175         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 46          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010255938 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.0676      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.136      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00716    |\n",
            "|    reward               | 0.007948859 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.000842    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 183           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 55            |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0061304877  |\n",
            "|    clip_fraction        | 0.0491        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.9         |\n",
            "|    explained_variance   | 0.149         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.131        |\n",
            "|    n_updates            | 40            |\n",
            "|    policy_gradient_loss | -0.00391      |\n",
            "|    reward               | -0.0011453264 |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.000623      |\n",
            "-------------------------------------------\n",
            "======PPO Validation from:  2019-04-04 00:00:00 to  2019-07-05 00:00:00\n",
            "PPO Sharpe Ratio:  -0.016631486427048748\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_441_1\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    episodes        | 4            |\n",
            "|    fps             | 58           |\n",
            "|    time_elapsed    | 158          |\n",
            "|    total_timesteps | 9312         |\n",
            "| train/             |              |\n",
            "|    actor_loss      | -1.07e+03    |\n",
            "|    critic_loss     | 985          |\n",
            "|    learning_rate   | 0.0005       |\n",
            "|    n_updates       | 6984         |\n",
            "|    reward          | 0.0018053207 |\n",
            "-------------------------------------\n",
            "day: 2327, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 10034.76\n",
            "total_reward: 34.76\n",
            "total_cost: 9.99\n",
            "total_trades: 9308\n",
            "Sharpe: 0.221\n",
            "=================================\n",
            "======DDPG Validation from:  2019-04-04 00:00:00 to  2019-07-05 00:00:00\n",
            "======Best Model Retraining from:  2010-01-01 to  2019-07-05 00:00:00\n",
            "======Trading from:  2019-07-05 00:00:00 to  2019-10-03 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  45.85564342289035\n",
            "======Model training from:  2010-01-01 to  2019-07-05 00:00:00\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_504_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 226          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0743      |\n",
            "|    reward             | -0.003805439 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.000177     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 225          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 4            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | -0.154       |\n",
            "|    reward             | 0.0030097761 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.000227     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 185          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 8            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.212       |\n",
            "|    reward             | -0.014748502 |\n",
            "|    std                | 1.08         |\n",
            "|    value_loss         | 0.000444     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 159           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.7         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | 0.0856        |\n",
            "|    reward             | 0.00013549585 |\n",
            "|    std                | 1.11          |\n",
            "|    value_loss         | 6.47e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 155         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 16          |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.128       |\n",
            "|    reward             | 0.007690675 |\n",
            "|    std                | 1.14        |\n",
            "|    value_loss         | 0.000137    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 157          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 19           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.2        |\n",
            "|    explained_variance | -0.343       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | 0.0804       |\n",
            "|    reward             | -0.015125867 |\n",
            "|    std                | 1.18         |\n",
            "|    value_loss         | 4.72e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 160         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 21          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 0.091       |\n",
            "|    reward             | 0.009863834 |\n",
            "|    std                | 1.23        |\n",
            "|    value_loss         | 4.5e-05     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 163           |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 24            |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -15           |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | 0.175         |\n",
            "|    reward             | -4.683773e-06 |\n",
            "|    std                | 1.29          |\n",
            "|    value_loss         | 0.00023       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 168          |\n",
            "|    iterations         | 900          |\n",
            "|    time_elapsed       | 26           |\n",
            "|    total_timesteps    | 4500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.5        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 899          |\n",
            "|    policy_loss        | 0.0509       |\n",
            "|    reward             | 0.0052451314 |\n",
            "|    std                | 1.35         |\n",
            "|    value_loss         | 5.58e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 162          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | -0.0241      |\n",
            "|    reward             | -0.004206705 |\n",
            "|    std                | 1.41         |\n",
            "|    value_loss         | 8.66e-06     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 155            |\n",
            "|    iterations         | 1100           |\n",
            "|    time_elapsed       | 35             |\n",
            "|    total_timesteps    | 5500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -16.3          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1099           |\n",
            "|    policy_loss        | 0.154          |\n",
            "|    reward             | -6.7659086e-05 |\n",
            "|    std                | 1.47           |\n",
            "|    value_loss         | 9.92e-05       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 147         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | 0.123       |\n",
            "|    reward             | 0.006132255 |\n",
            "|    std                | 1.54        |\n",
            "|    value_loss         | 6.56e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 151          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.0371       |\n",
            "|    reward             | 0.0030244468 |\n",
            "|    std                | 1.61         |\n",
            "|    value_loss         | 3.14e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 152           |\n",
            "|    iterations         | 1400          |\n",
            "|    time_elapsed       | 45            |\n",
            "|    total_timesteps    | 7000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -17.4         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1399          |\n",
            "|    policy_loss        | 0.349         |\n",
            "|    reward             | -0.0137504395 |\n",
            "|    std                | 1.68          |\n",
            "|    value_loss         | 0.000431      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 155          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 48           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | 0.0468       |\n",
            "|    reward             | 0.0015643345 |\n",
            "|    std                | 1.74         |\n",
            "|    value_loss         | 3.45e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 157         |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -18.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | 0.0371      |\n",
            "|    reward             | 0.009512122 |\n",
            "|    std                | 1.82        |\n",
            "|    value_loss         | 1.18e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 157         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 54          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -18.6       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | -0.0416     |\n",
            "|    reward             | 0.003505334 |\n",
            "|    std                | 1.91        |\n",
            "|    value_loss         | 1.2e-05     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 155          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 57           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -19          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | 0.00804      |\n",
            "|    reward             | 6.344414e-05 |\n",
            "|    std                | 2.01         |\n",
            "|    value_loss         | 7.86e-07     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 151            |\n",
            "|    iterations         | 1900           |\n",
            "|    time_elapsed       | 62             |\n",
            "|    total_timesteps    | 9500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -19.5          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1899           |\n",
            "|    policy_loss        | -0.0192        |\n",
            "|    reward             | -0.00028733083 |\n",
            "|    std                | 2.12           |\n",
            "|    value_loss         | 1.66e-05       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 152         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 65          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -20         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -0.0976     |\n",
            "|    reward             | 0.009699472 |\n",
            "|    std                | 2.23        |\n",
            "|    value_loss         | 6.76e-05    |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2019-07-05 00:00:00 to  2019-10-03 00:00:00\n",
            "A2C Sharpe Ratio:  -0.13022384487863603\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_504_1\n",
            "--------------------------------------\n",
            "| time/              |               |\n",
            "|    fps             | 193           |\n",
            "|    iterations      | 1             |\n",
            "|    time_elapsed    | 10            |\n",
            "|    total_timesteps | 2048          |\n",
            "| train/             |               |\n",
            "|    reward          | -0.0029742464 |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 169         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010381996 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | -12.3       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.12       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00875    |\n",
            "|    reward               | -0.00454359 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 0.0033      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 184           |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 33            |\n",
            "|    total_timesteps      | 6144          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.007367851   |\n",
            "|    clip_fraction        | 0.103         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | -0.00289      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.142        |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -0.00535      |\n",
            "|    reward               | -0.0014983271 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.00377       |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 180            |\n",
            "|    iterations           | 4              |\n",
            "|    time_elapsed         | 45             |\n",
            "|    total_timesteps      | 8192           |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.01035        |\n",
            "|    clip_fraction        | 0.123          |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -12.9          |\n",
            "|    explained_variance   | 0.027          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | -0.121         |\n",
            "|    n_updates            | 30             |\n",
            "|    policy_gradient_loss | -0.00378       |\n",
            "|    reward               | -0.00011241211 |\n",
            "|    std                  | 1.02           |\n",
            "|    value_loss           | 0.00312        |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 189           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 53            |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.007445692   |\n",
            "|    clip_fraction        | 0.0891        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.9         |\n",
            "|    explained_variance   | 0.0301        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.138        |\n",
            "|    n_updates            | 40            |\n",
            "|    policy_gradient_loss | -0.00354      |\n",
            "|    reward               | 0.00043317061 |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.00189       |\n",
            "-------------------------------------------\n",
            "======PPO Validation from:  2019-07-05 00:00:00 to  2019-10-03 00:00:00\n",
            "PPO Sharpe Ratio:  -0.0320587005891374\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_504_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 4           |\n",
            "|    fps             | 64          |\n",
            "|    time_elapsed    | 148         |\n",
            "|    total_timesteps | 9564        |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -1.51e+03   |\n",
            "|    critic_loss     | 1.6e+03     |\n",
            "|    learning_rate   | 0.0005      |\n",
            "|    n_updates       | 7173        |\n",
            "|    reward          | 0.007944641 |\n",
            "------------------------------------\n",
            "day: 2390, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9990.01\n",
            "total_reward: -9.99\n",
            "total_cost: 9.99\n",
            "total_trades: 11950\n",
            "Sharpe: 0.228\n",
            "=================================\n",
            "======DDPG Validation from:  2019-07-05 00:00:00 to  2019-10-03 00:00:00\n",
            "======Best Model Retraining from:  2010-01-01 to  2019-10-03 00:00:00\n",
            "======Trading from:  2019-10-03 00:00:00 to  2020-01-03 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  45.85564342289035\n",
            "======Model training from:  2010-01-01 to  2019-10-03 00:00:00\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_567_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 190          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.1         |\n",
            "|    reward             | -0.003316354 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 6.94e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 203          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 4            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | -0.154       |\n",
            "|    reward             | 0.0010401832 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 0.000275     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 208          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.336       |\n",
            "|    reward             | -0.016063677 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 0.000648     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 208            |\n",
            "|    iterations         | 400            |\n",
            "|    time_elapsed       | 9              |\n",
            "|    total_timesteps    | 2000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -13.8          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 399            |\n",
            "|    policy_loss        | 0.249          |\n",
            "|    reward             | 0.000104274746 |\n",
            "|    std                | 1.13           |\n",
            "|    value_loss         | 0.000346       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 204          |\n",
            "|    iterations         | 500          |\n",
            "|    time_elapsed       | 12           |\n",
            "|    total_timesteps    | 2500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 499          |\n",
            "|    policy_loss        | 0.0488       |\n",
            "|    reward             | 0.0030991416 |\n",
            "|    std                | 1.14         |\n",
            "|    value_loss         | 2.56e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 179          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | 0.0418       |\n",
            "|    reward             | 0.0011901851 |\n",
            "|    std                | 1.17         |\n",
            "|    value_loss         | 1.32e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 171           |\n",
            "|    iterations         | 700           |\n",
            "|    time_elapsed       | 20            |\n",
            "|    total_timesteps    | 3500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14.5         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 699           |\n",
            "|    policy_loss        | 0.159         |\n",
            "|    reward             | -0.0034566536 |\n",
            "|    std                | 1.21          |\n",
            "|    value_loss         | 0.000123      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 169         |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -14.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | 0.153       |\n",
            "|    reward             | 0.006305925 |\n",
            "|    std                | 1.27        |\n",
            "|    value_loss         | 0.000149    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 172           |\n",
            "|    iterations         | 900           |\n",
            "|    time_elapsed       | 26            |\n",
            "|    total_timesteps    | 4500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -15.3         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 899           |\n",
            "|    policy_loss        | 0.158         |\n",
            "|    reward             | -0.0077598966 |\n",
            "|    std                | 1.32          |\n",
            "|    value_loss         | 0.000192      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 176          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 28           |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | 0.0978       |\n",
            "|    reward             | 0.0034666483 |\n",
            "|    std                | 1.38         |\n",
            "|    value_loss         | 4.18e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 179          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 0.0237       |\n",
            "|    reward             | -0.003176509 |\n",
            "|    std                | 1.44         |\n",
            "|    value_loss         | 4.78e-06     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 181         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 32          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -0.0176     |\n",
            "|    reward             | 0.008338401 |\n",
            "|    std                | 1.52        |\n",
            "|    value_loss         | 1e-05       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 179          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 36           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17          |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | -0.0279      |\n",
            "|    reward             | 0.0028131688 |\n",
            "|    std                | 1.59         |\n",
            "|    value_loss         | 9.13e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 176          |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 39           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | -0.302       |\n",
            "|    reward             | 0.0130797215 |\n",
            "|    std                | 1.68         |\n",
            "|    value_loss         | 0.000353     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 173          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | -0.0488      |\n",
            "|    reward             | 0.0013664933 |\n",
            "|    std                | 1.75         |\n",
            "|    value_loss         | 8.88e-06     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 172            |\n",
            "|    iterations         | 1600           |\n",
            "|    time_elapsed       | 46             |\n",
            "|    total_timesteps    | 8000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -18.2          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1599           |\n",
            "|    policy_loss        | -0.0881        |\n",
            "|    reward             | -0.00029557195 |\n",
            "|    std                | 1.83           |\n",
            "|    value_loss         | 3.11e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 174           |\n",
            "|    iterations         | 1700          |\n",
            "|    time_elapsed       | 48            |\n",
            "|    total_timesteps    | 8500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -18.7         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1699          |\n",
            "|    policy_loss        | 0.0776        |\n",
            "|    reward             | 0.00051478506 |\n",
            "|    std                | 1.93          |\n",
            "|    value_loss         | 2.44e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 176          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -19.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | -0.0873      |\n",
            "|    reward             | 0.0067680227 |\n",
            "|    std                | 2.04         |\n",
            "|    value_loss         | 6.47e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 178         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 53          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -19.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 0.0599      |\n",
            "|    reward             | 0.004598336 |\n",
            "|    std                | 2.15        |\n",
            "|    value_loss         | 1.7e-05     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 180           |\n",
            "|    iterations         | 2000          |\n",
            "|    time_elapsed       | 55            |\n",
            "|    total_timesteps    | 10000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -20.1         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1999          |\n",
            "|    policy_loss        | 0.0454        |\n",
            "|    reward             | -0.0016643344 |\n",
            "|    std                | 2.25          |\n",
            "|    value_loss         | 7.96e-06      |\n",
            "-----------------------------------------\n",
            "======A2C Validation from:  2019-10-03 00:00:00 to  2020-01-03 00:00:00\n",
            "A2C Sharpe Ratio:  0.06504802096993528\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_567_1\n",
            "--------------------------------------\n",
            "| time/              |               |\n",
            "|    fps             | 174           |\n",
            "|    iterations      | 1             |\n",
            "|    time_elapsed    | 11            |\n",
            "|    total_timesteps | 2048          |\n",
            "| train/             |               |\n",
            "|    reward          | 0.00039223328 |\n",
            "--------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 204           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 20            |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00543425    |\n",
            "|    clip_fraction        | 0.0549        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | -0.0377       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.146        |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | -0.00554      |\n",
            "|    reward               | 0.00092537963 |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 0.000587      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 196          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048756627 |\n",
            "|    clip_fraction        | 0.0522       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.134       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00551     |\n",
            "|    reward               | -0.003058596 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.000398     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 195           |\n",
            "|    iterations           | 4             |\n",
            "|    time_elapsed         | 41            |\n",
            "|    total_timesteps      | 8192          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0052086404  |\n",
            "|    clip_fraction        | 0.048         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.135        |\n",
            "|    n_updates            | 30            |\n",
            "|    policy_gradient_loss | -0.00404      |\n",
            "|    reward               | 0.00024282532 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.000388      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 193          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 52           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071650557 |\n",
            "|    clip_fraction        | 0.0887       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.9        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.141       |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.0073      |\n",
            "|    reward               | -0.004592101 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.000342     |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2019-10-03 00:00:00 to  2020-01-03 00:00:00\n",
            "PPO Sharpe Ratio:  -0.09190662796226512\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_567_1\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    episodes        | 4            |\n",
            "|    fps             | 66           |\n",
            "|    time_elapsed    | 147          |\n",
            "|    total_timesteps | 9816         |\n",
            "| train/             |              |\n",
            "|    actor_loss      | 35.8         |\n",
            "|    critic_loss     | 118          |\n",
            "|    learning_rate   | 0.0005       |\n",
            "|    n_updates       | 7362         |\n",
            "|    reward          | -0.022578577 |\n",
            "-------------------------------------\n",
            "day: 2453, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 10078.67\n",
            "total_reward: 78.67\n",
            "total_cost: 9.99\n",
            "total_trades: 9812\n",
            "Sharpe: 0.255\n",
            "=================================\n",
            "======DDPG Validation from:  2019-10-03 00:00:00 to  2020-01-03 00:00:00\n",
            "======Best Model Retraining from:  2010-01-01 to  2020-01-03 00:00:00\n",
            "======Trading from:  2020-01-03 00:00:00 to  2020-04-03 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  45.85564342289035\n",
            "======Model training from:  2010-01-01 to  2020-01-03 00:00:00\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_630_1\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 157            |\n",
            "|    iterations         | 100            |\n",
            "|    time_elapsed       | 3              |\n",
            "|    total_timesteps    | 500            |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -13            |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 99             |\n",
            "|    policy_loss        | -0.172         |\n",
            "|    reward             | -0.00022303581 |\n",
            "|    std                | 1.02           |\n",
            "|    value_loss         | 0.000218       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 119          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 8            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | -0.556       |\n",
            "|    reward             | 0.0022596694 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.00217      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 97           |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 15           |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.4        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | 0.333        |\n",
            "|    reward             | -0.026791103 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 0.00176      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 109          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 18           |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.5        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | 0.117        |\n",
            "|    reward             | -0.041500743 |\n",
            "|    std                | 1.08         |\n",
            "|    value_loss         | 0.00203      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 121          |\n",
            "|    iterations         | 500          |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 2500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 499          |\n",
            "|    policy_loss        | -0.172       |\n",
            "|    reward             | -0.011632565 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.000534     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 131           |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 22            |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.7         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | -0.0971       |\n",
            "|    reward             | 5.2188767e-05 |\n",
            "|    std                | 1.11          |\n",
            "|    value_loss         | 6.13e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 140          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 24           |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14          |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | -0.105       |\n",
            "|    reward             | 0.0017641353 |\n",
            "|    std                | 1.15         |\n",
            "|    value_loss         | 5.97e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 144            |\n",
            "|    iterations         | 800            |\n",
            "|    time_elapsed       | 27             |\n",
            "|    total_timesteps    | 4000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -14.3          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 799            |\n",
            "|    policy_loss        | -0.35          |\n",
            "|    reward             | -0.00040716477 |\n",
            "|    std                | 1.19           |\n",
            "|    value_loss         | 0.00057        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 132            |\n",
            "|    iterations         | 900            |\n",
            "|    time_elapsed       | 33             |\n",
            "|    total_timesteps    | 4500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -14.7          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 899            |\n",
            "|    policy_loss        | -0.107         |\n",
            "|    reward             | -0.00024697513 |\n",
            "|    std                | 1.24           |\n",
            "|    value_loss         | 7e-05          |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 129         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -0.162      |\n",
            "|    reward             | 0.014180076 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 0.000283    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 134         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 41          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -15.4       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -0.0762     |\n",
            "|    reward             | 0.004719641 |\n",
            "|    std                | 1.34        |\n",
            "|    value_loss         | 0.000191    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 138          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | 0.0575       |\n",
            "|    reward             | 0.0036632442 |\n",
            "|    std                | 1.39         |\n",
            "|    value_loss         | 1.63e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 142          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 45           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.379        |\n",
            "|    reward             | -0.011465835 |\n",
            "|    std                | 1.45         |\n",
            "|    value_loss         | 0.000591     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 146           |\n",
            "|    iterations         | 1400          |\n",
            "|    time_elapsed       | 47            |\n",
            "|    total_timesteps    | 7000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -16.3         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1399          |\n",
            "|    policy_loss        | 0.16          |\n",
            "|    reward             | 0.00024418326 |\n",
            "|    std                | 1.49          |\n",
            "|    value_loss         | 0.000166      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 146         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 0.384       |\n",
            "|    reward             | 0.014520857 |\n",
            "|    std                | 1.52        |\n",
            "|    value_loss         | 0.000669    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 143           |\n",
            "|    iterations         | 1600          |\n",
            "|    time_elapsed       | 55            |\n",
            "|    total_timesteps    | 8000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -16.8         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1599          |\n",
            "|    policy_loss        | 0.156         |\n",
            "|    reward             | -0.0006175537 |\n",
            "|    std                | 1.57          |\n",
            "|    value_loss         | 0.000106      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 143         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 59          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | -0.0721     |\n",
            "|    reward             | 0.009339843 |\n",
            "|    std                | 1.63        |\n",
            "|    value_loss         | 2.24e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 145           |\n",
            "|    iterations         | 1800          |\n",
            "|    time_elapsed       | 62            |\n",
            "|    total_timesteps    | 9000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -17.6         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1799          |\n",
            "|    policy_loss        | -0.134        |\n",
            "|    reward             | -0.0018614868 |\n",
            "|    std                | 1.71          |\n",
            "|    value_loss         | 8.2e-05       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 147          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 64           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -18          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -0.0187      |\n",
            "|    reward             | 0.0024023438 |\n",
            "|    std                | 1.79         |\n",
            "|    value_loss         | 2.09e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 148          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 67           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -18.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | -0.0263      |\n",
            "|    reward             | -0.001768074 |\n",
            "|    std                | 1.87         |\n",
            "|    value_loss         | 4.74e-06     |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2020-01-03 00:00:00 to  2020-04-03 00:00:00\n",
            "A2C Sharpe Ratio:  -0.2379678597438892\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_630_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 168         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 12          |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | 0.001518835 |\n",
            "------------------------------------\n",
            "day: 2516, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 2009.21\n",
            "total_reward: -7990.79\n",
            "total_cost: 5002.82\n",
            "total_trades: 14498\n",
            "Sharpe: -0.369\n",
            "=================================\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 188            |\n",
            "|    iterations           | 2              |\n",
            "|    time_elapsed         | 21             |\n",
            "|    total_timesteps      | 4096           |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.008358267    |\n",
            "|    clip_fraction        | 0.122          |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -12.8          |\n",
            "|    explained_variance   | -6.19          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | -0.136         |\n",
            "|    n_updates            | 10             |\n",
            "|    policy_gradient_loss | -0.0063        |\n",
            "|    reward               | -7.1710434e-05 |\n",
            "|    std                  | 1              |\n",
            "|    value_loss           | 0.00204        |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 190          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007900822  |\n",
            "|    clip_fraction        | 0.0779       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | -3.09        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.151       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00753     |\n",
            "|    reward               | 0.0014932235 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.00179      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 190          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071232948 |\n",
            "|    clip_fraction        | 0.0944       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | -0.095       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.131       |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00459     |\n",
            "|    reward               | 6.361434e-05 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.00123      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 194          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 52           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.008116251  |\n",
            "|    clip_fraction        | 0.11         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.9        |\n",
            "|    explained_variance   | 0.0343       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.12        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00642     |\n",
            "|    reward               | 0.0021816771 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.000924     |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2020-01-03 00:00:00 to  2020-04-03 00:00:00\n",
            "PPO Sharpe Ratio:  -0.3081525280332546\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_630_1\n",
            "day: 2516, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 38625.60\n",
            "total_reward: 28625.60\n",
            "total_cost: 501.64\n",
            "total_trades: 12813\n",
            "Sharpe: 1.098\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    episodes        | 4            |\n",
            "|    fps             | 61           |\n",
            "|    time_elapsed    | 163          |\n",
            "|    total_timesteps | 10068        |\n",
            "| train/             |              |\n",
            "|    actor_loss      | -47.6        |\n",
            "|    critic_loss     | 89.8         |\n",
            "|    learning_rate   | 0.0005       |\n",
            "|    n_updates       | 7551         |\n",
            "|    reward          | -0.006588902 |\n",
            "-------------------------------------\n",
            "======DDPG Validation from:  2020-01-03 00:00:00 to  2020-04-03 00:00:00\n",
            "======Best Model Retraining from:  2010-01-01 to  2020-04-03 00:00:00\n",
            "======Trading from:  2020-04-03 00:00:00 to  2020-07-06 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  45.85564342289035\n",
            "======Model training from:  2010-01-01 to  2020-04-03 00:00:00\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_693_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 161          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.529       |\n",
            "|    reward             | -0.008258037 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.00139      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 174           |\n",
            "|    iterations         | 200           |\n",
            "|    time_elapsed       | 5             |\n",
            "|    total_timesteps    | 1000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -13.3         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 199           |\n",
            "|    policy_loss        | 0.101         |\n",
            "|    reward             | -0.0037927616 |\n",
            "|    std                | 1.06          |\n",
            "|    value_loss         | 0.00017       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 187         |\n",
            "|    iterations         | 300         |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 1500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.5       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 299         |\n",
            "|    policy_loss        | -0.411      |\n",
            "|    reward             | -0.04574558 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.00174     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 176          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -0.548       |\n",
            "|    reward             | -0.033608392 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 0.00138      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 165          |\n",
            "|    iterations         | 500          |\n",
            "|    time_elapsed       | 15           |\n",
            "|    total_timesteps    | 2500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 499          |\n",
            "|    policy_loss        | -0.0687      |\n",
            "|    reward             | -0.008951901 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 0.000179     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 159           |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 18            |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -14           |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | 0.00488       |\n",
            "|    reward             | -0.0055970596 |\n",
            "|    std                | 1.15          |\n",
            "|    value_loss         | 2.71e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 155          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 22           |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.3        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | 0.0942       |\n",
            "|    reward             | 0.0024772808 |\n",
            "|    std                | 1.18         |\n",
            "|    value_loss         | 5.94e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 155          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 25           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -14.6        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | -0.00126     |\n",
            "|    reward             | -0.007867355 |\n",
            "|    std                | 1.23         |\n",
            "|    value_loss         | 2.19e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 160           |\n",
            "|    iterations         | 900           |\n",
            "|    time_elapsed       | 27            |\n",
            "|    total_timesteps    | 4500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -15           |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 899           |\n",
            "|    policy_loss        | -0.152        |\n",
            "|    reward             | -0.0011724918 |\n",
            "|    std                | 1.28          |\n",
            "|    value_loss         | 0.000123      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 165          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | 0.0899       |\n",
            "|    reward             | 0.0030730204 |\n",
            "|    std                | 1.34         |\n",
            "|    value_loss         | 3.95e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 166          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 33           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -15.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 0.0294       |\n",
            "|    reward             | 0.0057627195 |\n",
            "|    std                | 1.39         |\n",
            "|    value_loss         | 5.62e-06     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 155         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -16.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | 0.103       |\n",
            "|    reward             | 0.008872021 |\n",
            "|    std                | 1.45        |\n",
            "|    value_loss         | 5.48e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 150          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.5        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.126        |\n",
            "|    reward             | 0.0044240444 |\n",
            "|    std                | 1.52         |\n",
            "|    value_loss         | 6.12e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 148          |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 47           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -16.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | -0.0163      |\n",
            "|    reward             | -0.002762654 |\n",
            "|    std                | 1.58         |\n",
            "|    value_loss         | 1.22e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 151         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 49          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -17.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | -0.134      |\n",
            "|    reward             | 0.005938308 |\n",
            "|    std                | 1.64        |\n",
            "|    value_loss         | 6.89e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 153           |\n",
            "|    iterations         | 1600          |\n",
            "|    time_elapsed       | 52            |\n",
            "|    total_timesteps    | 8000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -17.5         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1599          |\n",
            "|    policy_loss        | -0.044        |\n",
            "|    reward             | -0.0025276046 |\n",
            "|    std                | 1.69          |\n",
            "|    value_loss         | 8.79e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 152          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 55           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -17.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | 0.394        |\n",
            "|    reward             | 6.978103e-05 |\n",
            "|    std                | 1.74         |\n",
            "|    value_loss         | 0.000505     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 152          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -18          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | 0.753        |\n",
            "|    reward             | 0.0059205475 |\n",
            "|    std                | 1.8          |\n",
            "|    value_loss         | 0.00236      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 144         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 65          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -18.2       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 0.226       |\n",
            "|    reward             | 0.022635434 |\n",
            "|    std                | 1.84        |\n",
            "|    value_loss         | 0.000269    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 144         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 69          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -18.4       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -1.18       |\n",
            "|    reward             | 0.034164567 |\n",
            "|    std                | 1.88        |\n",
            "|    value_loss         | 0.00494     |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2020-04-03 00:00:00 to  2020-07-06 00:00:00\n",
            "A2C Sharpe Ratio:  0.09004492875628257\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_693_1\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    fps             | 251          |\n",
            "|    iterations      | 1            |\n",
            "|    time_elapsed    | 8            |\n",
            "|    total_timesteps | 2048         |\n",
            "| train/             |              |\n",
            "|    reward          | 0.0016054182 |\n",
            "-------------------------------------\n",
            "day: 2579, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 1119.17\n",
            "total_reward: -8880.83\n",
            "total_cost: 6224.58\n",
            "total_trades: 15078\n",
            "Sharpe: -0.523\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 197          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042942185 |\n",
            "|    clip_fraction        | 0.0455       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.259        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.127       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00351     |\n",
            "|    reward               | 0.001111149  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.000275     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 201           |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 30            |\n",
            "|    total_timesteps      | 6144          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0056485077  |\n",
            "|    clip_fraction        | 0.0555        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | 0.38          |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.11         |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -0.00414      |\n",
            "|    reward               | -0.0008920824 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.000293      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 191          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051466054 |\n",
            "|    clip_fraction        | 0.045        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.625        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.127       |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00357     |\n",
            "|    reward               | 0.0057585025 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.000175     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 194           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 52            |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.006209527   |\n",
            "|    clip_fraction        | 0.0828        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | 0.648         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.12         |\n",
            "|    n_updates            | 40            |\n",
            "|    policy_gradient_loss | -0.00643      |\n",
            "|    reward               | -0.0021203065 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.000146      |\n",
            "-------------------------------------------\n",
            "======PPO Validation from:  2020-04-03 00:00:00 to  2020-07-06 00:00:00\n",
            "PPO Sharpe Ratio:  0.1743830387079543\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_693_1\n",
            "day: 2579, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9994.30\n",
            "total_reward: -5.70\n",
            "total_cost: 9.99\n",
            "total_trades: 12894\n",
            "Sharpe: 0.193\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 4           |\n",
            "|    fps             | 59          |\n",
            "|    time_elapsed    | 173         |\n",
            "|    total_timesteps | 10320       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | 48.9        |\n",
            "|    critic_loss     | 108         |\n",
            "|    learning_rate   | 0.0005      |\n",
            "|    n_updates       | 7740        |\n",
            "|    reward          | 0.022724614 |\n",
            "------------------------------------\n",
            "======DDPG Validation from:  2020-04-03 00:00:00 to  2020-07-06 00:00:00\n",
            "======Best Model Retraining from:  2010-01-01 to  2020-07-06 00:00:00\n",
            "======Trading from:  2020-07-06 00:00:00 to  2020-10-02 00:00:00\n",
            "Ensemble Strategy took:  56.49162572622299  minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Op7jyI7lm4hm",
        "outputId": "d8356c0f-673d-4ab1-879e-972e5bf32871"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Iter  Val Start    Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
              "0  126 2018-01-02 2018-04-04       DDPG  -0.344844  -0.285821   -0.200955\n",
              "1  189 2018-04-04 2018-07-03        A2C   0.333763   0.245514    0.150688\n",
              "2  252 2018-07-03 2018-10-02        A2C   0.358912   0.124735    0.261753\n",
              "3  315 2018-10-02 2019-01-03        PPO  -0.221576  -0.150745   -0.225136\n",
              "4  378 2019-01-03 2019-04-04       DDPG   0.571566   0.381142    0.873514\n",
              "5  441 2019-04-04 2019-07-05        A2C   0.297377  -0.016631    0.195488\n",
              "6  504 2019-07-05 2019-10-03        PPO  -0.130224  -0.032059   -0.071943\n",
              "7  567 2019-10-03 2020-01-03       DDPG   0.065048  -0.091907    0.247086\n",
              "8  630 2020-01-03 2020-04-03       DDPG  -0.237968  -0.308153   -0.020193\n",
              "9  693 2020-04-03 2020-07-06       DDPG   0.090045   0.174383    0.336998"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd957613-5023-4aa8-9523-d3984c39c15f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126</td>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>2018-04-04</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.344844</td>\n",
              "      <td>-0.285821</td>\n",
              "      <td>-0.200955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>189</td>\n",
              "      <td>2018-04-04</td>\n",
              "      <td>2018-07-03</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.333763</td>\n",
              "      <td>0.245514</td>\n",
              "      <td>0.150688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>252</td>\n",
              "      <td>2018-07-03</td>\n",
              "      <td>2018-10-02</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.358912</td>\n",
              "      <td>0.124735</td>\n",
              "      <td>0.261753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>315</td>\n",
              "      <td>2018-10-02</td>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>PPO</td>\n",
              "      <td>-0.221576</td>\n",
              "      <td>-0.150745</td>\n",
              "      <td>-0.225136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>378</td>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>2019-04-04</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.571566</td>\n",
              "      <td>0.381142</td>\n",
              "      <td>0.873514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>441</td>\n",
              "      <td>2019-04-04</td>\n",
              "      <td>2019-07-05</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.297377</td>\n",
              "      <td>-0.016631</td>\n",
              "      <td>0.195488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>504</td>\n",
              "      <td>2019-07-05</td>\n",
              "      <td>2019-10-03</td>\n",
              "      <td>PPO</td>\n",
              "      <td>-0.130224</td>\n",
              "      <td>-0.032059</td>\n",
              "      <td>-0.071943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>567</td>\n",
              "      <td>2019-10-03</td>\n",
              "      <td>2020-01-03</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.065048</td>\n",
              "      <td>-0.091907</td>\n",
              "      <td>0.247086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>630</td>\n",
              "      <td>2020-01-03</td>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.237968</td>\n",
              "      <td>-0.308153</td>\n",
              "      <td>-0.020193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>693</td>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>2020-07-06</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.090045</td>\n",
              "      <td>0.174383</td>\n",
              "      <td>0.336998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd957613-5023-4aa8-9523-d3984c39c15f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd957613-5023-4aa8-9523-d3984c39c15f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd957613-5023-4aa8-9523-d3984c39c15f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 7: Analyze Results"
      ],
      "metadata": {
        "id": "JQNioH9UxmEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the datest to which the testing predictions. \n",
        "test_dates = df_processed[(df_processed.date > TEST_START_DATE)&(df_processed.date <= TEST_END_DATE)].date.unique()\n",
        "\n",
        "trade_date_df = pd.DataFrame({'datadate':test_dates}) # Convert the dates to a dataframe"
      ],
      "metadata": {
        "id": "LQ2EPqa7zphL"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_list = []\n",
        "# for every cycle (rebalance_window + validation_window) read the csv files into a dataframe\n",
        "for i in range(rebalance_window+validation_window, len(test_dates)+1,rebalance_window):\n",
        "     result_df = pd.read_csv(f'results/account_value_trade_ensemble_{i}.csv')\n",
        "     results_list.append(result_df)\n",
        "\n",
        "df_ensemble_results  = pd.concat(results_list, ignore_index=True)  # Create a dataframe to store execution results"
      ],
      "metadata": {
        "id": "yY1iZr1-zq8O"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 7.1: Calcualte Sharpe ratio"
      ],
      "metadata": {
        "id": "1bi0NhRExrSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Sharpe ratio\n",
        "sharpe=(252**0.5)*df_ensemble_results.account_value.pct_change(1).mean()/df_ensemble_results.account_value.pct_change(1).std()\n",
        "\n",
        "print('Sharpe Ratio: ',sharpe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcGN6S1PzjpU",
        "outputId": "20f8a9a8-941c-472a-8ab0-18449a668319"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpe Ratio:  0.8546688049088031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_validation_dates = trade_date_df[validation_window:].reset_index(drop=True) # Get the stock market dates from historical data\n",
        "df_ensemble_results = df_ensemble_results.join(df_validation_dates) # Mask the results with the dates."
      ],
      "metadata": {
        "id": "bhQeQ969zvRa"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "df_ensemble_results.account_value.plot()     # plot the chance in the amount value with time during test period."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "4RYlDJUDm4an",
        "outputId": "97f6cffc-d76a-48ad-8f5c-974d112cd8c6"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 7.2: Backtest results"
      ],
      "metadata": {
        "id": "-zsjiQs0xuA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stats = backtest_stats(account_value=df_ensemble_results)\n",
        "stats_df = pd.DataFrame(stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOtqFrge0PaS",
        "outputId": "57b6fa4d-2ed6-4814-f533-cffec36c254a"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annual return          0.142964\n",
            "Cumulative returns     0.396630\n",
            "Annual volatility      0.174452\n",
            "Sharpe ratio           0.854669\n",
            "Calmar ratio           1.236743\n",
            "Stability              0.849327\n",
            "Max drawdown          -0.115597\n",
            "Omega ratio            1.169602\n",
            "Sortino ratio          1.200887\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.890179\n",
            "Daily value at risk   -0.021387\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 7.3: Baseline Statistics"
      ],
      "metadata": {
        "id": "XyXuFqoXxvYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_index = df.loc[df['tic'] == 'SPY'].sort_values(['date'])"
      ],
      "metadata": {
        "id": "-6-aJj-K0yd1"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (df_index['date'] > df_ensemble_results.loc[0,'date']) & (df_index['date'] <= df_ensemble_results.loc[len(df_ensemble_results)-1,'date'])\n",
        "df_index_masked = df_index.loc[mask].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "HpvUESpJ07ch"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_stats = backtest_stats(df_index_masked, value_col_name = 'close')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyycLaDO09Kz",
        "outputId": "22fb121e-095b-4ab7-ff8d-f6f3a60f1460"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annual return          0.121354\n",
            "Cumulative returns     0.330942\n",
            "Annual volatility      0.236552\n",
            "Sharpe ratio           0.604095\n",
            "Calmar ratio           0.359916\n",
            "Stability              0.554521\n",
            "Max drawdown          -0.337173\n",
            "Omega ratio            1.137069\n",
            "Sortino ratio          0.825409\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.702057\n",
            "Daily value at risk   -0.029236\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 7.4: Compare with Index"
      ],
      "metadata": {
        "id": "0JlN8dyDxwvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale index stocks with begining as 10000\n",
        "\n",
        "df_index_scaled = pd.DataFrame()\n",
        "\n",
        "df_index_scaled[\"date\"] = df_ensemble_results[\"date\"]\n",
        "\n",
        "df_index_scaled[\"spy\"] = df_index_masked['close'] / df_index_masked.iloc[0]['close'] * 10000\n"
      ],
      "metadata": {
        "id": "TtxmLvb44SfI"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_index_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "DCRq62Rq9wBC",
        "outputId": "9f66278a-ee2e-4d31-d157-7aa7a778eb1b"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           date           spy\n",
              "0    2018-04-04  10000.000000\n",
              "1    2018-04-05   9777.141321\n",
              "2    2018-04-06   9825.327421\n",
              "3    2018-04-09   9981.552869\n",
              "4    2018-04-10   9929.227721\n",
              "..          ...           ...\n",
              "625  2020-09-25  13196.873815\n",
              "626  2020-09-28  13125.003128\n",
              "627  2020-09-29  13224.516675\n",
              "628  2020-09-30  13309.419390\n",
              "629  2020-10-01           NaN\n",
              "\n",
              "[630 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc3fccd7-5cf2-4300-9453-b5195a4a6dd0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>spy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-04-04</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-04-05</td>\n",
              "      <td>9777.141321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-04-06</td>\n",
              "      <td>9825.327421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-04-09</td>\n",
              "      <td>9981.552869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-04-10</td>\n",
              "      <td>9929.227721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>2020-09-25</td>\n",
              "      <td>13196.873815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>2020-09-28</td>\n",
              "      <td>13125.003128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>2020-09-29</td>\n",
              "      <td>13224.516675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>2020-09-30</td>\n",
              "      <td>13309.419390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>2020-10-01</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>630 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc3fccd7-5cf2-4300-9453-b5195a4a6dd0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc3fccd7-5cf2-4300-9453-b5195a4a6dd0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc3fccd7-5cf2-4300-9453-b5195a4a6dd0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_results = pd.merge(df_ensemble_results, df_index_scaled, on =\"date\", how = \"left\")[[\"date\",\"account_value\",\"spy\"]]"
      ],
      "metadata": {
        "id": "tmq__tq19v62"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.set_index(\"date\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "2eRL4dvb_rKO",
        "outputId": "fbb53521-e746-4349-caa0-129c5e79eeff"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            account_value           spy\n",
              "date                                   \n",
              "2018-04-04   10000.000000  10000.000000\n",
              "2018-04-05   10079.479603   9777.141321\n",
              "2018-04-06    9924.454502   9825.327421\n",
              "2018-04-09    9957.314686   9981.552869\n",
              "2018-04-10   10010.884480   9929.227721\n",
              "...                   ...           ...\n",
              "2020-09-25   13623.655667  13196.873815\n",
              "2020-09-28   13849.337685  13125.003128\n",
              "2020-09-29   13771.108647  13224.516675\n",
              "2020-09-30   13876.829140  13309.419390\n",
              "2020-10-01   13966.304673           NaN\n",
              "\n",
              "[630 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d43af99-5520-4c4f-8a4d-5b25a94985fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "      <th>spy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018-04-04</th>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-04-05</th>\n",
              "      <td>10079.479603</td>\n",
              "      <td>9777.141321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-04-06</th>\n",
              "      <td>9924.454502</td>\n",
              "      <td>9825.327421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-04-09</th>\n",
              "      <td>9957.314686</td>\n",
              "      <td>9981.552869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-04-10</th>\n",
              "      <td>10010.884480</td>\n",
              "      <td>9929.227721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-25</th>\n",
              "      <td>13623.655667</td>\n",
              "      <td>13196.873815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-28</th>\n",
              "      <td>13849.337685</td>\n",
              "      <td>13125.003128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-29</th>\n",
              "      <td>13771.108647</td>\n",
              "      <td>13224.516675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-30</th>\n",
              "      <td>13876.829140</td>\n",
              "      <td>13309.419390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-01</th>\n",
              "      <td>13966.304673</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>630 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d43af99-5520-4c4f-8a4d-5b25a94985fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d43af99-5520-4c4f-8a4d-5b25a94985fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d43af99-5520-4c4f-8a4d-5b25a94985fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - #### Step 7.5: Vizualise the comparision with Index"
      ],
      "metadata": {
        "id": "QFNgSamJxyv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "KjlrtpRk9mc_",
        "outputId": "d8314657-6f9d-4600-f2e9-bf633538a358"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 125
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}