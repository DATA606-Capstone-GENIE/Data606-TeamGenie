{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKIG9MBixxX8"
   },
   "source": [
    "## Project: Portfolio Management Using Multi-Agent Reinforcement Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qC_9nFXzxxS_"
   },
   "source": [
    "## Part 3: Reinfocement Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lFG0XxoofZS"
   },
   "source": [
    "- Step 1: Import Libraries and Install Packages\n",
    "> - Step 1.1: Install required packages if not already installed\n",
    "> - Step 1.2: Import the necessary libraries\n",
    "- Step 2: Define Constants\n",
    "> - Step 2.1: Define start and end dates for training data\n",
    "> - Step 2.2: Define start and end dates for testing data\n",
    "- Step 3: Load and Merge Dataframes\n",
    "> - Step 3.1: Load YahooFinance and sentiment dataframes\n",
    "> - Step 3.2: Create GDP dataframe\n",
    "> - Step 3.3: Merge all dataframes into one\n",
    "- Step 4: Incorporate Technical Indicators\n",
    "> - Step 4.1: Use historical data to calculate technical indicators\n",
    "- Step 5: Design Environment Constants\n",
    "> - Step 5.1: Define environment parameters\n",
    "> - Step 5.2: Define A2C model parameters\n",
    "> - Step 5.3: Define PPO model parameters\n",
    "> - Step 5.4: Define DDPG model parameters\n",
    "> - Step 5.5: Define timesteps\n",
    "> - Step 5.6: Define ensemble agent parameters.\n",
    "> - Step 5.7: Define test dates dataframe.\n",
    "- Step 6: Implement Deep Reinforcement Learning Model\n",
    "> - Step 6.1: Build and train a deep reinforcement learning model using the environment and data\n",
    "- Step 7: Analyze Results\n",
    "> - Step 7.1: Model with Most-Volatile and Least-Volatile Stocks\n",
    ">> - Step 7.1.1: Calcualte Sharpe ratio\n",
    ">> - Step 7.1.2: Backtest results\n",
    ">> - Step 7.1.3: Baseline Statistics\n",
    ">> - Step 7.1.4: Compare with Index\n",
    ">> - Step 7.1.5: Vizualise the comparision with Index\n",
    "> - Step 7.2: Model with Most-Volatile Stocks\n",
    ">> - Step 7.2.1: Calcualte Sharpe ratio\n",
    ">> - Step 7.2.2: Backtest results\n",
    ">> - Step 7.2.3: Baseline Statistics\n",
    ">> - Step 7.2.4: Compare with Index\n",
    ">> - Step 7.2.5: Vizualise the comparision with Index\n",
    "> - Step 7.3: Model with Least-Volatile Stocks\n",
    ">> - Step 7.3.1: Calcualte Sharpe ratio\n",
    ">> - Step 7.3.2: Backtest results\n",
    ">> - Step 7.3.3: Baseline Statistics\n",
    ">> - Step 7.3.4: Compare with Index\n",
    ">> - Step 7.3.5: Vizualise the comparision with Index\n",
    "- Step 8: Conclusion\n",
    "> - Step 8.1: Summarize the results and provide insights on the effectiveness of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpIgm2TyyP8b"
   },
   "source": [
    "#### Step 1: Import Libraries and Install Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgYaDWpZpY2I"
   },
   "source": [
    "> - #### Step 1.1: Install required packages if not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBPaPwCTxoZ5",
    "outputId": "20062cdf-f35f-4e40-f157-f74697525ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyportfolioopt in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.5)\n",
      "Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyportfolioopt) (1.3.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyportfolioopt) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyportfolioopt) (1.5.3)\n",
      "Requirement already satisfied: scipy<2.0,>=1.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyportfolioopt) (1.10.1)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.6.2.post9)\n",
      "Requirement already satisfied: ecos>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (2.0.12)\n",
      "Requirement already satisfied: scs>=1.1.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (3.2.3)\n",
      "Requirement already satisfied: setuptools>65.5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (67.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=0.19->pyportfolioopt) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=0.19->pyportfolioopt) (2023.3)\n",
      "Requirement already satisfied: qdldl in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.1.7)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.19->pyportfolioopt) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell installs the yfinance package if only unable to import, indicating the package is not installed.\n",
    "This avoids isntalling the packages again.\n",
    "\"\"\"\n",
    "import importlib\n",
    "\n",
    "# gym Library\n",
    "try:\n",
    "    importlib.import_module('gym')\n",
    "except ImportError:\n",
    "    !pip install gym\n",
    "\n",
    "\n",
    "# swig Library\n",
    "try:\n",
    "    importlib.import_module('swig')\n",
    "except ImportError:\n",
    "    !pip install swig\n",
    "\n",
    "\n",
    "# wrds Library\n",
    "try:\n",
    "    importlib.import_module('wrds')\n",
    "except ImportError:\n",
    "    !pip install wrds\n",
    "\n",
    "\n",
    "# pyportfolioopt Library\n",
    "try:\n",
    "    importlib.import_module('pyportfolioopt')\n",
    "except ImportError:\n",
    "    !pip install pyportfolioopt\n",
    "\n",
    "# # condacolab Library\n",
    "# try:\n",
    "#     importlib.import_module('condacolab')\n",
    "# except ImportError:\n",
    "#     !pip install -q condacolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XPXudiz0-jW",
    "outputId": "edacba8f-afaa-434c-bd8b-b1b937fab3c5"
   },
   "outputs": [],
   "source": [
    "# import condacolab\n",
    "# condacolab.install()\n",
    "\n",
    "# # !apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx\n",
    "# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./FinRL\")\n",
    "# sys.path.append(\"./gym\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUGJByMKzzc3"
   },
   "source": [
    "> - #### Step 1.2: Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwDHd5-3xvqj",
    "outputId": "88f5206e-fb18-45e9-9d1e-15639afbfa44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas_datareader/compat/__init__.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  PANDAS_VERSION = LooseVersion(pd.__version__)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config_tickers import SP_500_TICKER\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent, DRLEnsembleAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmyY-7qW6_wR"
   },
   "source": [
    "#### Step 2:  Define the constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-ba72B_7Hz6"
   },
   "source": [
    "> - #### Step 2.1: Define start and end dates for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M-ngtJv1z39l"
   },
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2010-01-01'\n",
    "TRAIN_END_DATE = '2017-12-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igAw-Ypp7SQN"
   },
   "source": [
    "> - #### Step 2.2: Define start and end dates for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DehYPXWy7SzN"
   },
   "outputs": [],
   "source": [
    "TEST_START_DATE = '2018-01-01'\n",
    "TEST_END_DATE = '2020-12-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "074-8Duk7rAX"
   },
   "source": [
    "#### Step 3: Load and Merge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKh-XbTi8A1q",
    "outputId": "1d8ed1d7-231a-415d-af32-c56ce2b24a37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.7.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown) (3.12.0)\n",
      "Requirement already satisfied: requests[socks] in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown) (2.30.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Directory already exists: /Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/genie_data\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "import gdown\n",
    "# The link for the data folder in Google drive. \n",
    "data_url = \"https://drive.google.com/drive/folders/1zQGlgh5kHTXSq7eoyXf6i_uAWYFJ5xzx?usp=share_link\"\n",
    "\n",
    "current_path = os.getcwd() # Get the current working directory.\n",
    "\n",
    "data_folder_path = os.path.join(os.getcwd(),\"genie_data\") # Generate data folder path. \n",
    "\n",
    "# Check if the folder already exists locally\n",
    "\n",
    "if not os.path.exists(data_folder_path):\n",
    "    \n",
    "    os.makedirs(data_folder_path)\n",
    "    print(f\"Downloading data from Google Drive to: {data_folder_path}\")\n",
    "    gdown.download_folder(data_url,output=data_folder_path, quiet=True, use_cookies=False) # Download the data from Google Drive.\n",
    "    \n",
    "else:\n",
    "    print(f\"Directory already exists: {data_folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo4koJ9SF0l8"
   },
   "source": [
    "> - #### Step 3.1: Load YahooFinance and sentiment dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "zx2WEURa7qGH",
    "outputId": "90245c32-9d09-402a-87a1-57cb4f4decf3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.840000</td>\n",
       "      <td>22.922108</td>\n",
       "      <td>2175500</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>11.220000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>9.966131</td>\n",
       "      <td>14482500</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>4.164575</td>\n",
       "      <td>14901600</td>\n",
       "      <td>KEY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>25.320000</td>\n",
       "      <td>25.910000</td>\n",
       "      <td>24.930000</td>\n",
       "      <td>19.833185</td>\n",
       "      <td>3811400</td>\n",
       "      <td>LNC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15.245000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>9.583809</td>\n",
       "      <td>1332800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28549</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>50.520000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>50.360001</td>\n",
       "      <td>47.424179</td>\n",
       "      <td>563800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28550</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>147.470001</td>\n",
       "      <td>147.990005</td>\n",
       "      <td>147.009995</td>\n",
       "      <td>138.462997</td>\n",
       "      <td>2224900</td>\n",
       "      <td>PEP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28551</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>138.919998</td>\n",
       "      <td>137.550003</td>\n",
       "      <td>130.316620</td>\n",
       "      <td>3261400</td>\n",
       "      <td>PG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28552</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>372.339996</td>\n",
       "      <td>373.100006</td>\n",
       "      <td>371.570007</td>\n",
       "      <td>359.862762</td>\n",
       "      <td>49455300</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28553</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>65.519997</td>\n",
       "      <td>65.849998</td>\n",
       "      <td>65.389999</td>\n",
       "      <td>61.628376</td>\n",
       "      <td>1296400</td>\n",
       "      <td>XEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28554 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close    volume  \\\n",
       "0     2010-01-04   39.099998   39.419998   38.840000   22.922108   2175500   \n",
       "1     2010-01-04   11.220000   11.430000   10.950000    9.966131  14482500   \n",
       "2     2010-01-04    5.660000    5.970000    5.650000    4.164575  14901600   \n",
       "3     2010-01-04   25.320000   25.910000   24.930000   19.833185   3811400   \n",
       "4     2010-01-04   15.245000   15.350000   15.120000    9.583809   1332800   \n",
       "...          ...         ...         ...         ...         ...       ...   \n",
       "28549 2020-12-30   50.520000   51.000000   50.360001   47.424179    563800   \n",
       "28550 2020-12-30  147.470001  147.990005  147.009995  138.462997   2224900   \n",
       "28551 2020-12-30  138.600006  138.919998  137.550003  130.316620   3261400   \n",
       "28552 2020-12-30  372.339996  373.100006  371.570007  359.862762  49455300   \n",
       "28553 2020-12-30   65.519997   65.849998   65.389999   61.628376   1296400   \n",
       "\n",
       "       tic  day  \n",
       "0        D    0  \n",
       "1      DAL    0  \n",
       "2      KEY    0  \n",
       "3      LNC    0  \n",
       "4      LNT    0  \n",
       "...    ...  ...  \n",
       "28549  LNT    2  \n",
       "28550  PEP    2  \n",
       "28551   PG    2  \n",
       "28552  SPY    2  \n",
       "28553  XEL    2  \n",
       "\n",
       "[28554 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf_df = pd.read_csv('./genie_data/yf-data.csv',index_col='Unnamed: 0')\n",
    "yf_df[\"date\"] = pd.to_datetime(yf_df[\"date\"])\n",
    "\n",
    "yf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "wEDzfKjTJP2X",
    "outputId": "5d5938ed-f7e5-4865-aa62-120e812f3fde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>tick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ETSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5943</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ETSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ENPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71721 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  SentimentScore  tick\n",
       "1036 2005-01-01             0.0   LNC\n",
       "1003 2005-01-01             0.0   XEL\n",
       "1762 2005-01-01             0.0    PG\n",
       "2431 2005-01-01             0.0     D\n",
       "155  2005-01-01             0.0  ETSY\n",
       "...         ...             ...   ...\n",
       "7427 2020-12-31             0.0   KEY\n",
       "5943 2020-12-31             0.0  ETSY\n",
       "7021 2020-12-31             0.0    PG\n",
       "6010 2020-12-31             0.0  ENPH\n",
       "7022 2020-12-31             0.0     D\n",
       "\n",
       "[71721 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments_df = pd.read_csv('./genie_data/sentiments_df.csv',index_col='Unnamed: 0')\n",
    "sentiments_df[\"date\"] = pd.to_datetime(sentiments_df[\"date\"])\n",
    "\n",
    "sentiments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcEoLB0IFk2p"
   },
   "source": [
    "> - #### Step 3.2: Create GDP dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RACEQNl_7xxL"
   },
   "outputs": [],
   "source": [
    "gdp = web.DataReader(\"GDP\", 'fred', 2010, 2020)\n",
    "gdp = gdp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "njSxHpMhG9eN"
   },
   "outputs": [],
   "source": [
    "date = pd.date_range(start='2010-01-01', end='2020-12-30')\n",
    "date_df = pd.DataFrame()\n",
    "date_df['date'] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-VEpZbu3HS-U"
   },
   "outputs": [],
   "source": [
    "gdp['date']=pd.to_datetime(gdp['DATE'])\n",
    "gdp.rename(columns = {'GDP':'gdp'}, inplace = True)\n",
    "gdp = gdp.drop(['DATE'], axis=1)\n",
    "gdp_df=gdp.merge(date_df, on='date', how='right')\n",
    "gdp_df = gdp_df.fillna(method='ffill')\n",
    "gdp_df = gdp_df.merge(pd.DataFrame({\"tic\":yf_df.tic.unique()}),how=\"cross\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BITc6ro3L_Dr"
   },
   "source": [
    " > - #### Step 3.3:  Merge all dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CZa_G1ffI0yj"
   },
   "outputs": [],
   "source": [
    "df = pd.merge(pd.merge(yf_df, sentiments_df, how='left', left_on=['date','tic'], right_on = ['date','tick']),\n",
    "              gdp_df, how='left', left_on=['date','tic'], right_on = ['date','tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "uAaslu54h3aF",
    "outputId": "3f04ee36-ed0d-41f6-d69e-89ee58f3a0f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>tick</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.840000</td>\n",
       "      <td>22.922108</td>\n",
       "      <td>2175500</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>11.220000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>9.966131</td>\n",
       "      <td>14482500</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>4.164575</td>\n",
       "      <td>14901600</td>\n",
       "      <td>KEY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KEY</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>25.320000</td>\n",
       "      <td>25.910000</td>\n",
       "      <td>24.930000</td>\n",
       "      <td>19.833185</td>\n",
       "      <td>3811400</td>\n",
       "      <td>LNC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNC</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15.245000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>9.583809</td>\n",
       "      <td>1332800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNT</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41102</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>50.520000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>50.360001</td>\n",
       "      <td>47.424179</td>\n",
       "      <td>563800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNT</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41103</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>147.470001</td>\n",
       "      <td>147.990005</td>\n",
       "      <td>147.009995</td>\n",
       "      <td>138.462997</td>\n",
       "      <td>2224900</td>\n",
       "      <td>PEP</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PEP</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41104</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>138.919998</td>\n",
       "      <td>137.550003</td>\n",
       "      <td>130.316620</td>\n",
       "      <td>3261400</td>\n",
       "      <td>PG</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41105</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>372.339996</td>\n",
       "      <td>373.100006</td>\n",
       "      <td>371.570007</td>\n",
       "      <td>359.862762</td>\n",
       "      <td>49455300</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41106</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>65.519997</td>\n",
       "      <td>65.849998</td>\n",
       "      <td>65.389999</td>\n",
       "      <td>61.628376</td>\n",
       "      <td>1296400</td>\n",
       "      <td>XEL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XEL</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41107 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close    volume  \\\n",
       "0     2010-01-04   39.099998   39.419998   38.840000   22.922108   2175500   \n",
       "1     2010-01-04   11.220000   11.430000   10.950000    9.966131  14482500   \n",
       "2     2010-01-04    5.660000    5.970000    5.650000    4.164575  14901600   \n",
       "3     2010-01-04   25.320000   25.910000   24.930000   19.833185   3811400   \n",
       "4     2010-01-04   15.245000   15.350000   15.120000    9.583809   1332800   \n",
       "...          ...         ...         ...         ...         ...       ...   \n",
       "41102 2020-12-30   50.520000   51.000000   50.360001   47.424179    563800   \n",
       "41103 2020-12-30  147.470001  147.990005  147.009995  138.462997   2224900   \n",
       "41104 2020-12-30  138.600006  138.919998  137.550003  130.316620   3261400   \n",
       "41105 2020-12-30  372.339996  373.100006  371.570007  359.862762  49455300   \n",
       "41106 2020-12-30   65.519997   65.849998   65.389999   61.628376   1296400   \n",
       "\n",
       "       tic  day  SentimentScore tick        gdp  \n",
       "0        D    0             0.0    D  14764.611  \n",
       "1      DAL    0             0.0  DAL  14764.611  \n",
       "2      KEY    0             0.0  KEY  14764.611  \n",
       "3      LNC    0             0.0  LNC  14764.611  \n",
       "4      LNT    0             0.0  LNT  14764.611  \n",
       "...    ...  ...             ...  ...        ...  \n",
       "41102  LNT    2             0.0  LNT  21538.032  \n",
       "41103  PEP    2             0.0  PEP  21538.032  \n",
       "41104   PG    2             0.0   PG  21538.032  \n",
       "41105  SPY    2             NaN  NaN  21538.032  \n",
       "41106  XEL    2             0.0  XEL  21538.032  \n",
       "\n",
       "[41107 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rsKVwwfMRp3e"
   },
   "outputs": [],
   "source": [
    "df[\"SentimentScore\"] = df[\"SentimentScore\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "peiE61-qRrzU",
    "outputId": "93905ffe-3087-4e44-9995-2986af67f097"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>tick</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.840000</td>\n",
       "      <td>22.922108</td>\n",
       "      <td>2175500</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>11.220000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>9.966131</td>\n",
       "      <td>14482500</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>4.164575</td>\n",
       "      <td>14901600</td>\n",
       "      <td>KEY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KEY</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>25.320000</td>\n",
       "      <td>25.910000</td>\n",
       "      <td>24.930000</td>\n",
       "      <td>19.833185</td>\n",
       "      <td>3811400</td>\n",
       "      <td>LNC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNC</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15.245000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>9.583809</td>\n",
       "      <td>1332800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNT</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>61.189999</td>\n",
       "      <td>61.520000</td>\n",
       "      <td>60.639999</td>\n",
       "      <td>41.632233</td>\n",
       "      <td>6585900</td>\n",
       "      <td>PEP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PEP</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>61.110001</td>\n",
       "      <td>61.310001</td>\n",
       "      <td>60.630001</td>\n",
       "      <td>41.181229</td>\n",
       "      <td>9190800</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>112.370003</td>\n",
       "      <td>113.389999</td>\n",
       "      <td>111.510002</td>\n",
       "      <td>88.117897</td>\n",
       "      <td>118944600</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>21.379999</td>\n",
       "      <td>21.379999</td>\n",
       "      <td>21.040001</td>\n",
       "      <td>13.396955</td>\n",
       "      <td>2670400</td>\n",
       "      <td>XEL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XEL</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>38.860001</td>\n",
       "      <td>39.020000</td>\n",
       "      <td>38.080002</td>\n",
       "      <td>22.639708</td>\n",
       "      <td>2802200</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>11.320000</td>\n",
       "      <td>12.340000</td>\n",
       "      <td>11.290000</td>\n",
       "      <td>10.747787</td>\n",
       "      <td>25066000</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>6.190000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>4.325830</td>\n",
       "      <td>16660800</td>\n",
       "      <td>KEY</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KEY</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>25.799999</td>\n",
       "      <td>26.610001</td>\n",
       "      <td>25.719999</td>\n",
       "      <td>20.247015</td>\n",
       "      <td>4839200</td>\n",
       "      <td>LNC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNC</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>15.185000</td>\n",
       "      <td>15.555000</td>\n",
       "      <td>15.155000</td>\n",
       "      <td>9.808012</td>\n",
       "      <td>3684600</td>\n",
       "      <td>LNT</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNT</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>62.099998</td>\n",
       "      <td>60.900002</td>\n",
       "      <td>42.135311</td>\n",
       "      <td>8886000</td>\n",
       "      <td>PEP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PEP</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>61.130001</td>\n",
       "      <td>61.279999</td>\n",
       "      <td>60.599998</td>\n",
       "      <td>41.194714</td>\n",
       "      <td>8649400</td>\n",
       "      <td>PG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>113.260002</td>\n",
       "      <td>113.680000</td>\n",
       "      <td>112.849998</td>\n",
       "      <td>88.351143</td>\n",
       "      <td>111579900</td>\n",
       "      <td>SPY</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>20.950001</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.410000</td>\n",
       "      <td>13.238071</td>\n",
       "      <td>4321400</td>\n",
       "      <td>XEL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XEL</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>38.730000</td>\n",
       "      <td>38.290001</td>\n",
       "      <td>22.663235</td>\n",
       "      <td>2882500</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>11.990000</td>\n",
       "      <td>12.240000</td>\n",
       "      <td>11.850000</td>\n",
       "      <td>10.756669</td>\n",
       "      <td>14980700</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low      close     volume  tic  \\\n",
       "0  2010-01-04   39.099998   39.419998   38.840000  22.922108    2175500    D   \n",
       "1  2010-01-04   11.220000   11.430000   10.950000   9.966131   14482500  DAL   \n",
       "2  2010-01-04    5.660000    5.970000    5.650000   4.164575   14901600  KEY   \n",
       "3  2010-01-04   25.320000   25.910000   24.930000  19.833185    3811400  LNC   \n",
       "4  2010-01-04   15.245000   15.350000   15.120000   9.583809    1332800  LNT   \n",
       "5  2010-01-04   61.189999   61.520000   60.639999  41.632233    6585900  PEP   \n",
       "6  2010-01-04   61.110001   61.310001   60.630001  41.181229    9190800   PG   \n",
       "7  2010-01-04  112.370003  113.389999  111.510002  88.117897  118944600  SPY   \n",
       "8  2010-01-04   21.379999   21.379999   21.040001  13.396955    2670400  XEL   \n",
       "9  2010-01-05   38.860001   39.020000   38.080002  22.639708    2802200    D   \n",
       "10 2010-01-05   11.320000   12.340000   11.290000  10.747787   25066000  DAL   \n",
       "11 2010-01-05    5.880000    6.190000    5.880000   4.325830   16660800  KEY   \n",
       "12 2010-01-05   25.799999   26.610001   25.719999  20.247015    4839200  LNC   \n",
       "13 2010-01-05   15.185000   15.555000   15.155000   9.808012    3684600  LNT   \n",
       "14 2010-01-05   61.000000   62.099998   60.900002  42.135311    8886000  PEP   \n",
       "15 2010-01-05   61.130001   61.279999   60.599998  41.194714    8649400   PG   \n",
       "16 2010-01-05  113.260002  113.680000  112.849998  88.351143  111579900  SPY   \n",
       "17 2010-01-05   20.950001   21.000000   20.410000  13.238071    4321400  XEL   \n",
       "18 2010-01-06   38.500000   38.730000   38.290001  22.663235    2882500    D   \n",
       "19 2010-01-06   11.990000   12.240000   11.850000  10.756669   14980700  DAL   \n",
       "\n",
       "    day  SentimentScore tick        gdp  \n",
       "0     0             0.0    D  14764.611  \n",
       "1     0             0.0  DAL  14764.611  \n",
       "2     0             0.0  KEY  14764.611  \n",
       "3     0             0.0  LNC  14764.611  \n",
       "4     0             0.0  LNT  14764.611  \n",
       "5     0             0.0  PEP  14764.611  \n",
       "6     0             0.0   PG  14764.611  \n",
       "7     0             0.0  NaN  14764.611  \n",
       "8     0             0.0  XEL  14764.611  \n",
       "9     1             0.0    D  14764.611  \n",
       "10    1             0.0  DAL  14764.611  \n",
       "11    1             0.0  KEY  14764.611  \n",
       "12    1             0.0  LNC  14764.611  \n",
       "13    1             0.0  LNT  14764.611  \n",
       "14    1             0.0  PEP  14764.611  \n",
       "15    1             0.0   PG  14764.611  \n",
       "16    1             0.0  NaN  14764.611  \n",
       "17    1             0.0  XEL  14764.611  \n",
       "18    2             0.0    D  14764.611  \n",
       "19    2             0.0  DAL  14764.611  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uF2mO-m5hpMw",
    "outputId": "23571701-ee28-4cdd-8574-a925ce4c6a5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28554, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['date', 'tic'], inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>tick</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>11.220000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>9.966131</td>\n",
       "      <td>14482500</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>4.164575</td>\n",
       "      <td>14901600</td>\n",
       "      <td>KEY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KEY</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>25.320000</td>\n",
       "      <td>25.910000</td>\n",
       "      <td>24.930000</td>\n",
       "      <td>19.833185</td>\n",
       "      <td>3811400</td>\n",
       "      <td>LNC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNC</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>112.370003</td>\n",
       "      <td>113.389999</td>\n",
       "      <td>111.510002</td>\n",
       "      <td>88.117897</td>\n",
       "      <td>118944600</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>11.320000</td>\n",
       "      <td>12.340000</td>\n",
       "      <td>11.290000</td>\n",
       "      <td>10.747787</td>\n",
       "      <td>25066000</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41098</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>171.679993</td>\n",
       "      <td>177.550003</td>\n",
       "      <td>171.679993</td>\n",
       "      <td>172.929993</td>\n",
       "      <td>2474100</td>\n",
       "      <td>ENPH</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ENPH</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41099</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>178.300003</td>\n",
       "      <td>183.410004</td>\n",
       "      <td>176.119995</td>\n",
       "      <td>183.179993</td>\n",
       "      <td>2125600</td>\n",
       "      <td>ETSY</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ETSY</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41100</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>16.010000</td>\n",
       "      <td>16.320000</td>\n",
       "      <td>15.980000</td>\n",
       "      <td>14.926527</td>\n",
       "      <td>5757800</td>\n",
       "      <td>KEY</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KEY</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41101</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>46.046585</td>\n",
       "      <td>687300</td>\n",
       "      <td>LNC</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNC</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41105</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>372.339996</td>\n",
       "      <td>373.100006</td>\n",
       "      <td>371.570007</td>\n",
       "      <td>359.862762</td>\n",
       "      <td>49455300</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14714 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close     volume  \\\n",
       "1     2010-01-04   11.220000   11.430000   10.950000    9.966131   14482500   \n",
       "2     2010-01-04    5.660000    5.970000    5.650000    4.164575   14901600   \n",
       "3     2010-01-04   25.320000   25.910000   24.930000   19.833185    3811400   \n",
       "7     2010-01-04  112.370003  113.389999  111.510002   88.117897  118944600   \n",
       "10    2010-01-05   11.320000   12.340000   11.290000   10.747787   25066000   \n",
       "...          ...         ...         ...         ...         ...        ...   \n",
       "41098 2020-12-30  171.679993  177.550003  171.679993  172.929993    2474100   \n",
       "41099 2020-12-30  178.300003  183.410004  176.119995  183.179993    2125600   \n",
       "41100 2020-12-30   16.010000   16.320000   15.980000   14.926527    5757800   \n",
       "41101 2020-12-30   49.500000   50.000000   49.310001   46.046585     687300   \n",
       "41105 2020-12-30  372.339996  373.100006  371.570007  359.862762   49455300   \n",
       "\n",
       "        tic  day  SentimentScore  tick        gdp  \n",
       "1       DAL    0             0.0   DAL  14764.611  \n",
       "2       KEY    0             0.0   KEY  14764.611  \n",
       "3       LNC    0             0.0   LNC  14764.611  \n",
       "7       SPY    0             0.0   NaN  14764.611  \n",
       "10      DAL    1             0.0   DAL  14764.611  \n",
       "...     ...  ...             ...   ...        ...  \n",
       "41098  ENPH    2             0.0  ENPH  21538.032  \n",
       "41099  ETSY    2             0.0  ETSY  21538.032  \n",
       "41100   KEY    2             0.0   KEY  21538.032  \n",
       "41101   LNC    2             0.0   LNC  21538.032  \n",
       "41105   SPY    2             0.0   NaN  21538.032  \n",
       "\n",
       "[14714 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_volatile_stocks = [\"ENPH\",\"KEY\",\"DAL\",\"LNC\",\"ETSY\"]\n",
    "\n",
    "# Add index to both the stocks\n",
    "most_volatile_stocks.append(\"SPY\")\n",
    "\n",
    "df_mv = df[df[\"tic\"].isin(most_volatile_stocks)]\n",
    "\n",
    "df_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>tick</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.840000</td>\n",
       "      <td>22.922108</td>\n",
       "      <td>2175500</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15.245000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>9.583809</td>\n",
       "      <td>1332800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNT</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>61.189999</td>\n",
       "      <td>61.520000</td>\n",
       "      <td>60.639999</td>\n",
       "      <td>41.632233</td>\n",
       "      <td>6585900</td>\n",
       "      <td>PEP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PEP</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>61.110001</td>\n",
       "      <td>61.310001</td>\n",
       "      <td>60.630001</td>\n",
       "      <td>41.181229</td>\n",
       "      <td>9190800</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>112.370003</td>\n",
       "      <td>113.389999</td>\n",
       "      <td>111.510002</td>\n",
       "      <td>88.117897</td>\n",
       "      <td>118944600</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41102</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>50.520000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>50.360001</td>\n",
       "      <td>47.424179</td>\n",
       "      <td>563800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNT</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41103</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>147.470001</td>\n",
       "      <td>147.990005</td>\n",
       "      <td>147.009995</td>\n",
       "      <td>138.462997</td>\n",
       "      <td>2224900</td>\n",
       "      <td>PEP</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PEP</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41104</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>138.919998</td>\n",
       "      <td>137.550003</td>\n",
       "      <td>130.316620</td>\n",
       "      <td>3261400</td>\n",
       "      <td>PG</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41105</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>372.339996</td>\n",
       "      <td>373.100006</td>\n",
       "      <td>371.570007</td>\n",
       "      <td>359.862762</td>\n",
       "      <td>49455300</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41106</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>65.519997</td>\n",
       "      <td>65.849998</td>\n",
       "      <td>65.389999</td>\n",
       "      <td>61.628376</td>\n",
       "      <td>1296400</td>\n",
       "      <td>XEL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XEL</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16608 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close     volume  \\\n",
       "0     2010-01-04   39.099998   39.419998   38.840000   22.922108    2175500   \n",
       "4     2010-01-04   15.245000   15.350000   15.120000    9.583809    1332800   \n",
       "5     2010-01-04   61.189999   61.520000   60.639999   41.632233    6585900   \n",
       "6     2010-01-04   61.110001   61.310001   60.630001   41.181229    9190800   \n",
       "7     2010-01-04  112.370003  113.389999  111.510002   88.117897  118944600   \n",
       "...          ...         ...         ...         ...         ...        ...   \n",
       "41102 2020-12-30   50.520000   51.000000   50.360001   47.424179     563800   \n",
       "41103 2020-12-30  147.470001  147.990005  147.009995  138.462997    2224900   \n",
       "41104 2020-12-30  138.600006  138.919998  137.550003  130.316620    3261400   \n",
       "41105 2020-12-30  372.339996  373.100006  371.570007  359.862762   49455300   \n",
       "41106 2020-12-30   65.519997   65.849998   65.389999   61.628376    1296400   \n",
       "\n",
       "       tic  day  SentimentScore tick        gdp  \n",
       "0        D    0             0.0    D  14764.611  \n",
       "4      LNT    0             0.0  LNT  14764.611  \n",
       "5      PEP    0             0.0  PEP  14764.611  \n",
       "6       PG    0             0.0   PG  14764.611  \n",
       "7      SPY    0             0.0  NaN  14764.611  \n",
       "...    ...  ...             ...  ...        ...  \n",
       "41102  LNT    2             0.0  LNT  21538.032  \n",
       "41103  PEP    2             0.0  PEP  21538.032  \n",
       "41104   PG    2             0.0   PG  21538.032  \n",
       "41105  SPY    2             0.0  NaN  21538.032  \n",
       "41106  XEL    2             0.0  XEL  21538.032  \n",
       "\n",
       "[16608 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_volatile_stocks = [\"XEL\",\"PG\",\"LNT\",\"PEP\",\"D\"]\n",
    "\n",
    "# Add index to both the stocks\n",
    "least_volatile_stocks.append(\"SPY\")\n",
    "\n",
    "df_lv = df[df[\"tic\"].isin(least_volatile_stocks)]\n",
    "\n",
    "df_lv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jejabAiBTfmM"
   },
   "source": [
    "#### Step 4: Incorporate Technical Indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GpfYW-sqDLU"
   },
   "source": [
    "> - #### Step 4.1: Use historical data to calculate technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6nrmtBVGSdgs"
   },
   "outputs": [],
   "source": [
    "technical_indicators = ['macd', 'rsi_30', 'cci_30', 'dx_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pusTbgzUTqHJ"
   },
   "outputs": [],
   "source": [
    "fe_pipeline = FeatureEngineer(use_technical_indicator=True, \n",
    "                              tech_indicator_list = technical_indicators, \n",
    "                              use_turbulence=True, \n",
    "                              user_defined_feature = True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qWolIyIaT_BV",
    "outputId": "30160e41-2ce7-4f62-b2b6-2e8d11f653aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n",
      "Successfully added user defined features\n"
     ]
    }
   ],
   "source": [
    "df_processed = fe_pipeline.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n",
      "Successfully added user defined features\n"
     ]
    }
   ],
   "source": [
    "df_mv_processed = fe_pipeline.preprocess_data(df_mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n",
      "Successfully added user defined features\n"
     ]
    }
   ],
   "source": [
    "df_lv_processed = fe_pipeline.preprocess_data(df_lv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDR3MHqFlcUJ"
   },
   "source": [
    "#### Step 5:  Design Environment constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztF9rZzOqSy0"
   },
   "source": [
    "> - #### Step 5.1: Define environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "udfs = 2 # Sentiment Scores, GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6J0lQWUUFZ3",
    "outputId": "f3b46b7e-53b6-4ff2-9525-bd346abc8b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 9, state Space: 73\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(df_processed.tic.unique())\n",
    "\n",
    "state_space = 1 + 2 * stock_dimension + len(technical_indicators)*stock_dimension + udfs*stock_dimension\n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension}, state Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 4, state Space: 33\n"
     ]
    }
   ],
   "source": [
    "stock_dimension_mv = len(df_mv_processed.tic.unique())\n",
    "\n",
    "state_space_mv = 1 + 2 * stock_dimension_mv + len(technical_indicators)*stock_dimension_mv + udfs*stock_dimension_mv\n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension_mv}, state Space: {state_space_mv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 6, state Space: 49\n"
     ]
    }
   ],
   "source": [
    "stock_dimension_lv = len(df_lv_processed.tic.unique())\n",
    "\n",
    "state_space_lv = 1 + 2 * stock_dimension_lv + len(technical_indicators)*stock_dimension_lv + udfs*stock_dimension_lv\n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension_lv}, state Space: {state_space_lv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1-0s3GHBl-FQ"
   },
   "outputs": [],
   "source": [
    "technical_indicators.extend([\"SentimentScore\",\"gdp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "EJNQ1TXGmqnp"
   },
   "outputs": [],
   "source": [
    "# Defining a dictionary containing environment arguments\n",
    "\n",
    "env_variables = { \"hmax\": 100,                        # Maximum number of shares that can be traded at a time\n",
    "                  \"buy_cost_pct\": 0.001,              # Transaction cost for buying\n",
    "                  \"sell_cost_pct\": 0.001,             # Transaction cost for selling\n",
    "                  \"state_space\": state_space,         # State space for the environment\n",
    "                  \"tech_indicator_list\": technical_indicators,  # List of technical indicators used\n",
    "                  \"action_space\": stock_dimension,    # Action space for the environment\n",
    "                  \"reward_scaling\": 1e-4,             # Scaling factor for rewards\n",
    "                  \"print_verbosity\": 5                # Level of detail for logging during training\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dictionary containing environment arguments\n",
    "\n",
    "env_variables_mv = { \"hmax\": 100,                        # Maximum number of shares that can be traded at a time\n",
    "                  \"buy_cost_pct\": 0.001,              # Transaction cost for buying\n",
    "                  \"sell_cost_pct\": 0.001,             # Transaction cost for selling\n",
    "                  \"state_space\": state_space_mv,         # State space for the environment\n",
    "                  \"tech_indicator_list\": technical_indicators,  # List of technical indicators used\n",
    "                  \"action_space\": stock_dimension_mv,    # Action space for the environment\n",
    "                  \"reward_scaling\": 1e-4,             # Scaling factor for rewards\n",
    "                  \"print_verbosity\": 5                # Level of detail for logging during training\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dictionary containing environment arguments\n",
    "\n",
    "env_variables_lv = { \"hmax\": 100,                        # Maximum number of shares that can be traded at a time\n",
    "                  \"buy_cost_pct\": 0.001,              # Transaction cost for buying\n",
    "                  \"sell_cost_pct\": 0.001,             # Transaction cost for selling\n",
    "                  \"state_space\": state_space_lv,         # State space for the environment\n",
    "                  \"tech_indicator_list\": technical_indicators,  # List of technical indicators used\n",
    "                  \"action_space\": stock_dimension_lv,    # Action space for the environment\n",
    "                  \"reward_scaling\": 1e-4,             # Scaling factor for rewards\n",
    "                  \"print_verbosity\": 5                # Level of detail for logging during training\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGZ4QnPLrW_N"
   },
   "source": [
    "> - #### Step 5.2: Define A2C model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "GvzaGen2r4CE"
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yHV8PBWrWun"
   },
   "source": [
    "> -  #### Step 5.3: Define PPO model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "uxptBXIar91A"
   },
   "outputs": [],
   "source": [
    "PPO_model_kwargs = { \"ent_coef\": 0.01, \"n_steps\": 2048, \"learning_rate\": 0.00025, \"batch_size\": 128 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyDKWItvrWlR"
   },
   "source": [
    "> - #### Step 5.4: Define DDPG model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "7Znj3spJsFYI"
   },
   "outputs": [],
   "source": [
    "DDPG_model_kwargs = { \"buffer_size\": 10_000, \"learning_rate\": 0.0005, \"batch_size\":64 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2z-ad2wrWS4"
   },
   "source": [
    "> - #### Step 5.5: Define timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "aH3Nots0sLDq"
   },
   "outputs": [],
   "source": [
    "timesteps_dict = { 'a2c': 10_000, 'ppo': 10_000, 'ddpg': 10_000 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_UaT149r1Y0"
   },
   "source": [
    "> - #### Step 5.6: Define ensemble agent parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "m4YLBeq8sQGc"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63\n",
    "validation_window = 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - #### Step 5.7: Define test dates dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the datest to which the testing predictions. \n",
    "test_dates = df_processed[(df_processed.date > TEST_START_DATE)&(df_processed.date <= TEST_END_DATE)].date.unique()\n",
    "\n",
    "trade_date_df = pd.DataFrame({'datadate':test_dates}) # Convert the dates to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "DLvv-dSjsVv-"
   },
   "outputs": [],
   "source": [
    "ensemble_agent = DRLEnsembleAgent(initial_amount = 10000,\n",
    "                                  stock_dim = stock_dimension,\n",
    "                                  df = df_processed,\n",
    "                                  train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                                  val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                                  rebalance_window=rebalance_window,\n",
    "                                  validation_window=validation_window,\n",
    "                                  **env_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_agent_mv = DRLEnsembleAgent(initial_amount = 10000,\n",
    "                                  stock_dim = stock_dimension_mv,\n",
    "                                  df = df_processed,\n",
    "                                  train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                                  val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                                  rebalance_window=rebalance_window,\n",
    "                                  validation_window=validation_window,\n",
    "                                  **env_variables_mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_agent_lv = DRLEnsembleAgent(initial_amount = 10000,\n",
    "                                  stock_dim = stock_dimension_lv,\n",
    "                                  df = df_processed,\n",
    "                                  train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                                  val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                                  rebalance_window=rebalance_window,\n",
    "                                  validation_window=validation_window,\n",
    "                                  **env_variables_lv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXPiP6ybqZh3"
   },
   "source": [
    "#### Step 6: Implement Deep Reinforcement Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nGsa7SltetS"
   },
   "source": [
    "> - #### Step 6.1: Build and train a deep reinforcement learning model using the environment and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPjSkaADm4lF",
    "outputId": "9eeb1d11-c118-414f-9227-ecd009ce9271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-01-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_14\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 359           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.0497       |\n",
      "|    reward             | -0.0009931551 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 0.000267      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 350          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0138      |\n",
      "|    reward             | -0.004784603 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 6.22e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 358          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.724        |\n",
      "|    reward             | -0.041110557 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.00453      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 362          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 0.139        |\n",
      "|    reward             | -0.029361783 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.00112      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 360          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.428        |\n",
      "|    reward             | 0.0035014695 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.00106      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 362        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 8          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 0.198      |\n",
      "|    reward             | -0.0180712 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.000494   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 364          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.257        |\n",
      "|    reward             | -0.026018409 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 0.00058      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 365          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.202        |\n",
      "|    reward             | -0.011969639 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 0.000439     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 363         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.24       |\n",
      "|    reward             | -0.00797262 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 0.000385    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 364            |\n",
      "|    iterations         | 1000           |\n",
      "|    time_elapsed       | 13             |\n",
      "|    total_timesteps    | 5000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 999            |\n",
      "|    policy_loss        | -0.131         |\n",
      "|    reward             | -0.00065523677 |\n",
      "|    std                | 1.24           |\n",
      "|    value_loss         | 8.09e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 365          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.00313      |\n",
      "|    reward             | 0.0036857312 |\n",
      "|    std                | 1.28         |\n",
      "|    value_loss         | 1.12e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 365          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.0295      |\n",
      "|    reward             | 0.0046144696 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 1.15e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 364           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.0657        |\n",
      "|    reward             | -0.0031883442 |\n",
      "|    std                | 1.37          |\n",
      "|    value_loss         | 5.22e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 365           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.9         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.117         |\n",
      "|    reward             | 0.00035607643 |\n",
      "|    std                | 1.42          |\n",
      "|    value_loss         | 0.000107      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 365         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | -0.0249     |\n",
      "|    reward             | 0.009882542 |\n",
      "|    std                | 1.48        |\n",
      "|    value_loss         | 4.39e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 366          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.0772       |\n",
      "|    reward             | 0.0008314955 |\n",
      "|    std                | 1.54         |\n",
      "|    value_loss         | 3.06e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 365         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.0139      |\n",
      "|    reward             | 0.004860377 |\n",
      "|    std                | 1.61        |\n",
      "|    value_loss         | 0.000126    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 366          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.023        |\n",
      "|    reward             | 0.0030310692 |\n",
      "|    std                | 1.68         |\n",
      "|    value_loss         | 1.71e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 366          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.148        |\n",
      "|    reward             | 0.0047542807 |\n",
      "|    std                | 1.74         |\n",
      "|    value_loss         | 0.000144     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 366         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.0175     |\n",
      "|    reward             | 0.007841239 |\n",
      "|    std                | 1.8         |\n",
      "|    value_loss         | 1.13e-05    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.43248551161850746\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_14\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 492          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0036298938 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 469           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010941652   |\n",
      "|    clip_fraction        | 0.124         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.717        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.127        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00465      |\n",
      "|    reward               | -0.0030155738 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00146       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 464         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008603698 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | -0.503      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.127      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | -0.0159929  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00108     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065345843 |\n",
      "|    clip_fraction        | 0.0629       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | -0.127       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.13        |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 0.0050657587 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000931     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2012, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 2152.85\n",
      "total_reward: -7847.15\n",
      "total_cost: 4814.71\n",
      "total_trades: 12172\n",
      "Sharpe: -0.564\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 460            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 22             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.009502241    |\n",
      "|    clip_fraction        | 0.12           |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -13            |\n",
      "|    explained_variance   | 0.143          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.154         |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00781       |\n",
      "|    reward               | -0.00035309745 |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 0.000539       |\n",
      "--------------------------------------------\n",
      "======PPO Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.24294270673848453\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_14\n",
      "day: 2012, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 10060\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 160           |\n",
      "|    time_elapsed    | 50            |\n",
      "|    total_timesteps | 8052          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 193           |\n",
      "|    critic_loss     | 117           |\n",
      "|    learning_rate   | 0.0005        |\n",
      "|    n_updates       | 6039          |\n",
      "|    reward          | -0.0020182312 |\n",
      "--------------------------------------\n",
      "======DDPG Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======Trading from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -18.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.165       |\n",
      "|    reward             | -0.000803403 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 2             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | 0.049         |\n",
      "|    reward             | -0.0029678622 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 9.39e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 342           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.109        |\n",
      "|    reward             | -0.0009033657 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 0.000309      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 347         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.338      |\n",
      "|    reward             | -0.03809063 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00081     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 345         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.088       |\n",
      "|    reward             | -0.00148326 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 4.31e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 348           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.1           |\n",
      "|    reward             | -0.0011187851 |\n",
      "|    std                | 1.15          |\n",
      "|    value_loss         | 7.55e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.565       |\n",
      "|    reward             | -0.004312758 |\n",
      "|    std                | 1.2          |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 352           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.0738       |\n",
      "|    reward             | -0.0003799694 |\n",
      "|    std                | 1.25          |\n",
      "|    value_loss         | 3.48e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 352           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | 0.106         |\n",
      "|    reward             | 0.00036006776 |\n",
      "|    std                | 1.3           |\n",
      "|    value_loss         | 6.4e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 353          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.217       |\n",
      "|    reward             | 0.0054352395 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 0.000264     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 354          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.13        |\n",
      "|    reward             | -0.006925252 |\n",
      "|    std                | 1.42         |\n",
      "|    value_loss         | 8.18e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 353          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.162       |\n",
      "|    reward             | 0.0011846538 |\n",
      "|    std                | 1.49         |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.0353       |\n",
      "|    reward             | 0.0052139317 |\n",
      "|    std                | 1.55         |\n",
      "|    value_loss         | 6.27e-06     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 352          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.126        |\n",
      "|    reward             | 0.0034217357 |\n",
      "|    std                | 1.62         |\n",
      "|    value_loss         | 6.58e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 353          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.107        |\n",
      "|    reward             | 0.0045737494 |\n",
      "|    std                | 1.7          |\n",
      "|    value_loss         | 7.13e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 352          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.137       |\n",
      "|    reward             | 0.0023447021 |\n",
      "|    std                | 1.77         |\n",
      "|    value_loss         | 7.26e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 353          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.0431       |\n",
      "|    reward             | 0.0013811747 |\n",
      "|    std                | 1.85         |\n",
      "|    value_loss         | 1.25e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 354           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.7         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.07          |\n",
      "|    reward             | -0.0003912975 |\n",
      "|    std                | 1.94          |\n",
      "|    value_loss         | 1.88e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 354          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.142       |\n",
      "|    reward             | 0.0034594974 |\n",
      "|    std                | 2.04         |\n",
      "|    value_loss         | 6.88e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 354          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.46         |\n",
      "|    reward             | -0.001798856 |\n",
      "|    std                | 2.14         |\n",
      "|    value_loss         | 0.000544     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.08116485617140926\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_11\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 477           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0038272047 |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 457           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007309284   |\n",
      "|    clip_fraction        | 0.0597        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -4.81         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.132        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00555      |\n",
      "|    reward               | 0.00010500085 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00133       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 455           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0077897753  |\n",
      "|    clip_fraction        | 0.0987        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.469        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.132        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.0071       |\n",
      "|    reward               | -0.0002575576 |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 0.00144       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 453            |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 18             |\n",
      "|    total_timesteps      | 8192           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0066634044   |\n",
      "|    clip_fraction        | 0.0839         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | -0.00929       |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.131         |\n",
      "|    n_updates            | 30             |\n",
      "|    policy_gradient_loss | -0.00448       |\n",
      "|    reward               | -0.00034263308 |\n",
      "|    std                  | 0.999          |\n",
      "|    value_loss           | 0.000819       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 452          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008776533  |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.134       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | 0.0034102683 |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.000529     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.08133660870612641\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_11\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 158         |\n",
      "|    time_elapsed    | 52          |\n",
      "|    total_timesteps | 8304        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 227         |\n",
      "|    critic_loss     | 198         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6228        |\n",
      "|    reward          | 0.009493246 |\n",
      "------------------------------------\n",
      "day: 2075, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 8300\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "======DDPG Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======Trading from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -0.964       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.13        |\n",
      "|    reward             | -0.004145955 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.000377     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 2             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | 0.0639        |\n",
      "|    reward             | -0.0017587082 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 9.41e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 342          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.0219       |\n",
      "|    reward             | -0.010044962 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 0.000156     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 344           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 5             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.209         |\n",
      "|    reward             | -0.0053442814 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 0.000394      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 342          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.0962      |\n",
      "|    reward             | 0.0019746146 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 5.21e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 345          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.00784      |\n",
      "|    reward             | 0.0063794455 |\n",
      "|    std                | 1.2          |\n",
      "|    value_loss         | 6.28e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 347          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.145       |\n",
      "|    reward             | -0.010047967 |\n",
      "|    std                | 1.25         |\n",
      "|    value_loss         | 7.85e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 348          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.00359      |\n",
      "|    reward             | 0.0030581625 |\n",
      "|    std                | 1.31         |\n",
      "|    value_loss         | 1.24e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 348         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.134      |\n",
      "|    reward             | 0.006031292 |\n",
      "|    std                | 1.38        |\n",
      "|    value_loss         | 7.8e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 349           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.151        |\n",
      "|    reward             | -0.0026360415 |\n",
      "|    std                | 1.44          |\n",
      "|    value_loss         | 0.000104      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 350          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.0185       |\n",
      "|    reward             | 0.0028753185 |\n",
      "|    std                | 1.51         |\n",
      "|    value_loss         | 3.1e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 349          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.2          |\n",
      "|    reward             | -0.001307048 |\n",
      "|    std                | 1.57         |\n",
      "|    value_loss         | 0.000362     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 350          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.0638      |\n",
      "|    reward             | -0.007959824 |\n",
      "|    std                | 1.64         |\n",
      "|    value_loss         | 1.9e-05      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 350            |\n",
      "|    iterations         | 1400           |\n",
      "|    time_elapsed       | 19             |\n",
      "|    total_timesteps    | 7000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -17.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1399           |\n",
      "|    policy_loss        | 0.0322         |\n",
      "|    reward             | -0.00017413235 |\n",
      "|    std                | 1.7            |\n",
      "|    value_loss         | 2.11e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0606       |\n",
      "|    reward             | 0.0073584593 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 2.42e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 351         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | -0.128      |\n",
      "|    reward             | 0.004525885 |\n",
      "|    std                | 1.85        |\n",
      "|    value_loss         | 6.1e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.0401       |\n",
      "|    reward             | 0.0061328993 |\n",
      "|    std                | 1.92         |\n",
      "|    value_loss         | 6.3e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 352          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.255        |\n",
      "|    reward             | 0.0025176825 |\n",
      "|    std                | 1.98         |\n",
      "|    value_loss         | 0.000306     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 351            |\n",
      "|    iterations         | 1900           |\n",
      "|    time_elapsed       | 27             |\n",
      "|    total_timesteps    | 9500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -19.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1899           |\n",
      "|    policy_loss        | -0.168         |\n",
      "|    reward             | -0.00085646764 |\n",
      "|    std                | 2.06           |\n",
      "|    value_loss         | 0.000127       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.103        |\n",
      "|    reward             | 0.0051034396 |\n",
      "|    std                | 2.15         |\n",
      "|    value_loss         | 6.16e-05     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.3146812527383791\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_11\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 465           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | 0.00021804828 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 440          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067674685 |\n",
      "|    clip_fraction        | 0.0736       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -3.22        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.14        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | 0.0017792553 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00184      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 438           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0104587665  |\n",
      "|    clip_fraction        | 0.11          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.057         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.134        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00585      |\n",
      "|    reward               | -0.0050120447 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00287       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 439         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007035602 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.0964      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.137      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | -0.0040179  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00205     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 440          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006791761  |\n",
      "|    clip_fraction        | 0.0611       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.0797       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.128       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | 0.0061896136 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00159      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.13569882538251174\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_11\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 156        |\n",
      "|    time_elapsed    | 54         |\n",
      "|    total_timesteps | 8556       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -9.18      |\n",
      "|    critic_loss     | 65         |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 6417       |\n",
      "|    reward          | 0.01224383 |\n",
      "-----------------------------------\n",
      "day: 2138, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10017.30\n",
      "total_reward: 17.30\n",
      "total_cost: 9.99\n",
      "total_trades: 6414\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "======DDPG Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======Trading from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 290          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0876      |\n",
      "|    reward             | 0.0008929382 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 5.94e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0742      |\n",
      "|    reward             | 0.0017474525 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.000192     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.0941      |\n",
      "|    reward             | -0.023192532 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.000197     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.101       |\n",
      "|    reward             | -0.011400041 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 6.6e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.0868        |\n",
      "|    reward             | -0.0065080835 |\n",
      "|    std                | 1.17          |\n",
      "|    value_loss         | 3.96e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0853        |\n",
      "|    reward             | 0.00087290653 |\n",
      "|    std                | 1.22          |\n",
      "|    value_loss         | 4.26e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.0285       |\n",
      "|    reward             | -0.0021947026 |\n",
      "|    std                | 1.27          |\n",
      "|    value_loss         | 5.19e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.0236        |\n",
      "|    reward             | -0.0075846724 |\n",
      "|    std                | 1.34          |\n",
      "|    value_loss         | 5.96e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.00347    |\n",
      "|    reward             | 0.004272891 |\n",
      "|    std                | 1.41        |\n",
      "|    value_loss         | 4.51e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.0654      |\n",
      "|    reward             | -0.001939364 |\n",
      "|    std                | 1.47         |\n",
      "|    value_loss         | 3.99e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.107       |\n",
      "|    reward             | 0.0006796599 |\n",
      "|    std                | 1.54         |\n",
      "|    value_loss         | 5.55e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 336            |\n",
      "|    iterations         | 1200           |\n",
      "|    time_elapsed       | 17             |\n",
      "|    total_timesteps    | 6000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -17.1          |\n",
      "|    explained_variance | 1.79e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1199           |\n",
      "|    policy_loss        | 0.0477         |\n",
      "|    reward             | -0.00049579644 |\n",
      "|    std                | 1.63           |\n",
      "|    value_loss         | 1.01e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.0656       |\n",
      "|    reward             | -0.0029718333 |\n",
      "|    std                | 1.71          |\n",
      "|    value_loss         | 2.42e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.00797       |\n",
      "|    reward             | -0.0066666305 |\n",
      "|    std                | 1.79          |\n",
      "|    value_loss         | 4.13e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0366       |\n",
      "|    reward             | -0.005305511 |\n",
      "|    std                | 1.89         |\n",
      "|    value_loss         | 6.28e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.118        |\n",
      "|    reward             | 0.0012164933 |\n",
      "|    std                | 1.99         |\n",
      "|    value_loss         | 4.63e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 26            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.0885       |\n",
      "|    reward             | -0.0025586034 |\n",
      "|    std                | 2.1           |\n",
      "|    value_loss         | 2.35e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.106        |\n",
      "|    reward             | -0.007617743 |\n",
      "|    std                | 2.2          |\n",
      "|    value_loss         | 4.36e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.0315       |\n",
      "|    reward             | 0.0003240139 |\n",
      "|    std                | 2.31         |\n",
      "|    value_loss         | 3.62e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.0303       |\n",
      "|    reward             | -0.0012802843 |\n",
      "|    std                | 2.44          |\n",
      "|    value_loss         | 4.08e-06      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.31312733630697004\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_11\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 439         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 4           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.002672128 |\n",
      "------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 438           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007294178   |\n",
      "|    clip_fraction        | 0.0857        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.175        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.134        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00664      |\n",
      "|    reward               | 0.00070342753 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000698      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 432           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008538209   |\n",
      "|    clip_fraction        | 0.0758        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0188        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.147        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00601      |\n",
      "|    reward               | -0.0038131103 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000708      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 432            |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 18             |\n",
      "|    total_timesteps      | 8192           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.007800538    |\n",
      "|    clip_fraction        | 0.104          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | 0.12           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.122         |\n",
      "|    n_updates            | 30             |\n",
      "|    policy_gradient_loss | -0.00521       |\n",
      "|    reward               | -0.00092212606 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.00058        |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 430          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007968657  |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.149       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00753     |\n",
      "|    reward               | 0.0037625257 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00038      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.17407091193714497\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_11\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 125          |\n",
      "|    time_elapsed    | 70           |\n",
      "|    total_timesteps | 8808         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 559          |\n",
      "|    critic_loss     | 320          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6606         |\n",
      "|    reward          | 0.0012483567 |\n",
      "-------------------------------------\n",
      "day: 2201, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 15407\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "======DDPG Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======Trading from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.152      |\n",
      "|    reward             | 0.008927309 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.00017     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.349      |\n",
      "|    reward             | 0.007313496 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.00201     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.277        |\n",
      "|    reward             | -0.028636869 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.572      |\n",
      "|    reward             | -0.07210316 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.0019      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.0989        |\n",
      "|    reward             | -0.0018912248 |\n",
      "|    std                | 1.11          |\n",
      "|    value_loss         | 5.4e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0545        |\n",
      "|    reward             | -0.0018218441 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 1.7e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.0243      |\n",
      "|    reward             | 0.009014223 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 2.36e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -0.148      |\n",
      "|    reward             | 0.008120613 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.433        |\n",
      "|    reward             | 0.0011065804 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 0.00106      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.00395     |\n",
      "|    reward             | 0.009708733 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 3.74e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 337         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.022      |\n",
      "|    reward             | 0.009464005 |\n",
      "|    std                | 1.33        |\n",
      "|    value_loss         | 8.52e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.196       |\n",
      "|    reward             | 0.0031714274 |\n",
      "|    std                | 1.39         |\n",
      "|    value_loss         | 0.000178     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16           |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.0822        |\n",
      "|    reward             | -0.0062392475 |\n",
      "|    std                | 1.43          |\n",
      "|    value_loss         | 5.79e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0409       |\n",
      "|    reward             | 0.0013340896 |\n",
      "|    std                | 1.49         |\n",
      "|    value_loss         | 1.14e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0546      |\n",
      "|    reward             | 0.0011479282 |\n",
      "|    std                | 1.55         |\n",
      "|    value_loss         | 1.46e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.161        |\n",
      "|    reward             | -0.005923542 |\n",
      "|    std                | 1.63         |\n",
      "|    value_loss         | 0.000229     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.647       |\n",
      "|    reward             | -0.011242276 |\n",
      "|    std                | 1.69         |\n",
      "|    value_loss         | 0.00142      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 338         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.135       |\n",
      "|    reward             | 0.023690907 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 0.000253    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.112       |\n",
      "|    reward             | -0.004278661 |\n",
      "|    std                | 1.8          |\n",
      "|    value_loss         | 6.22e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.14         |\n",
      "|    reward             | -0.004014917 |\n",
      "|    std                | 1.87         |\n",
      "|    value_loss         | 0.000109     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.6944304539766694\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_11\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 438           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0027693578 |\n",
      "--------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 425            |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.007180102    |\n",
      "|    clip_fraction        | 0.0764         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | -4.63          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.121         |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | -0.00559       |\n",
      "|    reward               | -0.00042023015 |\n",
      "|    std                  | 0.998          |\n",
      "|    value_loss           | 0.00128        |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073970975 |\n",
      "|    clip_fraction        | 0.0771       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.0277      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.138       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | -0.000629974 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00208      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 409           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0071567902  |\n",
      "|    clip_fraction        | 0.0743        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0959        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.14         |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00375      |\n",
      "|    reward               | -0.0032471786 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00122       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009214434  |\n",
      "|    clip_fraction        | 0.0804       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.204        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.118       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | 0.0033042913 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000796     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.8015484087104054\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_11\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 161         |\n",
      "|    time_elapsed    | 56          |\n",
      "|    total_timesteps | 9060        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.34e+03    |\n",
      "|    critic_loss     | 1.08e+03    |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6795        |\n",
      "|    reward          | -0.02004017 |\n",
      "------------------------------------\n",
      "day: 2264, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10049.41\n",
      "total_reward: 49.41\n",
      "total_cost: 9.99\n",
      "total_trades: 6792\n",
      "Sharpe: 0.238\n",
      "=================================\n",
      "======DDPG Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======Trading from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 304            |\n",
      "|    iterations         | 100            |\n",
      "|    time_elapsed       | 1              |\n",
      "|    total_timesteps    | 500            |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.2          |\n",
      "|    explained_variance | -9.72          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 99             |\n",
      "|    policy_loss        | 0.00409        |\n",
      "|    reward             | -0.00050459063 |\n",
      "|    std                | 1.05           |\n",
      "|    value_loss         | 9.47e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 296         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | -0.0391     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.0583     |\n",
      "|    reward             | 0.003726681 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.000114    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.0868     |\n",
      "|    reward             | -0.01882526 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.000131    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 281          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.226       |\n",
      "|    reward             | -0.012546061 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 0.000306     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.104        |\n",
      "|    reward             | 0.0010671566 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 5.65e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 289           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.038        |\n",
      "|    reward             | -0.0002951495 |\n",
      "|    std                | 1.21          |\n",
      "|    value_loss         | 1.59e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 290           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | -12.9         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.354         |\n",
      "|    reward             | 0.00050947035 |\n",
      "|    std                | 1.26          |\n",
      "|    value_loss         | 0.00155       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 289          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.000695    |\n",
      "|    reward             | -0.002451939 |\n",
      "|    std                | 1.31         |\n",
      "|    value_loss         | 4.1e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 291          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.111       |\n",
      "|    reward             | 0.0009856347 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 4.2e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 291           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.0328       |\n",
      "|    reward             | -0.0015318741 |\n",
      "|    std                | 1.45          |\n",
      "|    value_loss         | 9.09e-06      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 294            |\n",
      "|    iterations         | 1100           |\n",
      "|    time_elapsed       | 18             |\n",
      "|    total_timesteps    | 5500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1099           |\n",
      "|    policy_loss        | -0.0871        |\n",
      "|    reward             | -0.00029134215 |\n",
      "|    std                | 1.53           |\n",
      "|    value_loss         | 3.34e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 295           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | -0.0867       |\n",
      "|    reward             | 0.00056332856 |\n",
      "|    std                | 1.62          |\n",
      "|    value_loss         | 3.21e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 293          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.0428       |\n",
      "|    reward             | 0.0017821322 |\n",
      "|    std                | 1.72         |\n",
      "|    value_loss         | 9.93e-06     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 294          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0669       |\n",
      "|    reward             | 0.0012489804 |\n",
      "|    std                | 1.81         |\n",
      "|    value_loss         | 2.34e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 296           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | -0.0617       |\n",
      "|    reward             | 0.00042932015 |\n",
      "|    std                | 1.9           |\n",
      "|    value_loss         | 1.05e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 294           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.117         |\n",
      "|    reward             | -0.0006881247 |\n",
      "|    std                | 2.01          |\n",
      "|    value_loss         | 4.3e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 294           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.0281       |\n",
      "|    reward             | -0.0007110064 |\n",
      "|    std                | 2.13          |\n",
      "|    value_loss         | 5.3e-06       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 293         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.0635      |\n",
      "|    reward             | -0.00272609 |\n",
      "|    std                | 2.26        |\n",
      "|    value_loss         | 1.2e-05     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 292        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 0.079      |\n",
      "|    reward             | 0.00163899 |\n",
      "|    std                | 2.39       |\n",
      "|    value_loss         | 1.69e-05   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 292            |\n",
      "|    iterations         | 2000           |\n",
      "|    time_elapsed       | 34             |\n",
      "|    total_timesteps    | 10000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -21.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1999           |\n",
      "|    policy_loss        | -0.0747        |\n",
      "|    reward             | -4.2853546e-05 |\n",
      "|    std                | 2.51           |\n",
      "|    value_loss         | 1.65e-05       |\n",
      "------------------------------------------\n",
      "======A2C Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.18659800904931786\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_11\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 375         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 5           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.004884427 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 362          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072588394 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -7.27        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.143       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00846     |\n",
      "|    reward               | 0.0036482762 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00121      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006917357 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.0111      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.133      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    reward               | 0.012056688 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.000784    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 352           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006391854   |\n",
      "|    clip_fraction        | 0.0542        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.525        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.132        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00587      |\n",
      "|    reward               | 0.00057302887 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00068       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 350           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0061250296  |\n",
      "|    clip_fraction        | 0.0541        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0106        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.128        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00442      |\n",
      "|    reward               | 0.00031745297 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000654      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.04542609270529556\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_11\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 136           |\n",
      "|    time_elapsed    | 68            |\n",
      "|    total_timesteps | 9312          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 655           |\n",
      "|    critic_loss     | 375           |\n",
      "|    learning_rate   | 0.0005        |\n",
      "|    n_updates       | 6984          |\n",
      "|    reward          | -0.0009732113 |\n",
      "--------------------------------------\n",
      "day: 2327, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10035.33\n",
      "total_reward: 35.33\n",
      "total_cost: 9.99\n",
      "total_trades: 11635\n",
      "Sharpe: 0.239\n",
      "=================================\n",
      "======DDPG Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======Trading from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 292          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.177       |\n",
      "|    reward             | -0.004296363 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.000229     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 0.133       |\n",
      "|    reward             | 0.014326201 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.000188    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.399      |\n",
      "|    reward             | -0.03808394 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.00118     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.194       |\n",
      "|    reward             | 0.0025133942 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.000205     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.063        |\n",
      "|    reward             | 0.0077406103 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 3.46e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 326            |\n",
      "|    iterations         | 600            |\n",
      "|    time_elapsed       | 9              |\n",
      "|    total_timesteps    | 3000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 599            |\n",
      "|    policy_loss        | 0.0547         |\n",
      "|    reward             | -0.00016289369 |\n",
      "|    std                | 1.14           |\n",
      "|    value_loss         | 2.4e-05        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.102        |\n",
      "|    reward             | 0.0017983277 |\n",
      "|    std                | 1.19         |\n",
      "|    value_loss         | 5.56e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.0348      |\n",
      "|    reward             | 0.0038723617 |\n",
      "|    std                | 1.24         |\n",
      "|    value_loss         | 1.35e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.0818      |\n",
      "|    reward             | 0.005424123 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 5.51e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.101         |\n",
      "|    reward             | -0.0036282921 |\n",
      "|    std                | 1.35          |\n",
      "|    value_loss         | 4.46e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.0967        |\n",
      "|    reward             | -0.0047387374 |\n",
      "|    std                | 1.42          |\n",
      "|    value_loss         | 4.05e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.091        |\n",
      "|    reward             | 0.0021725483 |\n",
      "|    std                | 1.49         |\n",
      "|    value_loss         | 4.21e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 304           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.0494        |\n",
      "|    reward             | 0.00087846164 |\n",
      "|    std                | 1.57          |\n",
      "|    value_loss         | 2.21e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 302        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 0.307      |\n",
      "|    reward             | -0.0229668 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 0.000416   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0554      |\n",
      "|    reward             | 0.0030629158 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 1.87e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.0497       |\n",
      "|    reward             | 0.0018165584 |\n",
      "|    std                | 1.8          |\n",
      "|    value_loss         | 8.21e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 298           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.0474       |\n",
      "|    reward             | -7.029658e-05 |\n",
      "|    std                | 1.9           |\n",
      "|    value_loss         | 7.91e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 299         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.0769      |\n",
      "|    reward             | 0.004323695 |\n",
      "|    std                | 2           |\n",
      "|    value_loss         | 2.28e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0939      |\n",
      "|    reward             | 0.0005286109 |\n",
      "|    std                | 2.11         |\n",
      "|    value_loss         | 7.01e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 299         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 0.125       |\n",
      "|    reward             | 0.007041048 |\n",
      "|    std                | 2.22        |\n",
      "|    value_loss         | 8.65e-05    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.01038222593560576\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_11\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 365          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 5            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.015412079 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 330           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 12            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00742367    |\n",
      "|    clip_fraction        | 0.0752        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -1.68         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.143        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00682      |\n",
      "|    reward               | -0.0035267577 |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 0.00112       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 335          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010380041  |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.125       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | 7.144386e-06 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.00199      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 341           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009220025   |\n",
      "|    clip_fraction        | 0.0679        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0634        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.125        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00474      |\n",
      "|    reward               | 9.2868635e-05 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00116       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 342          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00707193   |\n",
      "|    clip_fraction        | 0.0773       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.184        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.125       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | 0.0009901848 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000772     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.06171627835145619\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_11\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 140         |\n",
      "|    time_elapsed    | 68          |\n",
      "|    total_timesteps | 9564        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -612        |\n",
      "|    critic_loss     | 357         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7173        |\n",
      "|    reward          | 0.008683494 |\n",
      "------------------------------------\n",
      "day: 2390, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10037.77\n",
      "total_reward: 37.77\n",
      "total_cost: 9.99\n",
      "total_trades: 7170\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "======DDPG Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======Trading from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_567_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 289           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.0393       |\n",
      "|    reward             | -0.0015983571 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 1.8e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 0.243       |\n",
      "|    reward             | 0.014192032 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.000419    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.0794      |\n",
      "|    reward             | -0.025407445 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.000268     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 6             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.102         |\n",
      "|    reward             | -0.0036502506 |\n",
      "|    std                | 1.11          |\n",
      "|    value_loss         | 0.0001        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.0108      |\n",
      "|    reward             | 0.006517662 |\n",
      "|    std                | 1.13        |\n",
      "|    value_loss         | 1.71e-06    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 600            |\n",
      "|    time_elapsed       | 9              |\n",
      "|    total_timesteps    | 3000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 599            |\n",
      "|    policy_loss        | 0.0705         |\n",
      "|    reward             | -0.00090637023 |\n",
      "|    std                | 1.17           |\n",
      "|    value_loss         | 3.11e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.5         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.0325       |\n",
      "|    reward             | -0.0063852663 |\n",
      "|    std                | 1.22          |\n",
      "|    value_loss         | 1.59e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.137       |\n",
      "|    reward             | 0.005490484 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 0.000167    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.194        |\n",
      "|    reward             | -0.009846745 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 0.0002       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.0341      |\n",
      "|    reward             | 0.004329935 |\n",
      "|    std                | 1.38        |\n",
      "|    value_loss         | 4.37e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.0731       |\n",
      "|    reward             | -0.0021658223 |\n",
      "|    std                | 1.44          |\n",
      "|    value_loss         | 3.06e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0574       |\n",
      "|    reward             | 0.0052146693 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 2.64e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.0826      |\n",
      "|    reward             | 0.0032002304 |\n",
      "|    std                | 1.6          |\n",
      "|    value_loss         | 5.35e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.101       |\n",
      "|    reward             | 0.0011939248 |\n",
      "|    std                | 1.7          |\n",
      "|    value_loss         | 3.27e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.00336      |\n",
      "|    reward             | 0.0010761714 |\n",
      "|    std                | 1.8          |\n",
      "|    value_loss         | 4.26e-07     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 328            |\n",
      "|    iterations         | 1600           |\n",
      "|    time_elapsed       | 24             |\n",
      "|    total_timesteps    | 8000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1599           |\n",
      "|    policy_loss        | -0.09          |\n",
      "|    reward             | -0.00058538077 |\n",
      "|    std                | 1.9            |\n",
      "|    value_loss         | 2.85e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.0852       |\n",
      "|    reward             | -0.0022847692 |\n",
      "|    std                | 2.01          |\n",
      "|    value_loss         | 3.95e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.0357        |\n",
      "|    reward             | -0.0004305893 |\n",
      "|    std                | 2.13          |\n",
      "|    value_loss         | 1.14e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.0813        |\n",
      "|    reward             | 3.7445672e-05 |\n",
      "|    std                | 2.27          |\n",
      "|    value_loss         | 1.34e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 329            |\n",
      "|    iterations         | 2000           |\n",
      "|    time_elapsed       | 30             |\n",
      "|    total_timesteps    | 10000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -20.7          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1999           |\n",
      "|    policy_loss        | 0.0727         |\n",
      "|    reward             | -0.00058298593 |\n",
      "|    std                | 2.41           |\n",
      "|    value_loss         | 1.69e-05       |\n",
      "------------------------------------------\n",
      "======A2C Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.13435997765275692\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_567_11\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 435          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0017888559 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 419           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006532482   |\n",
      "|    clip_fraction        | 0.0659        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -4.25         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.13         |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00378      |\n",
      "|    reward               | -0.0014350384 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00165       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 414          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005997493  |\n",
      "|    clip_fraction        | 0.0688       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.491       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.152       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | -0.008337578 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000546     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008326242  |\n",
      "|    clip_fraction        | 0.0925       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | -0.298       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.144       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    reward               | 0.0030072082 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000228     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 408          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045153154 |\n",
      "|    clip_fraction        | 0.0533       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.167        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.126       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | -0.001576959 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000344     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.02116804955819361\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_567_11\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 152          |\n",
      "|    time_elapsed    | 64           |\n",
      "|    total_timesteps | 9816         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -337         |\n",
      "|    critic_loss     | 131          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 7362         |\n",
      "|    reward          | -0.022717545 |\n",
      "-------------------------------------\n",
      "day: 2453, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.02\n",
      "total_reward: -9.98\n",
      "total_cost: 9.98\n",
      "total_trades: 9812\n",
      "Sharpe: 0.193\n",
      "=================================\n",
      "======DDPG Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======Trading from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_630_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 289         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.047      |\n",
      "|    reward             | 0.007246319 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 4.27e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.3      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 0.192      |\n",
      "|    reward             | 0.00416614 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.000177   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.189        |\n",
      "|    reward             | -0.0039089164 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.000269      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.342       |\n",
      "|    reward             | -0.021368679 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.000659     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.228       |\n",
      "|    reward             | -0.009976507 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.000273     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.141        |\n",
      "|    reward             | -0.0012679683 |\n",
      "|    std                | 1.16          |\n",
      "|    value_loss         | 9.38e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.0923      |\n",
      "|    reward             | -0.004211746 |\n",
      "|    std                | 1.2          |\n",
      "|    value_loss         | 3.92e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.0618        |\n",
      "|    reward             | -0.0034655456 |\n",
      "|    std                | 1.26          |\n",
      "|    value_loss         | 3.85e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.00785      |\n",
      "|    reward             | -0.001462857 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 2.24e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.235      |\n",
      "|    reward             | 0.007996658 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 0.0023      |\n",
      "|    reward             | 0.006797179 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 9.27e-06    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 320            |\n",
      "|    iterations         | 1200           |\n",
      "|    time_elapsed       | 18             |\n",
      "|    total_timesteps    | 6000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1199           |\n",
      "|    policy_loss        | -0.021         |\n",
      "|    reward             | -0.00083250273 |\n",
      "|    std                | 1.54           |\n",
      "|    value_loss         | 6.13e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.131         |\n",
      "|    reward             | -0.0056684874 |\n",
      "|    std                | 1.62          |\n",
      "|    value_loss         | 5.61e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.0828        |\n",
      "|    reward             | 0.00040981435 |\n",
      "|    std                | 1.68          |\n",
      "|    value_loss         | 3.17e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0291       |\n",
      "|    reward             | 0.0053448486 |\n",
      "|    std                | 1.75         |\n",
      "|    value_loss         | 2.38e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.151         |\n",
      "|    reward             | -0.0016830795 |\n",
      "|    std                | 1.83          |\n",
      "|    value_loss         | 9.7e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.0832      |\n",
      "|    reward             | 0.0076673073 |\n",
      "|    std                | 1.92         |\n",
      "|    value_loss         | 2.37e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.141        |\n",
      "|    reward             | -0.0046551623 |\n",
      "|    std                | 2.02          |\n",
      "|    value_loss         | 8.24e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | -0.0436       |\n",
      "|    reward             | -0.0022807026 |\n",
      "|    std                | 2.13          |\n",
      "|    value_loss         | 6.28e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.302        |\n",
      "|    reward             | 0.0041060187 |\n",
      "|    std                | 2.23         |\n",
      "|    value_loss         | 0.00025      |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.09328498999677018\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_630_11\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 439          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0016867481 |\n",
      "-------------------------------------\n",
      "day: 2516, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 1130.18\n",
      "total_reward: -8869.82\n",
      "total_cost: 3212.94\n",
      "total_trades: 14022\n",
      "Sharpe: -0.382\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 423           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004789155   |\n",
      "|    clip_fraction        | 0.0508        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.831         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.134        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00275      |\n",
      "|    reward               | -0.0014166264 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000163      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 416          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008835511  |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.139       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00838     |\n",
      "|    reward               | -0.002154883 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000619     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 413            |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 19             |\n",
      "|    total_timesteps      | 8192           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.008607313    |\n",
      "|    clip_fraction        | 0.106          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | -0.307         |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.144         |\n",
      "|    n_updates            | 30             |\n",
      "|    policy_gradient_loss | -0.00856       |\n",
      "|    reward               | -0.00070889405 |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 0.000525       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074665025 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.127       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | 0.0036761812 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00036      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.20248774378110906\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_630_11\n",
      "day: 2516, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 44314.41\n",
      "total_reward: 34314.41\n",
      "total_cost: 484.65\n",
      "total_trades: 5566\n",
      "Sharpe: 1.037\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 161          |\n",
      "|    time_elapsed    | 62           |\n",
      "|    total_timesteps | 10068        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -294         |\n",
      "|    critic_loss     | 120          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 7551         |\n",
      "|    reward          | -0.019073663 |\n",
      "-------------------------------------\n",
      "======DDPG Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======Trading from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_693_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 288          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.00213     |\n",
      "|    reward             | 0.0017693507 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 1.24e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 305           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.499        |\n",
      "|    reward             | -0.0077633215 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 0.00145       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.0474      |\n",
      "|    reward             | -0.013785008 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.000195     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 6             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.219         |\n",
      "|    reward             | -0.0028183144 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 0.00066       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | -0.134        |\n",
      "|    reward             | -0.0013460309 |\n",
      "|    std                | 1.16          |\n",
      "|    value_loss         | 0.00011       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.107        |\n",
      "|    reward             | -0.008866813 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 0.00013      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.0944       |\n",
      "|    reward             | 0.0006255146 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 4.19e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.0195       |\n",
      "|    reward             | -0.004335905 |\n",
      "|    std                | 1.26         |\n",
      "|    value_loss         | 3.09e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.0204       |\n",
      "|    reward             | -0.0023990015 |\n",
      "|    std                | 1.32          |\n",
      "|    value_loss         | 2.43e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.0871        |\n",
      "|    reward             | -0.0011419067 |\n",
      "|    std                | 1.39          |\n",
      "|    value_loss         | 4.37e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.0449       |\n",
      "|    reward             | 0.0030287125 |\n",
      "|    std                | 1.45         |\n",
      "|    value_loss         | 1.47e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0567       |\n",
      "|    reward             | 0.0014843141 |\n",
      "|    std                | 1.5          |\n",
      "|    value_loss         | 1.29e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 0.0866      |\n",
      "|    reward             | 0.004287465 |\n",
      "|    std                | 1.56        |\n",
      "|    value_loss         | 4.32e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | -0.0133       |\n",
      "|    reward             | -0.0010226624 |\n",
      "|    std                | 1.63          |\n",
      "|    value_loss         | 9.03e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0858      |\n",
      "|    reward             | 0.0051129055 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 3.2e-05      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 318            |\n",
      "|    iterations         | 1600           |\n",
      "|    time_elapsed       | 25             |\n",
      "|    total_timesteps    | 8000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -17.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1599           |\n",
      "|    policy_loss        | 0.0504         |\n",
      "|    reward             | -0.00041147566 |\n",
      "|    std                | 1.76           |\n",
      "|    value_loss         | 1.87e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.245        |\n",
      "|    reward             | 0.0015688189 |\n",
      "|    std                | 1.84         |\n",
      "|    value_loss         | 0.000205     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.00267      |\n",
      "|    reward             | -0.0007924657 |\n",
      "|    std                | 1.93          |\n",
      "|    value_loss         | 1.43e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0883      |\n",
      "|    reward             | 0.0019180906 |\n",
      "|    std                | 2.01         |\n",
      "|    value_loss         | 3.01e-05     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 319       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -19.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -0.531    |\n",
      "|    reward             | 0.0125938 |\n",
      "|    std                | 2.09      |\n",
      "|    value_loss         | 0.000857  |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.20951264275757153\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_693_11\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 425           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0008579502 |\n",
      "--------------------------------------\n",
      "day: 2579, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 1940.02\n",
      "total_reward: -8059.98\n",
      "total_cost: 7410.11\n",
      "total_trades: 15331\n",
      "Sharpe: -0.371\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 413           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010410843   |\n",
      "|    clip_fraction        | 0.129         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -4.17         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.0938       |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00487      |\n",
      "|    reward               | 0.00033532086 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00149       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064646634 |\n",
      "|    clip_fraction        | 0.0598       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0127       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.144       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | -0.001993468 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00218      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 408         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008815044 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.047       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.131      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | 0.016651133 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0014      |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 400           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009651246   |\n",
      "|    clip_fraction        | 0.11          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0155        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.139        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00581      |\n",
      "|    reward               | -0.0011534067 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00129       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.03235601341891779\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_693_11\n",
      "day: 2579, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9994.30\n",
      "total_reward: -5.70\n",
      "total_cost: 9.99\n",
      "total_trades: 20632\n",
      "Sharpe: 0.193\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 156         |\n",
      "|    time_elapsed    | 65          |\n",
      "|    total_timesteps | 10320       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 54.9        |\n",
      "|    critic_loss     | 108         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7740        |\n",
      "|    reward          | 0.022724614 |\n",
      "------------------------------------\n",
      "======DDPG Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-07-06T00:00:00.000000000\n",
      "======Trading from:  2020-07-06T00:00:00.000000000 to  2020-10-02T00:00:00.000000000\n",
      "Ensemble Strategy took:  24.443182416756947  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs, PPO_model_kwargs, DDPG_model_kwargs, timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.432486</td>\n",
       "      <td>-0.242943</td>\n",
       "      <td>-0.199786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.081165</td>\n",
       "      <td>-0.081337</td>\n",
       "      <td>0.063708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.314681</td>\n",
       "      <td>0.135699</td>\n",
       "      <td>0.252091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>-0.313127</td>\n",
       "      <td>-0.174071</td>\n",
       "      <td>-0.218579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.69443</td>\n",
       "      <td>0.801548</td>\n",
       "      <td>0.551737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.186598</td>\n",
       "      <td>-0.045426</td>\n",
       "      <td>0.380683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>0.061716</td>\n",
       "      <td>0.099379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.13436</td>\n",
       "      <td>-0.021168</td>\n",
       "      <td>0.080388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.093285</td>\n",
       "      <td>-0.202488</td>\n",
       "      <td>0.118578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.209513</td>\n",
       "      <td>0.032356</td>\n",
       "      <td>0.3365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter  Val Start    Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126 2018-01-02 2018-04-04       DDPG  -0.432486  -0.242943   -0.199786\n",
       "1  189 2018-04-04 2018-07-03       DDPG  -0.081165  -0.081337    0.063708\n",
       "2  252 2018-07-03 2018-10-02        A2C   0.314681   0.135699    0.252091\n",
       "3  315 2018-10-02 2019-01-03        PPO  -0.313127  -0.174071   -0.218579\n",
       "4  378 2019-01-03 2019-04-04        PPO    0.69443   0.801548    0.551737\n",
       "5  441 2019-04-04 2019-07-05       DDPG   0.186598  -0.045426    0.380683\n",
       "6  504 2019-07-05 2019-10-03       DDPG   0.010382   0.061716    0.099379\n",
       "7  567 2019-10-03 2020-01-03       DDPG   -0.13436  -0.021168    0.080388\n",
       "8  630 2020-01-03 2020-04-03       DDPG  -0.093285  -0.202488    0.118578\n",
       "9  693 2020-04-03 2020-07-06       DDPG   0.209513   0.032356      0.3365"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10079.479603</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>0.007948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9924.454502</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>-0.015380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9957.314686</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>0.003311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010.884480</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>0.005380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>14152.119266</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>0.020194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>14318.897842</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>0.011785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>14228.380480</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>-0.006322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>14354.006153</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>0.008829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>14478.012785</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0.008639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     account_value        date  daily_return\n",
       "0     10000.000000  2018-04-04           NaN\n",
       "1     10079.479603  2018-04-05      0.007948\n",
       "2      9924.454502  2018-04-06     -0.015380\n",
       "3      9957.314686  2018-04-09      0.003311\n",
       "4     10010.884480  2018-04-10      0.005380\n",
       "..             ...         ...           ...\n",
       "625   14152.119266  2020-09-25      0.020194\n",
       "626   14318.897842  2020-09-28      0.011785\n",
       "627   14228.380480  2020-09-29     -0.006322\n",
       "628   14354.006153  2020-09-30      0.008829\n",
       "629   14478.012785  2020-10-01      0.008639\n",
       "\n",
       "[630 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "# for every cycle (rebalance_window + validation_window) read the csv files into a dataframe\n",
    "for i in range(rebalance_window+validation_window, len(test_dates)+1,rebalance_window):\n",
    "     result_df = pd.read_csv(f'results/account_value_trade_ensemble_{i}.csv')\n",
    "     results_list.append(result_df)\n",
    "\n",
    "df_ensemble_results  = pd.concat(results_list, ignore_index=True)  # Create a dataframe to store execution results\n",
    "\n",
    "df_ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-01-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_15\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | 0.0228        |\n",
      "|    reward             | -0.0076047475 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 0.000398      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 351           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 2             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | 0.0774        |\n",
      "|    reward             | 0.00014288197 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 9.01e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 359          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.239       |\n",
      "|    reward             | -0.014676867 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 0.000544     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 365           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 5             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.23          |\n",
      "|    reward             | 0.00018293152 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 0.000406      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 363         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.119       |\n",
      "|    reward             | 0.001483902 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 8e-05       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 366           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.0617       |\n",
      "|    reward             | -0.0017780266 |\n",
      "|    std                | 1.19          |\n",
      "|    value_loss         | 1.76e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 369           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.123         |\n",
      "|    reward             | -0.0036882313 |\n",
      "|    std                | 1.25          |\n",
      "|    value_loss         | 0.000129      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 370          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.169        |\n",
      "|    reward             | -0.006455175 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 0.000221     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 368           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.0898       |\n",
      "|    reward             | -0.0070795994 |\n",
      "|    std                | 1.37          |\n",
      "|    value_loss         | 5.21e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 369          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.00868      |\n",
      "|    reward             | 0.0034500977 |\n",
      "|    std                | 1.43         |\n",
      "|    value_loss         | 3.65e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 369          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.165       |\n",
      "|    reward             | 0.0052446635 |\n",
      "|    std                | 1.5          |\n",
      "|    value_loss         | 0.000115     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 369           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.0153        |\n",
      "|    reward             | 0.00043307588 |\n",
      "|    std                | 1.57          |\n",
      "|    value_loss         | 1.64e-06      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 368           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.0396        |\n",
      "|    reward             | 0.00037701047 |\n",
      "|    std                | 1.65          |\n",
      "|    value_loss         | 1.14e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 368           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.0492        |\n",
      "|    reward             | 0.00014366193 |\n",
      "|    std                | 1.74          |\n",
      "|    value_loss         | 1.3e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 369          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0081       |\n",
      "|    reward             | 0.0034075503 |\n",
      "|    std                | 1.85         |\n",
      "|    value_loss         | 4.1e-06      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 369           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.0531        |\n",
      "|    reward             | -0.0023555572 |\n",
      "|    std                | 1.96          |\n",
      "|    value_loss         | 8.42e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 368         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.0439     |\n",
      "|    reward             | 0.008396323 |\n",
      "|    std                | 2.07        |\n",
      "|    value_loss         | 2.57e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 369          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.0303      |\n",
      "|    reward             | 0.0015844853 |\n",
      "|    std                | 2.19         |\n",
      "|    value_loss         | 3.24e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 369          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.156       |\n",
      "|    reward             | 0.0027476307 |\n",
      "|    std                | 2.31         |\n",
      "|    value_loss         | 5.59e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 369         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.0658     |\n",
      "|    reward             | 0.001576684 |\n",
      "|    std                | 2.45        |\n",
      "|    value_loss         | 9.49e-06    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.3549780971080988\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_15\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 510          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0026926917 |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 475          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067179366 |\n",
      "|    clip_fraction        | 0.0617       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -4.85        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.123       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 0.0015734683 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00643      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 467           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0059580496  |\n",
      "|    clip_fraction        | 0.0825        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.481         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.142        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00703      |\n",
      "|    reward               | -0.0067661605 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000159      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 467         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006395847 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.135      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | 0.004424092 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.17e-05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2012, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 1722.55\n",
      "total_reward: -8277.45\n",
      "total_cost: 4254.29\n",
      "total_trades: 11770\n",
      "Sharpe: -0.556\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 466            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 21             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.005908146    |\n",
      "|    clip_fraction        | 0.0584         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | 0.543          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.136         |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00409       |\n",
      "|    reward               | -0.00060590985 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.000152       |\n",
      "--------------------------------------------\n",
      "======PPO Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.35052332783469803\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_15\n",
      "day: 2012, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 8048\n",
      "Sharpe: 0.214\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 172           |\n",
      "|    time_elapsed    | 46            |\n",
      "|    total_timesteps | 8052          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -113          |\n",
      "|    critic_loss     | 66.1          |\n",
      "|    learning_rate   | 0.0005        |\n",
      "|    n_updates       | 6039          |\n",
      "|    reward          | -0.0037865173 |\n",
      "--------------------------------------\n",
      "======DDPG Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======Trading from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.27         |\n",
      "|    reward             | -0.0033663067 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 0.000648      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 344          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0649      |\n",
      "|    reward             | 0.0016743958 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.000121     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 354          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.321       |\n",
      "|    reward             | -0.014385182 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 0.000667     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 359           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 5             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | -0.0503       |\n",
      "|    reward             | -0.0036420317 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 1.73e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 357           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 6             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.124         |\n",
      "|    reward             | 0.00011200854 |\n",
      "|    std                | 1.16          |\n",
      "|    value_loss         | 9.25e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 360           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.134        |\n",
      "|    reward             | 0.00036591763 |\n",
      "|    std                | 1.21          |\n",
      "|    value_loss         | 0.000122      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 362          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -1.74        |\n",
      "|    reward             | -0.003320144 |\n",
      "|    std                | 1.26         |\n",
      "|    value_loss         | 0.0134       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 363           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.00828      |\n",
      "|    reward             | -0.0017627078 |\n",
      "|    std                | 1.32          |\n",
      "|    value_loss         | 9.14e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 361           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.121        |\n",
      "|    reward             | -0.0012461313 |\n",
      "|    std                | 1.37          |\n",
      "|    value_loss         | 6.04e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 362          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.115       |\n",
      "|    reward             | 0.0007559541 |\n",
      "|    std                | 1.43         |\n",
      "|    value_loss         | 7.24e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 363          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.118       |\n",
      "|    reward             | -0.002099593 |\n",
      "|    std                | 1.5          |\n",
      "|    value_loss         | 7.36e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 364           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | -0.148        |\n",
      "|    reward             | -0.0036955574 |\n",
      "|    std                | 1.58          |\n",
      "|    value_loss         | 9.28e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 362         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 0.0429      |\n",
      "|    reward             | 0.004779031 |\n",
      "|    std                | 1.66        |\n",
      "|    value_loss         | 9.12e-06    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 362          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.116        |\n",
      "|    reward             | 0.0030795622 |\n",
      "|    std                | 1.73         |\n",
      "|    value_loss         | 5.52e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 362         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.101       |\n",
      "|    reward             | 0.004012691 |\n",
      "|    std                | 1.82        |\n",
      "|    value_loss         | 6.41e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 361          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.126       |\n",
      "|    reward             | 0.0021601655 |\n",
      "|    std                | 1.91         |\n",
      "|    value_loss         | 5.5e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 361          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.0414       |\n",
      "|    reward             | 0.0014763412 |\n",
      "|    std                | 2            |\n",
      "|    value_loss         | 9.41e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 357           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.108         |\n",
      "|    reward             | -0.0005049791 |\n",
      "|    std                | 2.1           |\n",
      "|    value_loss         | 3.72e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 346         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.164      |\n",
      "|    reward             | 0.003996413 |\n",
      "|    std                | 2.2         |\n",
      "|    value_loss         | 8.12e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 341            |\n",
      "|    iterations         | 2000           |\n",
      "|    time_elapsed       | 29             |\n",
      "|    total_timesteps    | 10000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -20.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1999           |\n",
      "|    policy_loss        | 0.454          |\n",
      "|    reward             | -0.00024101538 |\n",
      "|    std                | 2.32           |\n",
      "|    value_loss         | 0.000574       |\n",
      "------------------------------------------\n",
      "======A2C Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.11649690713049783\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_12\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 347           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 5             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0004979949 |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 352           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 11            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0064286124  |\n",
      "|    clip_fraction        | 0.052         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -3.6          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.116        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00308      |\n",
      "|    reward               | -0.0035621005 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00314       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 381            |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 16             |\n",
      "|    total_timesteps      | 6144           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.008174393    |\n",
      "|    clip_fraction        | 0.0792         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | 0.0768         |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.135         |\n",
      "|    n_updates            | 20             |\n",
      "|    policy_gradient_loss | -0.00474       |\n",
      "|    reward               | -0.00047276326 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.000533       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 397           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006732575   |\n",
      "|    clip_fraction        | 0.0736        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.189         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.134        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00678      |\n",
      "|    reward               | -0.0023438898 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000462      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043797116 |\n",
      "|    clip_fraction        | 0.0454       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.131        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.124       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 0.0007659756 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000371     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.19090686397485263\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_12\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 163         |\n",
      "|    time_elapsed    | 50          |\n",
      "|    total_timesteps | 8304        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 154         |\n",
      "|    critic_loss     | 114         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6228        |\n",
      "|    reward          | 0.009755521 |\n",
      "------------------------------------\n",
      "day: 2075, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10016.05\n",
      "total_reward: 16.05\n",
      "total_cost: 9.99\n",
      "total_trades: 10375\n",
      "Sharpe: 0.215\n",
      "=================================\n",
      "======DDPG Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======Trading from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.108      |\n",
      "|    reward             | 0.004030388 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.000102    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.257       |\n",
      "|    reward             | 0.0023641856 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.000627     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.205      |\n",
      "|    reward             | -0.03019576 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.000628    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | 0.0074331635 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.000426     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -0.133      |\n",
      "|    reward             | 0.005739412 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 0.000183    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 344         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -0.216      |\n",
      "|    reward             | 0.008444542 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.00033     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 346         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -0.507      |\n",
      "|    reward             | 0.008590811 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 0.00133     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 349         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -0.33       |\n",
      "|    reward             | 0.019996537 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 0.000902    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 348         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.00969    |\n",
      "|    reward             | 0.005507213 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 1.15e-06    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 350           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.208        |\n",
      "|    reward             | -0.0017353082 |\n",
      "|    std                | 1.31          |\n",
      "|    value_loss         | 0.000184      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 352          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.205        |\n",
      "|    reward             | 0.0012904304 |\n",
      "|    std                | 1.35         |\n",
      "|    value_loss         | 0.000266     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 352           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.0046        |\n",
      "|    reward             | -0.0015373691 |\n",
      "|    std                | 1.41          |\n",
      "|    value_loss         | 2.78e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 353           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.146        |\n",
      "|    reward             | -0.0034977403 |\n",
      "|    std                | 1.48          |\n",
      "|    value_loss         | 7.95e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 354           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.0215        |\n",
      "|    reward             | -0.0012572893 |\n",
      "|    std                | 1.55          |\n",
      "|    value_loss         | 5.78e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 355           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | 0.0289        |\n",
      "|    reward             | 0.00073225173 |\n",
      "|    std                | 1.64          |\n",
      "|    value_loss         | 1.36e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 354          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.0445       |\n",
      "|    reward             | 0.0022863126 |\n",
      "|    std                | 1.73         |\n",
      "|    value_loss         | 9.53e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 354         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.0541     |\n",
      "|    reward             | 0.004034341 |\n",
      "|    std                | 1.83        |\n",
      "|    value_loss         | 3.19e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 355         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.119       |\n",
      "|    reward             | 0.006147558 |\n",
      "|    std                | 1.93        |\n",
      "|    value_loss         | 7.61e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 356          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0852      |\n",
      "|    reward             | -0.004690952 |\n",
      "|    std                | 2.03         |\n",
      "|    value_loss         | 3.96e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 355           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.172        |\n",
      "|    reward             | 0.00033532592 |\n",
      "|    std                | 2.13          |\n",
      "|    value_loss         | 8.44e-05      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.3001702642781466\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_12\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    fps             | 489            |\n",
      "|    iterations      | 1              |\n",
      "|    time_elapsed    | 4              |\n",
      "|    total_timesteps | 2048           |\n",
      "| train/             |                |\n",
      "|    reward          | -0.00043924304 |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 452           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005252543   |\n",
      "|    clip_fraction        | 0.0602        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -3.86         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.137        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00467      |\n",
      "|    reward               | -0.0008239751 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00348       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 399          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005983518  |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.131       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 0.0011067063 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000256     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 409           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0061570075  |\n",
      "|    clip_fraction        | 0.0742        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.0852       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.111        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00531      |\n",
      "|    reward               | -0.0019312978 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000183      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005820848 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.135      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | 0.006167956 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.000153    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.2805423555435201\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_12\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 155         |\n",
      "|    time_elapsed    | 55          |\n",
      "|    total_timesteps | 8556        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 411         |\n",
      "|    critic_loss     | 257         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6417        |\n",
      "|    reward          | 0.006161148 |\n",
      "------------------------------------\n",
      "day: 2138, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10044.60\n",
      "total_reward: 44.60\n",
      "total_cost: 9.99\n",
      "total_trades: 10690\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "======DDPG Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======Trading from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.00267      |\n",
      "|    reward             | -9.624159e-05 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 1.06e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.174       |\n",
      "|    reward             | -0.006313678 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.000369     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.0978     |\n",
      "|    reward             | 0.020411856 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.000162    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 342          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 0.0926       |\n",
      "|    reward             | -0.008542599 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 7.08e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.064        |\n",
      "|    reward             | -0.007966077 |\n",
      "|    std                | 1.19         |\n",
      "|    value_loss         | 2.48e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 344           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.154        |\n",
      "|    reward             | -0.0027166815 |\n",
      "|    std                | 1.24          |\n",
      "|    value_loss         | 0.000186      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 347           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.15          |\n",
      "|    reward             | -0.0016027866 |\n",
      "|    std                | 1.29          |\n",
      "|    value_loss         | 0.000133      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 348         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.197       |\n",
      "|    reward             | 0.004148377 |\n",
      "|    std                | 1.34        |\n",
      "|    value_loss         | 0.000193    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 348          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.086        |\n",
      "|    reward             | 0.0019864135 |\n",
      "|    std                | 1.39         |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 349          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.0479       |\n",
      "|    reward             | 0.0011952089 |\n",
      "|    std                | 1.45         |\n",
      "|    value_loss         | 2.23e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 351           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.214        |\n",
      "|    reward             | -0.0011272206 |\n",
      "|    std                | 1.51          |\n",
      "|    value_loss         | 0.000189      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 350          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.00924     |\n",
      "|    reward             | 0.0060743876 |\n",
      "|    std                | 1.57         |\n",
      "|    value_loss         | 3.79e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 351           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.2         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.0824       |\n",
      "|    reward             | -0.0017701938 |\n",
      "|    std                | 1.64          |\n",
      "|    value_loss         | 5.57e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0674       |\n",
      "|    reward             | -0.005828808 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 1.98e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.055       |\n",
      "|    reward             | -0.010028887 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 2.33e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 350          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.102        |\n",
      "|    reward             | -0.004509086 |\n",
      "|    std                | 1.87         |\n",
      "|    value_loss         | 9.14e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 351           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.7         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.044        |\n",
      "|    reward             | -0.0029548502 |\n",
      "|    std                | 1.93          |\n",
      "|    value_loss         | 3.8e-05       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 352            |\n",
      "|    iterations         | 1800           |\n",
      "|    time_elapsed       | 25             |\n",
      "|    total_timesteps    | 9000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -19            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1799           |\n",
      "|    policy_loss        | -0.12          |\n",
      "|    reward             | -0.00041653446 |\n",
      "|    std                | 2              |\n",
      "|    value_loss         | 4.56e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.00717     |\n",
      "|    reward             | 0.0005669529 |\n",
      "|    std                | 2.08         |\n",
      "|    value_loss         | 1.19e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.0389       |\n",
      "|    reward             | -0.000780909 |\n",
      "|    std                | 2.18         |\n",
      "|    value_loss         | 5.14e-06     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.06293533542727149\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_12\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 487          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0031854163 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 458           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0077135446  |\n",
      "|    clip_fraction        | 0.0688        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -5.49         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.141        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00625      |\n",
      "|    reward               | -0.0007832579 |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 0.00505       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 452          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009962568  |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.00169     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.118       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | -0.006559248 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00371      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 448           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007490065   |\n",
      "|    clip_fraction        | 0.0815        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.00104       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.135        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00428      |\n",
      "|    reward               | 0.00093731354 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00264       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 448           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009333629   |\n",
      "|    clip_fraction        | 0.0818        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.000166     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.127        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00396      |\n",
      "|    reward               | 0.00046402327 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00183       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.06329330751065734\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_12\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 157          |\n",
      "|    time_elapsed    | 55           |\n",
      "|    total_timesteps | 8808         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 129          |\n",
      "|    critic_loss     | 135          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6606         |\n",
      "|    reward          | 0.0035022239 |\n",
      "-------------------------------------\n",
      "day: 2201, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10002.14\n",
      "total_reward: 2.14\n",
      "total_cost: 9.99\n",
      "total_trades: 11005\n",
      "Sharpe: 0.228\n",
      "=================================\n",
      "======DDPG Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======Trading from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.081      |\n",
      "|    reward             | 0.006438909 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 7.16e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 0.0728       |\n",
      "|    reward             | -0.002341875 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.136       |\n",
      "|    reward             | -0.018220915 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.000491     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 345         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.076       |\n",
      "|    reward             | 8.93467e-05 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.000453    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 343          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.0322       |\n",
      "|    reward             | 0.0010819593 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 9.16e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 344           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.2         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0302        |\n",
      "|    reward             | -0.0017701269 |\n",
      "|    std                | 1.18          |\n",
      "|    value_loss         | 7.8e-06       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 343          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.037        |\n",
      "|    reward             | 0.0015091067 |\n",
      "|    std                | 1.22         |\n",
      "|    value_loss         | 1.36e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 339           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.1         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.0539       |\n",
      "|    reward             | -8.181144e-05 |\n",
      "|    std                | 1.29          |\n",
      "|    value_loss         | 2.46e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 340            |\n",
      "|    iterations         | 900            |\n",
      "|    time_elapsed       | 13             |\n",
      "|    total_timesteps    | 4500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.6          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 899            |\n",
      "|    policy_loss        | -0.0606        |\n",
      "|    reward             | -0.00021362473 |\n",
      "|    std                | 1.37           |\n",
      "|    value_loss         | 1.28e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 342          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.116       |\n",
      "|    reward             | 0.0012287995 |\n",
      "|    std                | 1.43         |\n",
      "|    value_loss         | 8.51e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 343        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -0.0311    |\n",
      "|    reward             | 0.00242746 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 1.09e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 343           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | -0.0567       |\n",
      "|    reward             | -0.0008242594 |\n",
      "|    std                | 1.59          |\n",
      "|    value_loss         | 2.58e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 344           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.00649      |\n",
      "|    reward             | -0.0008353892 |\n",
      "|    std                | 1.69          |\n",
      "|    value_loss         | 2.44e-07      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | -0.182        |\n",
      "|    reward             | -0.0020435036 |\n",
      "|    std                | 1.78          |\n",
      "|    value_loss         | 0.000103      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 346          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.187       |\n",
      "|    reward             | 0.0044228365 |\n",
      "|    std                | 1.86         |\n",
      "|    value_loss         | 0.000134     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.00644       |\n",
      "|    reward             | -0.0062761884 |\n",
      "|    std                | 1.95          |\n",
      "|    value_loss         | 7.82e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 346           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.141        |\n",
      "|    reward             | -0.0068880212 |\n",
      "|    std                | 2.04          |\n",
      "|    value_loss         | 6.39e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 346           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.138        |\n",
      "|    reward             | -0.0022263438 |\n",
      "|    std                | 2.14          |\n",
      "|    value_loss         | 0.000151      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 345          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.103       |\n",
      "|    reward             | -0.008559826 |\n",
      "|    std                | 2.24         |\n",
      "|    value_loss         | 6.24e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 346           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.0201        |\n",
      "|    reward             | -0.0032852206 |\n",
      "|    std                | 2.35          |\n",
      "|    value_loss         | 2.37e-05      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.660362911548754\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_12\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 459          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0007979426 |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 449          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057184584 |\n",
      "|    clip_fraction        | 0.0716       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -2.88        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.127       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | 0.0008679386 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00112      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 445          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010443611  |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0274       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.141       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    reward               | 0.0007576767 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00175      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 443           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008726625   |\n",
      "|    clip_fraction        | 0.0767        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0881        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.131        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00458      |\n",
      "|    reward               | -0.0016385873 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.0012        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 441           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0079976795  |\n",
      "|    clip_fraction        | 0.0868        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.00623       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.125        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00459      |\n",
      "|    reward               | 0.00057994004 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000876      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.33262934895014934\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_12\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 158          |\n",
      "|    time_elapsed    | 57           |\n",
      "|    total_timesteps | 9060         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 969          |\n",
      "|    critic_loss     | 771          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6795         |\n",
      "|    reward          | -0.008919014 |\n",
      "-------------------------------------\n",
      "day: 2264, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10019.71\n",
      "total_reward: 19.71\n",
      "total_cost: 9.99\n",
      "total_trades: 11320\n",
      "Sharpe: 0.210\n",
      "=================================\n",
      "======DDPG Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======Trading from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.0962       |\n",
      "|    reward             | -0.0067259795 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 0.000102      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 0.37        |\n",
      "|    reward             | 0.019655604 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.00085     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 337         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.163      |\n",
      "|    reward             | -0.05366001 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.001       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.43        |\n",
      "|    reward             | 0.041278593 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00367     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.298        |\n",
      "|    reward             | 0.0060595064 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.000576     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0125      |\n",
      "|    reward             | 0.0013427357 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 4.46e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.167       |\n",
      "|    reward             | 0.004654766 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.000136    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.0527        |\n",
      "|    reward             | -0.0028832292 |\n",
      "|    std                | 1.19          |\n",
      "|    value_loss         | 2.45e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 338         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.281      |\n",
      "|    reward             | 0.007588382 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 0.000451    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.133      |\n",
      "|    reward             | 0.006986366 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 9.69e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.133        |\n",
      "|    reward             | 0.0024657543 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 7.92e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 0.117       |\n",
      "|    reward             | -0.00563004 |\n",
      "|    std                | 1.34        |\n",
      "|    value_loss         | 8.74e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 340           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.588         |\n",
      "|    reward             | -0.0036638612 |\n",
      "|    std                | 1.38          |\n",
      "|    value_loss         | 0.00213       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.143        |\n",
      "|    reward             | 0.0061467844 |\n",
      "|    std                | 1.41         |\n",
      "|    value_loss         | 0.000142     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 339       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 0.24      |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 0.000236  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.386        |\n",
      "|    reward             | -0.013335261 |\n",
      "|    std                | 1.48         |\n",
      "|    value_loss         | 0.000603     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.504      |\n",
      "|    reward             | 0.010131201 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 0.00134     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 342          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0205       |\n",
      "|    reward             | 0.0009648331 |\n",
      "|    std                | 1.54         |\n",
      "|    value_loss         | 0.000154     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0584      |\n",
      "|    reward             | 0.0045028897 |\n",
      "|    std                | 1.56         |\n",
      "|    value_loss         | 4.84e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 342          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.0205       |\n",
      "|    reward             | -0.006604748 |\n",
      "|    std                | 1.6          |\n",
      "|    value_loss         | 3.32e-05     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.1927383166157406\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_12\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 466           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0018213486 |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 450           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006487826   |\n",
      "|    clip_fraction        | 0.0678        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.036        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.142        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00456      |\n",
      "|    reward               | 0.00032170766 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00076       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 446          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066687497 |\n",
      "|    clip_fraction        | 0.0715       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0561       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.136       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | 0.0047938516 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.00165      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 444          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064916974 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.0458      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.143       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | 0.004225831  |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.00119      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 443           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0067532845  |\n",
      "|    clip_fraction        | 0.0897        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.136         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.14         |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00523      |\n",
      "|    reward               | 0.00017819137 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000929      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.23427309364589005\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_12\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 166          |\n",
      "|    time_elapsed    | 55           |\n",
      "|    total_timesteps | 9312         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -167         |\n",
      "|    critic_loss     | 90.1         |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6984         |\n",
      "|    reward          | -0.000605245 |\n",
      "-------------------------------------\n",
      "day: 2327, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9999.55\n",
      "total_reward: -0.45\n",
      "total_cost: 9.99\n",
      "total_trades: 13962\n",
      "Sharpe: 0.167\n",
      "=================================\n",
      "======DDPG Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======Trading from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.065      |\n",
      "|    reward             | 0.004436346 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 3.35e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.00557      |\n",
      "|    reward             | -0.0010564512 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 2.42e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 0.178       |\n",
      "|    reward             | -0.01791954 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.000246    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 0.0746       |\n",
      "|    reward             | -0.018726712 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 0.000484     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.0367       |\n",
      "|    reward             | 0.0074218484 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 1.13e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0265        |\n",
      "|    reward             | -0.0005011313 |\n",
      "|    std                | 1.2           |\n",
      "|    value_loss         | 3.76e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.0191       |\n",
      "|    reward             | 0.0047955806 |\n",
      "|    std                | 1.25         |\n",
      "|    value_loss         | 3.28e-06     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 337            |\n",
      "|    iterations         | 800            |\n",
      "|    time_elapsed       | 11             |\n",
      "|    total_timesteps    | 4000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 799            |\n",
      "|    policy_loss        | -0.0273        |\n",
      "|    reward             | -0.00031557033 |\n",
      "|    std                | 1.32           |\n",
      "|    value_loss         | 3.53e-06       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.00694     |\n",
      "|    reward             | 0.001437772 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 1.1e-06     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.049        |\n",
      "|    reward             | -0.001592693 |\n",
      "|    std                | 1.47         |\n",
      "|    value_loss         | 1.4e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.062         |\n",
      "|    reward             | -0.0031750873 |\n",
      "|    std                | 1.56          |\n",
      "|    value_loss         | 1.55e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | -0.0233       |\n",
      "|    reward             | -0.0017117258 |\n",
      "|    std                | 1.64          |\n",
      "|    value_loss         | 4.61e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.115       |\n",
      "|    reward             | 0.0009580254 |\n",
      "|    std                | 1.74         |\n",
      "|    value_loss         | 4.73e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0517       |\n",
      "|    reward             | -0.008947358 |\n",
      "|    std                | 1.85         |\n",
      "|    value_loss         | 1.02e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | -0.0651     |\n",
      "|    reward             | 0.002114124 |\n",
      "|    std                | 1.94        |\n",
      "|    value_loss         | 2.22e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.0265       |\n",
      "|    reward             | 0.0069326237 |\n",
      "|    std                | 2.05         |\n",
      "|    value_loss         | 2.62e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.0703     |\n",
      "|    reward             | 0.002182692 |\n",
      "|    std                | 2.16        |\n",
      "|    value_loss         | 1.84e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.0284      |\n",
      "|    reward             | -0.002033638 |\n",
      "|    std                | 2.29         |\n",
      "|    value_loss         | 3.17e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | -0.0319       |\n",
      "|    reward             | -0.0018470024 |\n",
      "|    std                | 2.41          |\n",
      "|    value_loss         | 1.44e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 0.114       |\n",
      "|    reward             | 0.004242246 |\n",
      "|    std                | 2.54        |\n",
      "|    value_loss         | 4.44e-05    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.0927296550845213\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_12\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 426           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0022848924 |\n",
      "--------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 413            |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.007815215    |\n",
      "|    clip_fraction        | 0.0879         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | -7.03          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.138         |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | -0.00524       |\n",
      "|    reward               | -0.00042328873 |\n",
      "|    std                  | 0.998          |\n",
      "|    value_loss           | 0.00273        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 412            |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 14             |\n",
      "|    total_timesteps      | 6144           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.008872384    |\n",
      "|    clip_fraction        | 0.108          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.7          |\n",
      "|    explained_variance   | -0.000686      |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.15          |\n",
      "|    n_updates            | 20             |\n",
      "|    policy_gradient_loss | -0.00477       |\n",
      "|    reward               | -0.00047008684 |\n",
      "|    std                  | 0.997          |\n",
      "|    value_loss           | 0.00514        |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 412           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0057286886  |\n",
      "|    clip_fraction        | 0.0818        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.00932       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.126        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00343      |\n",
      "|    reward               | -0.0005383614 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00328       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 415           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0058994773  |\n",
      "|    clip_fraction        | 0.0596        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0389        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.137        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00383      |\n",
      "|    reward               | 2.0796298e-05 |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 0.00239       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.025407084234825683\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_12\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 153         |\n",
      "|    time_elapsed    | 62          |\n",
      "|    total_timesteps | 9564        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 187         |\n",
      "|    critic_loss     | 123         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7173        |\n",
      "|    reward          | 0.022806942 |\n",
      "------------------------------------\n",
      "day: 2390, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10038.65\n",
      "total_reward: 38.65\n",
      "total_cost: 9.99\n",
      "total_trades: 7170\n",
      "Sharpe: 0.184\n",
      "=================================\n",
      "======DDPG Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======Trading from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_567_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.00669     |\n",
      "|    reward             | 0.017667528 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 7.11e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | 0.0886        |\n",
      "|    reward             | -0.0037286577 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 0.000168      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.177       |\n",
      "|    reward             | -0.008893925 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.000445     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.349      |\n",
      "|    reward             | -0.03148519 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.000833    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 328            |\n",
      "|    iterations         | 500            |\n",
      "|    time_elapsed       | 7              |\n",
      "|    total_timesteps    | 2500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 499            |\n",
      "|    policy_loss        | -0.128         |\n",
      "|    reward             | -0.00028750658 |\n",
      "|    std                | 1.13           |\n",
      "|    value_loss         | 0.000113       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.0121       |\n",
      "|    reward             | 0.0017708696 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 1.17e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.00704      |\n",
      "|    reward             | -0.004508852 |\n",
      "|    std                | 1.19         |\n",
      "|    value_loss         | 3.76e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.128       |\n",
      "|    reward             | 0.004579183 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 7.16e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.238        |\n",
      "|    reward             | -0.008819948 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 0.000312     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.015       |\n",
      "|    reward             | 0.0016983298 |\n",
      "|    std                | 1.34         |\n",
      "|    value_loss         | 4.62e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.0465       |\n",
      "|    reward             | -0.0014700014 |\n",
      "|    std                | 1.39          |\n",
      "|    value_loss         | 9.03e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -0.0201     |\n",
      "|    reward             | 0.006576334 |\n",
      "|    std                | 1.47        |\n",
      "|    value_loss         | 9.15e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -0.0679     |\n",
      "|    reward             | 0.005138751 |\n",
      "|    std                | 1.54        |\n",
      "|    value_loss         | 2.91e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.084       |\n",
      "|    reward             | 0.008800162 |\n",
      "|    std                | 1.61        |\n",
      "|    value_loss         | 3.77e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0163       |\n",
      "|    reward             | 0.0042933463 |\n",
      "|    std                | 1.68         |\n",
      "|    value_loss         | 2.34e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -0.0124       |\n",
      "|    reward             | -0.0006389917 |\n",
      "|    std                | 1.76          |\n",
      "|    value_loss         | 2.35e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.102       |\n",
      "|    reward             | -0.002253898 |\n",
      "|    std                | 1.86         |\n",
      "|    value_loss         | 4.78e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0874       |\n",
      "|    reward             | -0.004642958 |\n",
      "|    std                | 1.96         |\n",
      "|    value_loss         | 4.24e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 2.38e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 0.283       |\n",
      "|    reward             | 0.005765107 |\n",
      "|    std                | 2.07        |\n",
      "|    value_loss         | 0.000184    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.00457       |\n",
      "|    reward             | -0.0003031514 |\n",
      "|    std                | 2.17          |\n",
      "|    value_loss         | 5.69e-06      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.03233493510553303\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_567_12\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 450          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.014862582 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 438           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006556574   |\n",
      "|    clip_fraction        | 0.0884        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -3.35         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.124        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.006        |\n",
      "|    reward               | -0.0011169664 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00122       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 432          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071561914 |\n",
      "|    clip_fraction        | 0.0822       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0138       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.129       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    reward               | 0.0010193838 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000345     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 424          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008061191  |\n",
      "|    clip_fraction        | 0.0659       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.136       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | 0.0020725785 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000168     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005430087  |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.143       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | -0.004895954 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 7.27e-05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.08583367411062448\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_567_12\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 162          |\n",
      "|    time_elapsed    | 60           |\n",
      "|    total_timesteps | 9816         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -370         |\n",
      "|    critic_loss     | 181          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 7362         |\n",
      "|    reward          | -0.022939766 |\n",
      "-------------------------------------\n",
      "day: 2453, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10909.22\n",
      "total_reward: 909.22\n",
      "total_cost: 9.99\n",
      "total_trades: 4906\n",
      "Sharpe: 0.257\n",
      "=================================\n",
      "======DDPG Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======Trading from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_630_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.037       |\n",
      "|    reward             | -0.008169154 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.000227     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 253          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0141      |\n",
      "|    reward             | 0.0088573415 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.000136     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 257         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.0125     |\n",
      "|    reward             | -0.03620573 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.000296    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 247          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | -19.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 0.619        |\n",
      "|    reward             | -0.010624319 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.00489      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 252          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.132       |\n",
      "|    reward             | -0.011041664 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.000319     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -0.0718    |\n",
      "|    reward             | 0.01204462 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 3.69e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 269         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -0.234      |\n",
      "|    reward             | 0.005530455 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.000221    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 276           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.509        |\n",
      "|    reward             | 0.00025887336 |\n",
      "|    std                | 1.22          |\n",
      "|    value_loss         | 0.0015        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 281        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.8      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | -0.34      |\n",
      "|    reward             | 0.03203996 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 0.00068    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.314        |\n",
      "|    reward             | -0.008373617 |\n",
      "|    std                | 1.28         |\n",
      "|    value_loss         | 0.000695     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 289          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.0292      |\n",
      "|    reward             | 0.0018496559 |\n",
      "|    std                | 1.31         |\n",
      "|    value_loss         | 2.93e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 292          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0472       |\n",
      "|    reward             | 0.0060637323 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 2.75e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 295            |\n",
      "|    iterations         | 1300           |\n",
      "|    time_elapsed       | 22             |\n",
      "|    total_timesteps    | 6500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1299           |\n",
      "|    policy_loss        | 0.0969         |\n",
      "|    reward             | -0.00074900716 |\n",
      "|    std                | 1.41           |\n",
      "|    value_loss         | 4.75e-05       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 298           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.0411        |\n",
      "|    reward             | -0.0025457356 |\n",
      "|    std                | 1.47          |\n",
      "|    value_loss         | 3.79e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.145        |\n",
      "|    reward             | 0.0062137544 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 301            |\n",
      "|    iterations         | 1600           |\n",
      "|    time_elapsed       | 26             |\n",
      "|    total_timesteps    | 8000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1599           |\n",
      "|    policy_loss        | 0.0158         |\n",
      "|    reward             | -0.00052758324 |\n",
      "|    std                | 1.59           |\n",
      "|    value_loss         | 1.66e-05       |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 302        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 0.14       |\n",
      "|    reward             | 0.00626942 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 8.41e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.394       |\n",
      "|    reward             | -0.023668041 |\n",
      "|    std                | 1.72         |\n",
      "|    value_loss         | 0.000568     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 31            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.198         |\n",
      "|    reward             | -0.0012270581 |\n",
      "|    std                | 1.77          |\n",
      "|    value_loss         | 0.000134      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.234      |\n",
      "|    reward             | 0.010042861 |\n",
      "|    std                | 1.81        |\n",
      "|    value_loss         | 0.000223    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.26619720089942295\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_630_12\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 442           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | 0.00035288552 |\n",
      "--------------------------------------\n",
      "day: 2516, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 1823.07\n",
      "total_reward: -8176.93\n",
      "total_cost: 3733.31\n",
      "total_trades: 14408\n",
      "Sharpe: -0.354\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 427           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0066012125  |\n",
      "|    clip_fraction        | 0.0571        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -3.04         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.12         |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00487      |\n",
      "|    reward               | 0.00083593547 |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 0.00422       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 422           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0074159806  |\n",
      "|    clip_fraction        | 0.0761        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.355        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.154        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00592      |\n",
      "|    reward               | -0.0003559551 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000458      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 423           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007999148   |\n",
      "|    clip_fraction        | 0.0807        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.299         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.148        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00556      |\n",
      "|    reward               | -0.0012689648 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000299      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 419            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 24             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.007059415    |\n",
      "|    clip_fraction        | 0.077          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | 0.297          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.114         |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00609       |\n",
      "|    reward               | -0.00030976054 |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 0.000309       |\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.2099215013359223\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_630_12\n",
      "day: 2516, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 33015.24\n",
      "total_reward: 23015.24\n",
      "total_cost: 464.11\n",
      "total_trades: 5543\n",
      "Sharpe: 0.878\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 164         |\n",
      "|    time_elapsed    | 61          |\n",
      "|    total_timesteps | 10068       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -373        |\n",
      "|    critic_loss     | 185         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7551        |\n",
      "|    reward          | 0.009161208 |\n",
      "------------------------------------\n",
      "======DDPG Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======Trading from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_693_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 296          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.472       |\n",
      "|    reward             | -0.014347639 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.00143      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.251      |\n",
      "|    reward             | 0.008253915 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.00143     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.912      |\n",
      "|    reward             | -0.07579197 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.00636     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.554      |\n",
      "|    reward             | 0.018447561 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.00278     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.305       |\n",
      "|    reward             | 0.0072794454 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.000812     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0243      |\n",
      "|    reward             | -0.012184414 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 6.77e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.241       |\n",
      "|    reward             | 0.005831608 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.000377    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.164       |\n",
      "|    reward             | -0.01680396 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 0.00026     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.778       |\n",
      "|    reward             | -0.017091995 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 0.00299      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.1          |\n",
      "|    reward             | -0.0014669409 |\n",
      "|    std                | 1.19          |\n",
      "|    value_loss         | 0.000931      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.00634     |\n",
      "|    reward             | 0.0039951135 |\n",
      "|    std                | 1.22         |\n",
      "|    value_loss         | 4.84e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | 0.0050952896 |\n",
      "|    std                | 1.25         |\n",
      "|    value_loss         | 7.37e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.126        |\n",
      "|    reward             | 0.0073478483 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 0.000103     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | -0.0449       |\n",
      "|    reward             | -0.0023776817 |\n",
      "|    std                | 1.34          |\n",
      "|    value_loss         | 1.94e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | -0.00166    |\n",
      "|    reward             | 0.011483359 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 1.28e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.0269        |\n",
      "|    reward             | -0.0007640339 |\n",
      "|    std                | 1.43          |\n",
      "|    value_loss         | 7.4e-06       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.191       |\n",
      "|    reward             | 0.004244845 |\n",
      "|    std                | 1.48        |\n",
      "|    value_loss         | 0.000185    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.021         |\n",
      "|    reward             | -0.0067040403 |\n",
      "|    std                | 1.54          |\n",
      "|    value_loss         | 2.86e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 19           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 497          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0203      |\n",
      "|    reward             | -6.59338e-05 |\n",
      "|    std                | 1.61         |\n",
      "|    value_loss         | 3.53e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 500         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.432      |\n",
      "|    reward             | 0.044241127 |\n",
      "|    std                | 1.68        |\n",
      "|    value_loss         | 0.000894    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.3253394975601841\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_693_12\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 342         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 5           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.002918357 |\n",
      "------------------------------------\n",
      "day: 2579, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 2256.49\n",
      "total_reward: -7743.51\n",
      "total_cost: 6407.69\n",
      "total_trades: 15144\n",
      "Sharpe: -0.331\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 299          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071534133 |\n",
      "|    clip_fraction        | 0.0993       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -4.71        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.12        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    reward               | 0.0012248415 |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 0.00205      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 324          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007915173  |\n",
      "|    clip_fraction        | 0.088        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.108       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -0.005678873 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00531      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009495043 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | -0.072      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.139      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    reward               | 0.011260442 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00443     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 352          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008810873  |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | -0.2         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.13        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | 0.0001920024 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00338      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.1530938663222239\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_693_12\n",
      "day: 2579, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 7737\n",
      "Sharpe: 0.191\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 152        |\n",
      "|    time_elapsed    | 67         |\n",
      "|    total_timesteps | 10320      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 10.3       |\n",
      "|    critic_loss     | 89.1       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 7740       |\n",
      "|    reward          | 0.02207375 |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-07-06T00:00:00.000000000\n",
      "======Trading from:  2020-07-06T00:00:00.000000000 to  2020-10-02T00:00:00.000000000\n",
      "Ensemble Strategy took:  32.04377751747767  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "df_summary_mv = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs, PPO_model_kwargs, DDPG_model_kwargs, timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.354978</td>\n",
       "      <td>-0.350523</td>\n",
       "      <td>-0.167613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.116497</td>\n",
       "      <td>-0.190907</td>\n",
       "      <td>0.197413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.30017</td>\n",
       "      <td>0.280542</td>\n",
       "      <td>0.401344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.062935</td>\n",
       "      <td>-0.063293</td>\n",
       "      <td>-0.336428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.660363</td>\n",
       "      <td>0.332629</td>\n",
       "      <td>0.873381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.192738</td>\n",
       "      <td>0.234273</td>\n",
       "      <td>0.346537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.09273</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>0.215326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.032335</td>\n",
       "      <td>0.085834</td>\n",
       "      <td>0.119572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>-0.266197</td>\n",
       "      <td>-0.209922</td>\n",
       "      <td>-0.305741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.325339</td>\n",
       "      <td>0.153094</td>\n",
       "      <td>0.326671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter  Val Start    Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126 2018-01-02 2018-04-04       DDPG  -0.354978  -0.350523   -0.167613\n",
       "1  189 2018-04-04 2018-07-03       DDPG   0.116497  -0.190907    0.197413\n",
       "2  252 2018-07-03 2018-10-02       DDPG    0.30017   0.280542    0.401344\n",
       "3  315 2018-10-02 2019-01-03        A2C   0.062935  -0.063293   -0.336428\n",
       "4  378 2019-01-03 2019-04-04       DDPG   0.660363   0.332629    0.873381\n",
       "5  441 2019-04-04 2019-07-05       DDPG   0.192738   0.234273    0.346537\n",
       "6  504 2019-07-05 2019-10-03       DDPG    0.09273   0.025407    0.215326\n",
       "7  567 2019-10-03 2020-01-03       DDPG  -0.032335   0.085834    0.119572\n",
       "8  630 2020-01-03 2020-04-03        PPO  -0.266197  -0.209922   -0.305741\n",
       "9  693 2020-04-03 2020-07-06       DDPG   0.325339   0.153094    0.326671"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10068.554474</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>0.006855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9843.539894</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>-0.022348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9892.059730</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>0.004929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10049.745361</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>0.015941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>12720.722388</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>0.016180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>12943.162812</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>0.017486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>12861.828091</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>-0.006284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>12960.768336</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>0.007693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>13048.231505</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0.006748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     account_value        date  daily_return\n",
       "0     10000.000000  2018-04-04           NaN\n",
       "1     10068.554474  2018-04-05      0.006855\n",
       "2      9843.539894  2018-04-06     -0.022348\n",
       "3      9892.059730  2018-04-09      0.004929\n",
       "4     10049.745361  2018-04-10      0.015941\n",
       "..             ...         ...           ...\n",
       "625   12720.722388  2020-09-25      0.016180\n",
       "626   12943.162812  2020-09-28      0.017486\n",
       "627   12861.828091  2020-09-29     -0.006284\n",
       "628   12960.768336  2020-09-30      0.007693\n",
       "629   13048.231505  2020-10-01      0.006748\n",
       "\n",
       "[630 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "# for every cycle (rebalance_window + validation_window) read the csv files into a dataframe\n",
    "for i in range(rebalance_window+validation_window, len(test_dates)+1,rebalance_window):\n",
    "     result_df = pd.read_csv(f'results/account_value_trade_ensemble_{i}.csv')\n",
    "     results_list.append(result_df)\n",
    "\n",
    "df_ensemble_results_mv  = pd.concat(results_list, ignore_index=True)  # Create a dataframe to store execution results\n",
    "\n",
    "df_ensemble_results_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-01-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_16\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.0901       |\n",
      "|    reward             | -0.0058654905 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 8.99e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 349        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 0.278      |\n",
      "|    reward             | 0.01705781 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.000606   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 359          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.0854      |\n",
      "|    reward             | -0.046983525 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.000725     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 363         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.0841      |\n",
      "|    reward             | 0.005557536 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.000645    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 361            |\n",
      "|    iterations         | 500            |\n",
      "|    time_elapsed       | 6              |\n",
      "|    total_timesteps    | 2500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 499            |\n",
      "|    policy_loss        | 0.235          |\n",
      "|    reward             | -0.00049881666 |\n",
      "|    std                | 1.11           |\n",
      "|    value_loss         | 0.000374       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 361          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0369      |\n",
      "|    reward             | 0.0019469351 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 1.28e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 363           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.194         |\n",
      "|    reward             | 0.00014977055 |\n",
      "|    std                | 1.19          |\n",
      "|    value_loss         | 0.000224      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 365          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.0835       |\n",
      "|    reward             | -0.001008894 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 0.000152     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 365           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.102        |\n",
      "|    reward             | -0.0037759775 |\n",
      "|    std                | 1.28          |\n",
      "|    value_loss         | 6.32e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 367          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.0875      |\n",
      "|    reward             | 0.0046360176 |\n",
      "|    std                | 1.34         |\n",
      "|    value_loss         | 3.28e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 368         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 0.0455      |\n",
      "|    reward             | 0.012411541 |\n",
      "|    std                | 1.4         |\n",
      "|    value_loss         | 2.04e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 369         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 0.0223      |\n",
      "|    reward             | 0.010311107 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 3.13e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 368          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.227        |\n",
      "|    reward             | -0.007526502 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 0.000258     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 369           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.0976        |\n",
      "|    reward             | 0.00093895016 |\n",
      "|    std                | 1.6           |\n",
      "|    value_loss         | 6.31e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 370         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.162       |\n",
      "|    reward             | 0.010615209 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 9.35e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 370           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.0252        |\n",
      "|    reward             | 0.00071553973 |\n",
      "|    std                | 1.75          |\n",
      "|    value_loss         | 7.88e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 370          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.0807       |\n",
      "|    reward             | 0.0035916707 |\n",
      "|    std                | 1.83         |\n",
      "|    value_loss         | 6.89e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 370          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.00535     |\n",
      "|    reward             | 0.0012561342 |\n",
      "|    std                | 1.92         |\n",
      "|    value_loss         | 5.54e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 371         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.313      |\n",
      "|    reward             | 0.011862979 |\n",
      "|    std                | 2.02        |\n",
      "|    value_loss         | 0.000305    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 370          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.0625      |\n",
      "|    reward             | 0.0009851372 |\n",
      "|    std                | 2.12         |\n",
      "|    value_loss         | 1.01e-05     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.26745261429944717\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_16\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 514          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 3            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0016480006 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 465           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010152541   |\n",
      "|    clip_fraction        | 0.105         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.986        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.123        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.008        |\n",
      "|    reward               | 0.00017343127 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00202       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 455          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007483297  |\n",
      "|    clip_fraction        | 0.0617       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.175       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.152       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -0.010784055 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00121      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 461         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008674145 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.136      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | 0.007329005 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.000571    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2012, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 2807.11\n",
      "total_reward: -7192.89\n",
      "total_cost: 5812.81\n",
      "total_trades: 11908\n",
      "Sharpe: -0.480\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 465            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 22             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.006917342    |\n",
      "|    clip_fraction        | 0.0645         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.9          |\n",
      "|    explained_variance   | 0.159          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.15          |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00423       |\n",
      "|    reward               | -0.00075090904 |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 0.000421       |\n",
      "--------------------------------------------\n",
      "======PPO Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.425203905065214\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_16\n",
      "day: 2012, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10002.07\n",
      "total_reward: 2.07\n",
      "total_cost: 9.99\n",
      "total_trades: 16096\n",
      "Sharpe: 0.224\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 17            |\n",
      "|    time_elapsed    | 452           |\n",
      "|    total_timesteps | 8052          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 158           |\n",
      "|    critic_loss     | 167           |\n",
      "|    learning_rate   | 0.0005        |\n",
      "|    n_updates       | 6039          |\n",
      "|    reward          | -0.0019547748 |\n",
      "--------------------------------------\n",
      "======DDPG Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======Trading from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0528      |\n",
      "|    reward             | 0.0039803647 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 5.09e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.263      |\n",
      "|    reward             | 0.004548563 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.000488    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 347          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.195        |\n",
      "|    reward             | -0.024338353 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 0.000782     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 354         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.0645     |\n",
      "|    reward             | -0.03036726 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.000274    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 352          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.132        |\n",
      "|    reward             | -0.005255062 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 356          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.141       |\n",
      "|    reward             | 0.0022619131 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 9.64e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 358          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 2.38e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.913       |\n",
      "|    reward             | -0.002679587 |\n",
      "|    std                | 1.22         |\n",
      "|    value_loss         | 0.0037       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 360           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.0616       |\n",
      "|    reward             | -0.0015063242 |\n",
      "|    std                | 1.27          |\n",
      "|    value_loss         | 4.19e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 359           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.0556       |\n",
      "|    reward             | -0.0035657864 |\n",
      "|    std                | 1.32          |\n",
      "|    value_loss         | 1.63e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 360         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.0163     |\n",
      "|    reward             | 0.007029196 |\n",
      "|    std                | 1.38        |\n",
      "|    value_loss         | 5.42e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 362          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.015       |\n",
      "|    reward             | 0.0001903658 |\n",
      "|    std                | 1.44         |\n",
      "|    value_loss         | 1.53e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 362            |\n",
      "|    iterations         | 1200           |\n",
      "|    time_elapsed       | 16             |\n",
      "|    total_timesteps    | 6000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.4          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1199           |\n",
      "|    policy_loss        | -0.174         |\n",
      "|    reward             | -2.8184206e-05 |\n",
      "|    std                | 1.51           |\n",
      "|    value_loss         | 0.000134       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 361         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -0.00451    |\n",
      "|    reward             | 0.006346066 |\n",
      "|    std                | 1.57        |\n",
      "|    value_loss         | 4.4e-06     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 362          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0143       |\n",
      "|    reward             | 0.0018490305 |\n",
      "|    std                | 1.64         |\n",
      "|    value_loss         | 5.93e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 363           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | -0.0548       |\n",
      "|    reward             | -0.0022188944 |\n",
      "|    std                | 1.72          |\n",
      "|    value_loss         | 2.28e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 361          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.0158      |\n",
      "|    reward             | 0.0016754578 |\n",
      "|    std                | 1.81         |\n",
      "|    value_loss         | 3.47e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 362          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.0882       |\n",
      "|    reward             | 0.0017355625 |\n",
      "|    std                | 1.89         |\n",
      "|    value_loss         | 2.81e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 362          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0369       |\n",
      "|    reward             | 0.0013243712 |\n",
      "|    std                | 1.98         |\n",
      "|    value_loss         | 4.74e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 363         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.0514     |\n",
      "|    reward             | 0.004558643 |\n",
      "|    std                | 2.08        |\n",
      "|    value_loss         | 1.8e-05     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 362            |\n",
      "|    iterations         | 2000           |\n",
      "|    time_elapsed       | 27             |\n",
      "|    total_timesteps    | 10000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -19.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1999           |\n",
      "|    policy_loss        | 0.229          |\n",
      "|    reward             | -0.00067458616 |\n",
      "|    std                | 2.18           |\n",
      "|    value_loss         | 0.000144       |\n",
      "------------------------------------------\n",
      "======A2C Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.056273506894844956\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_13\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 505           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0005486482 |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 478        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00796189 |\n",
      "|    clip_fraction        | 0.0893     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.8      |\n",
      "|    explained_variance   | -4.35      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.13      |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0087    |\n",
      "|    reward               | 0.00963428 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.00457    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 470          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008358671  |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.00638     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.147       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | 0.0010036502 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00548      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 465           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0064244037  |\n",
      "|    clip_fraction        | 0.109         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.00411       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.137        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00441      |\n",
      "|    reward               | 0.00015623616 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00414       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 458           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0068623386  |\n",
      "|    clip_fraction        | 0.0875        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | -0.0393       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.153        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00589      |\n",
      "|    reward               | -0.0021434086 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00303       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.14867620208744747\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_13\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 157         |\n",
      "|    time_elapsed    | 52          |\n",
      "|    total_timesteps | 8304        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 10.1        |\n",
      "|    critic_loss     | 220         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6228        |\n",
      "|    reward          | 0.012696555 |\n",
      "------------------------------------\n",
      "day: 2075, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10033.33\n",
      "total_reward: 33.33\n",
      "total_cost: 9.99\n",
      "total_trades: 12450\n",
      "Sharpe: 0.210\n",
      "=================================\n",
      "======DDPG Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======Trading from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.0338      |\n",
      "|    reward             | 0.012920777 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.78e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 343           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 2             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.0833       |\n",
      "|    reward             | -0.0057431026 |\n",
      "|    std                | 1.05          |\n",
      "|    value_loss         | 0.00018       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 352           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.0917       |\n",
      "|    reward             | -0.0010046094 |\n",
      "|    std                | 1.09          |\n",
      "|    value_loss         | 0.000343      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 356          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.414       |\n",
      "|    reward             | -0.045081567 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.00106      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 354           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | -0.0438       |\n",
      "|    reward             | -0.0004986771 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 1.22e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 356        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 8          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -0.153     |\n",
      "|    reward             | 0.00794186 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 0.000173   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 358          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.155       |\n",
      "|    reward             | -0.012968188 |\n",
      "|    std                | 1.22         |\n",
      "|    value_loss         | 0.000127     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 360         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -0.0286     |\n",
      "|    reward             | 0.010120546 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 1.68e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 359          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.116       |\n",
      "|    reward             | 0.0033810518 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 8.73e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 360          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.249       |\n",
      "|    reward             | 0.0018713494 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 0.000273     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 360         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 0.121       |\n",
      "|    reward             | 0.006948928 |\n",
      "|    std                | 1.42        |\n",
      "|    value_loss         | 8.05e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 361          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.0283      |\n",
      "|    reward             | 0.0011054339 |\n",
      "|    std                | 1.49         |\n",
      "|    value_loss         | 6.61e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 360          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.114       |\n",
      "|    reward             | -0.007317485 |\n",
      "|    std                | 1.55         |\n",
      "|    value_loss         | 5.16e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 361           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.00326       |\n",
      "|    reward             | 0.00083407725 |\n",
      "|    std                | 1.62          |\n",
      "|    value_loss         | 1.21e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 360          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.17         |\n",
      "|    reward             | 0.0032939413 |\n",
      "|    std                | 1.7          |\n",
      "|    value_loss         | 0.000123     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 360           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.0111        |\n",
      "|    reward             | 0.00035901845 |\n",
      "|    std                | 1.78          |\n",
      "|    value_loss         | 3.79e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 360         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.0328      |\n",
      "|    reward             | 0.008712798 |\n",
      "|    std                | 1.86        |\n",
      "|    value_loss         | 2.61e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 361         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.049       |\n",
      "|    reward             | 0.009562729 |\n",
      "|    std                | 1.93        |\n",
      "|    value_loss         | 1.18e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 361         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.0164     |\n",
      "|    reward             | -0.00971646 |\n",
      "|    std                | 2.01        |\n",
      "|    value_loss         | 1.38e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 361          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.131        |\n",
      "|    reward             | 0.0012152771 |\n",
      "|    std                | 2.11         |\n",
      "|    value_loss         | 7.84e-05     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.16244633610947415\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_13\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    fps             | 496            |\n",
      "|    iterations      | 1              |\n",
      "|    time_elapsed    | 4              |\n",
      "|    total_timesteps | 2048           |\n",
      "| train/             |                |\n",
      "|    reward          | -0.00030536254 |\n",
      "---------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 470            |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0051347553   |\n",
      "|    clip_fraction        | 0.048          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | -2.54          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.132         |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | -0.00223       |\n",
      "|    reward               | -8.3924075e-05 |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 0.000334       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 461           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005510021   |\n",
      "|    clip_fraction        | 0.0515        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.35          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.129        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00444      |\n",
      "|    reward               | -0.0008895767 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00021       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 462           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0076658055  |\n",
      "|    clip_fraction        | 0.0592        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.0446        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.127        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00403      |\n",
      "|    reward               | -0.0013895996 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000221      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 456          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053920085 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.143       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    reward               | 0.0044454704 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000109     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.09525548141711562\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_13\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 157         |\n",
      "|    time_elapsed    | 54          |\n",
      "|    total_timesteps | 8556        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -65.6       |\n",
      "|    critic_loss     | 52.3        |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6417        |\n",
      "|    reward          | 0.002974634 |\n",
      "------------------------------------\n",
      "day: 2138, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 4276\n",
      "Sharpe: 0.154\n",
      "=================================\n",
      "======DDPG Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======Trading from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -0.0731    |\n",
      "|    reward             | 0.01275086 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 6.56e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 340           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 2             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.0384       |\n",
      "|    reward             | -0.0063591795 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.000457      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 349        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -0.539     |\n",
      "|    reward             | 0.10592154 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.00252    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 353         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.747      |\n",
      "|    reward             | -0.08196742 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.00275     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.134        |\n",
      "|    reward             | -0.009658621 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.00014      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 352           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.0156       |\n",
      "|    reward             | -0.0072187893 |\n",
      "|    std                | 1.15          |\n",
      "|    value_loss         | 1.36e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 354          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.26         |\n",
      "|    reward             | 0.0033789119 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 0.000473     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 354         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.0587      |\n",
      "|    reward             | 0.012905445 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 4.99e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 21            |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 209           |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | 0.148         |\n",
      "|    reward             | -0.0038546987 |\n",
      "|    std                | 1.25          |\n",
      "|    value_loss         | 0.000265      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 211           |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.142        |\n",
      "|    reward             | -0.0015489807 |\n",
      "|    std                | 1.29          |\n",
      "|    value_loss         | 0.000216      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 25          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.155      |\n",
      "|    reward             | 0.002216314 |\n",
      "|    std                | 1.34        |\n",
      "|    value_loss         | 9.9e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 27            |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 215           |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.318         |\n",
      "|    reward             | -0.0010471954 |\n",
      "|    std                | 1.38          |\n",
      "|    value_loss         | 0.000445      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 29           |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.262        |\n",
      "|    reward             | 0.0012518096 |\n",
      "|    std                | 1.42         |\n",
      "|    value_loss         | 0.000285     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 31           |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 220          |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.016        |\n",
      "|    reward             | -0.003775833 |\n",
      "|    std                | 1.46         |\n",
      "|    value_loss         | 1.78e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 33           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 223          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0889       |\n",
      "|    reward             | -0.007052551 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 7.47e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 35            |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 224           |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.074         |\n",
      "|    reward             | -0.0028343212 |\n",
      "|    std                | 1.59          |\n",
      "|    value_loss         | 7.82e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 37           |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.201       |\n",
      "|    reward             | -0.001204176 |\n",
      "|    std                | 1.64         |\n",
      "|    value_loss         | 0.0002       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.0569      |\n",
      "|    reward             | 0.001399288 |\n",
      "|    std                | 1.69        |\n",
      "|    value_loss         | 2.92e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 40            |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 233           |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.00287       |\n",
      "|    reward             | -0.0038276124 |\n",
      "|    std                | 1.75          |\n",
      "|    value_loss         | 6.78e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 42            |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 236           |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.191        |\n",
      "|    reward             | -0.0031426505 |\n",
      "|    std                | 1.82          |\n",
      "|    value_loss         | 0.000124      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.007835093833624804\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_13\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 341           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 6             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0012399607 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 333          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067260675 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -3.98        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.126       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 0.0017478893 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00284      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 336           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005940848   |\n",
      "|    clip_fraction        | 0.0581        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0801        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.132        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00333      |\n",
      "|    reward               | -0.0023989244 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00104       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 350          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075978795 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.115       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.118       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00887     |\n",
      "|    reward               | 0.0041964874 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.000979     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 352          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009352291  |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | 0.0858       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.115       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    reward               | 0.0022439728 |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 0.000635     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.09389063092548133\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_13\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 138        |\n",
      "|    time_elapsed    | 63         |\n",
      "|    total_timesteps | 8808       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -298       |\n",
      "|    critic_loss     | 140        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 6606       |\n",
      "|    reward          | 0.00101055 |\n",
      "-----------------------------------\n",
      "day: 2201, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10064.72\n",
      "total_reward: 64.72\n",
      "total_cost: 9.99\n",
      "total_trades: 6603\n",
      "Sharpe: 0.251\n",
      "=================================\n",
      "======DDPG Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======Trading from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0765      |\n",
      "|    reward             | 0.0063608913 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 4.97e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0686      |\n",
      "|    reward             | -0.002104781 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 5.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.138       |\n",
      "|    reward             | 0.0027999894 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.000174     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 345          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.149       |\n",
      "|    reward             | -0.020042086 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 0.000136     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 343            |\n",
      "|    iterations         | 500            |\n",
      "|    time_elapsed       | 7              |\n",
      "|    total_timesteps    | 2500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.4          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 499            |\n",
      "|    policy_loss        | 0.112          |\n",
      "|    reward             | -0.00010996539 |\n",
      "|    std                | 1.2            |\n",
      "|    value_loss         | 6.98e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0356        |\n",
      "|    reward             | -0.0011512011 |\n",
      "|    std                | 1.25          |\n",
      "|    value_loss         | 1e-05         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 346          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.0367       |\n",
      "|    reward             | 0.0008120842 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 6.66e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 347           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.7         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.0373        |\n",
      "|    reward             | 0.00047493898 |\n",
      "|    std                | 1.39          |\n",
      "|    value_loss         | 7.65e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 346          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.0877       |\n",
      "|    reward             | 0.0031871994 |\n",
      "|    std                | 1.48         |\n",
      "|    value_loss         | 3.85e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 347         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.103      |\n",
      "|    reward             | 0.005397097 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 8.42e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 349          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.0638      |\n",
      "|    reward             | 0.0093071805 |\n",
      "|    std                | 1.62         |\n",
      "|    value_loss         | 3.14e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 348           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.241         |\n",
      "|    reward             | -0.0022910477 |\n",
      "|    std                | 1.69          |\n",
      "|    value_loss         | 0.000341      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 349           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.698        |\n",
      "|    reward             | -0.0079234345 |\n",
      "|    std                | 1.76          |\n",
      "|    value_loss         | 0.00201       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 349           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | -0.00579      |\n",
      "|    reward             | -0.0019200258 |\n",
      "|    std                | 1.83          |\n",
      "|    value_loss         | 2.4e-06       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 350          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0867      |\n",
      "|    reward             | 0.0001868534 |\n",
      "|    std                | 1.91         |\n",
      "|    value_loss         | 2.81e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 349           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -0.0395       |\n",
      "|    reward             | -0.0029143717 |\n",
      "|    std                | 2.01          |\n",
      "|    value_loss         | 1.85e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 350           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.5         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.0588       |\n",
      "|    reward             | -0.0078338785 |\n",
      "|    std                | 2.1           |\n",
      "|    value_loss         | 1.42e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 350           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.0711       |\n",
      "|    reward             | -0.0030720048 |\n",
      "|    std                | 2.21          |\n",
      "|    value_loss         | 2.91e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 350          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.27        |\n",
      "|    reward             | -0.008404142 |\n",
      "|    std                | 2.31         |\n",
      "|    value_loss         | 0.000264     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 350          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.00691      |\n",
      "|    reward             | -0.005060181 |\n",
      "|    std                | 2.43         |\n",
      "|    value_loss         | 1.5e-05      |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.775161025317046\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_13\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 470           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0054892595 |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 459           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0057910243  |\n",
      "|    clip_fraction        | 0.0718        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -3.49         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.129        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00572      |\n",
      "|    reward               | -0.0016378537 |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 0.00155       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 453           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008162382   |\n",
      "|    clip_fraction        | 0.0526        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.7         |\n",
      "|    explained_variance   | -0.0479       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.126        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00393      |\n",
      "|    reward               | -0.0008952423 |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 0.000441      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 452          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068164635 |\n",
      "|    clip_fraction        | 0.0701       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | -0.0118      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.131       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | -0.002659514 |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.000348     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 449           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0064801825  |\n",
      "|    clip_fraction        | 0.054         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0538        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.131        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.0042       |\n",
      "|    reward               | 0.00056749076 |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 0.000284      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.32839065834275466\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_13\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 154          |\n",
      "|    time_elapsed    | 58           |\n",
      "|    total_timesteps | 9060         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 38.3         |\n",
      "|    critic_loss     | 78           |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6795         |\n",
      "|    reward          | -0.010489271 |\n",
      "-------------------------------------\n",
      "day: 2264, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 9056\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "======DDPG Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======Trading from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.586       |\n",
      "|    reward             | 0.014876182 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.00131     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -0.253       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.165       |\n",
      "|    reward             | 0.0017781932 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.000362     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.18        |\n",
      "|    reward             | -0.025449246 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.000399     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 343         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.115      |\n",
      "|    reward             | 0.006400144 |\n",
      "|    std                | 1.13        |\n",
      "|    value_loss         | 0.000106    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.175       |\n",
      "|    reward             | 0.005603567 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.00018     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 343          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0369      |\n",
      "|    reward             | 0.0011446386 |\n",
      "|    std                | 1.2          |\n",
      "|    value_loss         | 1.26e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 345            |\n",
      "|    iterations         | 700            |\n",
      "|    time_elapsed       | 10             |\n",
      "|    total_timesteps    | 3500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 699            |\n",
      "|    policy_loss        | -0.0335        |\n",
      "|    reward             | -0.00037295924 |\n",
      "|    std                | 1.26           |\n",
      "|    value_loss         | 5.87e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.142         |\n",
      "|    reward             | -0.0018910067 |\n",
      "|    std                | 1.32          |\n",
      "|    value_loss         | 0.000117      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.7         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.0829       |\n",
      "|    reward             | 0.00070886366 |\n",
      "|    std                | 1.39          |\n",
      "|    value_loss         | 4.59e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.00324       |\n",
      "|    reward             | -0.0017035959 |\n",
      "|    std                | 1.47          |\n",
      "|    value_loss         | 7.61e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 346           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.0383        |\n",
      "|    reward             | 0.00027724184 |\n",
      "|    std                | 1.55          |\n",
      "|    value_loss         | 8.23e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 345          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.12        |\n",
      "|    reward             | 0.0019921302 |\n",
      "|    std                | 1.63         |\n",
      "|    value_loss         | 4.98e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 346        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 0.179      |\n",
      "|    reward             | 0.00024811 |\n",
      "|    std                | 1.71       |\n",
      "|    value_loss         | 0.000122   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 346         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.0312      |\n",
      "|    reward             | 0.002125705 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 1.38e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 346          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0509       |\n",
      "|    reward             | 0.0016927554 |\n",
      "|    std                | 1.85         |\n",
      "|    value_loss         | 1.05e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 346           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.0394        |\n",
      "|    reward             | -0.0007417484 |\n",
      "|    std                | 1.94          |\n",
      "|    value_loss         | 6.87e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 346         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.214      |\n",
      "|    reward             | 0.005003501 |\n",
      "|    std                | 2.03        |\n",
      "|    value_loss         | 0.000217    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 346         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.0394      |\n",
      "|    reward             | 0.005336355 |\n",
      "|    std                | 2.12        |\n",
      "|    value_loss         | 7.07e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 345          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.0655       |\n",
      "|    reward             | 0.0013807708 |\n",
      "|    std                | 2.21         |\n",
      "|    value_loss         | 1.68e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.2         |\n",
      "|    explained_variance | 2.98e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.00903      |\n",
      "|    reward             | -0.0039299615 |\n",
      "|    std                | 2.3           |\n",
      "|    value_loss         | 8.71e-06      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.2541722421545794\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_13\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 441          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0036903843 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 429           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0074455906  |\n",
      "|    clip_fraction        | 0.0797        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -5.28         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.143        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.0065       |\n",
      "|    reward               | -0.0008886209 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00308       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 429          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060553206 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.719       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.144       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | 0.0021967678 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000542     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 429          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064987913 |\n",
      "|    clip_fraction        | 0.0557       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.239       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.126       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | 0.011535506  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00032      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 429           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005745249   |\n",
      "|    clip_fraction        | 0.06          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.245         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.152        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.0054       |\n",
      "|    reward               | -0.0019393965 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000192      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.19209248064034443\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_13\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 149          |\n",
      "|    time_elapsed    | 62           |\n",
      "|    total_timesteps | 9312         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 869          |\n",
      "|    critic_loss     | 561          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6984         |\n",
      "|    reward          | 0.0016393487 |\n",
      "-------------------------------------\n",
      "day: 2327, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 9308\n",
      "Sharpe: 0.220\n",
      "=================================\n",
      "======DDPG Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======Trading from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.0815      |\n",
      "|    reward             | 0.018228045 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.00012     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | 0.085         |\n",
      "|    reward             | -0.0032500688 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.000129      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.116        |\n",
      "|    reward             | -0.0009932289 |\n",
      "|    std                | 1.11          |\n",
      "|    value_loss         | 0.000379      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.433      |\n",
      "|    reward             | -0.04769722 |\n",
      "|    std                | 1.13        |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.0649      |\n",
      "|    reward             | 0.005277241 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 2.44e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 0.0166      |\n",
      "|    reward             | -0.00641405 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 2.73e-06    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.0246        |\n",
      "|    reward             | -0.0003910911 |\n",
      "|    std                | 1.22          |\n",
      "|    value_loss         | 5.24e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.169        |\n",
      "|    reward             | -0.0008554886 |\n",
      "|    std                | 1.28          |\n",
      "|    value_loss         | 0.000144      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 335            |\n",
      "|    iterations         | 900            |\n",
      "|    time_elapsed       | 13             |\n",
      "|    total_timesteps    | 4500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 899            |\n",
      "|    policy_loss        | 0.00791        |\n",
      "|    reward             | -0.00085130235 |\n",
      "|    std                | 1.34           |\n",
      "|    value_loss         | 3.89e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.0461        |\n",
      "|    reward             | -0.0026498246 |\n",
      "|    std                | 1.42          |\n",
      "|    value_loss         | 1.02e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.077         |\n",
      "|    reward             | -0.0021058233 |\n",
      "|    std                | 1.5           |\n",
      "|    value_loss         | 2.57e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.0258        |\n",
      "|    reward             | -0.0031476074 |\n",
      "|    std                | 1.59          |\n",
      "|    value_loss         | 5.2e-06       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.0118      |\n",
      "|    reward             | 0.0011842729 |\n",
      "|    std                | 1.69         |\n",
      "|    value_loss         | 4.33e-06     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 300         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.0212      |\n",
      "|    reward             | 0.008426747 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 1.27e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 296          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0756      |\n",
      "|    reward             | 0.0011899492 |\n",
      "|    std                | 1.87         |\n",
      "|    value_loss         | 3.14e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 295          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.0136      |\n",
      "|    reward             | 0.0014570955 |\n",
      "|    std                | 1.97         |\n",
      "|    value_loss         | 1.23e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 295          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.0832      |\n",
      "|    reward             | 0.0017448158 |\n",
      "|    std                | 2.08         |\n",
      "|    value_loss         | 2e-05        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 297           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.0841       |\n",
      "|    reward             | -0.0016876874 |\n",
      "|    std                | 2.2           |\n",
      "|    value_loss         | 1.65e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 298          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.00602      |\n",
      "|    reward             | 0.0015864094 |\n",
      "|    std                | 2.32         |\n",
      "|    value_loss         | 7.49e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 0.0285      |\n",
      "|    reward             | 0.006594959 |\n",
      "|    std                | 2.43        |\n",
      "|    value_loss         | 7.74e-05    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.3172445948907356\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_13\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 418          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.001172366 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 404           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0065429937  |\n",
      "|    clip_fraction        | 0.0995        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -3.89         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.14         |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00681      |\n",
      "|    reward               | -0.0028756429 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00095       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 396           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008361862   |\n",
      "|    clip_fraction        | 0.11          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.000604     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.141        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00793      |\n",
      "|    reward               | -0.0003605252 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00178       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 395           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0068028904  |\n",
      "|    clip_fraction        | 0.101         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.135         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.125        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00638      |\n",
      "|    reward               | -0.0015395562 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00127       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 391            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 26             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.007062041    |\n",
      "|    clip_fraction        | 0.0993         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | 0.18           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.133         |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00609       |\n",
      "|    reward               | -0.00022136129 |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 0.000789       |\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.18588849627222528\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_13\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 152         |\n",
      "|    time_elapsed    | 62          |\n",
      "|    total_timesteps | 9564        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 421         |\n",
      "|    critic_loss     | 179         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7173        |\n",
      "|    reward          | 0.008083545 |\n",
      "------------------------------------\n",
      "day: 2390, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 16730\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "======DDPG Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======Trading from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_567_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.112      |\n",
      "|    reward             | 0.008571013 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000137    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.0307     |\n",
      "|    reward             | 0.004515735 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.000123    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.372      |\n",
      "|    reward             | 0.015311489 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00101     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 5             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | -0.129        |\n",
      "|    reward             | -0.0053879353 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 0.000123      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.0377       |\n",
      "|    reward             | 0.0024814287 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 1.98e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.00465       |\n",
      "|    reward             | -0.0026148052 |\n",
      "|    std                | 1.2           |\n",
      "|    value_loss         | 3.39e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.0328        |\n",
      "|    reward             | -0.0055564796 |\n",
      "|    std                | 1.25          |\n",
      "|    value_loss         | 1.06e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.0377      |\n",
      "|    reward             | 0.007230558 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 1.92e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.241        |\n",
      "|    reward             | -0.007836652 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 0.000318     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.00064     |\n",
      "|    reward             | 0.0014534997 |\n",
      "|    std                | 1.42         |\n",
      "|    value_loss         | 4.77e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 338           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.0182       |\n",
      "|    reward             | -0.0012129224 |\n",
      "|    std                | 1.48          |\n",
      "|    value_loss         | 1.1e-06       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.00111      |\n",
      "|    reward             | 0.0024401473 |\n",
      "|    std                | 1.56         |\n",
      "|    value_loss         | 1.26e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.0312       |\n",
      "|    reward             | 0.0027119534 |\n",
      "|    std                | 1.65         |\n",
      "|    value_loss         | 2.91e-06     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -0.122      |\n",
      "|    reward             | 0.004790862 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 5.36e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0665      |\n",
      "|    reward             | 0.0051033897 |\n",
      "|    std                | 1.86         |\n",
      "|    value_loss         | 1.69e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 338            |\n",
      "|    iterations         | 1600           |\n",
      "|    time_elapsed       | 23             |\n",
      "|    total_timesteps    | 8000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1599           |\n",
      "|    policy_loss        | -0.0456        |\n",
      "|    reward             | -0.00053225685 |\n",
      "|    std                | 1.96           |\n",
      "|    value_loss         | 7.89e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 338           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.135        |\n",
      "|    reward             | -0.0019889274 |\n",
      "|    std                | 2.07          |\n",
      "|    value_loss         | 7.99e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0198       |\n",
      "|    reward             | -0.012930362 |\n",
      "|    std                | 2.17         |\n",
      "|    value_loss         | 4.02e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.162        |\n",
      "|    reward             | 0.0021192753 |\n",
      "|    std                | 2.28         |\n",
      "|    value_loss         | 6.05e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 338           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.017        |\n",
      "|    reward             | -0.0018760872 |\n",
      "|    std                | 2.39          |\n",
      "|    value_loss         | 3.49e-06      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.20124103098240234\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_567_13\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 454          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.016665526 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 430           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0076762754  |\n",
      "|    clip_fraction        | 0.0928        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -2.6          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.129        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.0088       |\n",
      "|    reward               | -0.0026643404 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00172       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 420           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009033313   |\n",
      "|    clip_fraction        | 0.0842        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.12         |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00519      |\n",
      "|    reward               | -0.0018892717 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000434      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006680578  |\n",
      "|    clip_fraction        | 0.0638       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.139       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    reward               | 0.0024064356 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000352     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006141893  |\n",
      "|    clip_fraction        | 0.0584       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | -4.17e-05    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.137       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | -0.001264559 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000364     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.16324678358290595\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_567_13\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 152         |\n",
      "|    time_elapsed    | 64          |\n",
      "|    total_timesteps | 9816        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -48.9       |\n",
      "|    critic_loss     | 74.1        |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7362        |\n",
      "|    reward          | -0.02562327 |\n",
      "------------------------------------\n",
      "day: 2453, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10021.16\n",
      "total_reward: 21.16\n",
      "total_cost: 9.99\n",
      "total_trades: 7359\n",
      "Sharpe: 0.205\n",
      "=================================\n",
      "======DDPG Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======Trading from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_630_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 294           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | -12.7         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.262        |\n",
      "|    reward             | -0.0034054876 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 0.000758      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0802      |\n",
      "|    reward             | 0.0011691776 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 8.84e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.124      |\n",
      "|    reward             | 0.027344815 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.000142    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.206       |\n",
      "|    reward             | -0.017126434 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.000205     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.019       |\n",
      "|    reward             | -0.004760454 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 2.9e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.0652       |\n",
      "|    reward             | -0.0006468341 |\n",
      "|    std                | 1.21          |\n",
      "|    value_loss         | 2.04e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 330            |\n",
      "|    iterations         | 700            |\n",
      "|    time_elapsed       | 10             |\n",
      "|    total_timesteps    | 3500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.9          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 699            |\n",
      "|    policy_loss        | -0.0231        |\n",
      "|    reward             | -0.00027757933 |\n",
      "|    std                | 1.27           |\n",
      "|    value_loss         | 3.36e-06       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 329            |\n",
      "|    iterations         | 800            |\n",
      "|    time_elapsed       | 12             |\n",
      "|    total_timesteps    | 4000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 799            |\n",
      "|    policy_loss        | 0.0875         |\n",
      "|    reward             | -0.00043993798 |\n",
      "|    std                | 1.34           |\n",
      "|    value_loss         | 4.93e-05       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.059    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 1.72e-05 |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.05        |\n",
      "|    reward             | 0.0014678536 |\n",
      "|    std                | 1.51         |\n",
      "|    value_loss         | 1.52e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.0315       |\n",
      "|    reward             | 0.0017595271 |\n",
      "|    std                | 1.6          |\n",
      "|    value_loss         | 2.58e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.031         |\n",
      "|    reward             | 0.00085071067 |\n",
      "|    std                | 1.68          |\n",
      "|    value_loss         | 8.62e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.0857       |\n",
      "|    reward             | -0.007031427 |\n",
      "|    std                | 1.77         |\n",
      "|    value_loss         | 2.51e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0529       |\n",
      "|    reward             | 0.0021028854 |\n",
      "|    std                | 1.86         |\n",
      "|    value_loss         | 1.73e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.208       |\n",
      "|    reward             | 0.0025328025 |\n",
      "|    std                | 1.94         |\n",
      "|    value_loss         | 0.000176     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 1600           |\n",
      "|    time_elapsed       | 24             |\n",
      "|    total_timesteps    | 8000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -19.1          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1599           |\n",
      "|    policy_loss        | 0.0384         |\n",
      "|    reward             | -0.00043025758 |\n",
      "|    std                | 2.03           |\n",
      "|    value_loss         | 3.93e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.127      |\n",
      "|    reward             | 0.005777824 |\n",
      "|    std                | 2.13        |\n",
      "|    value_loss         | 4.73e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0755       |\n",
      "|    reward             | -0.015336027 |\n",
      "|    std                | 2.23         |\n",
      "|    value_loss         | 4.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.42        |\n",
      "|    reward             | -0.000833353 |\n",
      "|    std                | 2.32         |\n",
      "|    value_loss         | 0.000474     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 0.283       |\n",
      "|    reward             | 0.008837103 |\n",
      "|    std                | 2.41        |\n",
      "|    value_loss         | 0.000263    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.07316122180758253\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_630_13\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 444          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0017737583 |\n",
      "-------------------------------------\n",
      "day: 2516, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 1810.33\n",
      "total_reward: -8189.67\n",
      "total_cost: 4638.16\n",
      "total_trades: 14477\n",
      "Sharpe: -0.384\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 429           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007490715   |\n",
      "|    clip_fraction        | 0.073         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -1.03         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.111        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00469      |\n",
      "|    reward               | -0.0042580552 |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 0.00114       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 424          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007956862  |\n",
      "|    clip_fraction        | 0.0869       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.0875      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.127       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    reward               | 0.0014803236 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.00316      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 415           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008157982   |\n",
      "|    clip_fraction        | 0.0849        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.0616       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.124        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00595      |\n",
      "|    reward               | 0.00019234764 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00221       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 414          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006311186  |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0492       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.136       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    reward               | 0.0053573255 |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.00146      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.2900542074709814\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_630_13\n",
      "day: 2516, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 33521.85\n",
      "total_reward: 23521.85\n",
      "total_cost: 458.21\n",
      "total_trades: 12779\n",
      "Sharpe: 0.829\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 163         |\n",
      "|    time_elapsed    | 61          |\n",
      "|    total_timesteps | 10068       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 23.5        |\n",
      "|    critic_loss     | 56.8        |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7551        |\n",
      "|    reward          | 0.009282547 |\n",
      "------------------------------------\n",
      "======DDPG Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======Trading from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_693_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 295         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -2.35       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.202      |\n",
      "|    reward             | 0.008721582 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.000363    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 0.0128       |\n",
      "|    reward             | -0.004115445 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 3.57e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.00398     |\n",
      "|    reward             | -0.011195081 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 3.21e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.0737      |\n",
      "|    reward             | -0.006007754 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 3.14e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.00607       |\n",
      "|    reward             | -0.0059165177 |\n",
      "|    std                | 1.19          |\n",
      "|    value_loss         | 1.69e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0887        |\n",
      "|    reward             | -0.0024590504 |\n",
      "|    std                | 1.24          |\n",
      "|    value_loss         | 9.31e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.0374       |\n",
      "|    reward             | 0.0017442321 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 9.24e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.044        |\n",
      "|    reward             | -0.0036062873 |\n",
      "|    std                | 1.38          |\n",
      "|    value_loss         | 1.11e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.0248     |\n",
      "|    reward             | 0.002691132 |\n",
      "|    std                | 1.45        |\n",
      "|    value_loss         | 2.62e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.0913       |\n",
      "|    reward             | 0.0008540466 |\n",
      "|    std                | 1.54         |\n",
      "|    value_loss         | 3.72e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.122        |\n",
      "|    reward             | 0.0035661678 |\n",
      "|    std                | 1.61         |\n",
      "|    value_loss         | 4.94e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.093       |\n",
      "|    reward             | 0.0016767567 |\n",
      "|    std                | 1.69         |\n",
      "|    value_loss         | 7.71e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.0627      |\n",
      "|    reward             | 0.0036028682 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 2.17e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0165       |\n",
      "|    reward             | -0.016012074 |\n",
      "|    std                | 1.86         |\n",
      "|    value_loss         | 7.7e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0771      |\n",
      "|    reward             | -0.012226787 |\n",
      "|    std                | 1.95         |\n",
      "|    value_loss         | 2.62e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -0.148        |\n",
      "|    reward             | -0.0055069346 |\n",
      "|    std                | 2.03          |\n",
      "|    value_loss         | 7.78e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.159        |\n",
      "|    reward             | 0.0031314993 |\n",
      "|    std                | 2.11         |\n",
      "|    value_loss         | 8.9e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0832       |\n",
      "|    reward             | 0.0015236493 |\n",
      "|    std                | 2.21         |\n",
      "|    value_loss         | 2.18e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | -0.0431       |\n",
      "|    reward             | 2.8298633e-05 |\n",
      "|    std                | 2.33          |\n",
      "|    value_loss         | 4.93e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.341      |\n",
      "|    reward             | 0.012233784 |\n",
      "|    std                | 2.45        |\n",
      "|    value_loss         | 0.000376    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.246551160808198\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_693_13\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 339           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 6             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0038755361 |\n",
      "--------------------------------------\n",
      "day: 2579, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 3187.16\n",
      "total_reward: -6812.84\n",
      "total_cost: 10399.51\n",
      "total_trades: 15912\n",
      "Sharpe: -0.412\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 356           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 11            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009444406   |\n",
      "|    clip_fraction        | 0.123         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -1.51         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.141        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00628      |\n",
      "|    reward               | 0.00029857142 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00111       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 367           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0072311233  |\n",
      "|    clip_fraction        | 0.0906        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.032        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.12         |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.0066       |\n",
      "|    reward               | -0.0003096426 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00227       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 378          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067086997 |\n",
      "|    clip_fraction        | 0.0607       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.123       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | 0.003248935  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0016       |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 385            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 26             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0069116214   |\n",
      "|    clip_fraction        | 0.0887         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | 0.114          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.127         |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00479       |\n",
      "|    reward               | -0.00024273148 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.00101        |\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.25848677436084355\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_693_13\n",
      "day: 2579, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9994.04\n",
      "total_reward: -5.96\n",
      "total_cost: 9.99\n",
      "total_trades: 12895\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 163         |\n",
      "|    time_elapsed    | 63          |\n",
      "|    total_timesteps | 10320       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 27.5        |\n",
      "|    critic_loss     | 82.8        |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7740        |\n",
      "|    reward          | 0.041630223 |\n",
      "------------------------------------\n",
      "======DDPG Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-07-06T00:00:00.000000000\n",
      "======Trading from:  2020-07-06T00:00:00.000000000 to  2020-10-02T00:00:00.000000000\n",
      "Ensemble Strategy took:  43.610405548413596  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "df_summary_lv = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs, PPO_model_kwargs, DDPG_model_kwargs, timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "Op7jyI7lm4hm",
    "outputId": "d8356c0f-673d-4ab1-879e-972e5bf32871"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.267453</td>\n",
       "      <td>-0.425204</td>\n",
       "      <td>-0.200898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.056274</td>\n",
       "      <td>-0.148676</td>\n",
       "      <td>0.165294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.162446</td>\n",
       "      <td>-0.095255</td>\n",
       "      <td>0.451601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>-0.093891</td>\n",
       "      <td>-0.352264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.775161</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>0.486114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.254172</td>\n",
       "      <td>0.192092</td>\n",
       "      <td>0.196175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.317245</td>\n",
       "      <td>-0.185888</td>\n",
       "      <td>-0.071326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.201241</td>\n",
       "      <td>0.163247</td>\n",
       "      <td>-0.036135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.073161</td>\n",
       "      <td>-0.290054</td>\n",
       "      <td>-0.299961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.246551</td>\n",
       "      <td>0.258487</td>\n",
       "      <td>0.122576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter  Val Start    Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126 2018-01-02 2018-04-04       DDPG  -0.267453  -0.425204   -0.200898\n",
       "1  189 2018-04-04 2018-07-03       DDPG   0.056274  -0.148676    0.165294\n",
       "2  252 2018-07-03 2018-10-02       DDPG   0.162446  -0.095255    0.451601\n",
       "3  315 2018-10-02 2019-01-03        A2C  -0.007835  -0.093891   -0.352264\n",
       "4  378 2019-01-03 2019-04-04        A2C   0.775161   0.328391    0.486114\n",
       "5  441 2019-04-04 2019-07-05        A2C   0.254172   0.192092    0.196175\n",
       "6  504 2019-07-05 2019-10-03       DDPG  -0.317245  -0.185888   -0.071326\n",
       "7  567 2019-10-03 2020-01-03        A2C   0.201241   0.163247   -0.036135\n",
       "8  630 2020-01-03 2020-04-03        A2C  -0.073161  -0.290054   -0.299961\n",
       "9  693 2020-04-03 2020-07-06        PPO   0.246551   0.258487    0.122576"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10079.479603</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>0.007948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9924.454502</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>-0.015380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9957.314686</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>0.003311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010.884480</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>0.005380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>16673.567693</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>0.016857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>16843.540605</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>0.010194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>16775.123886</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>-0.004062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>16960.659343</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>0.011060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>17043.670540</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0.004894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     account_value        date  daily_return\n",
       "0     10000.000000  2018-04-04           NaN\n",
       "1     10079.479603  2018-04-05      0.007948\n",
       "2      9924.454502  2018-04-06     -0.015380\n",
       "3      9957.314686  2018-04-09      0.003311\n",
       "4     10010.884480  2018-04-10      0.005380\n",
       "..             ...         ...           ...\n",
       "625   16673.567693  2020-09-25      0.016857\n",
       "626   16843.540605  2020-09-28      0.010194\n",
       "627   16775.123886  2020-09-29     -0.004062\n",
       "628   16960.659343  2020-09-30      0.011060\n",
       "629   17043.670540  2020-10-01      0.004894\n",
       "\n",
       "[630 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "# for every cycle (rebalance_window + validation_window) read the csv files into a dataframe\n",
    "for i in range(rebalance_window+validation_window, len(test_dates)+1,rebalance_window):\n",
    "     result_df = pd.read_csv(f'results/account_value_trade_ensemble_{i}.csv')\n",
    "     results_list.append(result_df)\n",
    "\n",
    "df_ensemble_results_lv  = pd.concat(results_list, ignore_index=True)  # Create a dataframe to store execution results\n",
    "\n",
    "df_ensemble_results_lv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQNioH9UxmEC"
   },
   "source": [
    "#### Step 7: Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "LQ2EPqa7zphL"
   },
   "outputs": [],
   "source": [
    "# # Get the datest to which the testing predictions. \n",
    "# test_dates = df_processed[(df_processed.date > TEST_START_DATE)&(df_processed.date <= TEST_END_DATE)].date.unique()\n",
    "\n",
    "# trade_date_df = pd.DataFrame({'datadate':test_dates}) # Convert the dates to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "yY1iZr1-zq8O"
   },
   "outputs": [],
   "source": [
    "# results_list = []\n",
    "# # for every cycle (rebalance_window + validation_window) read the csv files into a dataframe\n",
    "# for i in range(rebalance_window+validation_window, len(test_dates)+1,rebalance_window):\n",
    "#      result_df = pd.read_csv(f'results/account_value_trade_ensemble_{i}.csv')\n",
    "#      results_list.append(result_df)\n",
    "\n",
    "# df_ensemble_results  = pd.concat(results_list, ignore_index=True)  # Create a dataframe to store execution results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bi0NhRExrSz"
   },
   "source": [
    "> - #### Step 7.1: Calcualte Sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcGN6S1PzjpU",
    "outputId": "20f8a9a8-941c-472a-8ab0-18449a668319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  0.9043775836276403\n"
     ]
    }
   ],
   "source": [
    "# Calculate Sharpe ratio\n",
    "sharpe=(252**0.5)*df_ensemble_results.account_value.pct_change(1).mean()/df_ensemble_results.account_value.pct_change(1).std()\n",
    "\n",
    "print('Sharpe Ratio: ',sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "bhQeQ969zvRa"
   },
   "outputs": [],
   "source": [
    "df_validation_dates = trade_date_df[validation_window:].reset_index(drop=True) # Get the stock market dates from historical data\n",
    "df_ensemble_results = df_ensemble_results.join(df_validation_dates) # Mask the results with the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "4RYlDJUDm4an",
    "outputId": "97f6cffc-d76a-48ad-8f5c-974d112cd8c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_ensemble_results.account_value.plot()     # plot the chance in the amount value with time during test period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zsjiQs0xuA4"
   },
   "source": [
    "> - #### Step 7.2: Backtest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOtqFrge0PaS",
    "outputId": "57b6fa4d-2ed6-4814-f533-cffec36c254a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return          0.159534\n",
      "Cumulative returns     0.447801\n",
      "Annual volatility      0.182268\n",
      "Sharpe ratio           0.904378\n",
      "Calmar ratio           1.076276\n",
      "Stability              0.828840\n",
      "Max drawdown          -0.148228\n",
      "Omega ratio            1.195666\n",
      "Sortino ratio          1.325742\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.968050\n",
      "Daily value at risk   -0.022309\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "stats = backtest_stats(account_value=df_ensemble_results)\n",
    "stats_df = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyXuFqoXxvYk"
   },
   "source": [
    "> - #### Step 7.3: Baseline Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "-6-aJj-K0yd1"
   },
   "outputs": [],
   "source": [
    "df_index = df.loc[df['tic'] == 'SPY'].sort_values(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "HpvUESpJ07ch"
   },
   "outputs": [],
   "source": [
    "mask = (df_index['date'] > df_ensemble_results.loc[0,'date']) & (df_index['date'] <= df_ensemble_results.loc[len(df_ensemble_results)-1,'date'])\n",
    "df_index_masked = df_index.loc[mask].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyycLaDO09Kz",
    "outputId": "22fb121e-095b-4ab7-ff8d-f6f3a60f1460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return          0.121354\n",
      "Cumulative returns     0.330942\n",
      "Annual volatility      0.236552\n",
      "Sharpe ratio           0.604095\n",
      "Calmar ratio           0.359916\n",
      "Stability              0.554521\n",
      "Max drawdown          -0.337173\n",
      "Omega ratio            1.137069\n",
      "Sortino ratio          0.825409\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.702057\n",
      "Daily value at risk   -0.029236\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "index_stats = backtest_stats(df_index_masked, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JlN8dyDxwvB"
   },
   "source": [
    "> - #### Step 7.4: Compare with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "TtxmLvb44SfI"
   },
   "outputs": [],
   "source": [
    "# Rescale index stocks with begining as 10000\n",
    "\n",
    "df_index_scaled = pd.DataFrame()\n",
    "\n",
    "df_index_scaled[\"date\"] = df_ensemble_results[\"date\"]\n",
    "\n",
    "df_index_scaled[\"spy\"] = df_index_masked['close'] / df_index_masked.iloc[0]['close'] * 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "DCRq62Rq9wBC",
    "outputId": "9f66278a-ee2e-4d31-d157-7aa7a778eb1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>spy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>9777.141321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>9825.327421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>9981.552869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>9929.227721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>13196.873815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>13125.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>13224.516675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>13309.419390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date           spy\n",
       "0    2018-04-04  10000.000000\n",
       "1    2018-04-05   9777.141321\n",
       "2    2018-04-06   9825.327421\n",
       "3    2018-04-09   9981.552869\n",
       "4    2018-04-10   9929.227721\n",
       "..          ...           ...\n",
       "625  2020-09-25  13196.873815\n",
       "626  2020-09-28  13125.003128\n",
       "627  2020-09-29  13224.516675\n",
       "628  2020-09-30  13309.419390\n",
       "629  2020-10-01           NaN\n",
       "\n",
       "[630 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "tmq__tq19v62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>spy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>10079.479603</td>\n",
       "      <td>9777.141321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>9924.454502</td>\n",
       "      <td>9825.327421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>9957.314686</td>\n",
       "      <td>9981.552869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>10010.884480</td>\n",
       "      <td>9929.227721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>14152.119266</td>\n",
       "      <td>13196.873815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>14318.897842</td>\n",
       "      <td>13125.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>14228.380480</td>\n",
       "      <td>13224.516675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>14354.006153</td>\n",
       "      <td>13309.419390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>14478.012785</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            account_value           spy\n",
       "date                                   \n",
       "2018-04-04   10000.000000  10000.000000\n",
       "2018-04-05   10079.479603   9777.141321\n",
       "2018-04-06    9924.454502   9825.327421\n",
       "2018-04-09    9957.314686   9981.552869\n",
       "2018-04-10   10010.884480   9929.227721\n",
       "...                   ...           ...\n",
       "2020-09-25   14152.119266  13196.873815\n",
       "2020-09-28   14318.897842  13125.003128\n",
       "2020-09-29   14228.380480  13224.516675\n",
       "2020-09-30   14354.006153  13309.419390\n",
       "2020-10-01   14478.012785           NaN\n",
       "\n",
       "[630 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.merge(df_ensemble_results, df_index_scaled, on =\"date\", how = \"left\")[[\"date\",\"account_value\",\"spy\"]]\n",
    "final_results.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "2eRL4dvb_rKO",
    "outputId": "fbb53521-e746-4349-caa0-129c5e79eeff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFNgSamJxyv3"
   },
   "source": [
    "> - #### Step 7.5: Vizualise the comparision with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "KjlrtpRk9mc_",
    "outputId": "d8314657-6f9d-4600-f2e9-bf633538a358"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  0.6424335260539589\n"
     ]
    }
   ],
   "source": [
    "# Calculate Sharpe ratio\n",
    "sharpe=(252**0.5)*df_ensemble_results_mv.account_value.pct_change(1).mean()/df_ensemble_results_mv.account_value.pct_change(1).std()\n",
    "\n",
    "print('Sharpe Ratio: ',sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble_results_mv = df_ensemble_results_mv.join(df_validation_dates) # Mask the results with the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_ensemble_results_mv.account_value.plot()     # plot the chance in the amount value with time during test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_mv = pd.merge(df_ensemble_results_mv, df_index_scaled, on =\"date\", how = \"left\")[[\"date\",\"account_value\",\"spy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>spy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>10068.554474</td>\n",
       "      <td>9777.141321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>9843.539894</td>\n",
       "      <td>9825.327421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>9892.059730</td>\n",
       "      <td>9981.552869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>10049.745361</td>\n",
       "      <td>9929.227721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>12720.722388</td>\n",
       "      <td>13196.873815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>12943.162812</td>\n",
       "      <td>13125.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>12861.828091</td>\n",
       "      <td>13224.516675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>12960.768336</td>\n",
       "      <td>13309.419390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>13048.231505</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            account_value           spy\n",
       "date                                   \n",
       "2018-04-04   10000.000000  10000.000000\n",
       "2018-04-05   10068.554474   9777.141321\n",
       "2018-04-06    9843.539894   9825.327421\n",
       "2018-04-09    9892.059730   9981.552869\n",
       "2018-04-10   10049.745361   9929.227721\n",
       "...                   ...           ...\n",
       "2020-09-25   12720.722388  13196.873815\n",
       "2020-09-28   12943.162812  13125.003128\n",
       "2020-09-29   12861.828091  13224.516675\n",
       "2020-09-30   12960.768336  13309.419390\n",
       "2020-10-01   13048.231505           NaN\n",
       "\n",
       "[630 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_mv.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACvTElEQVR4nOydd5hU5dmH75nZne29L733JiiCiqhItWDBhi2ixijG2OKnUYIlMWosKCaG2BOwK1FUBEEEAUHKSu+9bO9tZqd8f5w5M3Om7O7szvbnvq69TnvPmXd2Z+f8zlN1drvdjiAIgiAIQjtD39ITEARBEARBaApE5AiCIAiC0C4RkSMIgiAIQrtERI4gCIIgCO0SETmCIAiCILRLROQIgiAIgtAuEZEjCIIgCEK7RESOIAiCIAjtkpCWnkBLYrPZOHXqFDExMeh0upaejiAIgiAI9cBut1NWVkZmZiZ6vX97TYcWOadOnaJLly4tPQ1BEARBEBrA8ePH6dy5s9/jHVrkxMTEAMovKTY2toVnIwiCIAhCfSgtLaVLly7O+7g/OrTIUV1UsbGxInIEQRAEoY1RV6iJBB4LgiAIgtAuEZEjCIIgCEK7RESOIAiCIAjtkg4dk1MfrFYrNTU1LT0NoR1gMBgICQmRcgWCIAjNhIicWigvL+fEiRPY7faWnorQToiMjCQjIwOj0djSUxEEQWj3iMjxg9Vq5cSJE0RGRpKSkiJP30KjsNvtmM1m8vLyOHz4MH369Km1gJUgCILQeETk+KGmpga73U5KSgoREREtPR2hHRAREUFoaChHjx7FbDYTHh7e0lMSBEFo18ijZB2IBUcIJmK9EQRBaD7kG1cQBEEQhHaJiBxBEARBENolInIEwcHcuXMZPnx4S09DEARBCBIicoRWSffu3XnllVdaehqCIAhCG0ZEjiAIgtCq2Hy0iHfWHqbGamvpqQhtHBE59cRut1NptrTIT6DFCJcuXcq5555LfHw8SUlJXHLJJRw8eNB5/MSJE1x//fUkJiYSFRXFqFGj2LBhg/P4V199xZlnnkl4eDjJyclcccUVzmNFRUXcfPPNJCQkEBkZyZQpU9i/f7/zuC+XzyuvvEL37t2d27feeivTp0/n73//OxkZGSQlJXHPPfc4K0uPHz+eo0ePcv/996PT6erMcCstLSUiIoJvv/1Ws/+LL74gJiaGyspKAB555BH69u1LZGQkPXv25Iknnqi1mvX48eP5wx/+oNk3ffp0br31Vue2yWTioYceolOnTkRFRTF69GhWrVpV63wFQfCP3W7n9x9s5cmvdnH/R1ktPR2hjSN1cupJVY2VgXO+a5HX3vXUJCKN9f9TVVRU8MADDzB06FDKy8uZM2cOV1xxBVlZWVRWVnL++efTqVMnvvzyS9LT09myZQs2m/LE9PXXX3PFFVfwpz/9iffffx+z2cw333zjvPatt97K/v37+fLLL4mNjeWRRx5h6tSp7Nq1i9DQ0HrP8YcffiAjI4MffviBAwcOcO211zJ8+HDuuOMOPv/8c4YNG8add97JHXfcUee1YmNjueSSS1i0aBFTpkxx7l+4cCHTp08nMjISgJiYGN59910yMzPZvn07d9xxBzExMfzxj3+s97w9mT17Nrt27eLDDz8kMzOTL774gsmTJ7N9+3b69OnT4OsKQkflUH4FJ4urAFiy7TSl1Rt57boRxEXW//tFEFRE5LRDrrrqKs3222+/TUpKCrt27WLdunXk5eXxyy+/kJiYCEDv3r2dY//yl79w3XXX8eSTTzr3DRs2DMApbtauXcvYsWMBRUh06dKFxYsXM2PGjHrPMSEhgfnz52MwGOjfvz/Tpk1jxYoV3HHHHSQmJmIwGIiJiSE9Pb1e15s5cyY33XQTlZWVREZGUlpaytdff80XX3zhHPP4448717t3785DDz3Ehx9+2GCRc+zYMd555x2OHTtGZmYmAA899BBLly7lnXfe4a9//WuDrisIHZl1B/I126v35fHfDUe554Lefs4QBP+IyKknEaEGdj01qcVeOxD279/PnDlz2LBhA/n5+U4rzbFjx8jKymLEiBFOgeNJVlaWX+vJ7t27CQkJYfTo0c59SUlJ9OvXj927dwc0x0GDBmEwuN5XRkYG27dvD+ga7kydOpXQ0FC+/PJLrrvuOj777DNiY2OZMGGCc8xHH33Eq6++ysGDBykvL8disRAbG9vg19y+fTtWq5W+fftq9ptMJpKSkhp8XUHoyOw6Xeq1r7rG2gIzEdoDInLqiU6nC8hl1JJceumldOvWjX//+99kZmZis9kYPHgwZrO5zhYVjW1hodfrvWKIfMW9eLq2dDqdU4w1BKPRyNVXX82iRYu47rrrWLRoEddeey0hIcrfbP369cycOZMnn3ySSZMmERcXx4cffsiLL77Y4PdSXl6OwWBg8+bNGsEGEB0d3eD3IggdmZxSEwCzzu3BWz8dBqDSLCJHaBgSeNzOKCgoYO/evTz++ONcdNFFDBgwgKKiIufxoUOHkpWVRWFhoc/zhw4dyooVK3weGzBgABaLRROkrL7ewIEDAUhJSSE7O1sjDrKysgJ+H0ajEas1sC+2mTNnsnTpUnbu3MnKlSuZOXOm89i6devo1q0bf/rTnxg1ahR9+vTh6NGjtV4vJSWF06dPO7etVis7duxwbo8YMQKr1Upubi69e/fW/NTXzSYIgpbskmoAzu2dzKNT+gNQVGFuySkJbRgROe2MhIQEkpKSWLBgAQcOHGDlypU88MADzuPXX3896enpTJ8+nbVr13Lo0CE+++wz1q9fD8Cf//xnPvjgA/785z+ze/dutm/fznPPPQdAnz59uPzyy7njjjv46aef+PXXX7nxxhvp1KkTl19+OaBkJOXl5fH8889z8OBBXn/9da+sp/rQvXt3Vq9ezcmTJ8nPz6/7BGDcuHGkp6czc+ZMevTooXGr9enTh2PHjvHhhx9y8OBBXn31VU28ji8uvPBCvv76a77++mv27NnD7373O4qLi53H+/bty8yZM7n55pv5/PPPOXz4MBs3buTZZ5/l66+/Dvg9C4IAuWWKyEmNDSMhyghAUaWIHKFhiMhpZ+j1ej788EM2b97M4MGDuf/++3nhhRecx41GI8uWLSM1NZWpU6cyZMgQ/va3vzndLePHj+eTTz7hyy+/ZPjw4Vx44YVs3LjRef4777zDyJEjueSSSxgzZgx2u51vvvnG6X4aMGAA//jHP3j99dcZNmwYGzdu5KGHHgr4fTz11FMcOXKEXr16kZKSUq9zdDod119/Pb/++qvGigNw2WWXcf/99zN79myGDx/OunXreOKJJ2q93m233cYtt9zCzTffzPnnn0/Pnj254IILNGPeeecdbr75Zh588EH69evH9OnT+eWXX+jatWtgb1gQBMwWG/nliqBJjw0nIVIROYWV/ks9CEKt2APkxx9/tF9yySX2jIwMO2D/4osvNMdvueUWO6D5mTRpkmZMQUGB/YYbbrDHxMTY4+Li7Lfddpu9rKxMM+bXX3+1n3vuufawsDB7586d7c8995zXXD7++GN7v3797GFhYfbBgwfbv/7664DeS0lJiR2wl5SUeB2rqqqy79q1y15VVRXQNQWhNuRzJQj+OVFUae/2yBJ778e+tlutNvsvhwvs3R5ZYh/3/MqWnprQyqjt/u1OwJaciooKhg0bxuuvv+53zOTJkzl9+rTz54MPPtAcnzlzJjt37mT58uUsWbKE1atXc+eddzqPl5aWMnHiRLp168bmzZt54YUXmDt3LgsWLHCOWbduHddffz2zZs1i69atTJ8+nenTp2tiJgRBEIS2gxqPkxoTjl6vc7mrJCZHaCABpwtNmTJFU3DNF2FhYX4DL3fv3s3SpUv55ZdfGDVqFACvvfYaU6dO5e9//zuZmZksXLgQs9nM22+/jdFoZNCgQWRlZfHSSy85xdC8efOYPHkyDz/8MABPP/00y5cvZ/78+bzxxhuBvi2hlTNlyhTWrFnj89hjjz3GY4891swzEgQh2BwvVKqTd4pXsjxVd1VptQWL1UaIQSIshMBokpzoVatWkZqaSkJCAhdeeCHPPPOMs27I+vXriY+PdwocgAkTJqDX69mwYQNXXHEF69evZ9y4cRiNRueYSZMm8dxzz1FUVERCQgLr16/XBNSqYxYvXux3XiaTCZPJ5NwuLfWuxyC0Tt58802qqqp8HvNX80cQhLbFvpwyAHqnKSUY4iJC0enAbofiqhqSo8NacnpCGyToImfy5MlceeWV9OjRg4MHD/LYY48xZcoU1q9fj8FgIDs7m9TUVO0kQkJITEwkOzsbgOzsbHr06KEZk5aW5jyWkJBAdna2c5/7GPUavnj22Wc1lXyFtkOnTp1aegqCIDQx+3LKAeibqogcg15HeIiBqhorVVIrR2gAQRc51113nXN9yJAhDB06lF69erFq1SouuuiiYL9cQDz66KMa609paSldunRpwRkJgiAIKvtzFUtO37QY576wUD1VNVZMFulILgROkzs4e/bsSXJyMgcOHAAgPT2d3NxczRiLxUJhYaEzjic9PZ2cnBzNGHW7rjG1FWELCwsjNjZW8yMIgiC0PBUmC8ccMTl93EVOiHKbktYOQkNocpFz4sQJCgoKyMjIAGDMmDEUFxezefNm55iVK1dis9mcxdvGjBnD6tWrNSX0ly9fTr9+/UhISHCO8azMu3z5csaMGdPUb0kQBEEIMrtPl2K3Q1psGCkxrtibcEfvPrHkCA0hYJFTXl5OVlaWs1T/4cOHycrK4tixY5SXl/Pwww/z888/c+TIEVasWMHll19O7969mTRJaW45YMAAJk+ezB133MHGjRtZu3Yts2fP5rrrrnN2cr7hhhswGo3MmjWLnTt38tFHHzFv3jyNq+m+++5j6dKlvPjii+zZs4e5c+eyadMmZs+eHYRfiyAIgtCcbD9ZAsDgzDjNftWSY7KIJUcInIBFzqZNmxgxYgQjRowA4IEHHmDEiBHMmTMHg8HAtm3buOyyy+jbty+zZs1i5MiRrFmzhrAwlzJfuHAh/fv356KLLmLq1Kmce+65mho4cXFxLFu2jMOHDzNy5EgefPBB5syZo6mlM3bsWBYtWsSCBQsYNmwYn376KYsXL2bw4MGN+X0IgiAIzcyhvHJW7lHCGAZ38hQ5YskRGk7Agcfjx4/36szsznfffVfnNRITE1m0aFGtY4YOHeq3LorKjBkzmDFjRp2vJwiCILRO8stNTHjpR2yO28qo7gma405LTo2IHCFwpLKSIAiC0GLszyl3ChyAsb2SNcfDQsVdJTQcETmCIAhCi3G6xFXk86nLB2HQ6zTHxV0lNAYROfXFbgdzRcv81OIe9MWnn37KkCFDiIiIICkpiQkTJlBRUcGtt97K9OnTefLJJ0lJSSE2Npa77roLs1npC/P++++TlJSkqQoNMH36dG666aag/SoFQRBUThUrImfGyM7cPKa713GXu0osOULgNElbh3ZJTSX8NbNlXvuxU2CMqtfQ06dPc/311/P8889zxRVXUFZWxpo1a5xxVCtWrCA8PJxVq1Zx5MgRfvOb35CUlMRf/vIXZsyYwe9//3u+/PJLZ6xTbm4uX3/9NcuWLWuytycIQsflZLHSlDPT0a/KE1d2lVhyhMARS0474/Tp01gsFq688kq6d+/OkCFDuPvuu4mOVsqkG41G3n77bQYNGsS0adN46qmnePXVV7HZbERERHDDDTfwzjvvOK/33//+l65duzJ+/PgWekeCILRnVEtOJz8iR+rkCI1BLDn1JTRSsai01GvXk2HDhnHRRRcxZMgQJk2axMSJE7n66qudRRSHDRtGZKTremPGjKG8vJzjx4/TrVs37rjjDs4880xOnjxJp06dePfdd7n11lvR6XT+XlIQBKHBqCInIz7c53FxVwmNQUROfdHp6u0yakkMBgPLly9n3bp1LFu2jNdee40//elPbNiwoV7njxgxgmHDhvH+++8zceJEdu7cyddff93EsxYEoSOxP6eMVXvzuGVsdworlJhA9yrH7oSJJUdoBCJy2iE6nY5zzjmHc845hzlz5tCtWze++OILAH799VeqqqqIiFBMwz///DPR0dGaRqW33347r7zyCidPnmTChAnSxFQQhEZRbrLwxOIdTBuSwYSBaVz88mpASQsvrlLa9yREGn2eKzE5QmOQmJx2xoYNG/jrX//Kpk2bOHbsGJ9//jl5eXkMGDAAALPZzKxZs9i1axfffPMNf/7zn5k9ezZ6veujcMMNN3DixAn+/e9/c9ttt7XUWxEEoZ2wYPUhvth6ktvf36TZv2xXDlZHkZy4iFCf50qDTqExiMhpZ8TGxrJ69WqmTp1K3759efzxx3nxxReZMmUKABdddBF9+vRh3LhxXHvttVx22WXMnTtXc424uDiuuuoqoqOjmT59evO/CUEQ2hX7ssuc6xaryyKTV6aUq4gINTgDjD2ROjlCYxB3VTtjwIABLF26tNYxTz75JE8++WStY06ePMnMmTM1PccEQRAC4XB+BU9+tZMNhwqd+44XuYr/5TpETkKkbysOSMVjoXGIyBE0FBUVsWrVKlatWsU//vGPlp6OIAhtmEc+3cbGI4WafXtOlzrXna4qP/E4IL2rhMYhIkfQMGLECIqKinjuuefo169fS09HEIQ2zKH8cq99WceLvfbVZsmROjlCYxCR04F499136xxz5MiRJp+HIAgdAzWexp1D+RVe++Jrc1eFiLtKaDgSeCwIgiA0CapAcWf5rhyvffpaio1K4LHQGETk1IE9wOaYglAb8nkSOhKl1ZZ6jYsy+ncqSAq50BhE5PjBYFCeHtQO3YIQDCorKwEIDfVvnheE9kCN1UZBhcm5PaxLvNeYpy8fxNQh6dx9QS+/13FlV4klRwgcicnxQ0hICJGRkeTl5REaGqoplicIgWK326msrCQ3N5f4+HiniBaE9kp+uQnVcPn7i/pwVvdEbnxL217mpjHduWlM91qv43RXSXaV0ABE5PhBp9ORkZHB4cOHOXr0aEtPR2gnxMfHk56e3tLTEIQmJ7dUseKkx4bzwMV92ZdTpjn+u/H+rTfuSOCx0BhE5NSC0WikT58+4rISgkJoaKhYcIQOg9p4MylaqYHjnkE1bWgGD17ct17XkRRyoTGIyKkDvV5PeHh4S09DEAShTVHgEDmJUQ6RE+Eq+De0UxwhhvqFAEiDTqExSKCJIAiCEHQKHUHHSQ6RY3RLJzf6SC33hxqTY7XZNX2vBKE+iMgRBEEQgk5hRQ0ACVEuC45q1Tm/b0q9r6NmVwFUizVHCBBxVwmCIAhBx9OSA7DigfMpqDDRMyW63tcxurm1TDVWosPktiXUH/m0CIIgCEGn0BmTE+bclxBl1Fh26oNer8No0GO22iQuRwgYcVcJgiAIQccz8LgxSPCx0FBE5AiCIAhBxWK1cdjRiFNNIW8MrqrHUitHCAwROYIgCELQsFht3L1wC8WVNYSH6ukdQPyNP6TqsdBQROQIgiAIQWP5rhyWOTqNv3b9GQHH4PhCteRIk04hUETkCIIgCEFjf245AJcPz+TigWlBuabTkiMxOUKAiMgRBEEQAqK0uob//HyUgnKT17EjBUosTt+0mKC9ngQeCw1FRI4gCIIQEI99vp0nFu/goU9+9Tp2tKASgG5JkUF7PWnSKTQUETmCIAhCnVhtdhZuOMrxwkqWbDsNwA9787zGOUVOYlTQXjssVAKPhYYhxQAFQRCEOnlzzSGe/XYPybWkhOeUVpPvcGF1bRJLjogcITDEkiMIgiDUiZoxlV9udu4LNeg0Yz7dfAKAUd0SiIsIDdpri7tKaChiyREEQRB8Um6y8MBHWRj0Oo46AordqbHaeeX7ffxhQl8AftiTC8DVIzsHdR7hDndVtbirhAARS44gCILgk49+Oc6yXTl8uyNbY8Fx55Xv9zvr16iuqkAacNYHseQIDUVEjiAIguCTj3857nP/QxP7araLK2sAKHIsEyKD56oCV52cKikGKASIiBxBEATBi0qzhb05ZZp96bHhfHjn2dxzQW/N/qJKMxarjZIqh8gJQpVjd5JjlOvllXrX5RGE2hCRIwiCIHhxrLDSa9/QznGc3TMJnU7HpcMynfuLK2ucAgcgPohBxwCdE5RMrRPFVUG9rtD+kcBjQRCENs6SbafoFB/BiK4JDb5GSWUNn205wTfbT3OyuIquiYqwGNIpju0nSwCICXeJl5euGcaWo0WcLK6iuNLsdFXFhocQYgju83On+AgAThaJyGl2jm+EkuMw+KqWnkmDCPiTuHr1ai699FIyMzPR6XQsXrzY79i77roLnU7HK6+8otlfWFjIzJkziY2NJT4+nlmzZlFeXq4Zs23bNs477zzCw8Pp0qULzz//vNf1P/nkE/r37094eDhDhgzhm2++CfTtCIIgtEkWrD7Im2sOsS+njNmLtnLFP9ZhsTY8+2j6P9by1JJdbDpaxOmSajYcLgSge7KrqN+wLnHO9VCDngEZSuuGosoaiiqVwORgu6oAuiQoIud0SRU1jXiPQgN462L49DbI2dnSM2kQAYuciooKhg0bxuuvv17ruC+++IKff/6ZzMxMr2MzZ85k586dLF++nCVLlrB69WruvPNO5/HS0lImTpxIt27d2Lx5My+88AJz585lwYIFzjHr1q3j+uuvZ9asWWzdupXp06czffp0duzYEehbEgRBaFMUV5r56zd7eObr3ezJdsXNbD5a1KDrVddYOZzvnSIOSi2chbeP5rfn9+T6s7pqjsVHKoKmuMpMUYVZsy+YJEeHYQzRY7NDdkl10K8v+MHmJihLTrbcPBpBwO6qKVOmMGXKlFrHnDx5knvvvZfvvvuOadOmaY7t3r2bpUuX8ssvvzBq1CgAXnvtNaZOncrf//53MjMzWbhwIWazmbfffhuj0cigQYPIysripZdecoqhefPmMXnyZB5++GEAnn76aZYvX878+fN54403An1bgiAIbYbSKotz/WCuywr+ztojnNk9Eb1e5+s0vxRW+E4PB5gxsgtjeiVxTu9kr2Nq7E2xmyUnMciZVQB6vY7MuHCOFFRyqriKLonBq6bcnJRW12DQ6dibU0ZOSTVThmS09JRqx1TqWg+NaLl5NIKgx+TYbDZuuukmHn74YQYNGuR1fP369cTHxzsFDsCECRPQ6/Vs2LCBK664gvXr1zNu3DiMRtcTwaRJk3juuecoKioiISGB9evX88ADD2iuPWnSpFrdZyaTCZPJFZ1fWlrqd6wgCEJrxT3Id59bBtTSndn8fLiAsb28BUltuIuca0YphfwGd4pj6pAMkqPD/J6nuqaKKswUOdYTmsCSA66CgOY26q6qMFkY9fT3ZMYrYg1g5YPnB72mUFCpLm7pGTSaoIuc5557jpCQEH7/+9/7PJ6dnU1qaqp2EiEhJCYmkp2d7RzTo0cPzZi0tDTnsYSEBLKzs5373Meo1/DFs88+y5NPPhnwexIEQWhNFFe5RIlnmndD3DkFDpHTPz2G568eVu/z4h1Wm6LKGmdQcFpceMCvXx9CHcHMFqu9Sa7f1PxypBCz1eYUOKCIy54pLTipuqhyc39a22b6flBD4Ddv3sy8efN499130ekCM5c2B48++iglJSXOn+PHfRe6EgRBaM2oxfcADuVpY2nMDWhiWVih3MCSamm+6YsMh6A5VljBEUfbh+5BbMzpjsHhgrPY2qbI8RXz1Orfi7vIsfh3abZmgipy1qxZQ25uLl27diUkJISQkBCOHj3Kgw8+SPfu3QFIT08nNzdXc57FYqGwsJD09HTnmJycHM0YdbuuMepxX4SFhREbG6v5EQRBaGsUu7mrPGmIO6fA0bIhMcq/a8oXgzOVbKsDueXOAOhuSVG1ndJg1Gagjckga0n2nC7z2ldptvgY2YrQiJy2GfAdVJFz0003sW3bNrKyspw/mZmZPPzww3z33XcAjBkzhuLiYjZv3uw8b+XKldhsNkaPHu0cs3r1ampqXP/Iy5cvp1+/fiQkJDjHrFixQvP6y5cvZ8yYMcF8S4IgCK2OUh8iR42daZglRxE5SQGmf6fGhpMaE4bNDnllijWoexOJnLZuydl5usRrX4WplbepqCp2rVvbpiUn4Jic8vJyDhw44Nw+fPgwWVlZJCYm0rVrV5KSkjTjQ0NDSU9Pp1+/fgAMGDCAyZMnc8cdd/DGG29QU1PD7Nmzue6665zp5jfccANPPvkks2bN4pFHHmHHjh3MmzePl19+2Xnd++67j/PPP58XX3yRadOm8eGHH7Jp0yZNmrkgCEJ7pLhSe8PR65R4mp8OmDA1QuQkNqDGzeBOcax0dB8PC9GTGhOYNai+OGNybG3PklNjtbEvu9xrf9uy5HSQmJxNmzYxYsQIRowYAcADDzzAiBEjmDNnTr2vsXDhQvr3789FF13E1KlTOffcczXiJC4ujmXLlnH48GFGjhzJgw8+yJw5czS1dMaOHcuiRYtYsGABw4YN49NPP2Xx4sUMHjw40LckCILQanjrp8N+G2OquMfkADw2dQDdk5VYmIaInEOOeJHaMqn8MbiTq0Bgr5TogNPX64tqyalpg4HH+3PKfboRW78lp+2LnIAtOePHj8dur/+H7MiRI177EhMTWbRoUa3nDR06lDVr1tQ6ZsaMGcyYMaPecxEEQWhtVJgs/HvNIQCuP6srTy/ZBcDlIzKd3bc9cY/J6ZMazaxze/D0kt1A7e4qi9XGmgP5jOyWQKyjRcOhvHI2Hi5Ep4Pz+gSWeg4wONMV2ziia3zA59eXEL3yTG5tg+6qXad9lytp9ZYc9xTyNppdJb2rBEEQWgi73c69H2x1unsy3NKvc0tNfoveqdWF7x7fi3sv7INOpyMsVBEBtYmcN386zN++3cN5fZJ5dMoA/r5srzPG5YJ+qQ0qsjeks8uSMyCj6ZI52nLg8aE8b1cVQIW5lVtyytySezqKJUcQBEEIDj8dyHcKHIDPt7hK52eXVvsVHUcdHcInDUonwqhYe4yOmBWz1f+N8801hwFYsz+f0qpt/HrCFQx749ld/Z1WK+mx4YQadNRY7YztlVT3CQ2kLQcel/jJhqs0tXJLTtlp52pJeTlxtQxtrYjIEQRBaCF2nVLcGCF6HRab3dkUE/wX9SurrnFmMvVIcWUyGUNqt+Qs2XaK/HLX03iRW1xPakwY5/dN9XVaneh0OlY8MJ6Sqpomrd7blosBllb7FjOt3pJT6hLdH6w7wF1TW3AuDSSoKeSCIAgC9Y5bPO0QMmN8WED8iZzDbkHCalwNKJlN4F/kzF60VbPt7hr707QBTktJQ+iaFKlxWzUF7dKS01pjcqwW+Nf5msBjI/5rM7VmROQIgiAEkSe/2sm4F35wxs34Y292Ge+uOwJAj2Tv2jLZpb5FjlrhuKfHOU5Ljo+YFV9xLGra+G/O6c7lwzvVOtfWQFuOyVHrGoV4CMlWm11VsB9OZ2l2hYnIEQRBEN5Ze4TjhVVOAeMLq83OpFdWO7c9BQv4t+ScKFLicbp6tE9wxuT4sOTklHkHjapxPTNGdvE7z9aEM4W8DVpySqsVgRBp1GbLtVpLTv5+r11iyREEQRCczFuxn/2O5pnusTAAq/fnabZ9xbIUVPjOZql0xHHEhGtDKlVLjq86OaeLq7z2qWIo0H5VLYUrhbwtWnIUMRNp1P7NWq0lJ3+f1y6jzhJQ+ZjWgogcQRCEIFFdo71p3fdhFos2HGPUM9+zaMMx5/4f93qKHG9LTkmV76f8KsdreFoFahM5pxxWoZ4pUSREhmqOxXtst1ZUV0/bDDxWrCD9M2I0+ytauyUnJIJ1CZcDiruqLRZiFJEjCIIQJDwDTHedLuWxL7YDOJcAxxyuIpWMuAiveA1f/akAqhyWnIhQD5Hjx111OL+CP3yoBB0P6RRHV7feUjFhIX4LDrY2QpxtHdrWjba6xur8mzx9+WAuGZrBnEsGAtQZt9Ui2Kxw/Gdl/ap/cyC0L6C4q0yWVmp5qgUROYIgCEHCs92CP44WKMHD15/VlfduOwuDXudlmfErchyWnHBPkeMju8pms3P1P9eh6oLOCRF0SYhwHm9LgqGtBh6rf0e9Tvn9z7/hDK48Qwn0Lq22tD7hsPdbKDoC4fHQ8wIqrIqLzUhNg5q/tjQicgRBEIKEasnJiAsnNty7DFm5yYLNZud4kRIjc/f4XpzfNwXwjtcoM1k46y/f85/1RzT7nZYcD1GkWmTcs6uKq2oocFgLrjqjMzeP6c6fLx3ErHN7YNDrmDgoraFvtdlpqynk208qBRdjI0LR6ZT3EBse6rTcFbY2a86x9cpyyAwIi6akRplnmK6mQX3RWhopBigIghAk1O7g6XHhRBoNrD1QoDm+L6eMjLhwzBYbIXqdplaNpyUHILfMxNyvdnHTmO7Ofaolx8td5cOSo95AY8JDePGaYc79T1wykN9f2IdoH0KstdIWiwEWVZiZ9d4mAOIjXLFPer2OpGgjOaUm8svMZMRF+LtE86NWOU7oDkCRSfm9G7G0SZEjlhxBEIQgoTbOjIsI9dnRu6jCzJJflZtI54QIZ5wJQGSY79gYq83uDFwFlyXHUxSpxQCPFVYy7dU1bDtR7BQ5SVHeGVRxkaGNKgDY3LhSyNvOjfZfqw851x+Y2E9zTP18eGbetThl2coyJh2AQkclA3FXCYIgdHBKHDE58RGhmmrEKrllJl5cvheA35zTQ3MsMtS/VeWIo8ox1B2TA7DzVCl3vL/JKXISfIictobq3lG7kBdWmFv9TXefo4TAX64YzGXDMjXHklqtyHFYcmIyKKuuodisfK7CJPBYEAShY1NcpYiK+EgjsRHeouXrbaeprrHRNTGSm8d00xyz1lKD5LAPkeMvu0olp9REUaV/S05bwz2F/GRxFWf/dQXnv/ADxwoq6ziz5Sh39KxKiPT+/Sc76hPll7eimBy7HUoVkWOLzmD+DweoRplnpM4k7ipBEISOTEG5KnJ8W3J+OpAPwMSBac4gVBV/2VTgIXL8BB67W3JUthxVeg/5usm2NVwp5DYO5pZjtto4XVLNf34+0rITqwXVzRgd5i14U1qjJae6BCxKUPwn+2r414+HyLYnApBCMTXmVjTXetJ2os4EQRBaKUt3ZPPuusP8fEjpIp4ZH+F0q3gSatBxzZnerRTc4248cbdW1FUM0J1PNp8AILGdWXKq3Iou1jdtvyUoc1hyPKtTA0Q5hE9la+pErsbjhMex4oDiassjjmp7KOG6GkdX8oyWm18DEEuOIAhCI/nnjwedAgegc3wEcRG+KwlPHZJB37QYr/2lbhWO/zRV6Qp+zajOAJx0a8ugWnJqi8nxpF2IHLdigFVuwqDVVg1GKRkAvkVOSGus+3Nys7JM7IXL0KjjpD0ZAEPJ8RaZVmMQkSMIgtAI7HY7BxwBpiqZ8REad5V7vExmvO90Yfcb4R3jerJj7iRmjFIsPqdKFJFjs9mdcRGeMTme2+7tGpJ8ZHq1NZzFAG02jSWnvJX2f7Lb7W4ix1vwhjp6cdW0JpGz/ztl2XuCxkV6wq7UcjKWn2iJWTUKETmCIAiNILu0mgoPl0NGfLgm8Ni9N1WKH8HxzxtH0j89hoW3jwaUmJtODkGUXVKN1aZ103jG5IQa9JoChMvuH8dVZ3Rm+vDMNlX0zx/OFHKrXePiqTC1TktOVY3V6bL0FZOjWnJaVVf1w2sAsPa+mCP5ios0My6ckjDFRSUiRxAEoYNxILfca19YiEFjyXEXOamxvkXOyG4JLP3DOM7pnewaGxOGQa+jxmonr8ykETnhPnpOPTKlPwBndk8gNSacF68ZxivXjfAZBN3WcHUht2saobZWkaPG4+h1vgs9uoobthJLjrkCqhSX65bKFMxWG7HhIfz0yIUQq6S/GytzW3KGDUICjwVBEBrBQYfIMYboMVts9EhWBE2sW0xO10Q3kRMTTn0JMehJjw3nZHEVJ4urSI1RBFJ4qB69j0J+M0d3IzM+gv7p3jE/bR1X4LGNSrc4nPJWLnKiw0K8MunAvRdXK7HkqEHHoVEs3qW4XycPTkev12ELUSyKOmt1S82uwYjIEQRBaASnS5Qv/htHd+OiAan0SY0GtDE2mfEuYZMSE1h8TGpsGCeLq8grMzmv6Rl/484F/VIDun5bwRmoa7NTZXZZP1qvJUfJ+vIVjwMuy1SrcVc5iwCms+loMQAXD1SqHjtFjqXK15mtGhE5giAIKNVpNxwu5IazutbZ7sButzufzrNLFZGTHhemcTWFGvRcf1ZX8stNDMqMc+5PDVDkRDkad1bVWJw3dM9mnh0BVRR4ppBXtNLA49oyq6AVZlc52zlkcOqoIma6J0UCYA9RRLreIpYcQRCENsnEl1cDoANuPLub33HzV+7n7bVH+PSuMfRMiXZactJivd1Qz145BIACt4JvUT6CUGtDjeeoNFudNWESotp+jE2guAJ1bVS5uavMVhtmi63WFPqWoLYaOeCKyWk12VUOS05NVJpz7hlqJqDDkhNqqQCrBexW+Ox2yBgK4x5ukenWl9b1qRAEQWhhNh0prPX435fto7DCzLwV+wHIcVhyausknRQdxvL7x7H2/y4MeD5OkWOyunpRtYMKxoHi3rvK3ZIDrdNlpVpy/InaELdssVaBw5JTblSskTFhIa6sMKPy2e5cvg0WnA97v4XdX8LKZ5SA5VaMiBxBEAQ3zPV8sjZbbNjtdrIdlpx0H5Ycd/qkxThTwgMhwuiqjKv2ouqQIsfgcld5VglujcHHavNQz55iKqEhrjYVFSYLa/bntazrquAAAIUGReRkuMWR6UMjXeNydsDxDa7to+ubZXoNRUSOIAiCG2aL/ydr99YLBr2OnadKncX5/KWGNxanJafG4hQ57aGCcaA4s6tsNk0KObTOqseqYAn1J3LcYozu+u9mbnprI/9YdbDZ5udkx2fwyW9gn1II8GDECEBrmUxOjNeec3i12/qPvq+buwcOrYLylk07F5EjCILgRm0xEieLXNklS7ad5pLXfgIgLiLUq81CsFBFTpXZSmGFIyanQ1pyXCnXnpac1uiusjiyptR5e+KMMbLaWLNfady6cMPR5pmcSkUBfHob7PwcsENcV7bWKK1EMuJclpxuaUna83J2uNYdFiAvtv4H3r8cfnoluHMOEAk8FgRBcEN1M/jiRJHvFFp/faqCQaSbu6rcERCa2BEDj/Vuvas8LDmtqsmlAzXWRp23J6FuKfEq/sYGHXMF5O+DA99rdtv7T2XZrhwARvdMdO7PTE7EL/76WeUrMWsk9WrUVBuLiBxBEAQ3arfkVPrc76tsf7BwZVe53FXxHdGS41YMsMpD1FhaS60ZN1zuKj+WHLVOjpuo9jc26Kx4Gjb802v36YwJHPyxAqNBz0UDXK1AQsKjvMY6KfYjclQLT3Kfxsy00Yi7ShAEwY3aRE5+udnnfn9pwsEgwi2FvCPH5Kgp4hVmqzNtP8rxu7G1QpFTU193ldvc66rPFDQ8BU5oFCT3Y59xEAC9U6O1rUBCawmYry4Gk7ZBLRYzFB1R1pN6N3q6jUFEjiAIHR73m6S5lpTewsrmFznudXIKyjtudlVGXDije7jcJjodJDsKK1pbochRLTn+XFBGH72r/AUpB53UQa710XfBQ/vgzh/IrVQsZF5VuUN8iJy4rhDmKHJZclJ7rPioUksnNApiMoI48cARd5UgCB0e97Tx2iw5RY46NU9eNoi02HDu+u9mwH/p/mCgipz8MhMFjtfvnBh4KnpbR6fT8fatZ/LRL8cprDAzKDOWt346zNGCSmz2VihyHMLLr7vKLSXeta8ZLDn7lkHuTmX9jh+g0xnOQ3mOgoDeIsdH5mBkIoTHQk6JEpeTqjSHpfQ0rH5BWU/qpajRFkREjiAIHR6TpX4ix1mML8pIrJv1pmljcpRrH8pXiq4lRxvbRVfxOrHWADowuH63UWEh3HZuD+f2O+uOAK0zJkf9HIX4sc6oMUblbunvTR54fHobLJrh2o7UBhTnOypzJ0d7iBpfQiUqGdApmVZq3yuA/1wBebuV9RaOxwFxVwmCIGgyqjxrsLijtlVIjDRqrDfN4a5SUbuct2uqS2HeMHjvEqjFSmPQuaogtzZUC02onzgb1TXl/vaaPCYna5F2O1KbGp5XpoicejWRjUyCaEdwcnmO20V2u9aTROQIgiC0OCZL/Ro+qjE5CVGhxEa4WXKaUeTU1j6izVOWoxSae+McKD0Jx9ZD4SG/w1X3Tut0V9VhyfHhmnL/HAad/cu9A46N0ZpNlyWn7pgve2QSeThicsrzfA9q4aBjEHeVIAiCxpJTYbZgs9nRezxV2+12Z0xOYpSRsBCX+Ihqwq7gER7XHtIpzs/INo7NCv8aB+XZ2v1H1vittaJ3WnKaenKB46yT4yfOxleQsWdqfFDZ/qn3Pg83VCCWnG3F4XyxPZ+5oWgtOe60cI0cEJEjCIKgCTy225X2DZ61aMpMFmfsR0KksdnSfd1jf64Z1Zlrz+rSLK/b7BQf9RY4oPRGGnmrz1PUv0FrTCFXXWihdRQDdKdJRU7eHp+7zRYbTy/ZRUx4iDM1P7UOkbPCOoLHtvVhFEo8ka08R3EL2TzUZiuIyRGRIwhCh8ezynFemclL5KhWnEijoclaOPgiJjyUF64eSohBxxUjOjfb6zY7eXtd63FdoeSYsu6voi5ulpxW6K5yBR7XXgzQHc9KzkHDZlMqHAPoQ8CmiJNnv9lNdY2V//zsaifROSGCHsnRXpcoD0sn2pTNneb7WWY7E4A8nWJVNBWdJgLA7FYv5661EBbTJG8nECQmRxCEDo/JU+Q4YhMWrD7Iuc+tZNuJYt74UWme6KtGTVNbdWaM6tK+BQ64LA1DZsC9m+D6j5Tt0lN+T1E9Pq058NhfTI5PS05TiZySY1BTCQYjXPcBAO9YJvGv1Yd4b722X9YNo7v6/Dx/c87HXGN6gmW2Uc59ecQDYKh0xORUFSvLkHBIHxz0t9EQAhY5q1ev5tJLLyUzMxOdTsfixYs1x+fOnUv//v2JiooiISGBCRMmsGHDBs2YwsJCZs6cSWxsLPHx8cyaNYvy8nLNmG3btnHeeecRHh5Oly5deP75573m8sknn9C/f3/Cw8MZMmQI33zzTaBvRxAEwaclB+Cv3+zhRFEVl81fywcbFYtCglvfqFvHdqdnchSXD89svsm2V7IdTR9T+il1WVL6Kdtl2X4zrJzuqlZoyVEDj/1lV+l0Oi8xUV1jaxrXm2olS+oDfSdSevcOnrLc5HPoNaN8u0MNUUlstA8AXHPOsyuWHKO1Atb/QwkWBwiPB+DeD7Zy89sb2XGyJChvoyEELHIqKioYNmwYr7/+us/jffv2Zf78+Wzfvp2ffvqJ7t27M3HiRPLyXNHXM2fOZOfOnSxfvpwlS5awevVq7rzzTufx0tJSJk6cSLdu3di8eTMvvPACc+fOZcGCBc4x69at4/rrr2fWrFls3bqV6dOnM336dHbs2IEgCEIgeIocf+0bQGvJmXvZIFY+NL5JiwF2CPL2wa7FynqXs5VlTLqytFQprQN8oG/FKeQ1dVhywFUrxx1Pq2JQUK1kDuG49BjYHbf/q87ozFu3jEKvg5vHdPOukePAl4u2nAiq7I7/h+8ehS/vVdYj4gFYfzCf1fv8ZF41EwHH5EyZMoUpU6b4PX7DDTdotl966SXeeusttm3bxkUXXcTu3btZunQpv/zyC6NGKWav1157jalTp/L3v/+dzMxMFi5ciNls5u2338ZoNDJo0CCysrJ46aWXnGJo3rx5TJ48mYcffhiAp59+muXLlzN//nzeeOONQN+WIAgdGM/UXdWS44uO2DeqSSk9DT88o8SJ9LoQepyn7A+NUCwC1cWKNSciwetU1RLSGkWO05JTSxVjo0HvJWqqaqzOfmVBQ7XkpPTnw43H+L/PtwPQPSmSF68ZBsCWJy6uVayHh3qLtVCDnnx7HF10DiGjNuUMj6ekqsb5sNC9BWs7NWlMjtlsZsGCBcTFxTFsmPKLXL9+PfHx8U6BAzBhwgT0er3TrbV+/XrGjRuH0ej6Mpk0aRJ79+6lqKjIOWbChAma15s0aRLr16/3Ox+TyURpaanmRxAEwfNGk19u8us26Ih9o5oMux0WjIdd/1O2u47VHlf7HrlX1HVDLQbYGt1VTktOLVWMfQUlP+YQIEHFzZLz9JJdzt1Jblab+DoyBiN8WHIGZsa5auW4Ex7HEUeF7tSYsCatCF4XTSJylixZQnR0NOHh4bz88sssX76c5ORkALKzs0lNTdWMDwkJITExkezsbOeYtLQ0zRh1u64x6nFfPPvss8TFxTl/unRpp6mYgiAEhKe76sd9eZwurfY5Viw5QSRnpzZtPKmn9rjqsirz/b2u17feOjmWOrKrlGPet+ClO/3fwxqE1QK5isipSepLhVuaeiCCPcyHyBmUGUuePd57cEQ8hx0ip6UrdDeJyLngggvIyspi3bp1TJ48mWuuuYbc3NymeKmAePTRRykpKXH+HD/uPzVREISOg2rJOaNrPOGhevLKTLzv6IvkSYKInOCx1yNZJNFD5KgpyOYKn6e3ZktOXQ06QRuUfFb3RL/jGsXJTVBTAREJrMqP1xyyeNa1qQVflpwB6TGU2iO99pfpovlhr3LP75nSDkVOVFQUvXv35uyzz+att94iJCSEt956C4D09HQvwWOxWCgsLCQ9Pd05JidHW0FR3a5rjHrcF2FhYcTGxmp+BEEQVEtOp4RILhumZEqpDTE98fVlL/ih8DBUFvo/nr9fu+0pckLClaXFt1VN34pjcurnrnIde+KSgc71oL6fAyuUZa8L+WSLNh2/vNri4wTf+IrJSYkJJzzEW8S9vbmI/2Upr9UuLTme2Gw2TCYlkG/MmDEUFxezefNm5/GVK1dis9kYPXq0c8zq1aupqalxjlm+fDn9+vUjISHBOWbFihWa11m+fDljxoxp6rcjCEI7Q614bDToncGXuX7cVa2xum6rpOAgvD4a/nU+LL4HvvuT9xj3dgCxnSHcI74j1CFyanz/LVp3nZy63VVl1a57XJdEV0+yoNbLObERgJqu57J6vzbTqXeqd9E/f/gKhk6MMhLhI1a5xO4SNr4KCzYnAYuc8vJysrKyyMrKAuDw4cNkZWVx7NgxKioqeOyxx/j55585evQomzdv5rbbbuPkyZPMmKG0dx8wYACTJ0/mjjvuYOPGjaxdu5bZs2dz3XXXkZmpPEHdcMMNGI1GZs2axc6dO/noo4+YN28eDzzwgHMe9913H0uXLuXFF19kz549zJ07l02bNjF79uwg/FoEQehIqJ3Hw0L1zifWnFLlwaxvWjQX9XfFEZ7Vo4ncCu2NbR+B1aQUosv6L6yfD+UeYQuqyLl0Hty5yvsaIY4bv6XK50u0DXeV/9tsUaVL5MRFhKJ6rypM9bew1EmBUsRyp6UT1TU20mPD+fzusVx3ZhcentSv3pcx6LzFWvekSH6NPt9rfykuF1ZLW3ICDnnetGkTF1xwgXNbFR633HILb7zxBnv27OG9994jPz+fpKQkzjzzTNasWcOgQYOc5yxcuJDZs2dz0UUXodfrueqqq3j11Vedx+Pi4li2bBn33HMPI0eOJDk5mTlz5mhq6YwdO5ZFixbx+OOP89hjj9GnTx8WL17M4MGto8qiIAhtB2f35SgjxhDlppTtsOR0TYzizVtGUVBuorDC3KLpsG2KXV967ys+DtFuiSeqyOl8FkSneI+vw5KjuqssrdCS42zrUI9q2L1SotDpdEQZQygzWYIncmqqoOQEAGsKYoFCzu2TzBldEzijq3dKfm0kR4cxoms8+eUmrj+rKxMHppMaG86RlAt4NW8bvw9Z7Bzrbsnpmugds9OcBCxyxo8fj70W1fz555/XeY3ExEQWLVpU65ihQ4eyZs2aWsfMmDHDaSESBEGoL/nlJpKijOgcT6e5DqtNSmw4Jg9XQZzDHp8UHaZJuRVqwWpx9Uq6+2dYfDec2qJYdTqPVPZbTFCllAQhOs33deqIyQlpxQ061bYOtVlyzuqeyMYjhTxwsWJRiQpTRE5lQxp1Fh2FJffD2NlKvSFQYqKwQ1gcu0uUz/HAjIbFour1Oj7/nZLir3Oz6iTHhPGd9Sy/Ikd9aGgppHeVIAgdikUbjjHqme/5y9e7yXZ0Xc5xFP9LiwnzSpVNjpZsqoApPQF2KxjCILmfK6C42C2jtcIRH6IP8VnoD2jWwGOL1VbrA3zA17PVHZPzr5tG8vFvxzBtqFIPKDJM+ew1yJLzxV1wcAX85wrXvkLFVUVSL44VKS6/xlhWdDqdRuCAYuGpRCv+S1BETiDusKZCRI4gCB2GdQfyeewLpdjamz8d5op/rMVms5PncE2lxoYT7vHkmRob3uzzbPMUOZo+xncFvR7iHM1F3TuKq66qqFRljC9CHTE5NbXH5DS2C3mFycJ5z//A3Qu3sGZ/Hiv35NR9Uh3UJ7sqIcqoifGKMirOlQpzA0TOsXXe+9QKxEm9OF7oEDlJwXUfpUSHUWHX/o+U2KOYMCCNey7oHdTXaggtV4ZQEAShGTFbbPz2v5s1+06XVFNQYSZXteTEhnGiqFIzJjVGXFQBU3REWSZ0U5bxjsKrjvgQAModlhxfsTgqdVhyDEFyV32/O4fTJdWcLsnm2x1KMb5f/zzR6apsCGp2VW11cjyJNKqWnCBkV1WXwsEflNWY7pRUKUHOnRMiajsrYFJifFtyYiNah7wQS44gCB2CTUcKKXPUBXE32e/LKcNis6PTKab38BCtu0pEToBUFcHpX5X1hO7KMraTsnRvz1DlqJ8Tmez/WnW5q4JkydH7yByqakhcjBs1trobdHqitj+oDNSS45m1BvDZLDj8IwC5RkVkJkeHEWkMrvhQ3FVaS04VYY0SiMFERI4gCB2CVY5uyFee0YlP73LV09pxsgSAxEgjoQa9V7dlcVcFgMUEr58Nm5TiryT3VZZqzE1VsVIc8Nv/g2Prtcd8UWednMa3daiusbL1WLHX/kCqAfvCacmpR3aVSqRD5JQHaslZP1+7bSqH/cucm2sKlWDjQZnBL4CbHGPE5iUldK1G5LQOe5IgCEIT8+NeReSM75dKamw45/VJZs3+fPbnlgOunlSelV3FkhMABQe0vaiGOLJfw+OVZVURvHcZ5Lg1oYyspe5QXXVyguCuevCTX/l6m3cDUM9+Zp7c9NYGDuaW8/glA5k6JENzzGazo04pEEtOlMNdVRlo4PEOj6xmj4am/9mn3OqvGtk5sOvWg6Qo7f/HWvsQAGJr6WjenIglRxCEds+p4ir25pSh18F5vRX3SIojHfyAQ+TEOp483S05UUYDUS3YQblNUVUEn9zq2r70VZeAiYhXltXFWoEDjbLkBMNd5UvggLYzfZXZqnEh2e121uzP51RJNU99tcvr3PfWH3Gu15Zd5Yn6WasIxFVmMblinYyO6sJr57kOp49gT7Fyq3cvahks1BTx1dYhmO0GnjTfCNBqLDkicgRBaPesPZAPwLAu8c4GmykOC83BPEXkxPkQOeKqCoCVf3HVxhl+I4y8xXVMteT4ojaR47Tk1N7WoSnq5KiWHLvdziWvrWHUM9+zfJeSdWV28495tmAorjTzpJvwCa0lu8qTKGMDUsiLjgJ2ReCkDlD2bf2P48Wj2Db5YwAy4sKbVLDfUfMgY0zz2WdX4n9E5AiCIDQT204ocTdnunV6VkWOGowcG67cANzdVeKqCoAjbsVbPV1QobWIxYja3FWO338TBx77QhUy1TU2DuZVUGm28pevFfHi7sqyeAQELd56UrMdiCVHdZnmObL96kXRYWWZ0IPqSK3bjLjOHC4wA03fXsGEkQJcvcdiReQIgiA0D9scwcWDO7m+hFM8BIwvd5XnGMEDu135UddV+k2t/zVqdVfVUSenCbuQm2oU8VJmcvWXUntNuYscs4fIOVqoLUHg1dah9DRsesfne1Jr2BzzuIZfdn4BP/xVWU/oxsKDHunhNZUcKagAaPZ2JGLJEQRBaAZqrDZ2ny4FYGgtIkf9Uo5wEzmt5Yu6VWKzwr8vgPcuBYvZVV336reh25jaz3Wn1sDjetbJaRJLjuKGcq9ZU1JVQ3WNVSNsaqx2p+i578OtvLP2iOY6nhWC+eBaWPIHWPG012uqpQ2OF1bWXX25pkqJgTqdBYA9oQebqtK1YyryOJSviJyeTShy5l460Gtfa/nfEZEjCEK7xWK1sS+nDLPFRkx4CN3cqr16uqLUbBB3S05rMbm3SgoPwamtipvq2HqwWZS4kEFXBnad+lhyLNVaS5EDp7uqCS055dXa+Jic0mqvzCs1huZ/Waec+64c0Yll94/zvrBaQ2jrf70OdU5QPp9lJgt3eRSu9MK9sCJQlHEe++za7KmK8HRnYHVTuqtuPacHM0d31exrLSJH0gYEQWiX5JZVM/mVNRRWKDEJQzvHaZ6qU6K1cSJqhVaDm3shJly+Iv1S6rqh8/5lyjJtEPgorFcrtVpy3ISoxeQV2xOMOjn+UK015R5BwNkl1c7YGZVyk8UZ0K5ydq8k+qbF+H8BU6nXLneB/d3OHMpNFmeBQC+Kj2k2N+uHcNTusnjVJPblmtOu4O+mjsnJiHP9bUINOq9SDC1F65iFIAhCEDlaUMF5z/3gFDigjccBRdQY3WqY+HrybC21PloVNqtS1M/DkgBA5hm1nOgQPykDtLtry7wKcYsx8VErx9m7qpGF+3zhtOR4ipzSak16OSi9pjwzvKLqrCzs2/p0fl9XmwtTTS2p5O59wGZ9z48HCrAQwjTTX/hz0t/ZMX0ZO+09nEO6NKIxZ31wr6QcFxHq7aZrIUTkCILQ7rjz/c1eN6IhHiJHp9Np4nJ8CZoxvZKaZoJtmXemwnPd4H93ex/LGOb/vNu+g94T4Jr3XftCwmu3/BhCQee4TfmoleO05ATfW4XJYcnxTOf+YU8ul7z2k2ZfhcmKxUPkqB3FNVjM2m0fwcd/u2qIaw61FSRUO7qPug1L5ki+2a4UYdxp78Eacx+KK2s0w0MDKErYEKLCWqebV2yxgiC0O/bmlHnt65/u7TqIiwjlZLFyo3H/Yt7w2EXklZnolRLddJNsi5TnwvGffR/TGaD7Of7P7ToabvxMuy+qjuJ0Op1izamp8Bl8HKwGnb5QrShlHiJnsVvcjUqFyeIVF+TTklORp93O3w8ZQzW7MuIiiAkLocxkobpWS47DkhbXhT3ZZRqrZV6piQK3bbXxZ1PibslpTRZQseQIgtCmKaow8/2unDqzUeoy17un2KbFhnu5twTg5Bbf+8++G367GuK7+j7uj9o6kKvUUitH34Qp5M6YnOq6C/NVmCxeva58CovyHO22GoTsQZgjnqVWS06pox5PXGdnQUtVyJeZLDz0ievan9wVQLZbA3G35LSWoGMQkSMIQhvnN+/+wu3vb+ILtyJsvurbhIV433RuP68HGXHhvPObM/0HeAoKFQXw4Q3e++9aC5OfhfTB9b9W5ghleebtdY+tpVaOoZHFAGsTxmoGVX2qD5f7suT4+jx5WnIc6d+eqJ/VWkWOeq3oVA46WpMM7xJPjMfr3nZODwZlNr1gd7fkxEe2HpEj/9WCILRJrDY71//7Z7KOFwPw0S/HufIMJYW2vmXxrzyjs/McoRbsdvjiTrB7uE9CowITNyo3fq5YMXqOr3tsLbVyGtvWoTYRoR5TA4+To8PIL/ddiVix5Hi6q3xYcirytdunsnxez2nJ8eWuqqmGd6ZA3h4A3vu1gg92KfE5vVOj6Z0WremqnhRt9L5GE+BeX+rCJuiR1VDEkiMIQptkf24ZGw8XOrdLHW6FGquNSkeDw4kD0wCYMjjd+wJC/cnbAwe+V9YnPwf371SsMHetqf08f0QmQq8L6pduHuq/f1Vj2zrUJnLMHiLHPUXakwqztX6WHLNSmI84h1uvPNfn9VRLTrX7/L76A/zvHji0Ck653IavbShxtoHolRrtFUeWENk8Iqd7chQxYSH0SY1mmkdX9pZELDmCILRJThVr3Rd7s0upMlupcOsW/cKMYUzZk8NFA9Kae3rti0OrlGXPC+Dsu5T1aS82z2urMTm1ZFc12JJTS2CvyaIcU2Ny0mLD2e5oD+JJuQ9Ljrtlw0mNQ+RExEEJYKvxHoOrf5pzftWlsPkdZT2lv2ZsES5RM7JbAit2a+N+zJYAOpo3griIUNY9eiEhej0hTZzJFQitZyaCIAgBcKpYueldPDCNiFADNrvS2LCkSrlxxISHEBcRyhUjOreqbI82yaEflWV93EvBxtmJ3Dsmxxl4HERLzoiu8YDLkqP2fuqSGOE1VqXKbMXqkceu9+xZBWB29KRSawNZfYucsBBX4PHWY0Vc+dIS18Flj2vGWlHE1O/G9yI2PNTLVTSsS7zfeQebmPBQIpohkysQxJIjCEKbRLXkZMaFExMeQlWNlXKThWrHk2tryvBo01gtcMRRF6bn+c3/+mqVY1+WHF3jKh57pmj/fcYwiivNbD1WjMli40BuGXuyywg16JgyOMOrL5VKldnqlV3lE9VdFe4IBPZjyXG6q2qszF60lcSyAqilV+zoHok8eHFfAC7ol8q/bhpJXEQoVpudEV1raZvRARCRIwhCm+R0iXLTy4iPIDoshNwyE+Umi9NdJSInCNhscGA5mMuUHlPpQ+s+J9jUGnjcSHeVhyXHZrc7rShmi42f9iuBwmN7Jddqyams8Y7J8UmNh8ix+g6Qd7fklFTV0EvnXffJnWvP7OJ0Eel0OiYNkhg0FRE5giC0SZyWnPgIoh09pspNNZRVi8gJGu9fpjTgBOh+HuhbwBVRi8gJJPDYarPz/e4c+qbFOPs4eVpy7HY7RjeBoQazZzqEtD+qzNqYHL+Bt57uKr8xOa4UcqvNTjzlvi/nuIWnx/oPiu7oSEyOIAhtklMlLneVegMqq7ZQUK5Uem2urJJ2S1WxS+CkDoIx97TMPJzuKh91cgKw5KzZn8dv/7OZC/6+irUH8rHb7V7VjEf3SHKrUWOlwJEyHmU01NqLqtItuyouIpT5N4zwPdDTXVVnTI4Vm91OvM6HyInrwo32ZwBIqyXzq6MjlhxBENoUj36+nbwyE8cL3Sw5Yaolx8Jph/ipLeVXqAf5+5RlbCe4e13LzSPEfwq5msRTH0uOGqgOkHW8mB/35bFg9SEAuiVF8s6tZ9I9OYpdp5Xu4GsPFLD2QAGgpIP7CiQO0euw2OxUml29q6LDQvw3p/R0V2FXGp56WMjUOjlv/3QEk8VGgsFD5Ix/lIqzH2Tj3GWAkvkl+EZEjiAIbYaiCjMfbDzm3NbrIDUmzOWuqrZwyi1WR2gEjmJzpPRr2XmE1sNdVQ9LTlm1y2pitthYs99VmK9vWgw9HfVlfGUHRflqtolicbGYrUp2lSPwOMRQS+0f1ZITEe/aZ63xEjnhDmuSWnzQ3ZJz9Nzn6Db+LgoKFNdXeKjed+FBARB3lSAIbQi1R49KWmw4IQa9xpKTrYocseQ0HLsdtn+irHvUZWl2VEtObV3I6yVyXK4ps9WGapi5eGAaf5nuqtocG+797K+2LJg+PJPEKJcbVI3fqayxYHGkkBt8pY47X1iNyXFrs+AjLke15KgkOAKPn6mZyfnfd2HHyRLGvfADoFRi9ms5EkTkCILQdvAUOaq4cY/JOV0s7qpGs/tLOLxaWe8yumXn4mzQ6T8mJ1BLTo3FRo0j7/zWsd1JdXP3+KqppFpyXr52OOsfvdC5XxU5VWabcw4htYkcL3cV3nE5B1cy6cgLROASdQmOwONiR+G/P32x3XksObqW3HJBRI4gCG2Hg3kVmu3sUuVGoLqrSqtryHGUuM8Ud1XDydmpLDOGw8DLW3QqrgadtaSQ1yMmx9OSoxb7U4WKSqyPrDzVkqPT6TSNXl0ix5VdZdDXcltV3VVhsa59FXnwyW9g71Jl+z9XMPT0p1xlcLXM6KU/BcBJezIAe7JdKeUicmpHRI4gCG0GtduyyhmOQmdq5+U9p8uw2uyE6HXy5d8Yio4oy0HT69dfqimprU5OADE5pe4ix+ImcjxaEPi05PjJrFIFT2WNqxigX0uOzerqHG6MBL3jdTYugJ2fwwfXQrmrS3kYSpZgEiV01uVjs+vYbusBaOv7JLSijt+tERE5giC0GQ443FUvzhjGrWO788LVSnE61ZKjZsac0TWh9tgIAfZ8A891h/3fex8rOqosE7o354x8U1uDzga6q8xWG2arb0tOeKj3bTHST+CxWm/HbocKk1Jzx+/nbvHdrnVjNBgc4sTdQrX8CdccUY4P1SsZYIfsGZQT6XVZz55ZghYROYIgtAmqa6wcL1QCN8/rm8zcywY5Yyk8n7TH909p9vm1OT68HqqKYOFVyrbFBJ/dAVsXuiw5rUHk1NagU6e6q+q+TJmHJcfkx13lK4jX8/P13m1nMWlQGs+4BSyr1/drydn2oWs91M2SY3crSPjrB87VSBS36yDdEQAs6cN8Xrbc5LtqsqAgKeSCILQJjhZUYrMrjTdTPFxRvVNdnZhD9EqfIaEWLGbtdnUp7PsOtn+s/KjEd2veefnCV4PO75+E4qMYLngNqKclx6RNIffnrvJFpEeK9vl9Uzi/ryKkjSF6zBab01JULwtiaCQYHLffygLfr6lTRE4f/UkA+g8dDce8x90wumvdr9eBEUuOIAhtggOOeJxeKdFeT9s9U6KZd91wRnVL4F83jXS6EQQ/HF2r3T65yftmG5Op9KtqaYyOv6X7/H56CXZ8RlhuFlC/YoClVS6LR43VlV3lacnxRVQtLR1UAaRaVHzWyXGv1jzjXdDrXZYcPyLnwp6Ka6qPThE5vlL5v5x9DuP7itWyNsSSIwhCm0BNH3e32rhz+fBOXD68U3NOqe3y00va7cLDUHJcu2/EzJYPOgbIGAb6EMWFln8AEns6D4VYFReW2WJj+a4cZzsEX7i7dapqrE4XV0MsOZpjoQaKcfVM85ldVeEoPGgwwsDpyrrew5IT1xVKXKaaTlF29NjopVMyq5SijLs1lx3aOb7OuXd0ROQIgtAmUEVOrxTfIkeoJ6ZyVw2cftNg79eKgFDjcACS+8GZt7fE7LyJiIfu58KhVbDvWzjzDueh6HADydFh5JebuOP9TfW+pLvgqY8lpzbxFO4QQKUOd5XPmBw1qyoqxSUcVXdVhUPkDLsOVj/vmpetms66PMJ0NdTowwiN78ZzV4Xw+OIdnNcnhVvGdq9z3oKIHEEQWjkH88p5Z+1hVu7OBaBXiriiGoTFDCFGKDyobEcmQ4/zXCKn2GFFuP4j6De5xabpk/ShisgpPQ1Wk3O3Ua/jvdvO5G/f7nE2Zq2NGquN/bnllFfXLnL0Om0wc20VhdUWDJW1ZVeplpyoZLcXcbirzI6aN5kj4N4tsONz+OEZjFU5pFOonB6WRrzewLVnduWKEZ3rJcwEBRE5giC0al5ato+vt592bvfy464S/GC1wOe3w84vlG7iZ85S9if1hgSl7gq5u6E8R1mPb4WBrGqGldWsDZq2WRiUGcd/ZtWvKvOP+/K45e2NlDsEiU7n2/Ky+J5zeHXFAZKijFxQR6aeq7WDck3flhxFoBPldi2DR32b8FhI6uX8/RuP/cR84w4ATGGJXq8n1I+Af1urV6/m0ksvJTMzE51Ox+LFi53HampqeOSRRxgyZAhRUVFkZmZy8803c+rUKc01CgsLmTlzJrGxscTHxzNr1izKy7VFvrZt28Z5551HeHg4Xbp04fnnn8eTTz75hP79+xMeHs6QIUP45ptvAn07giC0Yqw2u0bgAHRN9K4VItTC/u8UgQOQuxN+ekVZT+rtShEv2A+mUiXYOKl3S8yydgyqyDFpLDlYTL7H+0GNvyl3ZFoZDXqfVpqhneN585ZRPHf1UCbXkakX5lb1GPxZctzcVSp6DxuD2urB6Pp8p+qKATAZExEaRsAip6KigmHDhvH66697HausrGTLli088cQTbNmyhc8//5y9e/dy2WWXacbNnDmTnTt3snz5cpYsWcLq1au58847ncdLS0uZOHEi3bp1Y/PmzbzwwgvMnTuXBQsWOMesW7eO66+/nlmzZrF161amT5/O9OnT2bFjR6BvSRCEVsquU6XO9Qv7p3LfRX0IrUegqOBGzi7tthrcmtRLCeJ1v9le+CfFpdXaUOdkMcPpX137fRQIrA3VClJdU//MqroIC1XcVWoxQJ+WnFLHg350mmufpyVHbfVg9HbHmsNE5DSUgN1VU6ZMYcqUKT6PxcXFsXz5cs2++fPnc9ZZZ3Hs2DG6du3K7t27Wbp0Kb/88gujRo0C4LXXXmPq1Kn8/e9/JzMzk4ULF2I2m3n77bcxGo0MGjSIrKwsXnrpJacYmjdvHpMnT+bhhx8G4Omnn2b58uXMnz+fN954I9C3JQhCK2T7yRIAxvVN4e1bz2zh2bRR8vcqy6HXwraPXPs7n6mIh4TuUHBA2dd1TLNPr14YHCJn24faonqBihwPgVyfzKr6XrOqRo3J8XHNQqVqMUm9XPv0PtxVAKHeIic8Pr3R8+yoNPkjUUlJCTqdjvj4eADWr19PfHy8U+AATJgwAb1ez4YNG5xjxo0bh9HoeqKYNGkSe/fupaioyDlmwoQJmteaNGkS69ev9zsXk8lEaWmp5kcQhNbL/lwlKLOvxOE0nDyHyBl4OQy7XlnvcraSsQTam60ao9PaMPixLtV4dyavDU/LTXAsOco1Kky1VDxWRY7779fdkqMzuFlyvN2xnTt1afQ8OypNKnKqq6t55JFHuP7664mNVf6A2dnZpKamasaFhISQmJhIdna2c0xaWppmjLpd1xj1uC+effZZ4uLinD9dusgHRxBaM2oBwL5pMS08kzZKwUHI36esJ/eFS16GS15RCtKpsSixma7xtXXQbkn8iZwGuqv8bTcENSan0uyw5HgWA7TWuDLX3Gr8aNyEcZ1B76jF48NdpcnKEgKiyT7RNTU1XHPNNdjtdv75z3821csExKOPPkpJSYnz5/jx43WfJAhCi7E/x1EAME0sOQHx3Z9gbhy8doYiBFIHKTfY0AgY9RuIdQumnfaikqJ99TstN9+6CPHTUb6xIicI7ipnJ3KzH0tOyXGwWZRu6jFuv3d3S457RpsPd5UmYFkIiCZJIVcFztGjR1m5cqXTigOQnp5Obm6uZrzFYqGwsJD09HTnmJycHM0YdbuuMepxX4SFhREW5uefRRCEFmPj4UKW7sjmrvE9SY1Rmm6aLFayS5WbWI8kqY1Tb7J3wPr5ru24LnDtf1yWAk8Se8Bda5pnbg3FM0hXxUfTztoI9bCyBNOSo9bV8cquOpWlLJP6aC1lej8iJ8yHoBeR02CCbslRBc7+/fv5/vvvSUpK0hwfM2YMxcXFbN682blv5cqV2Gw2Ro8e7RyzevVqampcDdWWL19Ov379SEhIcI5ZsWKF5trLly9nzJhWGjgnCIIXxwsr2XmqhDn/28Hbaw9zyas/YXPcLdwLtsVG+LnJCd5sdGWhEp0Od6/XBry2RQz+LDmBxeSEGbRCL5giR8XLknNwpbLseb52v8HNxuAucoxRMOM97VhxVzWYgC055eXlHDhwwLl9+PBhsrKySExMJCMjg6uvvpotW7awZMkSrFarM0YmMTERo9HIgAEDmDx5MnfccQdvvPEGNTU1zJ49m+uuu47MTMU3fMMNN/Dkk08ya9YsHnnkEXbs2MG8efN4+eWXna973333cf755/Piiy8ybdo0PvzwQzZt2qRJMxcEoXWSW1rN7e9vYtuJEu3+MhNFlWaSosOcpfcjjYb6dXbu6Oz6Erb+B/YvU7Yn/w0GXAZh7SCeyW/gcWtwV2mvocmustvh4A/Keq8LtCf6s+QADJoOn7htR0gKeUMJWORs2rSJCy5w/bEeeOABAG655Rbmzp3Ll19+CcDw4cM15/3www+MHz8egIULFzJ79mwuuugi9Ho9V111Fa+++qpzbFxcHMuWLeOee+5h5MiRJCcnM2fOHE0tnbFjx7Jo0SIef/xxHnvsMfr06cPixYsZPHhwoG9JEIRm5sd9eV4CR6W02qIROdG1dIAWHNjtsPRRKD2hbEcmKz2eDO3kd+evdk+AlpymcFd5XsNpyTGVwcc3K38TQxh0Has90d0FF1tHY9n28ndsAQL+zY0fPx57LW3tazumkpiYyKJFi2odM3ToUNasqd1PPGPGDGbMmFHn6wmC0LrIKfX/BF5apbipVXeViJx6UHDAJXCMMXDRE+3rxug3uyqwischBr2mL1UwA49VnFbH7Z+4XFXpg71Tw91jpGKkDk5T0Y7+CwRBaCuoAcWRRoMz9VZF7eZc4chWiQ6Xr6k6UV0iPc6HW75s2bk0BUGqkwOK5SW4FY/9WHLK3MqZDLrS+0Sb2+c+Os37uBAUWmlRBEEQ2jPZJcoT+MhuCc59AzKULMzSKkXclDksOVFGETl1olYszhzRsvNoKoJUJwfQtAVpisBjZ50ck6O7uD4Uzrzd+8TKQte62rdKCDry7SEIQrOjuquuGdWF6horgzvFcbywit2nS12WHEcvILHk1IPio8qyNXYQDwb+6uQEGHgMEBse6hTQngKlIfiNyaksUJYXzYHQcO8TK/Nd6z6ahLqOiS2iMchvTxCEZqO6xsr764+w+7TSUqV7UhSf3DWWP186iNgIRcw4Y3IcnaIlJqcOynNhv6NnYEK3lp1LU+GvTk4DLDkvXD2U0T0SGZARyxUjOjdyYr5ichy31QqHiPGX/q2KoLpIH9rAmQkglhxBEJqRP32xg8+2nHBup8W5ntBjw5UbmWrJKVctOSJy/GOzwjtTwe6I74jv3qLTaTL81skJXOSM7Z3M2N7Bqzvjt06OKmIik/CJu7vKF7evgJ9eholPN3KGHRux5AiC0Gy4C5yYsBCSo9xEjqPgnxqTo2ZXRYnI8Y3FDG9NhIL9rn1xjbdMtEr8uatMLd9k2dNd5cwwrkvkjP29shx6ne/jnUfBdQu1/a6EgJFvD0EQmoXsEu1T96BOsejdivzFOmJvXDE5isiJkZgc3+z8HE5ucm0n9/Md+9Ee8OeuqvJda6k58XRXqQH0LpHjp5DfeQ9Az/GQIe6opkS+PQRBCDpr9udxuriaa87s4tx3tKBCMyYtVntDVi05JVU11FhtzmKAUUY/PZc6Oid+ca3P/AyS+7TcXJoaf+4qUwlYLS1aE8jdXfXHyf0Y3TMJzJVQU6nsjPTjGtMboMuZzTDDjo2IHEEQgs5Nb20EIK/cxOmSKh6dMoCSKlcvutjwEO6f0FdzTpxD5Kzam8eYZ1eQHqeIIHFX+eGko//f1e9AnwktO5emxp8lB6C6uEV7O7nXyRnZ1VESQc2cMhjbR1uNNox8ewiCEFRqrDbn+gvf7VX2WeyM6q7cAM7vm8J7t53ldV63JFdF2PxyM/nlZgD6p8c25XTbJuZKpds4QKeRLTuX5kCnUwSD1ex9rKqoRUWO3i39u3tylLJSlqMso9NqTw8XmhwJPBYEIai4W2xUPtp0nOJKZX+cn47i3ZOivPZlxIUzuFMTi5zKQig+3rSvEWyO/AS2Gojr0n5r43jiXhCw/yWuppVVRS0zHwfxka7Pc2qMw61W7qh2LJWMWxwROYIgBBVVzHiy8YiSMqvWw/EkPNQ79ua8PsnomvJJ2GKCdy+B185wuX/aAvu+VZZ9Lu44lgJ3kXPxU66aQC0sclJjwvngjrP55vfnKZ/V09sgd7dyUHpStTjirhIEIWgcL6xkwks/+jz2/W7FhO/PkuOLbj6sO0Hj1FZYMN61/fmdMHtTcEVDdQn87x6I7Qxj74X934ExWull1JBg2S/vhS3/ARxpyv2mBW+urR13kRMSBhFq/Esd9WaagTG9HGni2dvhX+e5Doglp8URkSMIQtB43hGD4wu1fEhtIud343vxz1UHndtdEiP9jg2Ize/B/mUw6jfQ2xGku3yOdkzBAdi3FPpNCc5rAmQtgt1fKesb/unab62BETPrfx2LGdbOgy3vu/b1vwR6XxScebYF3IOPDW4ip4UtORoOr9ZuiyWnxRF3lSAIQaO82ttVdUG/FM12bSLnwYv7MuvcHs7tLgkRjZ9U4SH46vewZwl880eX2irP9R67Z0njX8+d7Z/63n9wRf2vset/8EwK/PCMdv8Fj3UcVxUAbu81xNg6RY4xWrstlpwWR0SOIAgNYk92KUfytbVvInzUtPnTtIF0ineJldpETohBz1k9XMXTgmLJOfiDa73wIBzfqLiR8nxYnUpPNf71VEzl2mJ9ACN/oyx3fAb5+73P8cVX93nvG3w1pA1q3PzaGpGujvUYwlyp2Wq375amogB+/UC7Tyw5LY6IHEEQAuZ4YSWXzV/Llf9cR3WN1bnfbLFpxo3rm0Lv1GguHZbp3BdbR0yOe6+qpChjLSPrycGV2u3DP0LuHpxxLX0mwXSHKymYIiffIaKiUuF36+Gqt2DKc67YkkXXQtGR2q9ht3tbKlIHwtVvBW+ebYXubrEuBiPoHZ8ju9X3+OZm0Qw4tl67r+vZLTMXwYmIHEEQAubDX45httgorDBz+fy1TJm3hn+sOkBemck5pmdyFP++Wanhcv1ZrsrHaiNOf4zpmcSMkZ2Zc8nAhmVWFR2BNy+GDf+CgoOw15GJNOQaZfnDX+CTW5X1XhfCzI+hs6PybDBFjpphk9of0gbCkKuVgNlpLyn7Cw/CvGFwyHegNqAUulM5+25lOeW54M2xLdH/Ete6Xq9UDAawWVpmPp54ZufN/AzC41pmLoITCTwWBCEgLFYbn2xyNdrcm6O4CworTBjcRMm4vinOvj7dkqJ4aGJfDuVVMDCj9ro3er2OF2YMa/gEd34BJzYqPyn9lSf93hfDsGth+8fKmDKHmEkdqCxjMpSlqRSqSyG8kbV5DnyvZFW5v4bK8BsUF5RqgXj/Mpj0LJw5y7sRpVq/JzIZJv1VSZ2urfpve6bbGJjygqsXVGsTOe5MeaH9V6FuI4jIEQShXtjtduat2M+nm0+Q67DYjO2VRFWNla3HiskpNWFwNNy8dlQXHpiobdsw+8Jm6q1UcMC1nrdHWQ67DtIGe49N6a8sw6KVp+7qEig73TiR88Nf4Uc3a0u6RwNGvcHbxfLdo2CugPMfdu2z22HZ48p6fBdH1d8OKnBURt/pWtc7bl+2ZnBXrfqbEvsz8Zn6BXtHJNQ9RmgWROQIglAvvth6kle+dwXL/nZcTx6dOgCrzU7fx7/FarNjtSlxLk9ePshncb9mIf+A977u5yqZLkm9tSKo21jXemwnReSUnICUfg1//c3vKcveE6DnBTBkRv3OO75Bu31qqxI/BP6bPHZknCKniS051hpY9ayyfsbNrs9GZaHiosoc4d1WQkROq0FicgRBqBcLVh/SbF/r6DBu0Otc5eyBM7sntJzAASjwyFpK6qNkueh0cOvXMOwGZX+PcZDUyzVObY9QdLjhr221QIUjNf3yf8DY2Uq6sycX/dl7X2SSdrvQ7ffd5+KGz6m90lwix1zuWi89qSztdvjnWFh4tVJE0pOI+Kadk1BvxJIjCEKdHM6vYE+2K1V3yuB0eqa4aoKkxoRxuqQagHsu6N3s83NSlgOVBcp6Yi9l/Yo3XMdj0uGSl6Dn+dpAVlCsPKAEKzeUijyw20BnqL1p5Dn3KSKrqhgWXqXsK8/RjilxxOP0vhhG/7bhc2qvNJvIcSuToAam11Qqbk2A078qS2MMmB3/IyHhTTsnod6IyBEEwSf7cso4kl/BryeK2XK0GFB6SS24aRShBm1cQkGFqzv0Ob1b0LWyyZFanXkG3Pad0rU6zKNAW2iEEqPjiVPk+HB31Rf1xhed5gqM9YXeAJ1HKevTXoSvH4SybCXd/cAKxdJT4gjuzhjq/zodGWfgcRPH5LiLnKKjytK9lYStRrvsdWHHq2HUihGRIwiCF1abnWv/tZ4ij2abUwZn+Cz4FxcRyomiKgBCDS3oBd/xubIcc4/iJvLlKvKHKnLqW6TPF2WO7tOBFIHrdq7j3NPwnyuU9ZBwl8iJ6+L7vI5OcwUeu7urih0ip8pN5FSXKnE7FsWSyZVvdrBK1K0bickRBEGDyWLlZFGVl8ABmDjId5n6F64exshuCXx+91ifx5sEm1UJFHbfVovrdRkd+PVUkVN8VOkV1RBUS46akl4fVEHkXhNn91cicuqiudxVJjeR48uSg13bIiQ0CK1IhKAhlhxBEJxUmCxc+OIqckpdRf3mXjqQ3DITnRIiSI4O83newMxYPvtdMwocgI9vVlw71/5XqUlSelJxGRiMEJtZ9/mexKQrvYfM5YpYSulb5yleNMSSEx6nWG5USwAo1ZKNjrYFcZ0Dn0dHoCViclRRXeXR+VwVtyAip5UhIkcQOihVZitX/GMtAzNjeema4QDszy3XCJwJA9K49Zwefq7QgtjtrmaaC6+CO1e5ehjFd609HsYfOp2SbXX6VyUuJzpV6fo9+CqI61S/azTEkqPTKZlVauaOirlMaV2Q2LP+1+pINFcxQHeRo65Xeogc9W8XGimuqlaGuKsEoYOy9kA+e7LL+HzLSWf/qeySKs2Y+MhWWnzOs5/TTy9DoSP1O6ERoswZfLwfVjwFy5+Ad6fV//yGWHIAwuN970/pH1hcUUeiJWJy1HXPz5/6dw8NQkNZIaiIyBGEDkp+ucticyBX+fJW08BVujakC/jxX2Dzu8qNYMMCJU062KgBoCqFh5ReUAAJ3Rt+3SRHVeaCA3DI0b286LDS/6rUzSVhKnPFzACUnISsRXBqi7IdiCUH/BePkywd/7SEu8qvJceRWi4ip9Uh7ipB6KAcLnB9ee/NLmNwpziyHSLnzO4JDOkUzx3nBegq2fwefPV7Zf3bR5Q4k18/gDt/CNa0FdQAULU2SfExOL5R2ZfRiL5Xqmuo6IgSC6MW5PvgOqXq8A0fw0czXW6pc/4AFz8J3z0Guxa7rhOoJcdf8TgROf5pCZFjNSkFH9VaTCrq50HicVodYskRhA7K4Tw3keNosqlaciYNSmfOpQN9pov7pOSk8vPtH1371EDaU1vAZgvKnJ2olpwe5ynL6hI4tl5Z79aIAGi1Z5W5wruDdGU+LPmDNsj04Apl6Zl2HrAlJ973fonH8U9zxOTY7XD0J+2+mgpvkaNacoxiyWltiMgRhA6I3W5nX46rgrFazfi0IyYnPS6Aiq2Fh2HeMHh5oDZDyJ1TWxs8Vy/sdti3TFlPH6JthxCV2jhhoD6J11Qp9U88cX+qBzBXKsvybO1+tVN2ffHnrmqM6629o1pysrfBlv8E55pFR2DrQsVaA7Drf3B4tXaMucIVg6PGcDktOSJyWhsicgShA7LhcCFHCiqd2/uyyzhdUsVeh9jJiAvA7H58o6vaK0D387zHNKYflCcnNytP14YwGHGTq+cUQN9JjctuCY1SluYKbQ0elbAY7ba5Qqmp4/lkH+gc/IqcboFdpyOhc7MyfjlbEb+N5fWz4X93wy9vKtvrXvMe8/M/IXensq52sS8VkdNaEZEjCB2Qz7coQbOXDVPqyWSXVjPm2ZWUVluICDUwpFNcbadrKT6m3T77bu8xntkojSFvj7Lsfg7Ed4HOZ7mODbm6cdfWWHJ8iByrR4FEc4WrIadKrwsDf1337Kpot3geT1EluNB7hJQGI8vK4sguPLBcWbo3cFVZ96prPXWAsqxxWPgCteAJTY4EHgutnuoaK7e/t4m02HD+fNlAYsNbaVpzG2LLsWJAETmbjxZxstiVOj6sSxzGkACef9Tg3D4TYcSN0H8qxHbS1n3xzEZpDMWOxpVqJeAJf1biMqwm31akQFBjKmqqtNYpFfd4HFBSilXXRWwnuPFzRXgFintDx+Q+3u4vwRtPkWM1gSFItzSro+K1qaz2cZ7uxG7nBOf1haAhlhyh1bPlWBE/Hcjnsy0n+OvXuwGlt9JLy/fx4Me/8vLyfZgtQQ5sbceUVtdwME9JGR/eNZ5hXbRWm4cm9gvsgqrIGXYdDLxcWb9uodZ0H0xLjpq6rYoJY5TSWfzy1xtWBNAddc7mct+WHLXS7Zm3O3bYXa0kotMgtb8yn0BxF1TTXlTijCY8Gfh1OhKef2trA1tx+EK12KntGoZcA2lDvMd51jfqdUHw5iAEBRE5QqvnkFsW0Je/nqKsuoZVe3N5dcV+Pttygnkr9rNk26kWnGHbYuOhQux26Oxo03DT2d2dx5b+4TxGda/D5H58IywYD/8YA+9Ph+M/K/vdi/BljoA/bIcLH1e2PcvgN4YSh3usKXo6OYWZHex+hLMhDKa8ADjibtSu5YGmjbsz6ApIHQjn3Acp/eDhg3DuHxp+vY6ApyWnof3GfKGKHNUVedYdrsw7d9yz4iKTtfFhQqtA3FVCq+dwbilhmDFhpNJs5dznfqCkSutKUANmhbpZsEaxvEwYoDTbPLtnInec1wOzxUa/tHrEgGx+z5UtlbtLWSb39a7pEpXsSqUOhruqPBdWPOnKdmlSkVML0Wmg1ysWG3M5ZC1U9jcmEyo8Du5e79qW1gB14+WuaoTI2faJq5Cj+7Uq8pVlVLK3ha7buVpLTkP6pQlNjogcocWY9/1+jhRU8NxVQ2uNAbl81/3cH7adDzP+j+eO93MIHDug4/qzuvDBxuPszy33e77goqSqho2HFcHx2/OVVGudTsefpg2s++TqEgiLVVJ23QmNgt98CyE+mndGOKxCjbHkVBbC9k+VYntH17r2N0XjSkOI0uBTvcl5Ns4EiE5RlqrIUQOvU+vxOxSCRzBFzue3a7etNUr38RpHBmJUqrbQ3/AblSKQNW5tUETktEpE5AgtQml1DS9/vw+ASYPSmDxYWzwtt6ya73bmEGe0cVn1L6CD27PncmjodyzaWsA/Q19hiuEXbNtDsBp+w8+5AfQX6sAcL1S+tJOijPVPE7fblSJ/GxfA2fe4RM5v18D2j2HQlcqTri/UbJPGWHJWPg2b3tbuG3Fj07kGQiNcN8xRs6DTGfDZLNfxKIfI8bT6SHXi5qVJY3JMLldVaCSERcOJza7jk59V3Ffugcn++o8JLUrAMTmrV6/m0ksvJTMzE51Ox+LFizXHP//8cyZOnEhSUhI6nY6srCyva1RXV3PPPfeQlJREdHQ0V111FTk5OZoxx44dY9q0aURGRpKamsrDDz+MxaKtbLlq1SrOOOMMwsLC6N27N++++26gb0doIbY6snsA7vrvFk12D8CDH//KE4t3MO+T5Zr9f0z5mUkphUwx/AKA3m7hUv16jhdVUmVu4kZ97YATRcrvuXMgPalOZykCB+Dn15VlWCykDYaJzygiwB/ulpyN/4av/hBY9WP3wn8qjxxRgoybyqXjXm5l/P8paelxboJKFXQWk+Y0Z80UoXnwiskx+R5XF77q65groDxPWVdF7ajfKMtBV7ric4zRrnOkpUOrJGCRU1FRwbBhw3j99df9Hj/33HN57rnn/F7j/vvv56uvvuKTTz7hxx9/5NSpU1x55ZXO41arlWnTpmE2m1m3bh3vvfce7777LnPmzHGOOXz4MNOmTeOCCy4gKyuLP/zhD9x+++189913gb4loZmpMlt59pvdmn2z3v3F2QnbbLE5XSq9ddqA4vjVf+ZfZbM1+/oaTmG3w/aTPrJhBECx4Jz/wg/c9V/labRzQgBfyId+9N434DIlLqUuVEFQXQLfPASb34HTW5WA5YUz6i7glr8fSk8AOhh5q5J55K9wXrBw7zqt1qlxL9ev3vSqi137zrhZSvo3N17uKh8p//XBlziqKnJZctS/99l3w42fwVVvusa5C+2GZNUJTU7A7qopU6YwZcoUv8dvuukmAI4cOeLzeElJCW+99RaLFi3iwguVolnvvPMOAwYM4Oeff+bss89m2bJl7Nq1i++//560tDSGDx/O008/zSOPPMLcuXMxGo288cYb9OjRgxdffBGAAQMG8NNPP/Hyyy8zadKkQN+W0Ix8vf00Q/K+4r2wj3kmZg5f5aezJ7uM//58lNvP68mWY0WYHCnh/XRKTZSaAdMJralwFekCuOZ9+Phm0igkmkp+PlTAWT2kGJcnVpud3y3czFG3CseBiZxV2u1OI2G674ccLyITlarEW93K7hcc0nb4rq0Nw+lflWXXs+HSefWecqOwu1kE1ZuY+1O6etOrcf0+ucxHZVyhafFVJ6chuP8dndcyu5rARqcqS2Mk9J7g/zpNEQgvNJpmTyHfvHkzNTU1TJjg+rD079+frl27sn69kl2wfv16hgwZQlpamnPMpEmTKC0tZefOnc4x7tdQx6jX8IXJZKK0tFTzIzQ/e7NLeSF0AWm6Yl41zudvVyr1J9748RBH8it45N+LeS/0b3xvfIgHQj8FILTTcMU1onLnj0pNlmjlM9JLd4qXlu/jg43HPF+uwzH3y53MeGMdZdXKk+3nW06w46T2sx4eUs96Mnn7XCLnwieg6xi4+u1aT/Fi8t+02znbXevrXlPcWP4sOmojzpZuVBnq9pQe6Sf+SGheghV47NmPTEWtf6SKWn9c/joMnK5YGoVWR7OLnOzsbIxGI/Hx8Zr9aWlpZGdnO8e4Cxz1uHqstjGlpaVUVWnjO1SeffZZ4uLinD9duojybgmOZ7vK4OsKD3G1fRmd4iPILzdxxT/WcqPhe843bKO3XnFVmaO7wBm3KIXWLv+H8tScOVy5QIpSuG5wiFIg7k9fbOdUse+/f0fAZLHy7roj/HKkiPfWHQHgq21Kld6HJ/Xj4Un96BQfwYxR9chMKjkJ/7sHsEO/qTDuIbhtaeCp0mHRcP4jru1sN5Gz6W3FjbX9E9/nqiKnpeuPaNxVHiJHJ+XGWgTPwOOG1snxZckBtyKPqbWfP+JGuOY9CA2gqa3QbHSo/85HH32UkpIS58/x48dbekodkqtPvaDZDvn2IZ4cqsTgFFXWMEJ/QHPcOOYOV5bOiJlK/INKp5EAPD2yisQoIzY7HCv086UVRDYeLuS2d3/haIGfp8AWwr1w4nc7c7Da7Gw5qlQbHt8vhXsu6M3a/7uQzgl1xI/Y7fDmBDixUQmubGz13fGPQqYjQNld5Khsed/3earLIL6FG1W6dyRXU9dnvKsEVt/0RYtMqcMTNEuOn/ITqsCuy5IjtGqaXeSkp6djNpspLi7W7M/JySE9Pd05xjPbSt2ua0xsbCwREb7jDcLCwoiNjdX8CM1Ldd4RJlh/AsDca5LjxmfnwmPziA4zkEoRo/T7tCd1Odv/BbuMBkCf9R8GxioWnKqaps+yuuZf61m5J5f/+8zHDbsFcS+KuPNUCZuPFlFushATFkL/9Fo+7zabtsFhZSGUOYK+b/gYUvo2bmI6ncsaU5Hnffz0Nu994KpB0xKWnDC3dhfuN8Jkx+9i0BXwx0PQc3yzTktwEDSR4+ehKN/xPSQip03T7CJn5MiRhIaGsmLFCue+vXv3cuzYMcaMGQPAmDFj2L59O7m5LrfG8uXLiY2NZeDAgc4x7tdQx6jXEFonx/cq2T2FxGKc+SHM/BRCo9Bnb+PDcQUsjXRk0IWEK92YYzu7XFO+cOtA/WrJfaRS1Kyp5J6p7y3N3hyXyLHZ4bWV+wE4s0ciBr2flGu7Hd66GP45FqyOMg2qwIlKUbp9B4OwaP/HTCXesRFWi1ufqmYUOZfOU2qjXPdf176JT0PGcLjjB21GjVQmbjmCJXL8uatU6nJXCa2agLOrysvLOXDA5U44fPgwWVlZJCYm0rVrVwoLCzl27BinTilfknv37gUUy0t6ejpxcXHMmjWLBx54gMTERGJjY7n33nsZM2YMZ5+tPLFPnDiRgQMHctNNN/H888+TnZ3N448/zj333ENYmFJV9a677mL+/Pn88Y9/5LbbbmPlypV8/PHHfP31143+pQjBp7jSzP0fZdHrwAoeD4WDUSNI1OshKknpC7P2FQavudt1wmWvQa8LAZ3vSroqUUkw9e/wzUMk2gq52rCaKvP4pn47TiKNjWwIGWQ821us2a+UpZ8yuJa+SpUFcHKTsl56Qom5KXWInJgMv6cFjLGOlhFl2ZDUy7Wdv09pXGmMVjp8Nxcjb1Uq2rp3tO51oePzKLQavGJyGpBdZbfDrv/VPsbhEhfaJgFbcjZt2sSIESMYMWIEAA888AAjRoxw1rD58ssvGTFiBNOmKRVor7vuOkaMGMEbb7zhvMbLL7/MJZdcwlVXXcW4ceNIT0/n888/dx43GAwsWbIEg8HAmDFjuPHGG7n55pt56qmnnGN69OjB119/zfLlyxk2bBgvvvgib775pqSPtyB2u531BwucVXXdeWn5Pn7Ym0cf3UllbLJbp+ux9ypND1XOuhOGXqMEeEYl1f3CZ90BY5TaOXG68iZ3V1msrmJ20WGto2i43W7n/z7bxso9ivVzfD+XiT1Er2PiwFpEjmotAZc1RRU5wRQX7pachB6QMkB7vOy0dltNH08fWr+aPMHE0Dr+rkIteFrRGlInZ/eXrt5jKiFuAcSXvCJF/to4Af8njx8/HnstBbxuvfVWbr311lqvER4ezuuvv+63oCBAt27d+Oabb+qcy9atW2sdIzQfn2w+wR8/3YZeB3+5YgjXn6W4GPbllLFwgxJb0Uev3FBTegxxnRiVDGffBWsddVDG3hv4izsKcUVgdhYVbCpyylxPjKGG1hG7f7K4ig9/cQXSz7lkIKv2KkX8bhrTjbjIUP8nl550rVcVO/apIieYlhw3kdNpJEyYCzs/V/pSZW9Tmn52P9c15nSWsqzNXSkIKg2pk+NZTRug21g4uFJZ99V5XGhTtI5vaKFdsPBnJRvBZocnFu8gv1z50pn3/X6sNjtTBiYxwqiInB6Dx2pPHvew0hfpN982LP7C8bQVgYnKJo7JOe0Wh1NmamCV1SCjtmtQ6ZkSzX9mncVvzunOgxP7+TkLOJUFK//i2lar+DpFThCbDrpXhE3tD/Fd4Jz7nGUAWPa4Mh+V7B3KMn1o8OYgtF8aEpPjGSd28/+UliXO43EIbRuxyQoBY7HaqDBbiYtwWQcO5Jbz64kSQvQ6wkMNlJssbD9Zwogu8Xy/6zTzQ+dxyaENyuDwOO/ibmExMPmvDZ+Uo1lihM7U5O6qUyWurtRKR/SWY8uxIpbtzKGg3PUUO22IYn05r08K5/WpJTOk4CD8+0JthV/VkqPWCIkNYqfvMLeYnES32Bt3y/DBFS7LTYEj9q+xmV1Cx6AhdXLsbn3Uup+nZMr9+pFrn1hy2jwicoSAueu/m/n5UCGf3DWGARnKl8C3208zTv8rZ2eGsj/xfL7Ylsdv3lGaaE7X/8Qlhg2uCyT3C36MhSpyMDd5dpW7Jae0ylLLyKbFbrdz45sbNJar/ukx/PWKIbWc5ca2j7QCBxRLjs3miofJCKIVxd1d5S5yh10PO5TK1pQpxT4xlUG5Y91dEAmCPxpiyanId62rnz33wo9hInLaOuKuEgLCZrPz/e5cyk0Wfudo9giw69efed/4HHfnP8PDuf9HGMoXTgTVPBL6ofYiQ64O/sTc3FVNHZPjXlG5tLoGm62OJpNNRG6Zt2vusuGZtcffuLPjc+99y+fAK4PBXAYhEYogDRpuvyd3kdNnAkxyWPEKDyvLgoPKMioFIuKDOAeh3dIgkeNWs0mtZO0eaCyWnDaPiBwhINzrwhwpqKTSbOFIfgVnFX7l3J9ZvJnLDOsAuNawigxdIWURneBPOfDAHiV7Ktg4LDmRuqaPyXF3V9nt8Px3e5v09fyxP8e7UmuXuioZq5ScgIL9SkuCB/dBn4nKfpvFFYicMSy4WUbuMTmeN4+0wcqySBU5DldVUu/gvb7QvmmMJUenh0tfdex0y9oSS06bR0SOEBBHTudysX4TIShumt2ny/hu+wmnqFHTgofrDpJECVcZVgOQN2iW0tslNqNpCqg5TMzhmJs+JsejAOAbPx5s0tfzx/7cMq995/SuR/PIigJ4eZCynnkGxKQp8QiedBvrva8x9BgP594P1/zH+1hiD2VZdFSpvFziyBRr6XYOQtuhIXVyVEvOb9e4Yr9sbi5od2EutElE5AgBEbvpNf5tfImXQ/8BwK5TJRTuXkWSrozq0Hg47wEAZoasYHP47xiiP4LFridm1LVNOzFnTE7TuqteWraXnae8u9c3tYvME7UmEShxOAa9jicvG0RilNF7sM2m3d7tVvxMLXDnyyU0+MrgTFZFr1fSxgde5n0stpPyN7TVQOEhqC5xzCshuHMQ2i+B1smxWaFK6ZmnabrqLnKkonWbR0SOUCd2u52s48VU11jpfexjAC41/Ewm+Tzxv510OrUcgMqek11NGN04oc8kOa2JK9Y6/OiROlODAo/tdjuVZgs5pdXUWG1+x7260lXt+6vZrpoueWUmtp8o4fcfbPVZDDHYrNqXx7JdOeh18Ncrh7D36cncMra7dpDVAm+cCwvGaW8AalCxMVqxrIC3mOh5gcuF1BzoDZDmsC7NH+VKHw+XFF6hngRaJ8dc7squCo937be1XDKBEHxE5Ah18saPh5j++lqe+XoXZTZXZeJR+r3osDHZoGRRxZ1xlRJQ6nFj6tRnOLqmfiIKdbmrGhKT88dPfmXgnO8Y/dcVPL1kF9U1VpbtzKas2iUO7Ha788HurO6JDO4US+cERVzllpm4dP5PfPnrKZ5asqvx76cOVu5WKhtfe2ZXzuiaQIh7UcKybKXTd95uZZm9HQ649XlTa9Fc/rork6TL2UoVYoApLyidtZv7KTbdLSvsgCKcJfBTqDeBxuSojTl1em3rmIZUThZaLZJCLtRKQbmJ55buAeDTn/fzTLgrG2GQ/ggn7Cmk6oqpNkQT3mu84pLoNEqpd+IgNLlH00/U3V1lDvBJbP/3/GnnzegMN/Cx9QLeX3+U44WV/LA3j07xESz9w3nEhIdSWmVxlnR5f9ZZ6HQ6UmLCOFFUxXPf7nFerjksOesOKgGT7u0bAMjbC29PgqoijxNehd4XKV/guQ4RljHMdTw6Be7+GXJ2KnVqWsJMn9THe59YcoT6EmidHLUxZ2ik9vN+zn2w9T8w4sbgzU1oMcSSI/ilymzlaTerRA9dtub4EN1hpxUnvO+FEOKIBzn7bs24OhszBgOHuypEZ6OmxgTf/QleGgTrXqv73F8XEa+r4PnQf9MJRcT9sFdZniyu4pvtSk+lUyVKwHFCZCjhoUpzwNQY5Qlw45FC5+XS49x63zQBeWUmDuZVoNPB2T3centZTLDqWW+BA3B0LWx5D/YtVZ5447sqjTjdCQ2HziO9Gx82FyNmeu+T7BahNi58wrUeqJupxpFAEOqRkZjcBx47DZfNb9zchFaBiBzBJ0UVZi5++Ue+zDrBXYYvuS1xO4P1SnqvzaDcxMcadnFniKPre7dzXCf3mQC3fgMDLoXoNBh5S9NP2O2LKsRcBuvnKx21f/5nnadadK5g3StSTnodX+cI8D3tEDkZca46GhUmb9dYhalpffpZx4sB6J0S7aqJU54Lr42CnV8o29NechXfyxiuLA+vcXVcHnx16wuqDI+D6z/y3icI/hj3EFz5prLuWdiyLpwix0cDTmNk6/v/EBqEuKsEL15attcZYHuLYTn/F/ohVEJpr4vhGOhH3wkb/w0Wt1Rqz3Tj7ucoP3Z783xZhBix60PQ2SxE1eSBWg+v2jsTypOayiLnP8Ls4SF8uTmSY24up3UHC7Db7ZwqVurjdI+1w7ePwMDpnNEtiZ8O5BMdFsLZPRP5fncu+eUNqNdRT2w2O/9efQiA4V3ilZ12O3x5L5Qccw0ccjX0nwYnNintFN6/DE5udmVRdR3TZHNsFDFp2m0ROUJdqNXTbYGKHDd3ldBuEUuOoKHcZHEKHD02HoxwFfmLPeYIBu09QduHaNgN/jNxmvNpyPFElmx3c9eYy+qsn2GtLHauh5cf47Zzuju3dTrFPVRQYXbG2sysWgQb3oB3JnPnuJ48NrU/Pzw0nv+botQIyi9vQL2OejL/hwNO19gwVeTsWqy4odwJj4OYdBhwCWSOAHRK7Rk1ayk6tcnm2CiiPUWOuKuEOtA53KsBi5xaLDlCu0FETjvmeGEl9324lY9/Oc7+HO/Ccb5YtlOJuxmsO8SmsLuItRRqB0QmQ5fRMGi6sh2TCVf8M/i9qBqC44ksVecRk+Jeut0H9qoS10bRUa47qyuTB6Xz50sHkulwTR3Jr2DXacUq1KfGVeE4OiyEO8f1IiUmjJRoJT6nrNrSJHVzqmusvLP2sHN74kCHIDi6Xln2v0QJ+r7MIw4pPNatcrAjctpTTLQWojwCqd1TewXBF3qHHTbgmByHJUcK/rVrxF3VTjleWMm0V9dQWm3hf1mnAHj2yiFcf1bXWs/beaKIafqfeSn0n4TpHKmUAy5TGiYeW6+kHYeGw4QnFcHTFH2oGojO8WWVgYcwK8+FOP/dtPUmN5dW0RHCQw28cdNIAFbszuVkcRWH8yvYk60IxRh8Z0/FRoQQatBRY7VTWGEmMz64T4g/7sujqLKGTvERrP7jBRj0DiuZWh241wVw5u2+T07pp7RxUImqR2XklsAQqjyZq/EVYc0QtC60bdRA+YBjclR3lVhy2jOt4PFbCDZ2u517P9hKabX2yebP/9tZp0Vn1IF5vG581SlwKrtdCBc/CTcvhj8egn6TlYHGSBj/CCS1og7Rjhtipq5As/vbn7eRW1rt6wwAQmrcRE7pSU2F4O7JinVo89Ei8spM6HQQZvXuGQWg0+mcFYcLmiAuZ81+xSI1YUCqS+AAFDticeJqEbDJbunZkUmKmGituMd3teZ5Cq2DBltyxF3VERCR086osdq49l8/k3W8mLAQHbef2wNjiB6jQY/ZauOu/25mT7afYFy7nSmlnzg3Dxh6EXbL566O0a3drOtIN+6k07qnVm7ZyfkvrGL1Ph9uK5sNo8VNtNhtYHK5r7onKe/5e0fxvS4JkehN/oVibLhyU3YvIhgM7HY7PzrmP66vm0un6AjkOOJs4rv4v0ByX9d6VCuNx1G5fL4ixHqOb+mZCG0BnRp47L9SuU8k8LhDICKnnbHuYAEbjxTSWZfLmqhHeXz35ewdt47PZypP+QfzKrjk1Z98xoxYsrWVenv1HaS1GLR2HJk4PfTaej6zDYsx1dTw/Hd7vM8xl6FzxKnYdI4nQrc6M71TlTRsNZi4S2KERgR5EhOuXMPTitZYdpws5XhhFeGhes7u6aiNYzHBP9yypOJqEzn93DbsQZ1b0EnoDvdtgxu/aOmZCG0B1ZJTXQJlOfU/z1+dHKFdISKnnXEgt5xM8vnQ+AyppiNQkYtu3asM+uYKBiUowsZis7PzlPeNuujYDs12k7diCDYOkdPJ4a6qsiuuo276XC7Wb2bHyVIO5Xm4mhyNIE32UMwRDguHm8gZmKnN7smM9Sj0Z9cKhugmsuR8tU2Jq5owII2oMMeX+q4vXU+jAGHR/i+QOdy1HpsZ1Lk1CWHRrSOYXWj9qDE5Jcfgxb5QkV+/8yQmp0Mg3yLtjIO5ZTwR+h8667T/6LryHN7rssS5fdU/17P9hFbolJzYrb1Y+tAmm2eT4FEd923rZL60KpaOcfptgKuSsYrNkT5eSiT6yERlp5vISY0JJzna1demV5RHbI9HerpqySkLsiVHjaU6p7dbwPDeb1zr4x+r/QJ6A9y7BQZfBRc+HtS5CUKLovfIn1Eb0NaFWHI6BCJy2hnX7fk9UxytFpj5qZJWPPZeAJL3fcS3Xd4nDCUo9stftdV9rXlKfZwdUWcr54y5p/kmHgw8CsfZ0bHYqlRinhKxE7Dz9JJdvLpCyTLam13GW99tAKCUKEKiHSKnUpuCrlpzjNRwcc6b2tes0WZaxTpETnmQqx4XVdagx8aZRxbAHkeV6VLFusOM95Qg8LpI6gVXvw2dRgZ1boLQoug82pDU1wJtFktOR0BETjti/a7DDDVvBaC083joczFctxAmPgOxSgr1gLylTNFvBKDcoyVBWIlSSfdY58uVc9raP79H4bgEyrlg0pXY9aEk1mTT3dF766Xl+/hm+2kmvbKakgOKyDka2gt9ZIJyokfvp4sHKG6sawyr6HXsE80x59Ogg5gmcleVVNUwQb+Z3rtegw9vgH3fQZlD5MRkBPW1BKFN4dVrrZ4iRwKPOwQictoRXyz/AYAKXSSRt36uPTjG1TTz/9J/IYJq8srcXC92O4nVSipyTOf+TT7XJsHDXfWudRIpSYnoup4NuFxWAPcs2kJ/3THO0e8E4FTMUIhwEzkFB+GLuyB3D1ePVAJ6z9b7CFz2FDlhTeOuKqo0M0m10AHs+BzKHAHWsSJyhA6Mp8jR1fO2pv7vGkXktGdE5LQTiirM2HKVSrwhnUYQEuLxjz/6LjjrtwCkF/7CUyHvklvmiiexV+QRay/DZteR0dNPi4bWjpsl5wrTk+y3dyY+0uhMRb4q5YTz+HjdVpaG/R9jDEpGWWXqGVqR89oZ8OsHsOJJIowG1v7fhZwzqLvrtUIcVq6aCs0UopsgJsdms1NSZeZCfZZr54lflG7iANHpQXstQWhzeMbk1MddZTEr/0Mglpx2joicNoDdbsdmU7J4rDY7sxdt4ay/fM/1C37moCNbaP2hAs5zWCrC0n1YYvQGOPsu5+aMkNXklrpEzu5tyj/8cVLomtZKq+HWhZslJ9ceD0B8ZKjTnTMk2fXl99sQVxB2ld2IsbObJefIT65rliv1cTrFR5Cgdzz5TXnelaHkx11VGkR3VWl1DZ3JJUHnlhlWeFBZRiZDiNH3iYLQEfCMyakP2z+GSkdyRsbwoE5HaF2IyGnlHC2o4OKXVzNgzlJ2niph56kSlmw7TW6ZifWHCvjNO79QXGlm/89fc7lhnXKSe7qwOwk9oO8UAArsMWSXVvPF1hMs3ZHNoq+V5punQ7piDGmjHwu7qxhYHvEASgVihzlab650upMK7a52Abn2eLokx7n6JuVsd13TPS5Jbf8QFut6+vMIPG6K7KriyhoG6Y4qG2phRhVxVQkdHU9LTn1ickocVt3+l0By79rHCm0a6V3Vynnhu70cyFWe4Ke9+hPD1c7TDo4VVjL8qeU8F/IVhMDp2GFkDLvB98V0OqV54997k6QrIwQL93/0Kwa9jif0SqbVaWO3pnw7TYtbi4k500dQabaQGhMORkf9mJoK4qNCKTNZSNK5qj4fs6cqfabipygNR9WAXoBKtz5Yjpo6hMe5xI/Zn8hpvCXHZrOj1+soqqjmNyGOLuPdzoHCQ65BSX18nywIHQXPekr1icmxOv4/YzsFfz5Cq6KNPrJ3DAorzHy7Q1u9d/fxXFIoIpN8rhqhxmLYOd+g1IY4MuReMNSiXSOTnE8+ySg3bavNTm+dInKq49vwU01Cd/jNt3DPL9x4djfuHOcQParVxVxJQqTi2uns1vrh6NlPMSAjVnFXnXGT9ppV7iLHIYzCY13Bih7uKrWtQ365mRprgGXm3bj9vV+4+OUfKawwE7pvCaPVoOdOI6HPJGV95G9g2osNfg1BaBd4uavqUdHb5hA50hut3SOWnFbM3uwy0mx5jNHvYpVtGAXEMT/0VS42bAGgzHY1n3ElnXV5pOuKMNlDiO5zXu0X1euV3kVlp+iiyyPbnsQthu8416BkGU0cf35Tv62mxb25o4rR5VqKiwslFIurU/lD+7kx2q2Xk6d/vrJQqWqs09XLXdU7NZrkaCP55Wa+2HqSa0bV0mqhFtReWQ9/8it/DFVirXIN6aQOv0Ep6FdyHNIGNejagtCu8HRX2erRjdwqIqejIJacVkzuiYP8EPYgLxrf4LHQhRiwOgUOQMzeT7nF8B1fGpUKtsfsaXRNTar7wpHKmE/CnuIaww88Gfqe81BStzaaWVUboY7GoqUnGZD7DZm6fPQ6O/aQCFccjkrGMO221QRmRwaVuyVHdVeVHNcMDw81cNPZ3QGcDTUDxeJmAfpxXx7GIiXIeE3SDAgJU15fBI4gKHimkNsDEDl6ETntHRE5zYjVZueNHw9yy9sbOVpQUef41D3vEaZT/hmvMvzEwfCbvMY8GfoeiY6sm/LIzsRF1uOf1s0F83zov7XHPKoGtwvcuqc/ZnqFs/VK+wpdfFfvdNPYTFeWlUpVofKlaHG4psJiIXWAsv7zG1BVrBmuNvXMLfVoAVFPzG4ix2KzE1GqxODUJLRhV6IgNBVelhwfbmK7HT6dBYsd9cLU8gsGyUxs74jIaUZ+3JfL377dw4/78nhzzeE6x/fOW+H/4O/WedV3GDG8nuX6z73f9/4hM+p3flvDo9jXlDiH9SW+q/dYnQ5mb4b7fnVVEq4scFlxQBE5Y3+vWIjMZUrhQDfSYpVeVzml2r5W9cVscX1JG7CSZFbipUJS+zboeoLQrvEMNPa05BxdB08nw45PIWuh4oK2ObIfa4tfFNoF8hduRtQsKVDq2tSKxUSSJdv3sd4XK+6KhO6Qu8u139MC4Y+z7oDSk/DTy8r21W9D6iCIa6eZBqFRms3xCflQCST4ySSLSlJ+IpOg7LTypahauEKjHF+MIcr5ubvApG10muboVJ5TWo3dbg+4m7vJTeRk6AoJxYLJHkJsWveAriMIHYK6YnI+uM4lakDpUi6WnA6DWHKakdP5xVyk30wKRRzILSe3zL87w1ZwGD12yuwRlA6+Rdk57mGleu+EPyvbcR5BrSn96j+ZhO6u9a5jILU/hMX4Hd6m8SyWd8oR1xRfR7q8KhorC6EsR1l374+lFh90t/IAKTGKJcdksVFSFWAq+c7F6NyKESY5MuDyiSMjPsrfWYLQcakrJsfq8T9YkSsxOR0IseQ0FzYbt+++lU7GY6y2DuHmmkfZeaqU1H7hPocXn9xDInDUnk6/S56F8fdCskdNFDfLS86Q35I24LL6z6eHI4sqtpOrem9HQS0a6Mtd5U6koyt5VSEccxRadPTBAlyCx6QVOeGhBuIjQymurCGn1KS0lqgPhYfgk1tQcr0WEomJdJ0SP1VgjyUjzvdnRRA6NHVZcjyFTHmuZFd1IMSS01yUnqRTjdIAc5xhO2GYOZBTXstwpQ9VbmgnQsOjvAUOaGJy0i5/un49W1QSe8A9v8Cdq+p/TnsjrnPtxx1ZaFQWwO6vlPUzbnEd92PJAUiLcbms6k3xMefqQN1Rfgn7Hf8yvgJAAXEkRYlpXRC88KyTY/OoNu4pZCrypE5OB0JETjNhKzyi2T5Dv5/9uWV+xxcfVzKAyqJqcam4P8GEhAU+qZS+4F4jpqNR13uPcFhyynOUL0aA9KGu405LjvffsUuikmK+N9v/39iLqiLn6n0hnxOlcwUuh8SkotcHFtsjCB0CL3eVR3aVp5Apz3XF5Ii7qt0jIqeZKDp1QLN9hm4/H286wYmiSn49Xsxfvt7lTDnOOl5Mxel9ANgSenpdy8lAh3sqrg63i+CbqDpEjmrJyd+vLHV6bXB3mG93FcDZPZVzfzqQX//5lLkCzbvqcjWHhveX9g2C4BNPC3ad7qocsKrZVSJy2jsSk9MM2Gx29u/dgXuZvj76E2CFBz7+lY2HlbgLY4iehyf15+2fDvOIXrnhDR16hv8LdxoJd/5Yd2yJ4E14HITWEeOixuTk7XVsJ2v75IS7uasO/ajE1Ay6AiLiObeP0sl9w+ECaqw2Qg31eJ4odfXMGqA/pjkUk9TB4qYEoaF4Bh6Lu6pDI5acJmL+yv288aNSP+XzrSc5eUTpPXQoXKlUOzJSeVJXBQ7A7tNlWKw2fth5jE46JcW8V3+PCryeZA533YyF+hOdVvcYZ0yOwxrjWR1ZteQUHYb3L4clf4D/3QNAv7QYjAY91TU2csvqWS+nzE/JAF+vLQiCbzwtOZ5CprpUUsg7EAGLnNWrV3PppZeSmZmJTqdj8eLFmuN2u505c+aQkZFBREQEEyZMYP/+/ZoxhYWFzJw5k9jYWOLj45k1axbl5dog3G3btnHeeecRHh5Oly5deP75573m8sknn9C/f3/Cw8MZMmQI33zzTaBvp0k4kl/B35ft42/f7mHhhqM89MmvTvfDsUSlt1KnmqPo0PqOV+7JZdXePP7I+wDYw+NEwASLa/+rTRk31iMdO8Ljdx+VrN1Wa+ccXYuzKWChUuRRp9ORFK18geY7RI7dbsdqq6V5YNlp/8faaw0jQQg2npYcT3eVpdrlrvLMzBLaHQGLnIqKCoYNG8brr7/u8/jzzz/Pq6++yhtvvMGGDRuIiopi0qRJVFe7skxmzpzJzp07Wb58OUuWLGH16tXceeedzuOlpaVMnDiRbt26sXnzZl544QXmzp3LggULnGPWrVvH9ddfz6xZs9i6dSvTp09n+vTp7NixI9C3FHR2n3bFaPzpix2Anb66EwDED5sGhjD0thoWhL7ERP0vrDHex2zDFwD85T9fcVPI9wDo0ocGljEl+GfApfCHba7twrorTnsJTM9ii2GxeOHWMiM5WgkGzy838cPeXG579xf6P/Ete7K9Y3gAKD6q2ZyT+hrc+jVc/BR09dF4VBAEb+qy5FjNYsnpQAQscqZMmcIzzzzDFVdc4XXMbrfzyiuv8Pjjj3P55ZczdOhQ3n//fU6dOuW0+OzevZulS5fy5ptvMnr0aM4991xee+01PvzwQ06dUmISFi5ciNls5u2332bQoEFcd911/P73v+ell15yvta8efOYPHkyDz/8MAMGDODpp5/mjDPOYP78+Q38VQSPo4f2MER3iFgq0GFjfuhrxOkqsaFn+BljoMc4AC7Sb2WB8WW66PO4LeRbAK43rASgmjC44o0Wew/tlkiHNSZ1YN1jYzMhOt21XelRpTrcl8hxZUiplpxNR4v4zTu/8MPePGqsdv656qD3edWlzhTyI5mXcJnpaU5FDYDu58I592ljgQRB8E9d2VWWaonJ6UAE9Zvz8OHDZGdnM2HCBOe+uLg4Ro8ezfr16wFYv3498fHxjBo1yjlmwoQJ6PV6NmzY4Bwzbtw4jEaXyp40aRJ79+6lqKjIOcb9ddQx6uv4wmQyUVpaqvlpCibteIivwh7nTP0eLtOv4xLDzwDoDKFKsOu1/wFAr3O5LhJ15cRQyRl6xbW3KP3huuu4CIHzm29g6LVw2at1jw0Jg3s3ubY9n/oSeyqm8NBIuNXhKrVUg7kScFlyVu3VdiO326G40qy9Vs5OZRnbiR8H/4Vt9l6EhXikxgqCUDeelhxP0WMxScXjDkRQHZLZ2UrgZFqaNqgzLS3NeSw7O5vUVG3qbkhICImJiZoxPXr08LqGeiwhIYHs7OxaX8cXzz77LE8++WQD3llgVBtioAYeCvlEkyWjU+MqQiMgPB6qizXnbY34HaU25cZoj6uj5YDQMFL6wZUL6h6nEhYDM96FH5+HiU9rj8Wkwz0bFLdWeLzi37dZFJeVMdIpctzdlwBf/nqKL389Rf/0GH5/UR+mDsmAHIebNW2ws0GnMUSsN4IQMF5tHTweKCzVrgKCYslp93Sob9FHH32UkpIS58/x48eb5HUG9FAsMJ5pwFzqZj1QO1y7EWKvIVGnBGDbY72PCy3EoCvg7vVKU1RPknopsTo6nStQ2eGySo6u3d+/J7uMuxduwW6zwtb/KjszR2C2KiInTESOIASOpyXHs3eVxeQWkyMip70T1G/R9HQlfiEnJ0ezPycnx3ksPT2d3FxtoTOLxUJhYaFmjK9ruL+GvzHqcV+EhYURGxur+WkS1Kwbdy7/B/Q4z7XtJmLskUmaoVa7jkF9+zbN3ISmw72hJ65GnSpv3zrKZxx59cGf4HQWGGM42WcmL3yn1OURS44gNABPS47F5L2ttn6QwON2T1C/RXv06EF6ejorVqxw7istLWXDhg2MGTMGgDFjxlBcXMzmzZudY1auXInNZmP06NHOMatXr6amxqXAly9fTr9+/UhISHCOcX8ddYz6Oi1KeLz3vjSPQFe3gFbdRXNg8t+c27aoVMb0qUcdF6F14d7QE4iN0D4lpsdGkOijWWelo7r1alMvzpm/3bnfWJ8CgoIgaKnLkmM1uYSPpJC3ewL+Fi0vLycrK4usrCxACTbOysri2LFj6HQ6/vCHP/DMM8/w5Zdfsn37dm6++WYyMzOZPn06AAMGDGDy5MnccccdbNy4kbVr1zJ79myuu+46MjOVqq433HADRqORWbNmsXPnTj766CPmzZvHAw884JzHfffdx9KlS3nxxRfZs2cPc+fOZdOmTcyePbvxv5XG4mHJWdXpTsgcoR3j/kjfe4Kmu3W9quMKrQ8Pd1VEqDZwONJo0Fh3QrHwUMhHJK18CICjVm0dnrBQ+RwIQsB4iRyHayokwm2fQ+SIu6rdE/C36KZNmxgxYgQjRig37QceeIARI0YwZ84cAP74xz9y7733cuedd3LmmWdSXl7O0qVLCQ93ldBfuHAh/fv356KLLmLq1Kmce+65mho4cXFxLFu2jMOHDzNy5EgefPBB5syZo6mlM3bsWBYtWsSCBQsYNmwYn376KYsXL2bw4MEN/mUEDQ+Rc6T3Ld5jhs+EkHCY+IySRZXuVtlYsqraJh7uqkijVuREGA3OYGSA+8O+ZHbI/5zbJ+1akWOQtHFBCBx/gce3L/ceK+6qdk/Atrrx48djt/uv2qrT6Xjqqad46qmn/I5JTExk0aJFtb7O0KFDWbNmTa1jZsyYwYwZM2qfcEvgJnIq7WGM7NPFe0z3c+CxU64Ouno9/D4Lvp8LZ/+uWaYpBJlIh8jxY8kJDzWQEKV8qRqwco3hB9yLXp+wa1s3FFbUsx2EIAgu/FlyQiO9x4q7qt0jj4pNgZvIKbDHMijTT4Cz3qMOSmIPuOY9jetKaEN4uKvCPURORKjBGWdzpn4vyTZtcUFPS05uqYgcQQiYn16CPW4tfpzuqjDFeu6OWHLaPSJymgI3kRMWn45eL60ZOgQe7qoIN3eVTgehBh0hjs/CRfotAHxldQnao/Y07jjPVR8qNVabnSUIQj358HplabdrWzh4Fv+TmJx2j9jqmgK3nkapvYa33DyE5sUju8o9Jkev06HT6TAYFJEzTq/00frGOpo3LJdxbvco/jx6HJcP78SkQel89Mtx7p8gZQQEoVG4Z1YZjN6FAcVd1e6Rv3BT4B543OfilpuH0Lx4uqvc2jKocWxXjOjExxsO0UuvdBxPHXAOt54zitE9XbWSRnVPZFR36T4vCI3GXdQYjK6sKhVpgNzuEZHTFES5xVb0HN9i0xCaGQ93lS835ZndE/nulm6EfGSF0EienHmxNN8UhKbCU+QIHQ4ROU1BaAT8do0SWOyr+rHQPol0s+TY7ZqnRJ3bumrFIbGXCBxBaEqc7iqdd6KH0CEQkdNUZAxt6RkIzY1qybFbwVSqEbiasgsFB5Rlcu9mnJwgdEBU91RImLimOijyGCkIwSI0wlVVteio/3F5e5RlUp+mn5MgdGRUS464qjosInIEIZgk9VKWy/7kf0zOTmXpq6u5IAjBo7Zu47M3Ne9chBZBRI4gBJOLlPYmHNugxOV4YrVA7m5lPX1I881LEDoiaiNOT0uOzgDJYkntCPx/e/cfFFXd7wH8vbjssgi7CyIsGCKWSeWPRyFp1er2uFcrp1/jNGU0WZleDW96ayqt+2hz+0GT8zQTTdlYU3arq/24WWapMZiYDoKSJGiXNClJBSoCFn/waz/3j2UPewB5qmd3T57zfs3snHW/X3e+56Ms7/2e7zmHIYcolDKv8m+72/3rcnoocafpO6DrLBA9FEjI7PfXiegPiB028Osdbf5t31s69L3yMekWQw5RKEXbei8G2dbYv72p1r8dxjOriEJmYQmQNLb/6956/zYuxb9NGOXfZl0fkWGR9vgpSxRqccn+bVtD/7bAN0teWoAodJzpQO6/9X898EUjvifkzNsM/Ot/AbP/HrmxkaYYcohCbWgg5PTO5AyP67kPVedp/9YyNMKDItK5ga6D0xaYyXH5t850YNpSfskwEIYcolCL6w05/3NfLsaPcOD1uy8HTv0M1Gzxt/VdI0BE/xzTACHH2zObGpjJIcPhxQCJQi1w/L+tAVOvSMIn/z4daDoKrJ4MZQkyZ3KIQuu3zOSQ4XAmhyjU4ob7t6eCFh5XrkfQOVYMOUSh1ncmx+fjTA4x5BCFnDKTExRyfvpG3YeHq4hCq+9MTndH7xeNOIYco2LIIQq1oMNVAPwXJPt+l7oPZ3KIQsvU59dZdzvQ1XPFY14Xx7AYcohCbWjP4aq2n/zbN2/035k8GEMOUYj1ucJ4VwfgC9y7aoDbOpAhMOQQhVpgJudUI9BxGqjb078PD1cRhZavW/3n7nbA1+V/HsVzbIyKIYco1AIzOb4u9WGq7Lt7n3Mmhyi0AoEmoCs45HAmx6gYcohCzWwBbAn+50eK/NsL/wqMmdnbhyGHKLT6hpzAhTeBgU8vJ0NgyCEKh8Ahq9qd/m3KuN57WgEMOUSh1jfkdJzqfc7DVYbFkEMUDoFDVoEbcsYmqi8lH82QQxRSfdfktPzY+5wLjw2LIYcoHGIT/dvudv/WHKMOORYuPCYKqb4zOf87v/c5Z3IMiyGHKBwCa3IChliAGLv6z0QUOn1DTjCGHMNiyCEKB1ui+s/mGPWanBhnRIdDpHvj5gz8umkIYDJFdiz0p8F4SxQOfWdyzFb/GR7zPgE6zwBDh2kzLiK9sqcBK370r3d7MgmQnjU6XI9jaAw5ROEQO8BMDgBkXhX5sRAZhTXevzXHAJ09Z1fxUJWh8XAVUTj0m8nhvXOIIiY66OeNIcfQGHKIwqHfmhyrNuMgMiKzrfc5Q46hMeQQhQNncoi0EzyTwzU5hsaQQxQO/UIOTxknihjO5FAPhhyicOBMDpF2gg8PM+QYGkMOUTiYLepgwzU5RJETzZkc8mPIIQqX4Iv/cSaHKHLMXJNDfgw5ROESfH8qzuQQRY7qFPIh2o2DNMeQQxQuwfen4kwOUeQE/7xFcSbHyBhyiMJliHXg50QUXmZeDJD8whJyvF4vli1bhoyMDNhsNkydOhV79+5V2kUEK1euRGpqKmw2GzweDw4fPqx6j6amJuTl5cFut8PpdGL+/Ploa2tT9Tlw4ACuvPJKxMTEID09Hc8991w4dofojwk+bTyK3yeIIiZ44THX5BhaWD5577vvPhQVFeGtt95CVVUVZs6cCY/Hg+PHjwMAnnvuORQWFuKVV15BWVkZhg4dilmzZuHs2bPKe+Tl5eHgwYMoKirC5s2bsXPnTixcuFBpb21txcyZM5GRkYGKigqsXr0aTzzxBNauXRuOXSL6/Ybw2jhEmjBzTQ71kBA7ffq0DBkyRDZv3qx6ffLkyfL444+Lz+cTl8slq1evVtqam5vFarXK+vXrRUTk0KFDAkD27t2r9NmyZYuYTCY5fvy4iIi8/PLLkpCQIO3t7UqfRx99VMaOHfubx9rS0iIApKWl5Q/tK9Gg1t0gssrufxBR5BQ/1fuz99+3aD0aCoPf+vs75DM5XV1d6O7uRkyMeqGlzWbDrl27UFtbi/r6eng8HqXN4XAgNzcXpaWlAIDS0lI4nU7k5OQofTweD6KiolBWVqb0ueqqq2Cx9H5bnjVrFmpqavDrr7+GereIfj+eUUWkDd6gk3qEPOTEx8fD7XbjySefxIkTJ9Dd3Y23334bpaWlOHnyJOrr6wEAKSkpqr+XkpKitNXX1yM5OVnVbjabkZiYqOoz0HsE2gbS3t6O1tZW1YMobHi4ikgbZq7JIb+wrMl56623ICIYMWIErFYrCgsLMXfuXERpvPiyoKAADodDeaSnp2s6HtI5zuQQaYPXyaEeYUkdF154IUpKStDW1oa6ujqUl5ejs7MTo0ePhsvlAgA0NDSo/k5DQ4PS5nK50NjYqGrv6upCU1OTqs9A7xFoG8iKFSvQ0tKiPOrq6v75nSU6F0uc1iMgMibVDTo5k2NkYZ1aGTp0KFJTU/Hrr79i27ZtuOmmm5CZmQmXy4Xi4mKlX2trK8rKyuB2uwEAbrcbzc3NqKioUPps374dPp8Pubm5Sp+dO3eis7NT6VNUVISxY8ciIaHPzRF7WK1W2O121YMobP5lOeBIB675T61HQmQs1vje51yTY2hhCTnbtm3D1q1bUVtbi6KiIlxzzTXIysrCPffcA5PJhGXLluGpp57Cpk2bUFVVhbvuugtpaWm4+eabAQCXXHIJrr32WixYsADl5eXYvXs3lixZgttvvx1paWkAgDvuuAMWiwXz58/HwYMH8e677+KFF17Agw8+GI5dIvr97GnAf1QDVz+s9UiIjCUm6AssQ46hheVfv6WlBStWrMCPP/6IxMREzJkzB08//TSio/3Tho888ghOnTqFhQsXorm5GdOnT8fWrVtVZ2S98847WLJkCWbMmIGoqCjMmTMHhYWFSrvD4cDnn3+O/Px8ZGdnIykpCStXrlRdS4eIiAwoxtH7fAhDjpGZRES0HoRWWltb4XA40NLSwkNXRER60VQLFP7F//zy+4DZf9d0OBR6v/X3N681T0RE+hI8k2Pc7/EEhhwiItIba9A3+84z2o2DNMeQQ0RE+hK8DqfzlHbjIM0x5BARkX51nNZ6BKQhhhwiItKvToYcI2PIISIi/epo03oEpCGGHCIi0i8erjI0hhwiItKfeP/V8XHhX7UdB2mKl4IkIiL9WVAM/N+nwF/u0HokpCGGHCIi0h97GjBlgdajII3xcBURERHpEkMOERER6RJDDhEREekSQw4RERHpEkMOERER6RJDDhEREekSQw4RERHpEkMOERER6RJDDhEREekSQw4RERHpEkMOERER6RJDDhEREekSQw4RERHpkqHvQi4iAIDW1laNR0JERES/VeD3duD3+LkYOuR4vV4AQHp6usYjISIiot/L6/XC4XCcs90k/ygG6ZjP58OJEycQHx8Pk8kUsvdtbW1Feno66urqYLfbQ/a+esH6DI71OTfWZnCsz+BYn3M732ojIvB6vUhLS0NU1LlX3hh6JicqKgoXXHBB2N7fbrefF/9ZtML6DI71OTfWZnCsz+BYn3M7n2oz2AxOABceExERkS4x5BAREZEuMeSEgdVqxapVq2C1WrUeyp8S6zM41ufcWJvBsT6DY33OTa+1MfTCYyIiItIvzuQQERGRLjHkEBERkS4x5BAREZEuMeQQERGRLjHkhMFLL72EUaNGISYmBrm5uSgvL9d6SGG3c+dO3HDDDUhLS4PJZMJHH32kahcRrFy5EqmpqbDZbPB4PDh8+LCqT1NTE/Ly8mC32+F0OjF//ny0tbVFcC/Cp6CgAJdffjni4+ORnJyMm2++GTU1Nao+Z8+eRX5+PoYNG4a4uDjMmTMHDQ0Nqj7Hjh3D7NmzERsbi+TkZDz88MPo6uqK5K6E3Jo1azBhwgTlImRutxtbtmxR2o1al3N59tlnYTKZsGzZMuU1I9foiSeegMlkUj2ysrKUdiPXBgCOHz+OO++8E8OGDYPNZsP48eOxb98+pV33n81CIbVhwwaxWCzy+uuvy8GDB2XBggXidDqloaFB66GF1WeffSaPP/64fPjhhwJANm7cqGp/9tlnxeFwyEcffSRff/213HjjjZKZmSlnzpxR+lx77bUyceJE2bNnj3z55Zdy0UUXydy5cyO8J+Exa9YseeONN6S6uloqKyvl+uuvl5EjR0pbW5vSZ9GiRZKeni7FxcWyb98+ueKKK2Tq1KlKe1dXl4wbN048Ho/s379fPvvsM0lKSpIVK1ZosUshs2nTJvn000/l22+/lZqaGnnsscckOjpaqqurRcS4dRlIeXm5jBo1SiZMmCBLly5VXjdyjVatWiWXXXaZnDx5Unn89NNPSruRa9PU1CQZGRly9913S1lZmRw9elS2bdsmR44cUfro/bOZISfEpkyZIvn5+cqfu7u7JS0tTQoKCjQcVWT1DTk+n09cLpesXr1aea25uVmsVqusX79eREQOHTokAGTv3r1Kny1btojJZJLjx49HbOyR0tjYKACkpKRERPz1iI6Olvfff1/p88033wgAKS0tFRF/kIyKipL6+nqlz5o1a8Rut0t7e3tkdyDMEhIS5LXXXmNdgni9XhkzZowUFRXJ1VdfrYQco9do1apVMnHixAHbjF6bRx99VKZPn37OdiN8NvNwVQh1dHSgoqICHo9HeS0qKgoejwelpaUajkxbtbW1qK+vV9XF4XAgNzdXqUtpaSmcTidycnKUPh6PB1FRUSgrK4v4mMOtpaUFAJCYmAgAqKioQGdnp6pGWVlZGDlypKpG48ePR0pKitJn1qxZaG1txcGDByM4+vDp7u7Ghg0bcOrUKbjdbtYlSH5+PmbPnq2qBcD/OwBw+PBhpKWlYfTo0cjLy8OxY8cAsDabNm1CTk4Obr31ViQnJ2PSpEl49dVXlXYjfDYz5ITQzz//jO7ubtUPCwCkpKSgvr5eo1FpL7Dvg9Wlvr4eycnJqnaz2YzExETd1c7n82HZsmWYNm0axo0bB8C//xaLBU6nU9W3b40GqmGg7XxWVVWFuLg4WK1WLFq0CBs3bsSll15q+LoEbNiwAV999RUKCgr6tRm9Rrm5uVi3bh22bt2KNWvWoLa2FldeeSW8Xq/ha3P06FGsWbMGY8aMwbZt27B48WI88MADePPNNwEY47PZ0HchJ9JCfn4+qqursWvXLq2H8qcxduxYVFZWoqWlBR988AHmzZuHkpISrYf1p1BXV4elS5eiqKgIMTExWg/nT+e6665Tnk+YMAG5ubnIyMjAe++9B5vNpuHItOfz+ZCTk4NnnnkGADBp0iRUV1fjlVdewbx58zQeXWRwJieEkpKSMGTIkH4r9xsaGuByuTQalfYC+z5YXVwuFxobG1XtXV1daGpq0lXtlixZgs2bN+OLL77ABRdcoLzucrnQ0dGB5uZmVf++NRqohoG285nFYsFFF12E7OxsFBQUYOLEiXjhhRcMXxfAf8ilsbERkydPhtlshtlsRklJCQoLC2E2m5GSkmL4GgVzOp24+OKLceTIEcP//0lNTcWll16qeu2SSy5RDucZ4bOZISeELBYLsrOzUVxcrLzm8/lQXFwMt9ut4ci0lZmZCZfLpapLa2srysrKlLq43W40NzejoqJC6bN9+3b4fD7k5uZGfMyhJiJYsmQJNm7ciO3btyMzM1PVnp2djejoaFWNampqcOzYMVWNqqqqVB84RUVFsNvt/T7Iznc+nw/t7e2sC4AZM2agqqoKlZWVyiMnJwd5eXnKc6PXKFhbWxu+++47pKamGv7/z7Rp0/pdquLbb79FRkYGAIN8Nmu98llvNmzYIFarVdatWyeHDh2ShQsXitPpVK3c1yOv1yv79++X/fv3CwB5/vnnZf/+/fLDDz+IiP80RafTKR9//LEcOHBAbrrppgFPU5w0aZKUlZXJrl27ZMyYMefNaYr/yOLFi8XhcMiOHTtUp7qePn1a6bNo0SIZOXKkbN++Xfbt2ydut1vcbrfSHjjVdebMmVJZWSlbt26V4cOHn/enui5fvlxKSkqktrZWDhw4IMuXLxeTySSff/65iBi3LoMJPrtKxNg1euihh2THjh1SW1sru3fvFo/HI0lJSdLY2Cgixq5NeXm5mM1mefrpp+Xw4cPyzjvvSGxsrLz99ttKH71/NjPkhMGLL74oI0eOFIvFIlOmTJE9e/ZoPaSw++KLLwRAv8e8efNExH+q4t/+9jdJSUkRq9UqM2bMkJqaGtV7/PLLLzJ37lyJi4sTu90u99xzj3i9Xg32JvQGqg0AeeONN5Q+Z86ckfvvv18SEhIkNjZWbrnlFjl58qTqfb7//nu57rrrxGazSVJSkjz00EPS2dkZ4b0JrXvvvVcyMjLEYrHI8OHDZcaMGUrAETFuXQbTN+QYuUa33XabpKamisVikREjRshtt92mug6MkWsjIvLJJ5/IuHHjxGq1SlZWlqxdu1bVrvfPZpOIiDZzSEREREThwzU5REREpEsMOURERKRLDDlERESkSww5REREpEsMOURERKRLDDlERESkSww5REREpEsMOURERKRLDDlERESkSww5REREpEsMOURERKRLDDlERESkS/8PdH/CKiEd+KIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results_mv.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  1.2769868158907691\n"
     ]
    }
   ],
   "source": [
    "# Calculate Sharpe ratio\n",
    "sharpe=(252**0.5)*df_ensemble_results_lv.account_value.pct_change(1).mean()/df_ensemble_results_lv.account_value.pct_change(1).std()\n",
    "\n",
    "print('Sharpe Ratio: ',sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble_results_lv = df_ensemble_results_lv.join(df_validation_dates) # Mask the results with the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6Y0lEQVR4nO3deXxTVfo/8E/SNOmapAvdoGWHspYKCEVAkQ5lGRRlVJBxcKw6KrjhFxV1GBx/Myhuwygjw7jgzMAw4ggqKFJBKEIBqZSdshUodINu6Zr1/v5I721umy5p06a0n/frlZfJvSf33lwweXjOc85RCIIggIiIiKiTUXr6AoiIiIjaAoMcIiIi6pQY5BAREVGnxCCHiIiIOiUGOURERNQpMcghIiKiTolBDhEREXVKDHKIiIioU1J5+gI8yWazIScnB4GBgVAoFJ6+HCIiImoGQRBQVlaGqKgoKJUN52u6dJCTk5OD6OhoT18GERERtUB2djZ69OjR4H6Xg5zU1FS8+eabSE9PR25uLjZt2oRZs2ZJ+8vLy/Hiiy9i8+bNKCwsRO/evfHUU0/hsccek9pUV1fjueeew4YNG2A0GpGUlIS//e1vCA8Pl9pcvnwZjz/+OH744QcEBARg/vz5WL58OVSq2kvetWsXFi1ahBMnTiA6OhqvvPIKHnzwwWZ/lsDAQAD2m6TVal29FUREROQBBoMB0dHR0u94Q1wOcioqKhAXF4eHHnoId999d739ixYtws6dO/Hvf/8bvXr1wvbt2/HEE08gKioKd9xxBwDg2WefxdatW7Fx40bodDosXLgQd999N/bu3QsAsFqtmDFjBiIiIrBv3z7k5ubiN7/5Dby9vfHnP/8ZAJCVlYUZM2bgsccew7p167Bjxw48/PDDiIyMRFJSUrM+i9hFpdVqGeQQERHdYJosNRFaAYCwadMm2bYhQ4YIf/zjH2XbbrrpJuHll18WBEEQSkpKBG9vb2Hjxo3S/lOnTgkAhLS0NEEQBOGbb74RlEqlkJeXJ7X54IMPBK1WKxiNRkEQBOH5558XhgwZIjvPfffdJyQlJTX7+ktLSwUAQmlpabPfQ0RERJ7V3N9vt4+uGjduHL766itcvXoVgiDghx9+wJkzZzBlyhQAQHp6OsxmMxITE6X3xMbGIiYmBmlpaQCAtLQ0DBs2TNZ9lZSUBIPBgBMnTkhtHI8hthGP4YzRaITBYJA9iIiIqHNye5Dz3nvvYfDgwejRowfUajWmTp2KVatWYeLEiQCAvLw8qNVq6PV62fvCw8ORl5cntXEMcMT94r7G2hgMBlRVVTm9tuXLl0On00kPFh0TERF1Xm0S5Ozfvx9fffUV0tPT8fbbb2PBggX4/vvv3X0qly1ZsgSlpaXSIzs729OXRERERG3ErUPIq6qq8NJLL2HTpk2YMWMGAGD48OHIyMjAW2+9hcTERERERMBkMqGkpESWzcnPz0dERAQAICIiAgcPHpQdOz8/X9on/lfc5thGq9XC19fX6fVpNBpoNBq3fFYiIiLq2NyayTGbzTCbzfUm5vHy8oLNZgMAjBw5Et7e3tixY4e0PzMzE5cvX0ZCQgIAICEhAceOHUNBQYHUJiUlBVqtFoMHD5baOB5DbCMeg4iIiLo2lzM55eXlOHfunPQ6KysLGRkZCA4ORkxMDG699VYsXrwYvr6+6NmzJ3bv3o1//vOfeOeddwAAOp0OycnJWLRoEYKDg6HVavHkk08iISEBY8eOBQBMmTIFgwcPxgMPPIAVK1YgLy8Pr7zyChYsWCBlYh577DG8//77eP755/HQQw9h586d+Oyzz7B161Z33BciIiK60bk6bOuHH34QANR7zJ8/XxAEQcjNzRUefPBBISoqSvDx8REGDhwovP3224LNZpOOUVVVJTzxxBNCUFCQ4OfnJ9x1111Cbm6u7DwXL14Upk2bJvj6+gqhoaHCc889J5jN5nrXMmLECEGtVgt9+vQRPvnkE5c+C4eQExER3Xia+/utEARB8GCM5VEGgwE6nQ6lpaWcDJCIiOgG0dzfb65CTkRERJ0SgxwiIiLqlBjkEBERUafEIIeIiIhcdjrPgH+kXoDJYvP0pTTIrZMBEhERUdcw9S97AAAabyV+k9DLsxfTAGZyiIiIqMXOFZR7+hIaxCCHiIiIXGKx1nZRhfh33OWSGOQQERGRS/LLjNJzrW/HrXxhkENEREQuySmpkp5brB13TmEGOUREROQSxyDHaLF68EoaxyCHiIiIXJJTUi0978hDyBnkEBERdRGGajOWfXUCR6+UtOo4JZUm6bmRQQ4RERF52iubjmPtvov49YcHWnWckkqz9JxBDhEREXncV0dyAACGakurjlPMTA4RERF1FFab+0ZBlVTVZnJYk0NEREQeVVBWWywcofVp1bFKZd1VHF1FREREHlRtrs24VJlbF5iUVLG7ioiIiDoIx26lcqMFgtDy7ivHwmN2VxEREZFHOQYjVpuAqX/Z02hXU3UD2Z4qk1WWvWF3FREREXlU3WAkM78MaecLnbY9frUUg5Zuw/JvTtXb59hVBTCTQ0RERB7mLBjJLqp02vbN7zIhCMDfUy/U2+fYVQWwJoeIiIg8zGitH4yczC1z2tbmUK/zu38dwod7aoOdSpN8jh1mcoiIiMijnAUjJ3MNTb7vuxP5+H9ba7utqkzy4zCTQ0RERB7lLBg5nWuAxUmGx+Zk5FXcq9uRXVQpZXLUXvYQgpkcIiIi8ihnwYjRYsPFwop6252NLi+tMuOdlDPSHDs6P++aY3B0FREREXmQY5DTK8QPgRoVAOd1Oc4yOQCQV1qNSpM9qAmqCXKYySEiIiKPMtVkXGYMj8SuxZNwZ3wUAOCUk7qchpa5SrtQiE/2ZgEA9L5qAKzJISIiIg8TgxFNTS1NdJAfAHt2pqG2zpzJLwdQ211lsQluXfzTnRjkEBERdXLpl4qx/NvTAAC1yv7T3y1QAwC4Vmas176s2lxvm0qpkL3W+3pLzztqXQ6DHCIiok5uzpo06bkY5IQG2IOc6+X1g5zyavlcOMN76LDtmQmybcH+aum54+KfHQmDHCIiok7ObK3tTtI0kskpqzbDahNQbpQHOVOHRiA62E+2LUCjgo+3/VgVddp3FCpPXwARERG1n7rdVUWVJpitNhRVmJCwfAfG9gmRRlCJ/NUqaFRe0Pl6o7TK3pXlq/aCn1qFarNJGlbe0bicyUlNTcXMmTMRFRUFhUKBzZs3y/YrFAqnjzfffFNqU1RUhHnz5kGr1UKv1yM5ORnl5eWy4xw9ehQTJkyAj48PoqOjsWLFinrXsnHjRsTGxsLHxwfDhg3DN9984+rHISIi6lLUXl4AgCA/NZQK+5w4RRUmfH0kBzYB2Odk0U7/muHmYTWBESAGOfZjOcvk2DpAMbLLQU5FRQXi4uKwatUqp/tzc3Nlj48//hgKhQKzZ8+W2sybNw8nTpxASkoKtmzZgtTUVDz66KPSfoPBgClTpqBnz55IT0/Hm2++iWXLlmHNmjVSm3379mHu3LlITk7G4cOHMWvWLMyaNQvHjx939SMRERF1WkKdOW/ETI6XUoGQgNouq7qFxY4CNPZgpptDkOOn9oK/2h781M38AMC8Dw8g6d1U/HSxqHUfoBVc7q6aNm0apk2b1uD+iIgI2esvv/wSkyZNQp8+fQAAp06dwrZt2/DTTz9h1KhRAID33nsP06dPx1tvvYWoqCisW7cOJpMJH3/8MdRqNYYMGYKMjAy88847UjC0cuVKTJ06FYsXLwYAvPbaa0hJScH777+P1atXu/qxiIiIOqW6q4aLQQ4AhGs1uFZmxJXiKigUDQc5TjM53ir41mRy6gY5NpuAo1dKUGGyQuvjDU9p08Lj/Px8bN26FcnJydK2tLQ06PV6KcABgMTERCiVShw4cEBqM3HiRKjVtZXbSUlJyMzMRHFxsdQmMTFRdr6kpCSkpaWhIUajEQaDQfYgIiLqzArqDBHXOAQ5QyJ1AIBjV0vqDRsP0NTmQfxqMjaDIrUO27zgrxGDHHl31YXrFagwWeHjrUTfbv5u+BQt06ZBzqefforAwEDcfffd0ra8vDyEhYXJ2qlUKgQHByMvL09qEx4eLmsjvm6qjbjfmeXLl0On00mP6Ojoln84IiKiG0C+QT7Zn7dXbcYmLloPADiSXVov43P3Td2l52LtzejewdI2sfAYACqM8kzO8aulAIAhUTqovDw3kLtNz/zxxx9j3rx58PHxacvTNNuSJUtQWloqPbKzsz19SURERG2qbibHca2puGh7JufIlRIU1wly+nYLwKr7b8KziQMQGxEIABgapZP2KxWAv9p5JudEjj3IGdZdB09qsyHke/bsQWZmJv773//KtkdERKCgoEC2zWKxoKioSKrniYiIQH5+vqyN+LqpNnVrghxpNBpoNJoG9xMREXUW3x7LhcZbiW+P5cq2O07cNyA8ECqlAmXVFpzOk5dwxIT4YdJAec+LWqXE63cPw/GcUsRHB+Hz9KsA6tfk5NYsFVF3bp321maZnI8++ggjR45EXFycbHtCQgJKSkqQnp4ubdu5cydsNhvGjBkjtUlNTYXZXBtVpqSkYODAgQgKCpLa7NixQ3bslJQUJCQktNVHIiIiuiFkXa/A4+t+xkNrD2HHaXliodphThtvLyV6h9prZk7kyIOccX1DnB57zs0x+H+zhkGpVEiZnIo6mRxxFuXQAHW997cnl4Oc8vJyZGRkICMjAwCQlZWFjIwMXL58WWpjMBiwceNGPPzww/XeP2jQIEydOhWPPPIIDh48iL1792LhwoWYM2cOoqLsK6Lef//9UKvVSE5OxokTJ/Df//4XK1euxKJFi6TjPP3009i2bRvefvttnD59GsuWLcOhQ4ewcOFCVz8SERFRpyLWxDgjDhsX9Q8PqNfmjdnDoFF5NXkev5ri5Mo6NTnXy00AgG4Bnu09cbm76tChQ5g0aZL0Wgw85s+fj7Vr1wIANmzYAEEQMHfuXKfHWLduHRYuXIjJkydDqVRi9uzZ+Otf/yrt1+l02L59OxYsWICRI0ciNDQUS5culc2lM27cOKxfvx6vvPIKXnrpJfTv3x+bN2/G0KFDXf1IREREnUrdrAwA3BXfHQEaFX41sodse7+wQAC1g3a2PDkeQ5tZS+PnZAj59XIjzhXYJ/gNDbzBgpzbbrut3sRCdT366KOygKSu4OBgrF+/vtFjDB8+HHv27Gm0zT333IN77rmn0TZERERdjVj46+j+MTEY3Su43va6Q7y7uRCY1C08ttoEJL6zW9of6uFMDhfoJCIi6iSKK0yoNltx4VoFAOBfyTdL+xxXDXfUXe8rPff2UrjUxSQNIa/J5BRWGGVD0fW+npsIEOACnURERJ3CmtTz+PM3pxGu1SDfYC/87R3qj1dmDEK+oRp9Qp1Pytc9qDbICQv0gbKR5R3qErurqmoyOQUG+XB1V47VFhjkEBERdQK7z1wDACnAAexBy8MT+jT6vrDA2rnsVF6uBSVi4bE4GWBBWXVjzdsdu6uIiIg6gbpz1YT4q2XrVDXEyyHb0kTJbT11a3IcMzl/m3eTawdrAwxyiIiIOoG6w7jDta6vNiDAtSjHr84q5OLsyveNisb0YZEun9/dGOQQERF1ApVm+YR84drmFxDPGmGfp+7JSf1dOmfdIeRid1WYC+duS6zJISIi6gRak8l541fD8fCEPhgSpW26sQM/Te2Mx4IgSN1VYR6eH0fETA4REVEnIC6tIM5zM8SFxTE1Ki8M7a6DQuFa4bF/TXeVIABGiw3FlfaZjoP9O0aQw0wOERF1KIIg4I1tmQgL1OCh8b09fTk3BKtNkBbe3PrUeBiqzOjbrf5yDe7m61279EOF0QJDlT3Q0nl4fhwRgxwiIupQLhZWYvXu8wCAMX2CMSSq+RmJrqrKYdHNQI23bFh4W1IqFfD19kKV2YpKkxVl1faJAAN9OkZ4we4qIiLqUArLa4ch/3XHWVQYLY20JqB2CLdCAfh4t+9Pu7+mtvjYUG2/DgY5REREThRWmKTn353Ix8QVP6DabG3kHSQWHft5e7lcV9Na4jDysmozymsCUm0H6a5ikENERB1KsUOQA9iDntzSjjWTbkcjDuEWZyBuT+Iw8iNXahcFZSaHiIjIicI6QQ4AqdaDnBO7q8QZiNuTGOS8tuUkAECjUkKjav/rcIZBDhERdShiJmfO6GhpW1k163IaI2ZyfNXtn0Gx2uSzJAf6dIyuKoBBDhERdTBFNUFOr1B/jOwZBICZnKZ4MpNz4VqF7LW2g3RVAQxyiIiogymSJpRTS7UdBmZyGlWbyWn/IKeszui3wA5SdAwwyCEiog5G7K4K9lNLXR/srmpchVh47IEg54nb+speM5NDRETUgJyakVTdAjVSJqc9uqsEQcDv/nUIv/n4IATBtdW4XXHgQiG+zLiKcwVlsNlaf56M7BJ8uOcCAEDrgXqYRb8YgHF9Q6TXnriGhnSccIuIiLq80kozrpXZJwPsGxbgEOS0fSanwmTFdyfyAQC5pdWI0vu69fhi4HTfmv3Stidu64vnp8a26rizVu2Vnuv92j/AUHkpcUu/UOw7Xwigdu2sjoCZHCIi6jDOFpQBAKJ0PgjQqKSsQHtkckwWm/Tc3fPpWaw2zFq1F/M/+Um2/W+7zrfquHUzQXo/dauO11KOwVXfbv4euQZnmMkhIqIO40x+OQCgf3ggALRrJsdxVuW6w6Jb63RemWyyPHe57rAEBuCZTA4A6H1rg6s+7bAwaHMxk0NERB3GhWv2IKdfmP2Hsj2DHMdFLs1W9wY5hgYyUQGtnKH4akmV7LVjsNGeAhyKjft0oEwOgxwiIuow8mvqccR6mEBN+3VXVcuCHFsjLV1nqHIepIUEtC4oqbvchacyOY6juiK07bMCenOwu4qIiDqMa2X2H+3Qmh9//5pMR3kbrkRebrTgkx+zZPO9ONbnuEPdbiVRa2tocupkcnQemqNmVM8gPDy+NwZEBLb7AqGNYZBDREQeca6gHFF6H2kVawDSyCpxhI6YIagytc0q5Kt3n8fr356ut93dmZyGgpzWDiHPKZFncoL8PdNdpVAo8MovB3vk3I1hkENERO0u/VIRfrU6DYIAPD25P+aNjUFYoA+ul9snAgyrCXL8NfYgp6KNghxnAQ7Qfpkcxy6ylsgtrVuT03HmqOkIWJNDRETtavuJPMz+wB7gAMDKHWdx/z8OwGixorTKXnsTGmAPcsQFJ9sqk9MQdxceXy+rv7I6IC92bom63VWemPG4I2OQQ0RE7erd78/W23auoBxXiu0/2N5eCqm2xM/b/qNtstpgcXMXUmMcu6sqjBYp+Gqpa3UyOWqV/ee32ty6z5TjUHg8dUhEh6qH6QgY5BARUbsqqqj9wT/92lRpGPXkt3cDALoFaKQfa8cFJytbmfVwhakmyBEEATf/6Xvc9FpKi7uWbDYBZ/LKZNuCakZBGVvxmYwWq1TDdOiVRKx+YGSLj9VZMcghIqJ25VuTndn4WAJ8vL3Qvc7yCb0d5lnRqJRQ1iQn2rPLSszkFFeaUWGywmoT6g3Xbq4L1yvqrdQdVDOqqjXdVfml9gBHo1IixEMFxx0dgxwiImpX4nBwMYMTGlj7A61QAMtmDnF4rZBGX1V6IMgpKKsNbFoaZB3JLqm3LbgmKLHYhBaP5BInAozS+7KbqgEuBzmpqamYOXMmoqKioFAosHnz5nptTp06hTvuuAM6nQ7+/v4YPXo0Ll++LO2vrq7GggULEBISgoCAAMyePRv5+fmyY1y+fBkzZsyAn58fwsLCsHjxYlgs8kh4165duOmmm6DRaNCvXz+sXbvW1Y9DRETtTJy9WAxyHOtdzv1purSkg0jssqo0tf2sxyJxdFWBobZrraFZi5tyJr+s3jbHod51u8GauwK6WOcT1oEWxOxoXA5yKioqEBcXh1WrVjndf/78eYwfPx6xsbHYtWsXjh49it///vfw8amdAfHZZ5/F119/jY0bN2L37t3IycnB3XffLe23Wq2YMWMGTCYT9u3bh08//RRr167F0qVLpTZZWVmYMWMGJk2ahIyMDDzzzDN4+OGH8d1337n6kYiIqJ2YrTYYawIIccmGUT2DAdhHBnkp62ck/KUgpz1rcuyBRkGZQ5DTwuJjx2OI9L7e0iKgjsXH76acwcj/9z2yiyqbPG5hTZAjjkSj+lyeJ2fatGmYNm1ag/tffvllTJ8+HStWrJC29e3bV3peWlqKjz76COvXr8ftt98OAPjkk08waNAg7N+/H2PHjsX27dtx8uRJfP/99wgPD8eIESPw2muv4YUXXsCyZcugVquxevVq9O7dG2+//TYAYNCgQfjxxx/x7rvvIikpydWPRURE7aDCoTZFnM34mcT+8FV74e747k7f49tG3VWNZUzMlvrdVYYWrp8lFgdrfVTSMfzUXvBReaHKbJVlclbusI88e/f7M3jn3hGNHreowj4sPZj1OA1ya02OzWbD1q1bMWDAACQlJSEsLAxjxoyRdWmlp6fDbDYjMTFR2hYbG4uYmBikpaUBANLS0jBs2DCEh4dLbZKSkmAwGHDixAmpjeMxxDbiMZwxGo0wGAyyBxERtR+xq0qjUsLby/4TpPdT44WpsfW6qUS1sx67t7vK1EgtjFSTY2h9JkcMcmJC/KRtvt5e8PEWh5HXD96MzZiMsLAmyGnt+ledmVuDnIKCApSXl+P111/H1KlTsX37dtx11124++67sXu3fWhgXl4e1Go19Hq97L3h4eHIy8uT2jgGOOJ+cV9jbQwGA6qq5JMjiZYvXw6dTic9oqOjW/2ZiYio+SpqApVAn+Z3JPi1UXdVY4XEYpBzraz1NTliNigmuDbI8VF7wadmlJmzuXKas9yD2F3FkVUNc3smBwDuvPNOPPvssxgxYgRefPFF/PKXv8Tq1avdeaoWWbJkCUpLS6VHdna2py+JiKhLKa/J5IhdVc0hDjl3d5DT2PGOXCnF10dyZJP4tWRCQJPFhuJK+/uiHYKcID+19LnEYeSO3WfWZgQ5RVImhzU5DXFrkBMaGgqVSoXBg+WLdA0aNEgaXRUREQGTyYSSkhJZm/z8fEREREht6o62El831Uar1cLXVz7ngkij0UCr1coeRETUfuoOH2+Otlqks7HRWikn8/Hkfw7jYFaRtM1Q5Xp3WWHNxIcqpQJan9p1pcb1DYFGyuTYP5djF1Vz1u0sLGdNTlPcGuSo1WqMHj0amZmZsu1nzpxBz549AQAjR46Et7c3duzYIe3PzMzE5cuXkZCQAABISEjAsWPHUFBQILVJSUmBVquVAqiEhATZMcQ24jGIiKjjaVGQo2mbwmNXj9eS7iqxuys0QCMLqnqG+Dt0w9m3ZzjMp9OcuXOkmhwGOQ1yeXRVeXk5zp07J73OyspCRkYGgoODERMTg8WLF+O+++7DxIkTMWnSJGzbtg1ff/01du3aBQDQ6XRITk7GokWLEBwcDK1WiyeffBIJCQkYO3YsAGDKlCkYPHgwHnjgAaxYsQJ5eXl45ZVXsGDBAmg09rTcY489hvfffx/PP/88HnroIezcuROfffYZtm7d6obbQkRE7vTTxSIE+6ul7ipXghyxbVkLa2KcKaow4ftTBU03dNCSwmOxSynIX437x/TEvvOFmDfG/o9+cX2u0iozLhVWYM6a/bXnauKzVpnqL2ZK9bkc5Bw6dAiTJk2SXi9atAgAMH/+fKxduxZ33XUXVq9ejeXLl+Opp57CwIED8b///Q/jx4+X3vPuu+9CqVRi9uzZMBqNSEpKwt/+9jdpv5eXF7Zs2YLHH38cCQkJ8Pf3x/z58/HHP/5RatO7d29s3boVzz77LFauXIkePXrgww8/5PBxIqIOJu18Ieb+w/4DPiTKXibgSuFxhNY+z9rVEueDSlri5U3H8O3xPJfeU9aCIeRiIKLzVaG73hebnrhF2ucY5Ow9Vyh7X0ll40HO6Tz76ODQAI1sYkGScznIue2225qcjfGhhx7CQw891OB+Hx8frFq1qsEJBQGgZ8+e+Oabb5q8lsOHDzd+wURE5FFp569Lz0/k2H+cx/YJafb7xYLd7OKmJ8hrrkOXil1+T0tmXBazP3rf+oGIGOSUVJrrFWKXVJoaPe7JXPt9HBzF2tLGcO0qIiJqU0eulMpe+6m9MDMuqtnvjw62DybJLnJfJidKZ88OxUY4n5vHmYoW1ATVZnK86+1zzOTkG4z13icOI998+CrmrEnDhWvl0n4xWBzCIKdRDHKIiKjNCIKAY1flQc7YPiEuDSGPDrJnckqrzC0axu2MpSaA+PXYnk22FWuCKo2t6K7yazzIySuVB3A2AbheMzLrjW2nsf9CEW5/e7cU+JysCXIGRzLIaQyDHCIiajPXy01S8a1ooAvZE8A+p444gqg5azo1hzgPjTjCqTE9guyZpEqztVmT9DkSa2ucZXL0frVBTm5pdb39YubKsUIk11ANq02QanLYXdU4BjlERNRmLhdVAAC6632hrlnGIXFQeGNvcUocQdRUQW5zWVwIcsSZigUBqLa41mUlZnK0TXRX5TkJcq7U1CD5a2qvMbuoElnXy1FttsFP7YVeIf4uXU9XwyCHiIjazKVC+w91TLAftj0zAf95ZCxG9gxy+TgqL/uS3WZb0/PHNIeYyRGXVhCFBdYfjj19WKS0YniFsWVBTmM1OcevluLCdXsw+P2iW/GrkT0AAJdr7p3jsg+XiyqlepzYiECnq7ZTLZdHVxERETWXGOT0DPFDn24B6NMtoEXHERfztFhd6y5qiKUmWPJT1/4MLvrFAAwID8Rj/06XtU0aEgE/by9UmKw1I6yaPy9Nc4IcmwBAEDBxQDf0CwuQapDE0WSOo7qe//yo9Lx/mGvdfl0RMzlERNRmLtfU0DiuwN0S3jWZHEszZgJuDmtNsKRR1f4Mhms10NaZv2fLk+Phq/aSZl12NZNjaCzIqVOMfP/NMQDqjyarcrJKOQBE6Z0vYUS1GOQQEVGbuVho74bpGdy62hGV0v5zZXax8LchYk2O2A0mcgw84qL1GNpdBwDwr7MEQ3MZaiYQrBs8AUC3OjMVT+gfCgAIr5n88Hq5ETab4HSVcgCI1Pu4dC1dEYMcIiJqE4Ig4Gy+fW6X/uEt66YSSTU5FhvMVht+v/k4Pvspu8XHE2tyxOBJFORXO2mfj0OWR+zWcnWuHHHxTcduMZFCocCK2cMBAImDwqRh9SEB9mu4Xm6ULdr54LhesvdH6ZjJaQprcoiIqE3klFaj3GiBSqlo9SggcWSWxWZDRnYJ/rX/kn27SolZ8d1dPp6YyXEs3BUEeZBjdcgaiSOcXJkrx2oTpPM4dos5umdUD/QI9kVsRO1QcHEkWXGlWbZe19JfDkbPED+8+vVJAMzkNAczOURE1CbO5JcBAHqH+kPdwI98c0mZHKuAKodsyvaTrq0/JarN5NQGOQMiAuHrMKTcsRamJZkck0MWpqHPr1AoMK5vKIId1p8K8lNDvCxxvS6NSgmlUiHNrQMwk9MczOQQEVGbOFfTVTUgvPWjgFQ1mRyz1SYLHsSZf10ljq7yUiqw9anxuFRYiZti5EPbqx2CHCmT40JNjtFhTp2GMjnOeCkVCPZX43q5CVeK7UGOGHwNDK/N+Pg2Y46fro5BDhERtQkxC9HakVUA4K0UR1cJMDuMsLpYWIlyo0VaeqG5rA6Fx0OidBgSpavXxrHgV8rkuDC6SgzGvJQKKUhrrhB/Da6Xm6Rh5L418/kMjtJi1f03sauqmdhdRUREbUIMcrq7YaizOE+O2WaDqc4w8sy8MpeP56wmpy5ZJqcFo6vEomG1iwEOAIQGistYyDM5ADBjeGS9rBM5xyCHiIjaRI4bgxyVw2SA5joTAhqqXVvqwWYTpPWg6o6uciSryanJFJW7UHgsdldpvF3/qQ3xtxcfX6mTySHXMMghIqI2IQY57pi0zlsqPJbX5ACuz4JscRg15SyTI07GN65viLRNyuS40F3VmkxOuNYe5GTVLPfAIKdlGOQQEZHbVZosKK5ZTDPKDfUj0mSAdWpyAMDq4npWjkPDVU6CnP88MhZPT+6PN2rmsAFqa3JO55dhzpo0/HC6oMnziEFOSzI5YmBYt/CYXMPCYyIicrurNT/OgRoVAn3qL2ngKm9V7bIOdYOcut1XTbE4BEXOMjk9gvzw7C8GyLaJo6uOZJcAAPZfKMLF12c0eh5jTeGyRuV6gBJZZ3g4Mzktw0wOERG5nbhSdr9WznQs8laKkwEKslmA7dvcm8lxxtmMxU0RC6Rb0l1Vt46JmZyWYZBDRERud+RKCQAgrofeLccTJwM0OcnkuLsmxxkxk+MKo7nlhcd1h4gP615/iDs1jUEOERG5nditExftnh9nb2l0lZMgx8VFO60Ow8cVimYGOS3I5Eg1OS2Y7TnEYQbkiQO6IXl8b5ePQQxyiIioDYijghzXZGoNcXSVsyHkFqtr3VXNmSOnLn8XJxsEaicDVLegJkehUOAXg8PRLVCDN2YPa3YwRnIsPCYiIrey2QSUVtlHVjmuydQa4ugqk7Mh5K5mcqz1161qil8LamJak8kBgDUPjITJamtR4TLZMZNDRERuVW6yQIw7dL6tH1kFyDM5dWc8dr0mp3a5heZqWSanpianhUGOQqFggNNKDHKIiMitSmvmx1GrlPBx09BnacZjmw3mOpkccwtHV7VXJqe1K7BTy/HOExGRW4ldVe7K4gAOa1c5yeRYm5HJEQQBB7OKUFpplrq3XFk0s+4Q8uYELrXdVczGeAprcoiIyK0MbRLk1C7rUG8ywGbU5Oy/UIS5/9gPlVKBvz8wEoBrmZx6XVvN6CEztbImh1qPd56IiNyqLTI5YuGxxSrAZLFHGGIXUnNGV4nraFlsAr44fBWAazU5dZmsNtiaCK6MrazJodbjnSciIrcqqQly9G2RybHZpO4qcakDazMyOY7Zn5JKEwDXMjnO1J15uaH9DHI8h3eeiIjcqm1rcmoLj/1qZiFuztpVjnU8hioLANczOSvnjMCc0dHSazFT0+A5pQU6WZPjKQxyiIjIrYoq7JkSrTu7q2STAdYEOd72stLmrF3lOLdOWbU9CBO7wJrrzhHd8frs4VIGqNrcvExOS9auIvfgnSciIre5cK0ca1IvAGibmhzHwmMfsSanGd1VRlmQ07JMjkjsfmoqk1NlavnaVeQeLt/51NRUzJw5E1FRUVAoFNi8ebNs/4MPPgiFQiF7TJ06VdamqKgI8+bNg1arhV6vR3JyMsrLy2Vtjh49igkTJsDHxwfR0dFYsWJFvWvZuHEjYmNj4ePjg2HDhuGbb75x9eMQEZEb7T5zTXo+vn+o246rVtVkchxWIffzbn7hsclJkCNmh1wldj81lcm5Xm4EAIQGaFp0Hmo9l4OciooKxMXFYdWqVQ22mTp1KnJzc6XHf/7zH9n+efPm4cSJE0hJScGWLVuQmpqKRx99VNpvMBgwZcoU9OzZE+np6XjzzTexbNkyrFmzRmqzb98+zJ07F8nJyTh8+DBmzZqFWbNm4fjx465+JCIicoO80mp89GMWAOCxW/tidK9gtx1byuRYajM5taOrXCs8FutzWprJ8WlmJqegzB7khGsZ5HiKy/PkTJs2DdOmTWu0jUajQUREhNN9p06dwrZt2/DTTz9h1KhRAID33nsP06dPx1tvvYWoqCisW7cOJpMJH3/8MdRqNYYMGYKMjAy88847UjC0cuVKTJ06FYsXLwYAvPbaa0hJScH777+P1atXu/qxiIiolZ7572FcKbYP1R4YEeDWY6uk0VUCVDVBja8L3VV117sCWj66qjmZHEEQkG+oBgCEBfq06DzUem3SUbhr1y6EhYVh4MCBePzxx1FYWCjtS0tLg16vlwIcAEhMTIRSqcSBAwekNhMnToRaXbuwW1JSEjIzM1FcXCy1SUxMlJ03KSkJaWlpDV6X0WiEwWCQPYiIqPUEQcD+C0XS637dAt16fHF0lcVhgU4pk9OcwmMnXVptWZNjqLJI3WrdApnJ8RS3BzlTp07FP//5T+zYsQNvvPEGdu/ejWnTpsFqtf9lyMvLQ1hYmOw9KpUKwcHByMvLk9qEh4fL2oivm2oj7ndm+fLl0Ol00iM6OrrBtkRE1DRBsGdRrtV0zYj6dPN363kcl3Wo7a5SSdua4jyT07KfwOZkcgrK7Fkcna+329bvIte5fVmHOXPmSM+HDRuG4cOHo2/fvti1axcmT57s7tO5ZMmSJVi0aJH02mAwMNAhImqhC9fKce/f9+PhCb0xNEonbf/vo2NbtGp3Y8SupXKjBTX1vFJ3VXMmA3QW5LRlTU6+gfU4HUGbj2vr06cPQkNDce7cOQBAREQECgoKZG0sFguKioqkOp6IiAjk5+fL2oivm2rTUC0QYK8V0mq1sgcREbXMu9+fxfVyI17/9jTO5JcBAH4xOBxj+oS4/Vzd9b4YFCn/zg7ysw9Rr7uWlTPOuqvasiZHrMcJ17Iex5PaPMi5cuUKCgsLERkZCQBISEhASUkJ0tPTpTY7d+6EzWbDmDFjpDapqakwm81Sm5SUFAwcOBBBQUFSmx07dsjOlZKSgoSEhLb+SEREhNp5YADgze8yAQCDItxbiyNSKhVY9/AYLJzUD/ePicHyu4chQucLoHmjq9yZyfGvySBVmiwNthFHVrEex7NczieWl5dLWRkAyMrKQkZGBoKDgxEcHIxXX30Vs2fPRkREBM6fP4/nn38e/fr1Q1JSEgBg0KBBmDp1Kh555BGsXr0aZrMZCxcuxJw5cxAVFQUAuP/++/Hqq68iOTkZL7zwAo4fP46VK1fi3Xfflc779NNP49Zbb8Xbb7+NGTNmYMOGDTh06JBsmDkREbnf2fwymKw2KBxihCqzPeAZEaNvs/MG+6vxf0kDpdffHMsF0MzuKmeZnBbOkxNQ0xUnzrfjDDM5HYPLQc6hQ4cwadIk6bVY4zJ//nx88MEHOHr0KD799FOUlJQgKioKU6ZMwWuvvQaNpjaaXbduHRYuXIjJkydDqVRi9uzZ+Otf/yrt1+l02L59OxYsWICRI0ciNDQUS5culc2lM27cOKxfvx6vvPIKXnrpJfTv3x+bN2/G0KFDW3QjiIioaReulWPqyj0NBhZxPfTtdi1id5PZxWUdRF4tLDwO8LH/dJYbG8vk1AQ5zOR4lMtBzm233SZV0zvz3XffNXmM4OBgrF+/vtE2w4cPx549exptc8899+Cee+5p8nxEROQee88XNhjgDIrUIqQdZ/cVR1y1tPC4pTU5gTWZnIpGghyx8DiMmRyPcvvoKiIi6ryOZJfU2xau1eD5pFjc0s99yzg0h1hT05wh5M6Kk1takyNlcup0V6WczEdRhRH3jY6pzeRwdJVHMcghIqJm2XgoG5+nX5Ft81N7Yf+SyVAoWhYwtEbtyuRNd1eJE/Pd0i8Ee8/ZJ6gNa2FXUoDGPqqrrE4m55F/HgIA3BQTVJvJ4WzHHsUgh4iImnQq14AXvzgGAAj0USEsUIPz1yqwZPogjwQ4gIvdVTWB0JO398fTkwcgz1CNybFhTbzLOWeZHMcyjozsEql7jKOrPItBDhERNemrIzmw2gSM6hmETx+6GYXlJpzMNSBpSHjTb24jXi0oPFarlLgpJqhV5xVrchwLj40ONT+LPz8KAOgT6s/Zjj2MQQ4RETVp77nrAIC5N8fAX6OCv0aFmBA/j16Tt1Jcz6r5hcdqr9ZPD+dsdJWzIeqTB7UsU0Tu0+aTARIR0Y2tuMKEY1dLAQDj+7dvcXFjpJqcZnRXiYXHalXrf/b81fXnyTE6mf34zhHdW30uah0GOURE1Ki0C4UQBGBAeECHmtxOHALenMJjd2ZyAqVMTu2s/HXXsfrzXcMwtLsO5FkMcoiIyClBELDh4GU8se5nAGj3IeJNUXm50F3lxkyOOONxtdkmZYiMdebhmTigY92rropBDhEROfXz5RJpRBUA3DawY9WYSJmcJrqrbDZBmkvHLd1VDiusn8gxAKg/2WBkzbpa5FksPCYiIqdO5pRKz9+9Lw4TO1A9DlBbk1NltmLL0RxoVM5HMjl2Z7kjyFGrlBgRrUdGdgkWrPsZW58aXy+T09KJBsm9GOQQEZFTmfllAIDHbu2Lu+J7ePhq6gvx1yBcq0G+wYiF6w836z3uqMkBgI/mj8LdH+zDpcJK/Hv/JYzuFSzt+/jBUW45B7UegxwiInIqM88e5AwID/DwlTinVinxr+QxWLHtNAorTE22n9i/m9vmrQkJ0ODu+B549/szuFpSjbiabNGgSC1uj/Xc3EEkxyCHiIjq2X3mGn66WAwAGBAe6OGradiA8EB8OH+0R84d5G9f3qGk0iQNIXdHdxi5D/80iIiong/3XAAAxEYEYnCk1sNX0zHp/dQAgKIKk1STo2GQ06HwT4OIiOq5XFQJAFh2xxAoWUTrVJCfmMkxS/PkMMjpWPinQUTURV24Vo4dp/LrbbdYbbhaXAUA6OnhpRs6sqCaTE5xpUkaQt7QCC/yDAY5RERd1OwP9iH500PYlVkAAKg2W7ErswDZxVWw2ASoVUqEB3acGY47miB/e5BTUmlGtZmZnI6IhcdERF1QdlEliivtyxJ8mZGD2waG4ZO9F/HGttOI1NkDm+ggX3ZVNULsrjJZbdK9ZJDTsfBPg4ioC9p3/rr0fP+FQgDAezvPAgByS6sBAL1C/Nv/wm4gvt5eUlCTb7DfM403f1Y7Ev5pEBF1MYIg4D8Hs6XXuaXVMFSb0TtUHtRMHRrR3pd2Q1EoFFJdjhgYumuyQXIP/mkQEXUxGdklyMgugY9D1uFyYaX0Qw0A3QI1mBkX5YnLu6FE6u1de+IaVho3TTZI7sGaHCKiLuZkrv0HOaFPCAzVFqRfKsbJHAOKamYN/mrhLegWqHHb7MCd2ehewTh8uQTXy40AWJPT0fBPg4iok7PZBPxr/yW88PlR7Dt3HReuVQAA+nQLQM9g+xDxPefsNTo6X28M76HnKtrNNKZ3sOw1g5yOhZkcIqJO7tO0i3j165MAgK3HcjG8hw4A0KebP6752H8Gvj6SAwAYFNlxl3DoiMb0CZG9ttoaaEgewZCTiKiT+/Fs7UiqcqMF+87bR1P1CQ1An27yxTdfmBrbrtd2owvQqHDm/02TXmfmGzx4NVQXgxwiok7ubEE5APsK2Y76hQVgoMPim6EBasTHBLXrtXUGapUS8TF6AMC0oZGevRiSYXcVEVEnVmWyIrvYvg7VH2YOxpw1+wEAt8eGoVugBvqaCe0Aez0Otcy/ksfgVK4BIxkkdijM5BARdWJn8ssgCPbZecf0DsZb98Th5l7BWDZzCADA22FeF46markAjQqjewVzhugOhpkcIqJORhAEfLz3Ii4XVuDb43kAgPiYICgUCvxqZA/8amQPWfunJvfH+zvP4rVZQz1xuURthkEOEVEn892JfLy25aT0OjRAjVfvGNJg+2cm98fvJvaBv4Y/CdS58G80EdENzmoToACkrpK/p56X9kVofbDtmQnQ1yw/4IxSqWCAQ50S/1YTEd3ACsqqMX3ljxgUGYjk8b2RmVeGw5dLAACzRkThiUn9Gg1wiDozlwuPU1NTMXPmTERFRUGhUGDz5s0Ntn3sscegUCjwl7/8Rba9qKgI8+bNg1arhV6vR3JyMsrLy2Vtjh49igkTJsDHxwfR0dFYsWJFveNv3LgRsbGx8PHxwbBhw/DNN9+4+nGIiG5Yhmozfv3hAVwvN2LP2et48JOfsPzb0wCAiQO64S9z4jEgnJP7UdflcpBTUVGBuLg4rFq1qtF2mzZtwv79+xEVVX+Bt3nz5uHEiRNISUnBli1bkJqaikcffVTabzAYMGXKFPTs2RPp6el48803sWzZMqxZs0Zqs2/fPsydOxfJyck4fPgwZs2ahVmzZuH48eOufiQiohvS299l4kx+eb3tKqUCvxnb0wNXRNSxKARBEFr8ZoUCmzZtwqxZs2Tbr169ijFjxuC7777DjBkz8Mwzz+CZZ54BAJw6dQqDBw/GTz/9hFGjRgEAtm3bhunTp+PKlSuIiorCBx98gJdffhl5eXlQq+1p1hdffBGbN2/G6dP2f6Xcd999qKiowJYtW6Tzjh07FiNGjMDq1aubdf0GgwE6nQ6lpaXQarVNv4GIqANJejcVmfllAIC+3fyRXVSFP945BElDIhDkzy4q6rya+/vt9nlybDYbHnjgASxevBhDhtSv5k9LS4Ner5cCHABITEyEUqnEgQMHpDYTJ06UAhwASEpKQmZmJoqLi6U2iYmJsmMnJSUhLS2twWszGo0wGAyyBxHRjajcaMGZAnuAc/ClyUh59lbsf2ky5twcwwCHqIbbg5w33ngDKpUKTz31lNP9eXl5CAsLk21TqVQIDg5GXl6e1CY8PFzWRnzdVBtxvzPLly+HTqeTHtHR0a59OCKiDuLYlVIIAhCl80GY1gdKpQLBDG6IZNwa5KSnp2PlypVYu3YtFIqON+vjkiVLUFpaKj2ys7M9fUlERC3y47lrAIBRvYI9fCVEHZdbg5w9e/agoKAAMTExUKlUUKlUuHTpEp577jn06tULABAREYGCggLZ+ywWC4qKihARESG1yc/Pl7URXzfVRtzvjEajgVarlT2IiG5EO0/bg5xJsd08fCVEHZdbg5wHHngAR48eRUZGhvSIiorC4sWL8d133wEAEhISUFJSgvT0dOl9O3fuhM1mw5gxY6Q2qampMJvNUpuUlBQMHDgQQUFBUpsdO3bIzp+SkoKEhAR3fiQiolbJLa3Cq1+fwP4LhSg3WrDv3HXklla16Fhmqw3PbDiMu/+2F6dyDfBSKnDrgLCm30jURbk8GWB5eTnOnTsnvc7KykJGRgaCg4MRExODkJAQWXtvb29ERERg4MCBAIBBgwZh6tSpeOSRR7B69WqYzWYsXLgQc+bMkYab33///Xj11VeRnJyMF154AcePH8fKlSvx7rvvSsd9+umnceutt+Ltt9/GjBkzsGHDBhw6dEg2zJyIqDnEQaZt0c3+p62nsOVoLj7Ze1Ha5q/2wo8v3O5SgXC50YL/t+UkNmfkSNt+N7EP63CIGuFyJufQoUOIj49HfHw8AGDRokWIj4/H0qVLm32MdevWITY2FpMnT8b06dMxfvx4WXCi0+mwfft2ZGVlYeTIkXjuueewdOlS2Vw648aNw/r167FmzRrExcXh888/x+bNmzF0KBeYI6LmK64wYdzrO/HIPw/BamvxjBpOVRgt+P5Ufv3tJivSLhQ2+zifp1/B0D98hw0/yesIn7y9f6uvkagza9U8OTc6zpND1LXtOJWP5E8PSa+XTIvF727t67bj7zydj4fWHpJtu3VAN+w+cw1xPXT44olb4KVsPHtUXGFC/Gsp9bY/mzgATycyyKGuyWPz5BAReVra+UIsWPczCsqqAQAmiw1/330e/7fxCK6XG6V2jgEOALz/wzmUVprhLpl59tmIZ8ZF4ZUZg/DOvXG4f0wMAODIlVL8PfU8zFZbo8e4XFRZb9sLU2Px1OR+brtOos6KC3QSUacz9x/7AQCVJgs++e3N2HT4irSmk9bHG0tnDnYazJRVW/DjueuYMTzSLddxpmY24tiIQDw8oQ8Ae/FwWKAGBWVGrNiWia1Hc/G/x8fBx9vL6TGultQWKQf6qGC1CZh9U/cOOU0HUUfDTA4RdVp7zl4HAOw8XTttxeaMqzBbbdifJa+J0ft5AwCultTPnLhKEATsOXsNmw5fBQD0DwuQ9nl7KbHiV8Ol1ydyDFj65XEcyS5xeqwrxfbruSMuCnuen4TvF92KMK1Pq6+RqCtgkENEnZbFJqDabMXec7UBTVGFCSdzDDiRU7usy5jewZh9Uw8AQE5JdavOKQgCnvzPYTzw0UFpW2yEvGagb7cA2evPDl3Bnav2osAgP3eVyYrVuy8AALoH+ULvp0aU3rdV10fUlbC7iog6HaUCEAdKfbjnAsqNFkTqfNArxB9pFwpx56q9EHt7fv/LwUge3xv/3n8JAHCluGVz2IjOXyvHlqO5AIBfDA7H6F5BiAnxk7Xp3kCgcrGwUpalWXfgEooqTI2+h4gaxiCHiDodby8ljBZ7Qe9b288AAJ6a3B/nC8qlodviuNLYiEAAtUFETknrgpzcUns2pl9YAP7xm1FO2yiVCgRqVCgzWmTbHYuiAeBkbm22aVh3Xauui6grYncVEXUq1WarFOCIvJQKzIyLQs86GRUAGCgGOUH2IOdqK4OcfIM9UInUNV43s/WpCfjkwdGYOqR2KZr8Ot1VBTXHenh8b8RF61t1XURdEYMcIupUDFX1R03FR+sRoFHh9kHhUDnMSxPoo0JogAYApFqX0iozyutkWFwhBirhTRQHx4T4YVJsGN741XD07eZf814jthzNwY6aCQTFrNLkQeEtvh6iroxBDhF1KqVOgpykmmxJd70v0n//CyT0sS8/8+69I6Q2ARoVdL72EVat6bIqkIIcTbPa63y9cc+oaADAqVwDFq4/jORPD6G4wiRllViPQ9QyrMkhohtalcmKi4UVGBRpH8EkBjnB/mr0DvVHXA89HhrfW2qv8/XGB7++CTkl1RgcJR/1FKX3RWmVGVdLqjAgPLBF1yN2V0W4MMxbbHvkSom07cuMqzBabFAogIgmur6IyDkGOUR0w/oy4ype23IS18tN+PA3o5A4OFwKcrrrffG/x8c5fZ/eTw29X/2FLbvrfXEq14CrrRhhlV8zy7Irc9mE1WR9ShwmKFx34LJ9X6AGahWT7kQtwf9ziOiGdKmwAk9vyMD1cvsQ67/uPAugNpMjdj25orveHpiI3VWXCyvxefoV2FxYuDO/tHk1OY6crSR+tsC+JES/sIB6+4ioeZjJIaIbUt1J+8SFLsUApVtg82piHInFx6fz7MsxzF69D9fKjKgyWfBAQq8m32+zCSgos3dXNbcmB2g8IBsUwcWDiVqKmRwiuiGJi2+KsovswU1rMiADaoaT7zxdgAMXCnGtJmBZd+Ay9p2/DovDYpqVJguMFqv0+vy1cmw5lguLTYBCAWnUVnPofetnckRirRERuY6ZHCK6IeWVyoOc6+VGFFWYcDbfHuS0pHD4tgHdMDhSi5O5Bhy6VCxtP51Xhvv/cQDPJPZHWKAPXv36BIwWG/zUXvj4wdEY3SsY9/09Teo6C/HXwNur+f+G9PFWQq1SwmSpvyJ5bGTLCqCJiEEOEd1gzhWUodpsQ17NUO3EQeE4mFUIQ7UFV4urcP6aPcjp34JMjkKhwJg+wTiZa0Clqf5cOZ/uu4hih+LgSpMVe85eQ59QfynAAezFwq6eV+/rLXV1Oeod6u/SsYioFoMcIrphZBdV4o7398JosSHQx/71dUu/EOSUVOFkrgHpl4pgtNigUSkRHVx/duPm8PX2AgCUV9cPcny8vQDI5+GpMFrrBSfOAqSm6P2cBzl+an5NE7UUa3KI6IaxcsdZVJqssNoEabh1hNZHGoK997x9Xaq+3QKkQmRXiUGOON+NI42TodyVJku9+qDcUtdXMmcwQ+R+DHKI6IZxIsdQb1uk3hfdaop89527DgDoH97yYde+6pogp6x+oFJhsjrdVlAnIHry9n4un9dQXX+mZh9vfkUTtQb/6UBEMl9mXEW3QA3G9Q319KXICIKAK0WV9bb3CwuQMjliENKSehyRj5jJcZKNcbZkRIXRInUzzRoRhXtHR2NUz2CXz1tUYaq3rbFRV0TUNP4zgYgkR7JL8PSGDNz/jwMuTYDXHgxVFpQ5WTgzQKNCWKB84r1+YS0fkSR2V+UZ6gc5jqOfbh3QDQBQabRK3VXRwX4Y1ze0RTMUO3auLf3lYKhVSvxlzgiXj0NEtRjkEJHEcdh0TmnLlzZoC9nF9ixOaED97IbjaKbhPXS4bWC3Fp9H7K5qLMb7xeBw/PaWXgCACpNF6q5ydVSVo7/MiYfezxsfzLsJD43vjROvJmFszUKiRNQy7K4iIgBAbmkVXttyUnp9rqAcPYJaNkKpLVypCXJ6BPnhtoFh+Dz9Cn6T0BMAcFPPIGh9VBjdKxh/+/VN0Ki8WnweMchpTLdADfw19q/PzLwyqdC4RwtHdAH2zNDh3/8CCoU9p+PKPDtE5ByDHCICAPx99wXZ63MF5bhtYJiHrqa+r4/mArDPG7PsjiGYHBsmXV+41gc///4X8FIqpCChpcTuqsaEBmjgVxMMWWyCVE/T2iUYWnvtRCTHfyoQEQDgYmGF7LU4qV5HcK6gDFuP5sJLqUDy+N4I0KgwbVikLOui8lK6JUioG+R88tvRmBwrD/ZCA9TwdzLk25X1qoio7THIISIAtQtb3hEXBQC4WuL6XC/NZbba8PGPWTibX9as9nvO2oeGj+sbgqHddW12XYC8u+qmGD0mDQzDkumDZG1C/Gu7qxwxE0PUsTDIISIIgoCrxfYgZ0S0HgCkxSnbwufpV/DHLSfxi3dTm2x7rqAMr35trxVqj2HtjpkccSXzunU6IQFq+Gvk29781fA2vzYicg1rcoi6sJST+QgL1KBniJ80x8yIGD0A4JqTyfDc5djVUum5xWqDqpEi249+zJKeT4pt+aip5vJxCHJCaiYZ9KvThRUaoJYFQ3NvjsE9o6Lb/NqIyDXM5BB1UcevluKRfx7Cnav24kpNFic0QI3omhFVhRUmWKz1V8Vuisliw5+/OYVF/81ocK4dxwDhTH7jtT8XrtlrhX49NgaxrSzsbQ7HrI24Pla9TI6/RtY1pfP1bvPrIiLXMcgh6qIOX66dE2f/BfuaT931vgjxV8NLqYAgQLaydnNUm614aO1PWJN6AV8cvoqzBc4DGMeFKH+6WNToMbNrZjm++6YeLl1LSzkGYIE1dTd116yqG9SE+HNmYqKOiEEOURf0zbFc/P7LE9Lr7SfzAQBRel8olQppwr3MZhYGA/a6nk2Hr+LHmvWjAKCw3HldT77DbMIf7DqPanP9NaEAwGixIrembc9WzEHjCseFPcXi4roFxcqaNvePiUGPIF/cO5pdVUQdEWtyiLoYQRBkk/4BwMEsezalu94XgH2phHwYMf/jgzj1x6lNTpC383Q+nv5PRr1lFxZ/fhRGixVfPH4LYkJqg5QChyAnz1CNA1lF0jIJjrKLqiAIgL/aC8EeyJYEOBlBNdsho/Tnu4ZBEASOqiLqoFzO5KSmpmLmzJmIioqCQqHA5s2bZfuXLVuG2NhY+Pv7IygoCImJiThw4ICsTVFREebNmwetVgu9Xo/k5GSUl8vT2kePHsWECRPg4+OD6OhorFixot61bNy4EbGxsfDx8cGwYcPwzTffuPpxiLqcU7m1M/TW1T3IHuQMcximfamowmlbRx//eFEW4GhralmullTherkJK747Le0TBEFaF+rmXvaFLOd/fBCf/ZRd77hZ1+3njgnxb9dA4s4RUYgO9sX0YZHStsVJA3HbwG5YdsdgWVsGOEQdl8tBTkVFBeLi4rBq1Sqn+wcMGID3338fx44dw48//ohevXphypQpuHbtmtRm3rx5OHHiBFJSUrBlyxakpqbi0UcflfYbDAZMmTIFPXv2RHp6Ot58800sW7YMa9askdrs27cPc+fORXJyMg4fPoxZs2Zh1qxZOH78uKsfiahLOXTJnrW5bWA3rHt4jGyfmMlZdscQaZs4f05jHFfnVquUSBwULtt/xqHbq7TKjGqzvaD5l3G1QcTz/zuKd1LOyN6XkW2vGxoa1fYFx45WzonH7v+bJJsLZ8Gkflj725sR6MMiY6IbhcvdVdOmTcO0adMa3H///ffLXr/zzjv46KOPcPToUUyePBmnTp3Ctm3b8NNPP2HUqFEAgPfeew/Tp0/HW2+9haioKKxbtw4mkwkff/wx1Go1hgwZgoyMDLzzzjtSMLRy5UpMnToVixcvBgC89tprSElJwfvvv4/Vq1e7+rGIuoxTufaAY0iUFn27Bcj2RdUEOXo/NRIHheP7U/nIaWJSQJtNkGZHfuzWvhjfLxQHswplbc7kl6PAUI27P9gnrdAdFqjBLwaH409bT8FYs7r3X3ecxcMTekNbE0j8fKkEADCyZ1ArPnHLKJXM0BDd6Nq08NhkMmHNmjXQ6XSIi4sDAKSlpUGv10sBDgAkJiZCqVRK3VppaWmYOHEi1OraPvikpCRkZmaiuLhYapOYmCg7X1JSEtLS0hq8HqPRCIPBIHsQdTWncu1/7wdFaustQxDtUNwbpfcBYF+4s65qsxUnckqx4eBlfH00B5UmK7y9FHhuygCM7x/qtH7mi8NXcaW4ShoS3jPED5E6X+x5YRL2vXi71K6kwp4VstkEHLlSAsC+ACcRkavapPB4y5YtmDNnDiorKxEZGYmUlBSEhtpnKs3Ly0NYmHwdGJVKheDgYOTl5UltevfuLWsTHh4u7QsKCkJeXp60zbGNeAxnli9fjldffbXVn4/oRmW1CcjMs2dyYiO0snqS3qH+sqHRYlYnM68MgiDgQFYRhvfQwU+twsL1h/H9qXzZseNjgqSVs8VJ9BydrzOcPCbYHwAQFmgPpiJ1PsgtrUZJlQkx8EOZ0YLKmgkKe4X4t+pzE1HX1CaZnEmTJiEjIwP79u3D1KlTce+996KgoKAtTuWSJUuWoLS0VHpkZ9cvdCTqzC4XVaLKbIVGpUSvmtFOb90Th/gYPdb+drSsrRjkfH+qAA9/eghz1uzHU//JgMVqQ+rZa7K2YYEa/OW+EdJrx3llRveyZ2GOXimVvSemzpBwMcAS63tKK+3/9fX2krq4iIhc0SbfHP7+/ujXrx/Gjh2Ljz76CCqVCh999BEAICIiol7AY7FYUFRUhIiICKlNfr78X4ni66baiPud0Wg00Gq1sgdRVyJ2VQ2MCJSWUvjVyB7Y9MQt6FknWyIGJwCw47T9/9nvT+Vj7/lCmCw2+Ku9sHLOCMTH6PGv5DFSUAQAEwd0Q0KfEDw1uT8GhAcCqD/nTnSwr+y1GOSU1AQ3YrDD2YSJqKXa5Z9HNpsNRqN9UrCEhASUlJQgPT1d2r9z507YbDaMGTNGapOamgqzuXbERkpKCgYOHIigoCCpzY4dO2TnSUlJQUJCQlt/HKIb1umaICc2IrDJtpE6X+xfMrne9vkfHwQADOmuw50jumPTE7dgYJ3j+Xh74T+PjsWiXwyoNxopPkaPe0f1kA3PBgC9X02QU8Ugh4jcw+Ugp7y8HBkZGcjIyAAAZGVlISMjA5cvX0ZFRQVeeukl7N+/H5cuXUJ6ejoeeughXL16Fffccw8AYNCgQZg6dSoeeeQRHDx4EHv37sXChQsxZ84cREVFAbCP0FKr1UhOTsaJEyfw3//+FytXrsSiRYuk63j66aexbds2vP322zh9+jSWLVuGQ4cOYeHChW64LUSdU0ZNl9GgyOZlMSN0PpgcG+Z0X3zNauVNiY+Rt5szOhorfhUnWwgTqA1mDAxyiMhNXA5yDh06hPj4eMTHxwMAFi1ahPj4eCxduhReXl44ffo0Zs+ejQEDBmDmzJkoLCzEnj17MGRI7bwb69atQ2xsLCZPnozp06dj/PjxsjlwdDodtm/fjqysLIwcORLPPfccli5dKptLZ9y4cVi/fj3WrFmDuLg4fP7559i8eTOGDh3amvtB1GmdKyjHnppamvH9Qpv9vrfuicPNvYNxd3x3dNf7QqGwL5b5u1v7Nuv9vxgUjt8k9JRehzopSgbsw9YBoKTSvl6WFOT4McghopZxeXTVbbfdBkFwvrIwAHzxxRdNHiM4OBjr169vtM3w4cOxZ8+eRtvcc889UoaIiBq39WguBAG4PTYM/cOb7q4SBfmr8dnv7N3AJZUmmCw2hGl9mv1+pVKBl6YPwj/TLgEANCrnS0SwJoeI3I1rVxF1MlUmKypNlnrDuMVZhxP6hLT42GK2xVU+3l54YGxPHM8pxejezue8qTu6qqTKJNtOROQqBjlEnczsD/bhbEEZ9i+ZLAt0xNFNA5pRdNwWXpvVeFdyUE0AJa6rZWAmh4haiZNPEHUiVSYrTuYaYLYK2HvevrRCudGCL36+gnM1k/ENdKGrqj2N7BkEpQI4drUUF66Vs7uKiFqNQQ5RJyKu2g0A5dX2VcFf/N9RLPrsCAD76uB1l3LoKCJ0Ppg4oBsA4NvjeQxyiKjVGOQQdSIXrtcunZBdXIm084XYcjRX2nZ7bJhsKYeO5ubewQDs9UMMcoiotViTQ9SJiItfAvYh4/85eFm2/4GEXu18Ra7pH2bvSjubX44yoz3I0TLIIaIWYpBD1IlcdOiuSj1zDUaLDQoFsPmJW1BWbcHIDr6ad/+wAADA+Wvl0mKfes6TQ0QtxCCHqBPJKa2SnhstNgDAiGg94po5O7GnRQf7Qa1SwmixSdfP7ioiainW5BB1IvkGY71tfbsFeOBKWsZLqZBWRxcxyCGilmKQQ9RJCIKA3JpMjuN6U326+Tf0lg4pOqg2yPFTe0ndVkREruK3B1EnYaiyoNps7+J5ecYgqJT2UVTDuus8eVku6xHkKz1nFoeIWoM1OUSdRK7BnsUJ9lejT7cA/PjC7ThypcSlxTg7gujg2kwOgxwiag0GOUSdhLgcQnjN4pkROh9E6CI8eUkt4pjJ4fBxImoNdlcRdRJn8uxrU/UM9muiZcfWK7S2hkjNehwiagV+gxB1EumXigEAN/XUe/ZCWmlgeCBmDIsEAMRF31j1RETUsbC7iqgTEARBCnI6+oR/TVEoFHj//ng8U9AfvUNvrJFhRNSxMMgh6gQuFVaisMIEtZcSQ2+w0VTOKBQK9O+gq6UT0Y2D3VVELhIEARnZJSirNnv0OjLzyvDWd5m4VmaUsjjDeuigUXl59LqIiDoKZnKIXPT9qQI88s9DGBKlxdanJnjkGq6VGTHvw/24Xm7CnrPXMDDCnvUYdYN3VRERuRODHCIXfXUkBwBwIsfgsWvYcjQH18tNAIAjV0px5EopgBu/HoeIyJ3YXUXkogBNbXeQIAgeuYajNUGNo0CNChMHdPPA1RARdUwMcohc5K+uTYAaqiweuYYjV0oAAM8mDpC2/TIuCj7erMchIhKxu4rIRSarTXp+taQKOr/2nZW33GjBhWsVAIBfj43BqF5BuFpchanDbrzZjYmI2hKDHCIXGapqR1XlllZhcJS2Xc+fW2Jfo0rn642QAA1u6adp1/MTEd0o2F1F5CJDdW0XVU5NwNGe8g1GAEC4lsENEVFjGOQQucgxk3OtzNju5883yBfiJCIi5xjkELmozCGTU1hhavfz55fZg5ywQAY5RESNYZBD5CKDw0zHRR4IcgrYXUVE1CwMcohccPF6BXJLq6XX3x7Pw6XCijY/ryAIKK20B1fHr9rnyGF3FRFR4zi6isgFT284XG/bbW/tQtbyGag2W7Fyx1nkl1Zjxa+GQ+Xlvn9D/HXHObz7/RloVEoYLfYh7MzkEBE1jpkcomYqrjBJyyc4Eic9fmPbaXyw6zy+OHwVp3LL3Hrud78/AwBSgDOmdzAS+oS69RxERJ0NgxyiZtp7/joAQKEANjw6VravrNqMTYevSq8rTG03E/KjE/vgv79LaPdJCImIbjQuBzmpqamYOXMmoqKioFAosHnzZmmf2WzGCy+8gGHDhsHf3x9RUVH4zW9+g5ycHNkxioqKMG/ePGi1Wuj1eiQnJ6O8vFzW5ujRo5gwYQJ8fHwQHR2NFStW1LuWjRs3IjY2Fj4+Phg2bBi++eYbVz8OUT3fncjDh3suwGqTr0t1smZBznljYuothPm/9CsoqawtSK4yW916TQPCA6Tns0Z0d+uxiYg6K5eDnIqKCsTFxWHVqlX19lVWVuLnn3/G73//e/z888/44osvkJmZiTvuuEPWbt68eThx4gRSUlKwZcsWpKam4tFHH5X2GwwGTJkyBT179kR6ejrefPNNLFu2DGvWrJHa7Nu3D3PnzkVycjIOHz6MWbNmYdasWTh+/LirH4lIYrLY8Lt/peP/bT2Fvi99gz9tPQlbTbBTUDMnTqTOF9516m2Wf3ta9rra5N4gx1TTTbVwUr92n2GZiOhG5XLh8bRp0zBt2jSn+3Q6HVJSUmTb3n//fdx88824fPkyYmJicOrUKWzbtg0//fQTRo0aBQB47733MH36dLz11luIiorCunXrYDKZ8PHHH0OtVmPIkCHIyMjAO++8IwVDK1euxNSpU7F48WIAwGuvvYaUlBS8//77WL16tasfiwgAcDrPIHv9jz1Z6B0agPvHxEhBTligveD39buH4cUvjgGw18qovZToFxaAk7kGt2dyyo32400fFunW4xIRdWZtXpNTWloKhUIBvV4PAEhLS4Ner5cCHABITEyEUqnEgQMHpDYTJ06EWq2W2iQlJSEzMxPFxcVSm8TERNm5kpKSkJaW1uC1GI1GGAwG2YPI0eHLJdLzGcPtAcU7KWdgswkoqJlpOKxm6Pacm2MwyqHbakL/UPQI8gXg/u6qCqO9xidAwwGRRETN1aZBTnV1NV544QXMnTsXWq09xZ6Xl4ewsDBZO5VKheDgYOTl5UltwsPDZW3E1021Efc7s3z5cuh0OukRHR3dug9Inc7O0wUAgGcS++Ode+MAANfLjSiqNElLOHQLqB26rfdzCMSHRsBX7QUAqHJjd5XVJkhBk7/Gy23HJSLq7NosyDGbzbj33nshCAI++OCDtjqNS5YsWYLS0lLpkZ2d7elLog7k0MUi7D5zDSqlAnfERUGj8kJoTUBzpbhKWsIhzGF+Gm8vhfR8fL9Q+LVBkFNurB2p5c9MDhFRs7XJN6YY4Fy6dAk7d+6UsjgAEBERgYKCAll7i8WCoqIiRERESG3y8/NlbcTXTbUR9zuj0Wig0XACNXLux3P2IeLTh0WiTzf7aKYInQbXy43IuGzvJlUpFQh2yN6cv1Y7KjBK7wsf75ogxw3dVYXlRmh9vaWuKm8vBTQqzvpARNRcbv/GFAOcs2fP4vvvv0dISIhsf0JCAkpKSpCeni5t27lzJ2w2G8aMGSO1SU1NhdlcOyQ3JSUFAwcORFBQkNRmx44dsmOnpKQgISHB3R+JuohTufYarbhovbQtoqb+ZtnXJwHYi46VytrszbShkbL3+LopyDlXUIab/7wDC9b9LAU5/hoVFApFE+8kIiKRy0FOeXk5MjIykJGRAQDIyspCRkYGLl++DLPZjF/96lc4dOgQ1q1bB6vViry8POTl5cFksqf6Bw0ahKlTp+KRRx7BwYMHsXfvXixcuBBz5sxBVFQUAOD++++HWq1GcnIyTpw4gf/+979YuXIlFi1aJF3H008/jW3btuHtt9/G6dOnsWzZMhw6dAgLFy50w22hrsZmE/DD6WsAgMGRtZnHuutDPZM4QPb6sVv74p1747D2wdEAaoOc6lYGOSt3nIPVJmD7yXypu8pfza4qIiJXuBzkHDp0CPHx8YiPjwcALFq0CPHx8Vi6dCmuXr2Kr776CleuXMGIESMQGRkpPfbt2ycdY926dYiNjcXkyZMxffp0jB8/XjYHjk6nw/bt25GVlYWRI0fiueeew9KlS2Vz6YwbNw7r16/HmjVrEBcXh88//xybN2/G0KFDW3M/qIt6csNhmKz2uWgcg5xIXW2Q013vi3tHy4vVfdVeuPumHgjyV0uvgdbX5GQ6DGWvqBk+zpFVRESucflb87bbboMgCA3ub2yfKDg4GOvXr2+0zfDhw7Fnz55G29xzzz245557mjwfUWOqzVaknLTXd/1yeKRsuYQova/0vF9YQL331uWOmhxBEHD+Wu3K5gVl9qHrHFlFROQaVjFSl5d+qRgmiw3hWg3emxsv2zd5UO00BbERgU0eq7Ymx9bi67lWZpQtKXGpsBIAR1YREbmKQQ51aUaLFa9+fQIAkNAnpF5hr87XG58/loCZcVFIHt+7yePVDiFv+QKdF2uCGlFGdgmA2iJoIiJqHv7TkLq0fecKcSbfPgz8d7f2ddpmVK9gjOoV3Kzj+ahb3111qbBC9vpAViEAYEB405kkIiKqxUwOdWkXawKKpCHhGBTZ+oUvxe6qzLwyaWFPV124Lg9yqmu6vvqHN10TREREtRjkUJcm1rv0CvF3y/HEIMdsFfCXHWddfn/W9Qp8sOu80339mckhInIJgxzq0sSuoZ5uCnIch5z/fKnY5fe/t9MeGIUFajD7ph7S9mB/NaJ0rMkhInIFgxzq0i4V2TM5PUP83HK8MK0Pls0cDADIKa1y6b2GajO2HM0FAKx+YCTmj+sp7bv/5hjOdkxE5CIGOdRlpV8qQlZN/Uvfbu6rdxGHnV8prnKpLufYlVKYLDb0CPJFfLQew3vo8ftfDsakgd3w8ISmR3YREZEcR1dRl/XxjxchCMDdN3VHhBu7giJ0PlAqAJPFhuvlRoQ1c+j3saulAIDhPXRS1iZ5fO9mDV0nIqL6mMmhLutKib07aeqQhleubwlvLyUidfaZkrOLm99ldbwmyBnaXefW6yEi6qoY5FCXVWCwL5dQdxFOd+geZA9yrhRXNtGylhjkDGOQQ0TkFgxyqEvacSofuaVtF+REB9kLma80M5NjqDZLMx0PjWKQQ0TkDgxyqMspMFQj+dND0uvQALXbz9FDyuRUQRAE/OX7M/gy42qD7U9cta863l3vK61oTkRErcPCY+py8mq6qUQqL/fH+j0cuquOXS3FX763z3/zy+FR8FLWHwrOrioiIvdjJoe6nMIKU5ufo0dNd9XV4ioUV5ql7U9tOIwqU/11rS7XzNfDpRuIiNyHQQ51OYXltUFOkJ93m5xDyuSUVKGw3Cht33o0F3/ZcUZ6nV1UifUHLuNamb1NMLuqiIjcht1V1GWUVpnx208OSlkTAPj3w2Pa5FyROh94eylgsthw9EqpbN8XP1/Fi1NjoVAo8PSGw/j5com0j0EOEZH7MJNDXcbavRfx8+USXK/J5DwyoTeGtNFIJpWXUppFec/Za7J918qMKKrpMnMMcABA78cgh4jIXRjkUJeRUyIfzh0SoGnT8w2MsK8afv6afemI7npfaV+50QIACNDIk6nBDHKIiNyGQQ51GcWV8oLjkDbuGoqN0MpePzdlALoF2gOrCqO9+Nhis8na6NuoRoiIqCtikENdxrmCctnr0DbO5PTp5i973S1QI2VuiitNuP2tXag2y4Mc1uQQEbkPgxzqEqpMVlwsrJBtGxKlbaC1e9TtigryU8NP7QUA2Hf+Oi5cr6j3HnE/ERG1HoMc6vQEQcDJ3FLYhNptapWy2auDt5RvnYDFV+0Ff7U98Mkucr7cg7j6OBERtR6HkFOnZrRYMe0ve6SsSe9QfwztrsMzif3b/Ny+3l71Xvtr7Nu+OpLT5ucnIurqGORQp5ZTUi3rFrojLgrP/mJAu5y7bpDjp/aCn8b5/3KvzBiEUb2C2+OyiIi6DAY51KmZLLWFvaEBGkwdGtFu567bXeXj7YUAdf3/5V6ZMQgPT+jTXpdFRNRlMMihTs1stQc5EVof7H9pcrue26dOJkejUsJPI9+2bOZgPHhL7/a8LCKiLoOFx9SpGWsyOWpV+/9VrztSSqFQSIXHosTB4e15SUREXQqDHOrwjBYrHlr7ExZvPIKSStdWEBe7q7y92n/UkrdX/f+9HDM5XzwxTlqtnIiI3I/dVdTh/ZRVjJ2nCwAAVWYr3r//JhiqzXjgo4OwWG34f7OGIj4myOl7xe4qtapjzD8jOAxjHxzZtvP0EBF1dczkUId3KtcgPd96LBc/ZBbg5U3HcSS7BCdyDPh478UG32vyYHeVM1Umq/S8bs0OERG5FzM55DFn88tQUmXG6CaGTp90CHIEAfjtJz/J9ueWOJ9YD3DI5Higu8qZSocgh4iI2pbL/7xNTU3FzJkzERUVBYVCgc2bN8v2f/HFF5gyZQpCQkKgUCiQkZFR7xjV1dVYsGABQkJCEBAQgNmzZyM/P1/W5vLly5gxYwb8/PwQFhaGxYsXw2KxyNrs2rULN910EzQaDfr164e1a9e6+nHIQyxWG+762z7cszoNJ3MM9fbnllbhox+z8Hn6FWw9lgsAWDlnBPqHBUhttD72GD3PUN3geUzWjpXJmTc2BgAwhQXHRERtzuVv/oqKCsTFxWHVqlUN7h8/fjzeeOONBo/x7LPP4uuvv8bGjRuxe/du5OTk4O6775b2W61WzJgxAyaTCfv27cOnn36KtWvXYunSpVKbrKwszJgxA5MmTUJGRgaeeeYZPPzww/juu+9c/UjkARnZJSg32oPWuf/Yj4IyeaDy7H8z8NqWk/i/jUdgstgQ7K/GbQPD8PrsYVB7KTFjeCS+fWYiAKDAYITNcc0GB7WFxx0jyOnbLQBHlk7B6l+P9PSlEBF1ei53V02bNg3Tpk1rcP8DDzwAALh48aLT/aWlpfjoo4+wfv163H777QCATz75BIMGDcL+/fsxduxYbN++HSdPnsT333+P8PBwjBgxAq+99hpeeOEFLFu2DGq1GqtXr0bv3r3x9ttvAwAGDRqEH3/8Ee+++y6SkpJc/VjUjkqrzHh6Q4bs9Zy/78emBbdA5+uNcqMFhy4Wy97zzr1x0Pl6Y2TPYPz0ciL8NV4QACgU9mxNUaXJ6ariUiangwQ5AKDz8/b0JRARdQnt/s2fnp4Os9mMxMREaVtsbCxiYmKQlpYGAEhLS8OwYcMQHl6b0k9KSoLBYMCJEyekNo7HENuIx3DGaDTCYDDIHtT+vjqSg6s1dTTxMXr4q71w4XoF3t6eCUEQ8MqmY7DUycyM7xcqPdf5eUPlpYS3lxIh/vbAJq/UeZeVlMnpIN1VRETUftr9mz8vLw9qtRp6vV62PTw8HHl5eVIbxwBH3C/ua6yNwWBAVZXzQtTly5dDp9NJj+joaHd8JHLR8SulAIAZwyOx6Ylb8I/5owAA/95/Ce/vPIfNGfbFK0f3CoKf2gu/u7UPVA1kYiJ09iAnv4G6HLHwWNOBMjlERNQ+utQ3/5IlS1BaWio9srOzPX1JXdLxHHuQM3N4JABgXN9Q/HJ4JGwC8HbKGQDA0O5a/P2BUTj5x6lYMm1Qg8eK0PoCaLj4uKPU5Cg6xuAuIqIupd2/+SMiImAymVBSUiLbnp+fj4iICKlN3dFW4uum2mi1Wvj6+jo9t0ajgVarlT2ofRktVpzJLwMADInSSdtfniEPZD6aPxrB/uomjydlchrqrrLau708NboqaYg92/jguF4eOT8RUVfW7t/8I0eOhLe3N3bs2CFty8zMxOXLl5GQkAAASEhIwLFjx1BQUCC1SUlJgVarxeDBg6U2jscQ24jHoI7HYrXhSHYpzFYBIf5q9AiqDUYjdb5YMXs4ooN98elDNyNc69OsY0bUtMttqibHQ5mcd+8bgU9+OxovTov1yPmJiLoyl0dXlZeX49y5c9LrrKwsZGRkIDg4GDExMSgqKsLly5eRk2Ovq8jMzARgz7xERERAp9MhOTkZixYtQnBwMLRaLZ588kkkJCRg7NixAIApU6Zg8ODBeOCBB7BixQrk5eXhlVdewYIFC6DR2P/l/thjj+H999/H888/j4ceegg7d+7EZ599hq1bt7b6ppD7nc4zYM6a/SipNAMAxva1z6Pk6N7R0bh3tGt1UmIw1FB3ldnD8+T4qVWYNDDMI+cmIurqXP7mP3ToEOLj4xEfHw8AWLRoEeLj46U5bL766ivEx8djxowZAIA5c+YgPj4eq1evlo7x7rvv4pe//CVmz56NiRMnIiIiAl988YW038vLC1u2bIGXlxcSEhLw61//Gr/5zW/wxz/+UWrTu3dvbN26FSkpKYiLi8Pbb7+NDz/8kMPHPSi7qBK//vAAXvzfUdm8N0aLFc9syJACHAAY1zfELeeM1NmzQQ0VHkvLOnSQGY+JiKj9KARBcD6LWhdgMBig0+lQWlrK+hw3ePI/h/H1EXsGr3eoP7Y9MwEalRfeTTmDlTvOwk/thcRB4bhUVIlPHmxezU1TzhWUIfGdVGh9VDi6rH6A+8LnR/HfQ9n4vykDsPD2/q0+HxEReV5zf7+5dhW5rNJkgaHKgghdbd3MleJKbD2aI73Oul6BjMslGNpdh0/2ZgEA3pg9HDPjotx6LWJ3laHaguvlxnoTAnq6u4qIiDyH3/zkskf+eQgTV/yAAxcKpW0bD12BTQAS+oRg+jD7CLj71uzHkD98B0O1Bb1C/DBjWKTbryXQxxvDe9hHaf1993nZvuNXS/HF4asAPD+EnIiI2h+/+cklRosVe88VwmS1IfnTQwAAq03A5+lXAABzbo7GyJ71VxVPHBQOpbJt6mIev7UvAOAfe7Kw7XietP2Bjw5Iz5nJISLqevjNTy45m18uPS83WpBTUoUfz13H1ZIq6Hy9kTQkwmlR8ZDubVfzNHVoBKYNtWePdmXWTjtQ7FDozEwOEVHXw29+csmpXPl6X4cuFeOrmmUYZo2Igo+3FwZF1g9oHCf+czeFQoFpNV1hZwvKnbbRMJNDRNTl8JufmlRttuKLn6+gsNyIY1dLZfue+s9h/O9ne1dV0pAIafuGR8dC51u72nafUP82vcb+YQEAgLP5ZXA2YJCZHCKiroejq6hJL/zvKL7MyMGUweE4kWPP5Nx9U3d88fNVWbtRvWprccb2CcGRP0xBRnYJ/NReDS6w6S69Q/2hVNhHWV0rM0LrEGABDHKIiLoifvNTo/ZfKMSXNd1R20/m42pJFXy8lXhpunytqWcS+zst7h0RrceA8MA2v04fby9EB/sBAM5fq0CBwSjbX2G0tPk1EBFRx8JMDjllqDZj4frDSD1zrd6+O+KiEBqgwZjewTiQVYQ/3zUM94+J8cBVynXX++JSYSVyS6vgVWckV1m1uYF3ERFRZ8Ugh+pZuzcLy74+Kdu25oGR+PpoLqw2G5bdMQQAsGreTfj5UjF+MTjcE5dZT5TevsRDTkmVrHssQuuDXw537ySERETU8THIIZnSSrMswBnWXYdXZgzCmD4hmOJQWAwAoQGaets8SQxyrpZUS11nd8RFYeWcEfUWAyUios6PQQ7JfOWwNAMA3Dc6GmP6uGcxzbbWXW9f4iG3tAq+3l4AgAidDwMcIqIuikEOyRzNLpG9jo1o+6Jhd3HsrvJX2/9qR2h9GnsLERF1YgxySOZ0Xpns9YAbMMi5UlyFAE1NkKNjkENE1FUxyCGJxWrDmXx7kPP+/fGIDvKD1se7iXd1HNFBflAqgEqTVZq0MJyZHCKiLotBDkkuFlbAaLHB19sL04dGttmCmm1FrVIiOtgPlworYbbaZz1mJoeIqOviZIAkEbMfQ6K0N1yAI+rtsHxEkJ83ohjkEBF1WQxySHL0ij3IGdaj7RbTbGu9QmqDnJE9gziyioioC2OQQxIxyBl+Awc58TF66bnjWlpERNT1sCaHANiLjk/kiEGO3rMX0wozh0fhSnEVDmQV4a747p6+HCIi8iAGOQQASL9UjGqzDQEaFXo7dPncaJRKBRZM6ocFkzx9JURE5GnsriIcv1qK+9bsBwAMigy8YYuOiYiIHDHIIXx1pHYphyFRN249DhERkSMGOV2cIAjYfiJPev3guF6euxgiIiI3Yk1OF2O1CfBSKiAIAr7MyMGHP17AxcJKKBXAgZcS0S1Q4+lLJCIicgtmcjqAKpMV353Ig8Vqa9H7/5d+BQvX/4yyanOj7ZZ8cQw3vZaClJP5+PpoLp75bwaOXzUAAF69cygDHCIi6lSYyekAXtl8HP/7+QqeSeyPZxIHyPZdLqzEX3acwV3x3TGhfzen739u4xEAQLdADf4wc4jTNn/ffR7/OXgZAPDIPw/BT+0l7UsaEo4HxvZ0x0chIiLqMJjJaUeCIGDb8TzklVbLtv3v5ysAgL98f1bW3my14cG1B/HFz1fx4Cc/4Wy+fIXwvNJqPPzpT9LrT/ZerNcGAL4/mY/l356Wbas0WREaoMaf7xqGFbPjWv3ZiIiIOhoGOe0o9ex1PPbvdNz65g+4Xm4EAFy4XiFrY6g2o7TKjNN5Bhy9UooL1+z7rTYB3zkUCFebrZj+1z34/lSB7P2/+fggiitMsm1/3WkPnubeHI1lMwdL29+YPRz3j4mBzu/GWWmciIioudhd1Y7SLxUDAIwWG17bchIr58TjWM1SCqL7/r4fhiozrpZU1Xu/uIAmAHy67yKK6gQzPUPsK3B/digbv7u1LwCgtNIsLdfw3JSBCPJTQ+PthaFRuht6jSoiIqKmMJPTjs7k1XYlfZmRg/PXynGpsBIA4ONt/6M4lWuoF+AM624PRr47kS91dX1zLLfe8X+T0AsAkHahECdySvG3XeeQ9JdUAPYAKDRAAy+lAnNvjmGAQ0REnR6DnDZSWG6s122UWade5tDFIlwqsndHPXl7f0wdEuH0WHfFd4e4mPb8jw+iymTFiRz7qKjFSQMBAO/eF4exfewLUu7KvIZfvvcjVmzLRJ7BHhRFB/m554MRERHdIFwOclJTUzFz5kxERUVBoVBg8+bNsv2CIGDp0qWIjIyEr68vEhMTcfasvKC2qKgI8+bNg1arhV6vR3JyMsrLy2Vtjh49igkTJsDHxwfR0dFYsWJFvWvZuHEjYmNj4ePjg2HDhuGbb75x9eO0iSqTFQmv78SUv6TCahMA2GtoLhbaA5pfjewBAHjhf8fwdc1sw9HBfrjv5minxxvTJxgvTI0FYA+UBi3dBotNQLhWgydu64sTryZh1ojuGBShRbC/GgAgCPJj3B4b5vbPSURE1JG5HORUVFQgLi4Oq1atcrp/xYoV+Otf/4rVq1fjwIED8Pf3R1JSEqqra0cUzZs3DydOnEBKSgq2bNmC1NRUPProo9J+g8GAKVOmoGfPnkhPT8ebb76JZcuWYc2aNVKbffv2Ye7cuUhOTsbhw4cxa9YszJo1C8ePH3f1I7ndsaulMFlsuFZmxLUye4Hx5aJKCAIQ6KNC4qBwqa3Zao9Gegb7YdLAMCybORjxMXrZ8QZHavHYrX2l4Eg0vl83KBQK+GtUUCgUUCoVSB7fu971PJs4APePiXHzpyQiIurYFIJQ99/8LrxZocCmTZswa9YsAPYsTlRUFJ577jn83//9HwCgtLQU4eHhWLt2LebMmYNTp05h8ODB+OmnnzBq1CgAwLZt2zB9+nRcuXIFUVFR+OCDD/Dyyy8jLy8ParU9M/Hiiy9i8+bNOH3aPhT6vvvuQ0VFBbZs2SJdz9ixYzFixAisXr26WddvMBig0+lQWloKrVbb0ttQz0c/ZuG1LScBAJ/8djT6dQvAqVwDHv1XOoZ11+HfyWMQ98ftsvccWTpFNsrpPwcvY8kXx/DOvXG4+yZ7cHO5sBIT3/wBADChfyjev/8m6HzlI6OqzVa8/u1pxMfo0S8sAGovJfqHB7rtsxEREXlac3+/3VqTk5WVhby8PCQmJkrbdDodxowZg7S0NABAWloa9Hq9FOAAQGJiIpRKJQ4cOCC1mThxohTgAEBSUhIyMzNRXFwstXE8j9hGPI8zRqMRBoNB9mgLR6+USM9/+8lP+MW7u7Hn7HUA9gJgnZ83zv5pGkZE6wEAc0ZH1xvGPWd0NI78YYoU4ABATIgf/vGbUXj8tr74aP7oegEOAPh4e2HZHUNw54juGBKlY4BDRERdlluHkOfl2edxCQ8Pl20PDw+X9uXl5SEsTF4folKpEBwcLGvTu3fvescQ9wUFBSEvL6/R8zizfPlyvPrqqy34ZK45kl0ie11ttuFf+y8BsAc5AODtpcS7941A2vnCet1QgD1L5iyI+cXgcPxicHi97URERCTXpUZXLVmyBKWlpdIjOzu7Tc7zz4fGNLgOVM9gf+l571B/3D8mBmpVl/pjICIiahdu/XWNiLAPgc7Pz5dtz8/Pl/ZFRESgoEA+S6/FYkFRUZGsjbNjOJ6joTbifmc0Gg20Wq3s0RZiQvwwd3T9kVIqpQK3DnS+/hQRERG5l1uDnN69eyMiIgI7duyQthkMBhw4cAAJCQkAgISEBJSUlCA9PV1qs3PnTthsNowZM0Zqk5qaCrO5dlXtlJQUDBw4EEFBQVIbx/OIbcTzeNqQ7rWT7W15cjyShoTjn8k3I1zr48GrIiIi6kIEF5WVlQmHDx8WDh8+LAAQ3nnnHeHw4cPCpUuXBEEQhNdff13Q6/XCl19+KRw9elS48847hd69ewtVVVXSMaZOnSrEx8cLBw4cEH788Uehf//+wty5c6X9JSUlQnh4uPDAAw8Ix48fFzZs2CD4+fkJf//736U2e/fuFVQqlfDWW28Jp06dEv7whz8I3t7ewrFjx5r9WUpLSwUAQmlpqau3oUlWq01Yt/+ScLmwwu3HJiIi6sqa+/vtcpDzww8/CADqPebPny8IgiDYbDbh97//vRAeHi5oNBph8uTJQmZmpuwYhYWFwty5c4WAgABBq9UKv/3tb4WysjJZmyNHjgjjx48XNBqN0L17d+H111+vdy2fffaZMGDAAEGtVgtDhgwRtm7d6tJnacsgh4iIiNpGc3+/WzVPzo2urebJISIiorbjkXlyiIiIiDoKBjlERETUKTHIISIiok6JQQ4RERF1SgxyiIiIqFNikENERESdEoMcIiIi6pQY5BAREVGnxCCHiIiIOiUGOURERNQpMcghIiKiTolBDhEREXVKKk9fgCeJa5MaDAYPXwkRERE1l/i73dQa4106yCkrKwMAREdHe/hKiIiIyFVlZWXQ6XQN7lcITYVBnZjNZkNOTg4CAwOhUCjcdlyDwYDo6GhkZ2c3ugR8V8X70zjen4bx3jSO96dxvD8Nu9HujSAIKCsrQ1RUFJTKhitvunQmR6lUokePHm12fK1We0P8ZfEU3p/G8f40jPemcbw/jeP9adiNdG8ay+CIWHhMREREnRKDHCIiIuqUGOS0AY1Ggz/84Q/QaDSevpQOifencbw/DeO9aRzvT+N4fxrWWe9Nly48JiIios6LmRwiIiLqlBjkEBERUafEIIeIiIg6JQY5RERE1CkxyGkDq1atQq9eveDj44MxY8bg4MGDnr6kNpeamoqZM2ciKioKCoUCmzdvlu0XBAFLly5FZGQkfH19kZiYiLNnz8raFBUVYd68edBqtdDr9UhOTkZ5eXk7foq2s3z5cowePRqBgYEICwvDrFmzkJmZKWtTXV2NBQsWICQkBAEBAZg9ezby8/NlbS5fvowZM2bAz88PYWFhWLx4MSwWS3t+FLf74IMPMHz4cGkSsoSEBHz77bfS/q56Xxry+uuvQ6FQ4JlnnpG2deV7tGzZMigUCtkjNjZW2t+V7w0AXL16Fb/+9a8REhICX19fDBs2DIcOHZL2d/rvZoHcasOGDYJarRY+/vhj4cSJE8Ijjzwi6PV6IT8/39OX1qa++eYb4eWXXxa++OILAYCwadMm2f7XX39d0Ol0wubNm4UjR44Id9xxh9C7d2+hqqpKajN16lQhLi5O2L9/v7Bnzx6hX79+wty5c9v5k7SNpKQk4ZNPPhGOHz8uZGRkCNOnTxdiYmKE8vJyqc1jjz0mREdHCzt27BAOHTokjB07Vhg3bpy032KxCEOHDhUSExOFw4cPC998840QGhoqLFmyxBMfyW2++uorYevWrcKZM2eEzMxM4aWXXhK8vb2F48ePC4LQde+LMwcPHhR69eolDB8+XHj66ael7V35Hv3hD38QhgwZIuTm5kqPa9euSfu78r0pKioSevbsKTz44IPCgQMHhAsXLgjfffedcO7cOalNZ/9uZpDjZjfffLOwYMEC6bXVahWioqKE5cuXe/Cq2lfdIMdmswkRERHCm2++KW0rKSkRNBqN8J///EcQBEE4efKkAED46aefpDbffvutoFAohKtXr7bbtbeXgoICAYCwe/duQRDs98Pb21vYuHGj1ObUqVMCACEtLU0QBHsgqVQqhby8PKnNBx98IGi1WsFoNLbvB2hjQUFBwocffsj74qCsrEzo37+/kJKSItx6661SkNPV79Ef/vAHIS4uzum+rn5vXnjhBWH8+PEN7u8K383srnIjk8mE9PR0JCYmStuUSiUSExORlpbmwSvzrKysLOTl5cnui06nw5gxY6T7kpaWBr1ej1GjRkltEhMToVQqceDAgXa/5rZWWloKAAgODgYApKenw2w2y+5RbGwsYmJiZPdo2LBhCA8Pl9okJSXBYDDgxIkT7Xj1bcdqtWLDhg2oqKhAQkIC74uDBQsWYMaMGbJ7AfDvDgCcPXsWUVFR6NOnD+bNm4fLly8D4L356quvMGrUKNxzzz0ICwtDfHw8/vGPf0j7u8J3M4McN7p+/TqsVqvsfxYACA8PR15enoeuyvPEz97YfcnLy0NYWJhsv0qlQnBwcKe7dzabDc888wxuueUWDB06FID986vVauj1elnbuvfI2T0U993Ijh07hoCAAGg0Gjz22GPYtGkTBg8e3OXvi2jDhg34+eefsXz58nr7uvo9GjNmDNauXYtt27bhgw8+QFZWFiZMmICysrIuf28uXLiADz74AP3798d3332Hxx9/HE899RQ+/fRTAF3ju7lLr0JO5AkLFizA8ePH8eOPP3r6UjqMgQMHIiMjA6Wlpfj8888xf/587N6929OX1SFkZ2fj6aefRkpKCnx8fDx9OR3OtGnTpOfDhw/HmDFj0LNnT3z22Wfw9fX14JV5ns1mw6hRo/DnP/8ZABAfH4/jx49j9erVmD9/voevrn0wk+NGoaGh8PLyqle5n5+fj4iICA9dleeJn72x+xIREYGCggLZfovFgqKiok517xYuXIgtW7bghx9+QI8ePaTtERERMJlMKCkpkbWve4+c3UNx341MrVajX79+GDlyJJYvX464uDisXLmyy98XwN7lUlBQgJtuugkqlQoqlQq7d+/GX//6V6hUKoSHh3f5e+RIr9djwIABOHfuXJf/+xMZGYnBgwfLtg0aNEjqzusK380MctxIrVZj5MiR2LFjh7TNZrNhx44dSEhI8OCVeVbv3r0REREhuy8GgwEHDhyQ7ktCQgJKSkqQnp4utdm5cydsNhvGjBnT7tfsboIgYOHChdi0aRN27tyJ3r17y/aPHDkS3t7esnuUmZmJy5cvy+7RsWPHZF84KSkp0Gq19b7IbnQ2mw1Go5H3BcDkyZNx7NgxZGRkSI9Ro0Zh3rx50vOufo8clZeX4/z584iMjOzyf39uueWWelNVnDlzBj179gTQRb6bPV353Nls2LBB0Gg0wtq1a4WTJ08Kjz76qKDX62WV+51RWVmZcPjwYeHw4cMCAOGdd94RDh8+LFy6dEkQBPswRb1eL3z55ZfC0aNHhTvvvNPpMMX4+HjhwIEDwo8//ij079//hhmm2JTHH39c0Ol0wq5du2RDXSsrK6U2jz32mBATEyPs3LlTOHTokJCQkCAkJCRI+8WhrlOmTBEyMjKEbdu2Cd26dbvhh7q++OKLwu7du4WsrCzh6NGjwosvvigoFAph+/btgiB03fvSGMfRVYLQte/Rc889J+zatUvIysoS9u7dKyQmJgqhoaFCQUGBIAhd+94cPHhQUKlUwp/+9Cfh7Nmzwrp16wQ/Pz/h3//+t9Sms383M8hpA++9954QExMjqNVq4eabbxb279/v6Utqcz/88IMAoN5j/vz5giDYhyr+/ve/F8LDwwWNRiNMnjxZyMzMlB2jsLBQmDt3rhAQECBotVrht7/9rVBWVuaBT+N+zu4NAOGTTz6R2lRVVQlPPPGEEBQUJPj5+Ql33XWXkJubKzvOxYsXhWnTpgm+vr5CaGio8Nxzzwlms7mdP417PfTQQ0LPnj0FtVotdOvWTZg8ebIU4AhC170vjakb5HTle3TfffcJkZGRglqtFrp37y7cd999snlguvK9EQRB+Prrr4WhQ4cKGo1GiI2NFdasWSPb39m/mxWCIAieySERERERtR3W5BAREVGnxCCHiIiIOiUGOURERNQpMcghIiKiTolBDhEREXVKDHKIiIioU2KQQ0RERJ0SgxwiIiLqlBjkEBERUafEIIeIiIg6JQY5RERE1CkxyCEiIqJO6f8DRL7pY6+2O0wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_ensemble_results_lv.account_value.plot()     # plot the chance in the amount value with time during test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_lv = pd.merge(df_ensemble_results_lv, df_index_scaled, on =\"date\", how = \"left\")[[\"date\",\"account_value\",\"spy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>spy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>10079.479603</td>\n",
       "      <td>9777.141321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>9924.454502</td>\n",
       "      <td>9825.327421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>9957.314686</td>\n",
       "      <td>9981.552869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>10010.884480</td>\n",
       "      <td>9929.227721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>16673.567693</td>\n",
       "      <td>13196.873815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>16843.540605</td>\n",
       "      <td>13125.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>16775.123886</td>\n",
       "      <td>13224.516675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>16960.659343</td>\n",
       "      <td>13309.419390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>17043.670540</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            account_value           spy\n",
       "date                                   \n",
       "2018-04-04   10000.000000  10000.000000\n",
       "2018-04-05   10079.479603   9777.141321\n",
       "2018-04-06    9924.454502   9825.327421\n",
       "2018-04-09    9957.314686   9981.552869\n",
       "2018-04-10   10010.884480   9929.227721\n",
       "...                   ...           ...\n",
       "2020-09-25   16673.567693  13196.873815\n",
       "2020-09-28   16843.540605  13125.003128\n",
       "2020-09-29   16775.123886  13224.516675\n",
       "2020-09-30   16960.659343  13309.419390\n",
       "2020-10-01   17043.670540           NaN\n",
       "\n",
       "[630 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_lv.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results_lv.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return          0.112297\n",
      "Cumulative returns     0.304823\n",
      "Annual volatility      0.195913\n",
      "Sharpe ratio           0.642434\n",
      "Calmar ratio           0.480721\n",
      "Stability              0.636771\n",
      "Max drawdown          -0.233601\n",
      "Omega ratio            1.132554\n",
      "Sortino ratio          0.884233\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.827437\n",
      "Daily value at risk   -0.024183\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "stats = backtest_stats(account_value=df_ensemble_results_mv)\n",
    "stats_df = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return          0.237728\n",
      "Cumulative returns     0.704367\n",
      "Annual volatility      0.179996\n",
      "Sharpe ratio           1.276987\n",
      "Calmar ratio           1.666635\n",
      "Stability              0.955641\n",
      "Max drawdown          -0.142640\n",
      "Omega ratio            1.281791\n",
      "Sortino ratio          1.908398\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.046383\n",
      "Daily value at risk   -0.021765\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "stats = backtest_stats(account_value=df_ensemble_results_lv)\n",
    "stats_df = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
