{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKIG9MBixxX8"
   },
   "source": [
    "## Project: Portfolio Management Using Multi-Agent Reinforcement Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qC_9nFXzxxS_"
   },
   "source": [
    "## Part 3: Reinfocement Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lFG0XxoofZS"
   },
   "source": [
    "- Step 1: Import Libraries and Install Packages\n",
    "> - Step 1.1: Install required packages if not already installed\n",
    "> - Step 1.2: Import the necessary libraries\n",
    "- Step 2: Define Constants\n",
    "> - Step 2.1: Define start and end dates for training data\n",
    "> - Step 2.2: Define start and end dates for testing data\n",
    "- Step 3: Load and Merge Dataframes\n",
    "> - Step 3.1: Load YahooFinance and sentiment dataframes\n",
    "> - Step 3.2: Create GDP dataframe\n",
    "> - Step 3.3: Merge all dataframes into one\n",
    "- Step 4: Incorporate Technical Indicators\n",
    "> - Step 4.1: Use historical data to calculate technical indicators\n",
    "- Step 5: Design Environment Constants\n",
    "> - Step 5.1: Define environment parameters\n",
    "> - Step 5.2: Define A2C model parameters\n",
    "> - Step 5.3: Define PPO model parameters\n",
    "> - Step 5.4: Define DDPG model parameters\n",
    "> - Step 5.5: Define timesteps\n",
    "> - Step 5.6: Define ensemble agent parameters.\n",
    "> - Step 5.7: Define test dates dataframe.\n",
    "- Step 6: Implement Deep Reinforcement Learning Model\n",
    "> - Step 6.1: Build and train a deep reinforcement learning model using the environment and data.\n",
    ">> - Step 6.1.1: Model with top voalatile 5 and least volatile 5 stocks.\n",
    ">> - Step 6.1.2: Model with top 5 voalatile stocks.\n",
    ">> - Step 6.1.3: Model with least volatile 5 stocks.\n",
    "- Step 7: Analyze Results\n",
    "> - Step 7.0: Baseline Statistics\n",
    "> - Step 7.1: Model with Most-Volatile and Least-Volatile Stocks\n",
    ">> - Step 7.1.1: Calcualte Sharpe ratio\n",
    ">> - Step 7.1.2: Backtest results\n",
    ">> - Step 7.1.3: Compare with Index\n",
    ">> - Step 7.1.4: Vizualise the comparision with Index\n",
    "> - Step 7.2: Model with Most-Volatile Stocks\n",
    ">> - Step 7.2.1: Calcualte Sharpe ratio\n",
    ">> - Step 7.2.2: Backtest results\n",
    ">> - Step 7.2.3: Compare with Index\n",
    ">> - Step 7.2.4: Vizualise the comparision with Index\n",
    "> - Step 7.3: Model with Least-Volatile Stocks\n",
    ">> - Step 7.3.1: Calcualte Sharpe ratio\n",
    ">> - Step 7.3.2: Backtest results\n",
    ">> - Step 7.3.3: Compare with Index\n",
    ">> - Step 7.3.4: Vizualise the comparision with Index\n",
    "- Step 8: Conclusion\n",
    "> - Step 8.1: Summarize the results and provide insights on the effectiveness of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpIgm2TyyP8b"
   },
   "source": [
    "#### Step 1: Import Libraries and Install Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgYaDWpZpY2I"
   },
   "source": [
    "> - #### Step 1.1: Install required packages if not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBPaPwCTxoZ5",
    "outputId": "20062cdf-f35f-4e40-f157-f74697525ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyportfolioopt in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.5)\n",
      "Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyportfolioopt) (1.3.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyportfolioopt) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyportfolioopt) (1.5.3)\n",
      "Requirement already satisfied: scipy<2.0,>=1.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyportfolioopt) (1.10.1)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.6.2.post9)\n",
      "Requirement already satisfied: ecos>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (2.0.12)\n",
      "Requirement already satisfied: scs>=1.1.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (3.2.3)\n",
      "Requirement already satisfied: setuptools>65.5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (67.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=0.19->pyportfolioopt) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=0.19->pyportfolioopt) (2023.3)\n",
      "Requirement already satisfied: qdldl in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.1.7)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.19->pyportfolioopt) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell installs the yfinance package if only unable to import, indicating the package is not installed.\n",
    "This avoids isntalling the packages again.\n",
    "\"\"\"\n",
    "import importlib\n",
    "\n",
    "# gym Library\n",
    "try:\n",
    "    importlib.import_module('gym')\n",
    "except ImportError:\n",
    "    !pip install gym\n",
    "\n",
    "\n",
    "# swig Library\n",
    "try:\n",
    "    importlib.import_module('swig')\n",
    "except ImportError:\n",
    "    !pip install swig\n",
    "\n",
    "\n",
    "# wrds Library\n",
    "try:\n",
    "    importlib.import_module('wrds')\n",
    "except ImportError:\n",
    "    !pip install wrds\n",
    "\n",
    "\n",
    "# pyportfolioopt Library\n",
    "try:\n",
    "    importlib.import_module('pyportfolioopt')\n",
    "except ImportError:\n",
    "    !pip install pyportfolioopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./FinRL\")\n",
    "sys.path.append(\"./stable_baselines3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUGJByMKzzc3"
   },
   "source": [
    "> - #### Step 1.2: Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwDHd5-3xvqj",
    "outputId": "88f5206e-fb18-45e9-9d1e-15639afbfa44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas_datareader/compat/__init__.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  PANDAS_VERSION = LooseVersion(pd.__version__)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config_tickers import SP_500_TICKER\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent, DRLEnsembleAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmyY-7qW6_wR"
   },
   "source": [
    "#### Step 2:  Define the constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-ba72B_7Hz6"
   },
   "source": [
    "> - #### Step 2.1: Define start and end dates for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M-ngtJv1z39l"
   },
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2010-01-01'\n",
    "TRAIN_END_DATE = '2017-12-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igAw-Ypp7SQN"
   },
   "source": [
    "> - #### Step 2.2: Define start and end dates for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DehYPXWy7SzN"
   },
   "outputs": [],
   "source": [
    "TEST_START_DATE = '2018-01-01'\n",
    "TEST_END_DATE = '2020-12-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "074-8Duk7rAX"
   },
   "source": [
    "#### Step 3: Load and Merge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKh-XbTi8A1q",
    "outputId": "1d8ed1d7-231a-415d-af32-c56ce2b24a37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.7.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown) (3.12.0)\n",
      "Requirement already satisfied: requests[socks] in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown) (2.30.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Directory already exists: /Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/genie_data\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "import gdown\n",
    "# The link for the data folder in Google drive. \n",
    "data_url = \"https://drive.google.com/drive/folders/1zQGlgh5kHTXSq7eoyXf6i_uAWYFJ5xzx?usp=share_link\"\n",
    "\n",
    "current_path = os.getcwd() # Get the current working directory.\n",
    "\n",
    "data_folder_path = os.path.join(os.getcwd(),\"genie_data\") # Generate data folder path. \n",
    "\n",
    "# Check if the folder already exists locally\n",
    "\n",
    "if not os.path.exists(data_folder_path):\n",
    "    \n",
    "    os.makedirs(data_folder_path)\n",
    "    print(f\"Downloading data from Google Drive to: {data_folder_path}\")\n",
    "    gdown.download_folder(data_url,output=data_folder_path, quiet=True, use_cookies=False) # Download the data from Google Drive.\n",
    "    \n",
    "else:\n",
    "    print(f\"Directory already exists: {data_folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo4koJ9SF0l8"
   },
   "source": [
    "> - #### Step 3.1: Load YahooFinance and sentiment dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "zx2WEURa7qGH",
    "outputId": "90245c32-9d09-402a-87a1-57cb4f4decf3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.840000</td>\n",
       "      <td>22.922108</td>\n",
       "      <td>2175500</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>11.220000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>9.966131</td>\n",
       "      <td>14482500</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>4.164575</td>\n",
       "      <td>14901600</td>\n",
       "      <td>KEY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>25.320000</td>\n",
       "      <td>25.910000</td>\n",
       "      <td>24.930000</td>\n",
       "      <td>19.833185</td>\n",
       "      <td>3811400</td>\n",
       "      <td>LNC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15.245000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>9.583809</td>\n",
       "      <td>1332800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28549</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>50.520000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>50.360001</td>\n",
       "      <td>47.424179</td>\n",
       "      <td>563800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28550</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>147.470001</td>\n",
       "      <td>147.990005</td>\n",
       "      <td>147.009995</td>\n",
       "      <td>138.462997</td>\n",
       "      <td>2224900</td>\n",
       "      <td>PEP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28551</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>138.919998</td>\n",
       "      <td>137.550003</td>\n",
       "      <td>130.316620</td>\n",
       "      <td>3261400</td>\n",
       "      <td>PG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28552</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>372.339996</td>\n",
       "      <td>373.100006</td>\n",
       "      <td>371.570007</td>\n",
       "      <td>359.862762</td>\n",
       "      <td>49455300</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28553</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>65.519997</td>\n",
       "      <td>65.849998</td>\n",
       "      <td>65.389999</td>\n",
       "      <td>61.628376</td>\n",
       "      <td>1296400</td>\n",
       "      <td>XEL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28554 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close    volume  \\\n",
       "0     2010-01-04   39.099998   39.419998   38.840000   22.922108   2175500   \n",
       "1     2010-01-04   11.220000   11.430000   10.950000    9.966131  14482500   \n",
       "2     2010-01-04    5.660000    5.970000    5.650000    4.164575  14901600   \n",
       "3     2010-01-04   25.320000   25.910000   24.930000   19.833185   3811400   \n",
       "4     2010-01-04   15.245000   15.350000   15.120000    9.583809   1332800   \n",
       "...          ...         ...         ...         ...         ...       ...   \n",
       "28549 2020-12-30   50.520000   51.000000   50.360001   47.424179    563800   \n",
       "28550 2020-12-30  147.470001  147.990005  147.009995  138.462997   2224900   \n",
       "28551 2020-12-30  138.600006  138.919998  137.550003  130.316620   3261400   \n",
       "28552 2020-12-30  372.339996  373.100006  371.570007  359.862762  49455300   \n",
       "28553 2020-12-30   65.519997   65.849998   65.389999   61.628376   1296400   \n",
       "\n",
       "       tic  day  \n",
       "0        D    0  \n",
       "1      DAL    0  \n",
       "2      KEY    0  \n",
       "3      LNC    0  \n",
       "4      LNT    0  \n",
       "...    ...  ...  \n",
       "28549  LNT    2  \n",
       "28550  PEP    2  \n",
       "28551   PG    2  \n",
       "28552  SPY    2  \n",
       "28553  XEL    2  \n",
       "\n",
       "[28554 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf_df = pd.read_csv('./genie_data/yf-data.csv',index_col='Unnamed: 0')\n",
    "yf_df[\"date\"] = pd.to_datetime(yf_df[\"date\"])\n",
    "\n",
    "yf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "wEDzfKjTJP2X",
    "outputId": "5d5938ed-f7e5-4865-aa62-120e812f3fde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ETSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5943</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ETSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ENPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71721 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  SentimentScore   tic\n",
       "1036 2005-01-01             0.0   LNC\n",
       "1003 2005-01-01             0.0   XEL\n",
       "1762 2005-01-01             0.0    PG\n",
       "2431 2005-01-01             0.0     D\n",
       "155  2005-01-01             0.0  ETSY\n",
       "...         ...             ...   ...\n",
       "7427 2020-12-31             0.0   KEY\n",
       "5943 2020-12-31             0.0  ETSY\n",
       "7021 2020-12-31             0.0    PG\n",
       "6010 2020-12-31             0.0  ENPH\n",
       "7022 2020-12-31             0.0     D\n",
       "\n",
       "[71721 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments_df = pd.read_csv('./genie_data/sentiments_df.csv',index_col='Unnamed: 0')\n",
    "sentiments_df[\"date\"] = pd.to_datetime(sentiments_df[\"date\"])\n",
    "\n",
    "sentiments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcEoLB0IFk2p"
   },
   "source": [
    "> - #### Step 3.2: Create GDP dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RACEQNl_7xxL"
   },
   "outputs": [],
   "source": [
    "gdp = web.DataReader(\"GDP\", 'fred', 2010, 2020)\n",
    "gdp = gdp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "njSxHpMhG9eN"
   },
   "outputs": [],
   "source": [
    "date = pd.date_range(start='2010-01-01', end='2020-12-30')\n",
    "date_df = pd.DataFrame()\n",
    "date_df['date'] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-VEpZbu3HS-U"
   },
   "outputs": [],
   "source": [
    "gdp['date']=pd.to_datetime(gdp['DATE'])\n",
    "gdp.rename(columns = {'GDP':'gdp'}, inplace = True)\n",
    "gdp = gdp.drop(['DATE'], axis=1)\n",
    "gdp_df=gdp.merge(date_df, on='date', how='right')\n",
    "gdp_df = gdp_df.fillna(method='ffill')\n",
    "gdp_df = gdp_df.merge(pd.DataFrame({\"tic\":yf_df.tic.unique()}),how=\"cross\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BITc6ro3L_Dr"
   },
   "source": [
    " > - #### Step 3.3:  Merge all dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CZa_G1ffI0yj"
   },
   "outputs": [],
   "source": [
    "df = pd.merge(pd.merge(yf_df, sentiments_df, how='left', left_on=['date','tic'], right_on = ['date','tic']),\n",
    "              gdp_df, how='left', left_on=['date','tic'], right_on = ['date','tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "uAaslu54h3aF",
    "outputId": "3f04ee36-ed0d-41f6-d69e-89ee58f3a0f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.840000</td>\n",
       "      <td>22.922108</td>\n",
       "      <td>2175500</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>11.220000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>9.966131</td>\n",
       "      <td>14482500</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>4.164575</td>\n",
       "      <td>14901600</td>\n",
       "      <td>KEY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>25.320000</td>\n",
       "      <td>25.910000</td>\n",
       "      <td>24.930000</td>\n",
       "      <td>19.833185</td>\n",
       "      <td>3811400</td>\n",
       "      <td>LNC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15.245000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>9.583809</td>\n",
       "      <td>1332800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41102</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>50.520000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>50.360001</td>\n",
       "      <td>47.424179</td>\n",
       "      <td>563800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41103</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>147.470001</td>\n",
       "      <td>147.990005</td>\n",
       "      <td>147.009995</td>\n",
       "      <td>138.462997</td>\n",
       "      <td>2224900</td>\n",
       "      <td>PEP</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41104</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>138.919998</td>\n",
       "      <td>137.550003</td>\n",
       "      <td>130.316620</td>\n",
       "      <td>3261400</td>\n",
       "      <td>PG</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41105</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>372.339996</td>\n",
       "      <td>373.100006</td>\n",
       "      <td>371.570007</td>\n",
       "      <td>359.862762</td>\n",
       "      <td>49455300</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41106</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>65.519997</td>\n",
       "      <td>65.849998</td>\n",
       "      <td>65.389999</td>\n",
       "      <td>61.628376</td>\n",
       "      <td>1296400</td>\n",
       "      <td>XEL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41107 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close    volume  \\\n",
       "0     2010-01-04   39.099998   39.419998   38.840000   22.922108   2175500   \n",
       "1     2010-01-04   11.220000   11.430000   10.950000    9.966131  14482500   \n",
       "2     2010-01-04    5.660000    5.970000    5.650000    4.164575  14901600   \n",
       "3     2010-01-04   25.320000   25.910000   24.930000   19.833185   3811400   \n",
       "4     2010-01-04   15.245000   15.350000   15.120000    9.583809   1332800   \n",
       "...          ...         ...         ...         ...         ...       ...   \n",
       "41102 2020-12-30   50.520000   51.000000   50.360001   47.424179    563800   \n",
       "41103 2020-12-30  147.470001  147.990005  147.009995  138.462997   2224900   \n",
       "41104 2020-12-30  138.600006  138.919998  137.550003  130.316620   3261400   \n",
       "41105 2020-12-30  372.339996  373.100006  371.570007  359.862762  49455300   \n",
       "41106 2020-12-30   65.519997   65.849998   65.389999   61.628376   1296400   \n",
       "\n",
       "       tic  day  SentimentScore        gdp  \n",
       "0        D    0             0.0  14764.611  \n",
       "1      DAL    0             0.0  14764.611  \n",
       "2      KEY    0             0.0  14764.611  \n",
       "3      LNC    0             0.0  14764.611  \n",
       "4      LNT    0             0.0  14764.611  \n",
       "...    ...  ...             ...        ...  \n",
       "41102  LNT    2             0.0  21538.032  \n",
       "41103  PEP    2             0.0  21538.032  \n",
       "41104   PG    2             0.0  21538.032  \n",
       "41105  SPY    2             NaN  21538.032  \n",
       "41106  XEL    2             0.0  21538.032  \n",
       "\n",
       "[41107 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rsKVwwfMRp3e"
   },
   "outputs": [],
   "source": [
    "df[\"SentimentScore\"] = df[\"SentimentScore\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "peiE61-qRrzU",
    "outputId": "93905ffe-3087-4e44-9995-2986af67f097"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.840000</td>\n",
       "      <td>22.922108</td>\n",
       "      <td>2175500</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>11.220000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>9.966131</td>\n",
       "      <td>14482500</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>4.164575</td>\n",
       "      <td>14901600</td>\n",
       "      <td>KEY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>25.320000</td>\n",
       "      <td>25.910000</td>\n",
       "      <td>24.930000</td>\n",
       "      <td>19.833185</td>\n",
       "      <td>3811400</td>\n",
       "      <td>LNC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15.245000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>9.583809</td>\n",
       "      <td>1332800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>61.189999</td>\n",
       "      <td>61.520000</td>\n",
       "      <td>60.639999</td>\n",
       "      <td>41.632233</td>\n",
       "      <td>6585900</td>\n",
       "      <td>PEP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>61.110001</td>\n",
       "      <td>61.310001</td>\n",
       "      <td>60.630001</td>\n",
       "      <td>41.181229</td>\n",
       "      <td>9190800</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>112.370003</td>\n",
       "      <td>113.389999</td>\n",
       "      <td>111.510002</td>\n",
       "      <td>88.117897</td>\n",
       "      <td>118944600</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>21.379999</td>\n",
       "      <td>21.379999</td>\n",
       "      <td>21.040001</td>\n",
       "      <td>13.396955</td>\n",
       "      <td>2670400</td>\n",
       "      <td>XEL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>38.860001</td>\n",
       "      <td>39.020000</td>\n",
       "      <td>38.080002</td>\n",
       "      <td>22.639708</td>\n",
       "      <td>2802200</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>11.320000</td>\n",
       "      <td>12.340000</td>\n",
       "      <td>11.290000</td>\n",
       "      <td>10.747787</td>\n",
       "      <td>25066000</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>6.190000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>4.325830</td>\n",
       "      <td>16660800</td>\n",
       "      <td>KEY</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>25.799999</td>\n",
       "      <td>26.610001</td>\n",
       "      <td>25.719999</td>\n",
       "      <td>20.247015</td>\n",
       "      <td>4839200</td>\n",
       "      <td>LNC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>15.185000</td>\n",
       "      <td>15.555000</td>\n",
       "      <td>15.155000</td>\n",
       "      <td>9.808012</td>\n",
       "      <td>3684600</td>\n",
       "      <td>LNT</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>62.099998</td>\n",
       "      <td>60.900002</td>\n",
       "      <td>42.135311</td>\n",
       "      <td>8886000</td>\n",
       "      <td>PEP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>61.130001</td>\n",
       "      <td>61.279999</td>\n",
       "      <td>60.599998</td>\n",
       "      <td>41.194714</td>\n",
       "      <td>8649400</td>\n",
       "      <td>PG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>113.260002</td>\n",
       "      <td>113.680000</td>\n",
       "      <td>112.849998</td>\n",
       "      <td>88.351143</td>\n",
       "      <td>111579900</td>\n",
       "      <td>SPY</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>20.950001</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.410000</td>\n",
       "      <td>13.238071</td>\n",
       "      <td>4321400</td>\n",
       "      <td>XEL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>38.730000</td>\n",
       "      <td>38.290001</td>\n",
       "      <td>22.663235</td>\n",
       "      <td>2882500</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>11.990000</td>\n",
       "      <td>12.240000</td>\n",
       "      <td>11.850000</td>\n",
       "      <td>10.756669</td>\n",
       "      <td>14980700</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low      close     volume  tic  \\\n",
       "0  2010-01-04   39.099998   39.419998   38.840000  22.922108    2175500    D   \n",
       "1  2010-01-04   11.220000   11.430000   10.950000   9.966131   14482500  DAL   \n",
       "2  2010-01-04    5.660000    5.970000    5.650000   4.164575   14901600  KEY   \n",
       "3  2010-01-04   25.320000   25.910000   24.930000  19.833185    3811400  LNC   \n",
       "4  2010-01-04   15.245000   15.350000   15.120000   9.583809    1332800  LNT   \n",
       "5  2010-01-04   61.189999   61.520000   60.639999  41.632233    6585900  PEP   \n",
       "6  2010-01-04   61.110001   61.310001   60.630001  41.181229    9190800   PG   \n",
       "7  2010-01-04  112.370003  113.389999  111.510002  88.117897  118944600  SPY   \n",
       "8  2010-01-04   21.379999   21.379999   21.040001  13.396955    2670400  XEL   \n",
       "9  2010-01-05   38.860001   39.020000   38.080002  22.639708    2802200    D   \n",
       "10 2010-01-05   11.320000   12.340000   11.290000  10.747787   25066000  DAL   \n",
       "11 2010-01-05    5.880000    6.190000    5.880000   4.325830   16660800  KEY   \n",
       "12 2010-01-05   25.799999   26.610001   25.719999  20.247015    4839200  LNC   \n",
       "13 2010-01-05   15.185000   15.555000   15.155000   9.808012    3684600  LNT   \n",
       "14 2010-01-05   61.000000   62.099998   60.900002  42.135311    8886000  PEP   \n",
       "15 2010-01-05   61.130001   61.279999   60.599998  41.194714    8649400   PG   \n",
       "16 2010-01-05  113.260002  113.680000  112.849998  88.351143  111579900  SPY   \n",
       "17 2010-01-05   20.950001   21.000000   20.410000  13.238071    4321400  XEL   \n",
       "18 2010-01-06   38.500000   38.730000   38.290001  22.663235    2882500    D   \n",
       "19 2010-01-06   11.990000   12.240000   11.850000  10.756669   14980700  DAL   \n",
       "\n",
       "    day  SentimentScore        gdp  \n",
       "0     0             0.0  14764.611  \n",
       "1     0             0.0  14764.611  \n",
       "2     0             0.0  14764.611  \n",
       "3     0             0.0  14764.611  \n",
       "4     0             0.0  14764.611  \n",
       "5     0             0.0  14764.611  \n",
       "6     0             0.0  14764.611  \n",
       "7     0             0.0  14764.611  \n",
       "8     0             0.0  14764.611  \n",
       "9     1             0.0  14764.611  \n",
       "10    1             0.0  14764.611  \n",
       "11    1             0.0  14764.611  \n",
       "12    1             0.0  14764.611  \n",
       "13    1             0.0  14764.611  \n",
       "14    1             0.0  14764.611  \n",
       "15    1             0.0  14764.611  \n",
       "16    1             0.0  14764.611  \n",
       "17    1             0.0  14764.611  \n",
       "18    2             0.0  14764.611  \n",
       "19    2             0.0  14764.611  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uF2mO-m5hpMw",
    "outputId": "23571701-ee28-4cdd-8574-a925ce4c6a5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28554, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['date', 'tic'], inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>11.220000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>9.966131</td>\n",
       "      <td>14482500</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>4.164575</td>\n",
       "      <td>14901600</td>\n",
       "      <td>KEY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>25.320000</td>\n",
       "      <td>25.910000</td>\n",
       "      <td>24.930000</td>\n",
       "      <td>19.833185</td>\n",
       "      <td>3811400</td>\n",
       "      <td>LNC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>112.370003</td>\n",
       "      <td>113.389999</td>\n",
       "      <td>111.510002</td>\n",
       "      <td>88.117897</td>\n",
       "      <td>118944600</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>11.320000</td>\n",
       "      <td>12.340000</td>\n",
       "      <td>11.290000</td>\n",
       "      <td>10.747787</td>\n",
       "      <td>25066000</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41098</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>171.679993</td>\n",
       "      <td>177.550003</td>\n",
       "      <td>171.679993</td>\n",
       "      <td>172.929993</td>\n",
       "      <td>2474100</td>\n",
       "      <td>ENPH</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41099</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>178.300003</td>\n",
       "      <td>183.410004</td>\n",
       "      <td>176.119995</td>\n",
       "      <td>183.179993</td>\n",
       "      <td>2125600</td>\n",
       "      <td>ETSY</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41100</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>16.010000</td>\n",
       "      <td>16.320000</td>\n",
       "      <td>15.980000</td>\n",
       "      <td>14.926527</td>\n",
       "      <td>5757800</td>\n",
       "      <td>KEY</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41101</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>46.046585</td>\n",
       "      <td>687300</td>\n",
       "      <td>LNC</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41105</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>372.339996</td>\n",
       "      <td>373.100006</td>\n",
       "      <td>371.570007</td>\n",
       "      <td>359.862762</td>\n",
       "      <td>49455300</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14714 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close     volume  \\\n",
       "1     2010-01-04   11.220000   11.430000   10.950000    9.966131   14482500   \n",
       "2     2010-01-04    5.660000    5.970000    5.650000    4.164575   14901600   \n",
       "3     2010-01-04   25.320000   25.910000   24.930000   19.833185    3811400   \n",
       "7     2010-01-04  112.370003  113.389999  111.510002   88.117897  118944600   \n",
       "10    2010-01-05   11.320000   12.340000   11.290000   10.747787   25066000   \n",
       "...          ...         ...         ...         ...         ...        ...   \n",
       "41098 2020-12-30  171.679993  177.550003  171.679993  172.929993    2474100   \n",
       "41099 2020-12-30  178.300003  183.410004  176.119995  183.179993    2125600   \n",
       "41100 2020-12-30   16.010000   16.320000   15.980000   14.926527    5757800   \n",
       "41101 2020-12-30   49.500000   50.000000   49.310001   46.046585     687300   \n",
       "41105 2020-12-30  372.339996  373.100006  371.570007  359.862762   49455300   \n",
       "\n",
       "        tic  day  SentimentScore        gdp  \n",
       "1       DAL    0             0.0  14764.611  \n",
       "2       KEY    0             0.0  14764.611  \n",
       "3       LNC    0             0.0  14764.611  \n",
       "7       SPY    0             0.0  14764.611  \n",
       "10      DAL    1             0.0  14764.611  \n",
       "...     ...  ...             ...        ...  \n",
       "41098  ENPH    2             0.0  21538.032  \n",
       "41099  ETSY    2             0.0  21538.032  \n",
       "41100   KEY    2             0.0  21538.032  \n",
       "41101   LNC    2             0.0  21538.032  \n",
       "41105   SPY    2             0.0  21538.032  \n",
       "\n",
       "[14714 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_volatile_stocks = [\"ENPH\",\"KEY\",\"DAL\",\"LNC\",\"ETSY\"]\n",
    "\n",
    "# Add index to both the stocks\n",
    "most_volatile_stocks.append(\"SPY\")\n",
    "\n",
    "df_mv = df[df[\"tic\"].isin(most_volatile_stocks)]\n",
    "\n",
    "df_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.840000</td>\n",
       "      <td>22.922108</td>\n",
       "      <td>2175500</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>15.245000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>9.583809</td>\n",
       "      <td>1332800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>61.189999</td>\n",
       "      <td>61.520000</td>\n",
       "      <td>60.639999</td>\n",
       "      <td>41.632233</td>\n",
       "      <td>6585900</td>\n",
       "      <td>PEP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>61.110001</td>\n",
       "      <td>61.310001</td>\n",
       "      <td>60.630001</td>\n",
       "      <td>41.181229</td>\n",
       "      <td>9190800</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>112.370003</td>\n",
       "      <td>113.389999</td>\n",
       "      <td>111.510002</td>\n",
       "      <td>88.117897</td>\n",
       "      <td>118944600</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14764.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41102</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>50.520000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>50.360001</td>\n",
       "      <td>47.424179</td>\n",
       "      <td>563800</td>\n",
       "      <td>LNT</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41103</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>147.470001</td>\n",
       "      <td>147.990005</td>\n",
       "      <td>147.009995</td>\n",
       "      <td>138.462997</td>\n",
       "      <td>2224900</td>\n",
       "      <td>PEP</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41104</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>138.919998</td>\n",
       "      <td>137.550003</td>\n",
       "      <td>130.316620</td>\n",
       "      <td>3261400</td>\n",
       "      <td>PG</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41105</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>372.339996</td>\n",
       "      <td>373.100006</td>\n",
       "      <td>371.570007</td>\n",
       "      <td>359.862762</td>\n",
       "      <td>49455300</td>\n",
       "      <td>SPY</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41106</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>65.519997</td>\n",
       "      <td>65.849998</td>\n",
       "      <td>65.389999</td>\n",
       "      <td>61.628376</td>\n",
       "      <td>1296400</td>\n",
       "      <td>XEL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21538.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16608 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close     volume  \\\n",
       "0     2010-01-04   39.099998   39.419998   38.840000   22.922108    2175500   \n",
       "4     2010-01-04   15.245000   15.350000   15.120000    9.583809    1332800   \n",
       "5     2010-01-04   61.189999   61.520000   60.639999   41.632233    6585900   \n",
       "6     2010-01-04   61.110001   61.310001   60.630001   41.181229    9190800   \n",
       "7     2010-01-04  112.370003  113.389999  111.510002   88.117897  118944600   \n",
       "...          ...         ...         ...         ...         ...        ...   \n",
       "41102 2020-12-30   50.520000   51.000000   50.360001   47.424179     563800   \n",
       "41103 2020-12-30  147.470001  147.990005  147.009995  138.462997    2224900   \n",
       "41104 2020-12-30  138.600006  138.919998  137.550003  130.316620    3261400   \n",
       "41105 2020-12-30  372.339996  373.100006  371.570007  359.862762   49455300   \n",
       "41106 2020-12-30   65.519997   65.849998   65.389999   61.628376    1296400   \n",
       "\n",
       "       tic  day  SentimentScore        gdp  \n",
       "0        D    0             0.0  14764.611  \n",
       "4      LNT    0             0.0  14764.611  \n",
       "5      PEP    0             0.0  14764.611  \n",
       "6       PG    0             0.0  14764.611  \n",
       "7      SPY    0             0.0  14764.611  \n",
       "...    ...  ...             ...        ...  \n",
       "41102  LNT    2             0.0  21538.032  \n",
       "41103  PEP    2             0.0  21538.032  \n",
       "41104   PG    2             0.0  21538.032  \n",
       "41105  SPY    2             0.0  21538.032  \n",
       "41106  XEL    2             0.0  21538.032  \n",
       "\n",
       "[16608 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_volatile_stocks = [\"XEL\",\"PG\",\"LNT\",\"PEP\",\"D\"]\n",
    "\n",
    "# Add index to both the stocks\n",
    "least_volatile_stocks.append(\"SPY\")\n",
    "\n",
    "df_lv = df[df[\"tic\"].isin(least_volatile_stocks)]\n",
    "\n",
    "df_lv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jejabAiBTfmM"
   },
   "source": [
    "#### Step 4: Incorporate Technical Indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GpfYW-sqDLU"
   },
   "source": [
    "> - #### Step 4.1: Use historical data to calculate technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6nrmtBVGSdgs"
   },
   "outputs": [],
   "source": [
    "technical_indicators = ['macd', 'rsi_30', 'cci_30', 'dx_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pusTbgzUTqHJ"
   },
   "outputs": [],
   "source": [
    "fe_pipeline = FeatureEngineer(use_technical_indicator=True, \n",
    "                              tech_indicator_list = technical_indicators, \n",
    "                              use_turbulence=True, \n",
    "                              user_defined_feature = True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qWolIyIaT_BV",
    "outputId": "30160e41-2ce7-4f62-b2b6-2e8d11f653aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n",
      "Successfully added user defined features\n"
     ]
    }
   ],
   "source": [
    "df_processed = fe_pipeline.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n",
      "Successfully added user defined features\n"
     ]
    }
   ],
   "source": [
    "df_mv_processed = fe_pipeline.preprocess_data(df_mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n",
      "/Users/venkatapraneethdonaparthi/Documents/Data606-TeamGenie/./FinRL/finrl/meta/preprocessor/preprocessors.py:158: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  indicator_df = indicator_df.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n",
      "Successfully added user defined features\n"
     ]
    }
   ],
   "source": [
    "df_lv_processed = fe_pipeline.preprocess_data(df_lv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDR3MHqFlcUJ"
   },
   "source": [
    "#### Step 5:  Design Environment constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztF9rZzOqSy0"
   },
   "source": [
    "> - #### Step 5.1: Define environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "udfs = 2 # Sentiment Scores, GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6J0lQWUUFZ3",
    "outputId": "f3b46b7e-53b6-4ff2-9525-bd346abc8b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 9, state Space: 73\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(df_processed.tic.unique())\n",
    "\n",
    "state_space = 1 + 2 * stock_dimension + len(technical_indicators)*stock_dimension + udfs*stock_dimension\n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension}, state Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 4, state Space: 33\n"
     ]
    }
   ],
   "source": [
    "stock_dimension_mv = len(df_mv_processed.tic.unique())\n",
    "\n",
    "state_space_mv = 1 + 2 * stock_dimension_mv + len(technical_indicators)*stock_dimension_mv + udfs*stock_dimension_mv\n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension_mv}, state Space: {state_space_mv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 6, state Space: 49\n"
     ]
    }
   ],
   "source": [
    "stock_dimension_lv = len(df_lv_processed.tic.unique())\n",
    "\n",
    "state_space_lv = 1 + 2 * stock_dimension_lv + len(technical_indicators)*stock_dimension_lv + udfs*stock_dimension_lv\n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension_lv}, state Space: {state_space_lv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1-0s3GHBl-FQ"
   },
   "outputs": [],
   "source": [
    "technical_indicators.extend([\"SentimentScore\",\"gdp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "EJNQ1TXGmqnp"
   },
   "outputs": [],
   "source": [
    "# Defining a dictionary containing environment arguments\n",
    "\n",
    "env_variables = { \"hmax\": 100,                        # Maximum number of shares that can be traded at a time\n",
    "                  \"buy_cost_pct\": 0.001,              # Transaction cost for buying\n",
    "                  \"sell_cost_pct\": 0.001,             # Transaction cost for selling\n",
    "                  \"state_space\": state_space,         # State space for the environment\n",
    "                  \"tech_indicator_list\": technical_indicators,  # List of technical indicators used\n",
    "                  \"action_space\": stock_dimension,    # Action space for the environment\n",
    "                  \"reward_scaling\": 1e-4,             # Scaling factor for rewards\n",
    "                  \"print_verbosity\": 5                # Level of detail for logging during training\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dictionary containing environment arguments\n",
    "\n",
    "env_variables_mv = { \"hmax\": 100,                        # Maximum number of shares that can be traded at a time\n",
    "                  \"buy_cost_pct\": 0.001,              # Transaction cost for buying\n",
    "                  \"sell_cost_pct\": 0.001,             # Transaction cost for selling\n",
    "                  \"state_space\": state_space_mv,         # State space for the environment\n",
    "                  \"tech_indicator_list\": technical_indicators,  # List of technical indicators used\n",
    "                  \"action_space\": stock_dimension_mv,    # Action space for the environment\n",
    "                  \"reward_scaling\": 1e-4,             # Scaling factor for rewards\n",
    "                  \"print_verbosity\": 5                # Level of detail for logging during training\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dictionary containing environment arguments\n",
    "\n",
    "env_variables_lv = { \"hmax\": 100,                        # Maximum number of shares that can be traded at a time\n",
    "                  \"buy_cost_pct\": 0.001,              # Transaction cost for buying\n",
    "                  \"sell_cost_pct\": 0.001,             # Transaction cost for selling\n",
    "                  \"state_space\": state_space_lv,         # State space for the environment\n",
    "                  \"tech_indicator_list\": technical_indicators,  # List of technical indicators used\n",
    "                  \"action_space\": stock_dimension_lv,    # Action space for the environment\n",
    "                  \"reward_scaling\": 1e-4,             # Scaling factor for rewards\n",
    "                  \"print_verbosity\": 5                # Level of detail for logging during training\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGZ4QnPLrW_N"
   },
   "source": [
    "> - #### Step 5.2: Define A2C model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "GvzaGen2r4CE"
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yHV8PBWrWun"
   },
   "source": [
    "> -  #### Step 5.3: Define PPO model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "uxptBXIar91A"
   },
   "outputs": [],
   "source": [
    "PPO_model_kwargs = { \"ent_coef\": 0.01, \"n_steps\": 2048, \"learning_rate\": 0.00025, \"batch_size\": 128 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyDKWItvrWlR"
   },
   "source": [
    "> - #### Step 5.4: Define DDPG model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7Znj3spJsFYI"
   },
   "outputs": [],
   "source": [
    "DDPG_model_kwargs = { \"buffer_size\": 10_000, \"learning_rate\": 0.0005, \"batch_size\":64 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2z-ad2wrWS4"
   },
   "source": [
    "> - #### Step 5.5: Define timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "aH3Nots0sLDq"
   },
   "outputs": [],
   "source": [
    "timesteps_dict = { 'a2c': 10_000, 'ppo': 10_000, 'ddpg': 10_000 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_UaT149r1Y0"
   },
   "source": [
    "> - #### Step 5.6: Define ensemble agent parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "m4YLBeq8sQGc"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63\n",
    "validation_window = 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - #### Step 5.7: Define test dates dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the datest to which the testing predictions. \n",
    "test_dates = df_processed[(df_processed.date > TEST_START_DATE)&(df_processed.date <= TEST_END_DATE)].date.unique()\n",
    "\n",
    "trade_date_df = pd.DataFrame({'datadate':test_dates}) # Convert the dates to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "DLvv-dSjsVv-"
   },
   "outputs": [],
   "source": [
    "ensemble_agent = DRLEnsembleAgent(initial_amount = 10000,\n",
    "                                  stock_dim = stock_dimension,\n",
    "                                  df = df_processed,\n",
    "                                  train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                                  val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                                  rebalance_window=rebalance_window,\n",
    "                                  validation_window=validation_window,\n",
    "                                  **env_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_agent_mv = DRLEnsembleAgent(initial_amount = 10000,\n",
    "                                  stock_dim = stock_dimension_mv,\n",
    "                                  df = df_processed,\n",
    "                                  train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                                  val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                                  rebalance_window=rebalance_window,\n",
    "                                  validation_window=validation_window,\n",
    "                                  **env_variables_mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_agent_lv = DRLEnsembleAgent(initial_amount = 10000,\n",
    "                                  stock_dim = stock_dimension_lv,\n",
    "                                  df = df_processed,\n",
    "                                  train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                                  val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                                  rebalance_window=rebalance_window,\n",
    "                                  validation_window=validation_window,\n",
    "                                  **env_variables_lv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXPiP6ybqZh3"
   },
   "source": [
    "#### Step 6: Implement Deep Reinforcement Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nGsa7SltetS"
   },
   "source": [
    "> - #### Step 6.1: Build and train a deep reinforcement learning model using the environment and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> - #### Step 6.1.1: Model with top voalatile 5 and least volatile 5 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPjSkaADm4lF",
    "outputId": "9eeb1d11-c118-414f-9227-ecd009ce9271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-01-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_14\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 347        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -0.0906    |\n",
      "|    reward             | 0.00148673 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 5.66e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.441       |\n",
      "|    reward             | -0.007437469 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.00154      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 305           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.6         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | 0.0564        |\n",
      "|    reward             | -0.0127669675 |\n",
      "|    std                | 1.1           |\n",
      "|    value_loss         | 0.000257      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 305           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 6             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.242         |\n",
      "|    reward             | -0.0054096207 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 0.000433      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 288          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.325        |\n",
      "|    reward             | 0.0018927528 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 0.000421     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0543      |\n",
      "|    reward             | 0.0008600382 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 1.56e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 271           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.171         |\n",
      "|    reward             | -0.0005264137 |\n",
      "|    std                | 1.26          |\n",
      "|    value_loss         | 0.000228      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 270           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.00497       |\n",
      "|    reward             | -0.0035007154 |\n",
      "|    std                | 1.32          |\n",
      "|    value_loss         | 3.01e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 271          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.085       |\n",
      "|    reward             | -0.003617524 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 2.74e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 271         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.0853     |\n",
      "|    reward             | 0.005462748 |\n",
      "|    std                | 1.45        |\n",
      "|    value_loss         | 3.51e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 273          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.0411       |\n",
      "|    reward             | 0.0126620075 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 2.5e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 276         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 0.0185      |\n",
      "|    reward             | 0.008237795 |\n",
      "|    std                | 1.6         |\n",
      "|    value_loss         | 2.37e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 279           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.203         |\n",
      "|    reward             | -0.0033641323 |\n",
      "|    std                | 1.66          |\n",
      "|    value_loss         | 0.000154      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 284           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.177         |\n",
      "|    reward             | -0.0013464786 |\n",
      "|    std                | 1.73          |\n",
      "|    value_loss         | 0.00015       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 0.103      |\n",
      "|    reward             | 0.01233903 |\n",
      "|    std                | 1.8        |\n",
      "|    value_loss         | 4.2e-05    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 291          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.0422       |\n",
      "|    reward             | 0.0013131774 |\n",
      "|    std                | 1.87         |\n",
      "|    value_loss         | 1.37e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 294          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.067        |\n",
      "|    reward             | 0.0031994584 |\n",
      "|    std                | 1.95         |\n",
      "|    value_loss         | 5.35e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 297         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.00224     |\n",
      "|    reward             | 0.002014945 |\n",
      "|    std                | 2.04        |\n",
      "|    value_loss         | 7.77e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 300          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.141        |\n",
      "|    reward             | 0.0072711757 |\n",
      "|    std                | 2.15         |\n",
      "|    value_loss         | 6.41e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 33           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.00458     |\n",
      "|    reward             | 0.0010470741 |\n",
      "|    std                | 2.24         |\n",
      "|    value_loss         | 1.15e-05     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.1888098936928092\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_14\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 452          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0012964134 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 434           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010103057   |\n",
      "|    clip_fraction        | 0.155         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.0058       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.126        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00586      |\n",
      "|    reward               | -0.0014513393 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00237       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 423          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006563967  |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0369       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.124       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    reward               | -0.007909881 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0017       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 424          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065179663 |\n",
      "|    clip_fraction        | 0.0692       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.135       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | 0.0029718948 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00112      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2012, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 2264.98\n",
      "total_reward: -7735.02\n",
      "total_cost: 3879.24\n",
      "total_trades: 11741\n",
      "Sharpe: -0.438\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 420           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007411806   |\n",
      "|    clip_fraction        | 0.101         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.231         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.138        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.0058       |\n",
      "|    reward               | -0.0016296586 |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 0.00078       |\n",
      "-------------------------------------------\n",
      "======PPO Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.4197534100339176\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_14\n",
      "day: 2012, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10002.07\n",
      "total_reward: 2.07\n",
      "total_cost: 9.99\n",
      "total_trades: 12072\n",
      "Sharpe: 0.224\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 150           |\n",
      "|    time_elapsed    | 53            |\n",
      "|    total_timesteps | 8052          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 164           |\n",
      "|    critic_loss     | 139           |\n",
      "|    learning_rate   | 0.0005        |\n",
      "|    n_updates       | 6039          |\n",
      "|    reward          | -0.0019547748 |\n",
      "--------------------------------------\n",
      "======DDPG Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======Trading from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.0533       |\n",
      "|    reward             | -0.0036039797 |\n",
      "|    std                | 1.05          |\n",
      "|    value_loss         | 3.61e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.364       |\n",
      "|    reward             | 0.0041586948 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.0011       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0.0427      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.171      |\n",
      "|    reward             | 0.014510369 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.000257    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 344         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.183       |\n",
      "|    reward             | -0.01123381 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.000413    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 341           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.0871        |\n",
      "|    reward             | -0.0028996987 |\n",
      "|    std                | 1.18          |\n",
      "|    value_loss         | 6e-05         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 345            |\n",
      "|    iterations         | 600            |\n",
      "|    time_elapsed       | 8              |\n",
      "|    total_timesteps    | 3000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.6          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 599            |\n",
      "|    policy_loss        | -0.0801        |\n",
      "|    reward             | -0.00093707425 |\n",
      "|    std                | 1.23           |\n",
      "|    value_loss         | 3.73e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 347          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.754       |\n",
      "|    reward             | -0.001841748 |\n",
      "|    std                | 1.28         |\n",
      "|    value_loss         | 0.00266      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 346           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.254        |\n",
      "|    reward             | -0.0086506205 |\n",
      "|    std                | 1.32          |\n",
      "|    value_loss         | 0.000277      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 345          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.192       |\n",
      "|    reward             | 0.0039260425 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 0.0002       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 347           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.122        |\n",
      "|    reward             | -0.0017878871 |\n",
      "|    std                | 1.44          |\n",
      "|    value_loss         | 0.000124      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 349         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.317      |\n",
      "|    reward             | 0.014162571 |\n",
      "|    std                | 1.48        |\n",
      "|    value_loss         | 0.000533    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 347          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.175       |\n",
      "|    reward             | 0.0016982609 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 0.00013      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 349          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.0537       |\n",
      "|    reward             | 0.0059827734 |\n",
      "|    std                | 1.56         |\n",
      "|    value_loss         | 1.96e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 347           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.124         |\n",
      "|    reward             | 0.00013363609 |\n",
      "|    std                | 1.61          |\n",
      "|    value_loss         | 5.22e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 346          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.259       |\n",
      "|    reward             | -0.004000685 |\n",
      "|    std                | 1.67         |\n",
      "|    value_loss         | 0.000265     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 346          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.174       |\n",
      "|    reward             | 0.0019277385 |\n",
      "|    std                | 1.74         |\n",
      "|    value_loss         | 0.000123     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 347          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.0562       |\n",
      "|    reward             | 0.0028497728 |\n",
      "|    std                | 1.8          |\n",
      "|    value_loss         | 1.66e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 348          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.026       |\n",
      "|    reward             | 0.0016677723 |\n",
      "|    std                | 1.87         |\n",
      "|    value_loss         | 8.02e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 347         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.12       |\n",
      "|    reward             | 0.008758932 |\n",
      "|    std                | 1.95        |\n",
      "|    value_loss         | 7.47e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 348         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 0.222       |\n",
      "|    reward             | 0.004964596 |\n",
      "|    std                | 2.03        |\n",
      "|    value_loss         | 0.000153    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.21394911483334586\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_14\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 442          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0022853643 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 426           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005178038   |\n",
      "|    clip_fraction        | 0.0732        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -6.16         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.135        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00652      |\n",
      "|    reward               | -0.0037251648 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.0034        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 414          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048797205 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.144       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.13        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    reward               | 0.0012671791 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00591      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 414          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124058    |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | -0.0138      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.142       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    reward               | 0.0010752047 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00401      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 390           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 26            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009300869   |\n",
      "|    clip_fraction        | 0.0991        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -13           |\n",
      "|    explained_variance   | -0.00148      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.134        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00593      |\n",
      "|    reward               | -0.0014995169 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.00284       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.020959060910404195\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_14\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 144         |\n",
      "|    time_elapsed    | 57          |\n",
      "|    total_timesteps | 8304        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 820         |\n",
      "|    critic_loss     | 564         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6228        |\n",
      "|    reward          | 0.009755521 |\n",
      "------------------------------------\n",
      "day: 2075, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10016.05\n",
      "total_reward: 16.05\n",
      "total_cost: 9.99\n",
      "total_trades: 8300\n",
      "Sharpe: 0.215\n",
      "=================================\n",
      "======DDPG Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======Trading from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.805       |\n",
      "|    reward             | -0.019667242 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.00424      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.178        |\n",
      "|    reward             | -0.0020121501 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.000641      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.802       |\n",
      "|    reward             | -0.067140825 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.00524      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.336      |\n",
      "|    reward             | -0.03604416 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.000634    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | -0.124        |\n",
      "|    reward             | -0.0003861752 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 6.52e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -0.184      |\n",
      "|    reward             | 0.010630837 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.000268    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 298          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.358       |\n",
      "|    reward             | 0.0069516585 |\n",
      "|    std                | 1.19         |\n",
      "|    value_loss         | 0.000691     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -0.249      |\n",
      "|    reward             | 0.005586974 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 0.000362    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 301         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.0252      |\n",
      "|    reward             | 0.010975536 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 3.13e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 303           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.4          |\n",
      "|    reward             | -0.0014913196 |\n",
      "|    std                | 1.3           |\n",
      "|    value_loss         | 0.000719      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 0.229       |\n",
      "|    reward             | 0.010115338 |\n",
      "|    std                | 1.35        |\n",
      "|    value_loss         | 0.000288    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 0.301       |\n",
      "|    reward             | 0.053798888 |\n",
      "|    std                | 1.4         |\n",
      "|    value_loss         | 0.000398    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.127       |\n",
      "|    reward             | -0.007655411 |\n",
      "|    std                | 1.44         |\n",
      "|    value_loss         | 6.45e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 304           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.0221        |\n",
      "|    reward             | -6.695967e-05 |\n",
      "|    std                | 1.48          |\n",
      "|    value_loss         | 9.61e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0346       |\n",
      "|    reward             | 0.0042787385 |\n",
      "|    std                | 1.55         |\n",
      "|    value_loss         | 8.7e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 0.0775      |\n",
      "|    reward             | 0.002457706 |\n",
      "|    std                | 1.63        |\n",
      "|    value_loss         | 2.65e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.0288      |\n",
      "|    reward             | 0.008273162 |\n",
      "|    std                | 1.7         |\n",
      "|    value_loss         | 2.23e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.107       |\n",
      "|    reward             | 0.010109522 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 4.43e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0315      |\n",
      "|    reward             | -0.010231831 |\n",
      "|    std                | 1.85         |\n",
      "|    value_loss         | 1.65e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.0998       |\n",
      "|    reward             | 0.0042681894 |\n",
      "|    std                | 1.93         |\n",
      "|    value_loss         | 7.44e-05     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.16329683068254838\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_14\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 429         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 4           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.00259806 |\n",
      "------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 407            |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0058873976   |\n",
      "|    clip_fraction        | 0.071          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | -7.36          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.118         |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | -0.00426       |\n",
      "|    reward               | -0.00050354825 |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 0.000827       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 406           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006442247   |\n",
      "|    clip_fraction        | 0.0545        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0208        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.134        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00412      |\n",
      "|    reward               | 0.00041044477 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000223      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 402           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006098495   |\n",
      "|    clip_fraction        | 0.0466        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.522         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.135        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00343      |\n",
      "|    reward               | -8.835614e-06 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000145      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 401          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068786647 |\n",
      "|    clip_fraction        | 0.0944       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.133       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00806     |\n",
      "|    reward               | 0.001961736  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0002       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.10603764692768342\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_14\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 156          |\n",
      "|    time_elapsed    | 54           |\n",
      "|    total_timesteps | 8556         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 325          |\n",
      "|    critic_loss     | 206          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6417         |\n",
      "|    reward          | 0.0061400305 |\n",
      "-------------------------------------\n",
      "day: 2138, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10017.30\n",
      "total_reward: 17.30\n",
      "total_cost: 9.99\n",
      "total_trades: 17104\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "======DDPG Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======Trading from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 296          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.578       |\n",
      "|    reward             | -0.014024737 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.00186      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -0.264     |\n",
      "|    reward             | 0.00742042 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.0011     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.735       |\n",
      "|    reward             | -0.057086095 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.00473      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.508      |\n",
      "|    reward             | 0.017073568 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.00233     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.0338      |\n",
      "|    reward             | -0.011477794 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 0.0771      |\n",
      "|    reward             | 0.003558223 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 6.21e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.0389       |\n",
      "|    reward             | -0.0034360795 |\n",
      "|    std                | 1.15          |\n",
      "|    value_loss         | 2.75e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.139        |\n",
      "|    reward             | -0.002785903 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 0.000176     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.223        |\n",
      "|    reward             | 0.0027046436 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 0.000618     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.134       |\n",
      "|    reward             | -0.009160909 |\n",
      "|    std                | 1.27         |\n",
      "|    value_loss         | 0.000256     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.143        |\n",
      "|    reward             | 0.00010976344 |\n",
      "|    std                | 1.31          |\n",
      "|    value_loss         | 9.03e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 326        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -0.35      |\n",
      "|    reward             | 0.01261063 |\n",
      "|    std                | 1.34       |\n",
      "|    value_loss         | 0.000609   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 0.0562      |\n",
      "|    reward             | -0.05418953 |\n",
      "|    std                | 1.37        |\n",
      "|    value_loss         | 9.27e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.0293      |\n",
      "|    reward             | -0.012739931 |\n",
      "|    std                | 1.4          |\n",
      "|    value_loss         | 2.49e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.128       |\n",
      "|    reward             | -0.004417859 |\n",
      "|    std                | 1.43         |\n",
      "|    value_loss         | 8.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.379        |\n",
      "|    reward             | -0.004024548 |\n",
      "|    std                | 1.47         |\n",
      "|    value_loss         | 0.000906     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.0813       |\n",
      "|    reward             | -0.0035972672 |\n",
      "|    std                | 1.5           |\n",
      "|    value_loss         | 6.54e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.142        |\n",
      "|    reward             | -0.0006092533 |\n",
      "|    std                | 1.54          |\n",
      "|    value_loss         | 8.88e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | -0.00241      |\n",
      "|    reward             | 0.00081975653 |\n",
      "|    std                | 1.59          |\n",
      "|    value_loss         | 1.61e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.0691       |\n",
      "|    reward             | -0.001467772 |\n",
      "|    std                | 1.65         |\n",
      "|    value_loss         | 1.69e-05     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.1655915539551398\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_14\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 418           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0013291889 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 401          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006322392  |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -6.73        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.152       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | -0.001752361 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00298      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 392           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010333696   |\n",
      "|    clip_fraction        | 0.146         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.107        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.137        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00574      |\n",
      "|    reward               | -0.0014463691 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00199       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 395           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0062947404  |\n",
      "|    clip_fraction        | 0.0646        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.0423       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.123        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00391      |\n",
      "|    reward               | -7.706404e-05 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00143       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 391          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076493896 |\n",
      "|    clip_fraction        | 0.094        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.00284     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.143       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | 0.0028143043 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00111      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.11650387180926587\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_14\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 152          |\n",
      "|    time_elapsed    | 57           |\n",
      "|    total_timesteps | 8808         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -592         |\n",
      "|    critic_loss     | 354          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6606         |\n",
      "|    reward          | 0.0012483567 |\n",
      "-------------------------------------\n",
      "day: 2201, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 13206\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "======DDPG Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======Trading from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0144      |\n",
      "|    reward             | 0.0046224548 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 2.37e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 0.00819      |\n",
      "|    reward             | -0.005270586 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.000123     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.0177       |\n",
      "|    reward             | -0.0053986227 |\n",
      "|    std                | 1.09          |\n",
      "|    value_loss         | 0.000249      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.323       |\n",
      "|    reward             | -0.032682538 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.000623     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.0954        |\n",
      "|    reward             | -0.0009232489 |\n",
      "|    std                | 1.14          |\n",
      "|    value_loss         | 3.83e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.104         |\n",
      "|    reward             | -0.0034392807 |\n",
      "|    std                | 1.17          |\n",
      "|    value_loss         | 5.85e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 337         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.0358      |\n",
      "|    reward             | 0.009571745 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 1.07e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.115       |\n",
      "|    reward             | -0.000915213 |\n",
      "|    std                | 1.27         |\n",
      "|    value_loss         | 0.000481     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | 0.163         |\n",
      "|    reward             | -0.0042436966 |\n",
      "|    std                | 1.31          |\n",
      "|    value_loss         | 0.000102      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.108      |\n",
      "|    reward             | 0.007985272 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 5.81e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.0324      |\n",
      "|    reward             | 0.0010363541 |\n",
      "|    std                | 1.43         |\n",
      "|    value_loss         | 1.09e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.206         |\n",
      "|    reward             | 0.00063737907 |\n",
      "|    std                | 1.5           |\n",
      "|    value_loss         | 0.000165      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.157        |\n",
      "|    reward             | -0.0035723494 |\n",
      "|    std                | 1.57          |\n",
      "|    value_loss         | 9.54e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.00384       |\n",
      "|    reward             | 0.00024933828 |\n",
      "|    std                | 1.65          |\n",
      "|    value_loss         | 5.21e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.145       |\n",
      "|    reward             | 0.0007276757 |\n",
      "|    std                | 1.73         |\n",
      "|    value_loss         | 6.87e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.0857       |\n",
      "|    reward             | 0.0006816502 |\n",
      "|    std                | 1.82         |\n",
      "|    value_loss         | 4.21e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 338           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.213        |\n",
      "|    reward             | -0.0036866232 |\n",
      "|    std                | 1.9           |\n",
      "|    value_loss         | 0.000141      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 338           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 26            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.062        |\n",
      "|    reward             | -0.0014277719 |\n",
      "|    std                | 2             |\n",
      "|    value_loss         | 1.89e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.098       |\n",
      "|    reward             | -0.003638342 |\n",
      "|    std                | 2.09         |\n",
      "|    value_loss         | 5.12e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.117         |\n",
      "|    reward             | -0.0035941259 |\n",
      "|    std                | 2.19          |\n",
      "|    value_loss         | 7.23e-05      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.4849395264566774\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_14\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 447           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0029877175 |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 429           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012449149   |\n",
      "|    clip_fraction        | 0.166         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -11.4         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.118        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00832      |\n",
      "|    reward               | -0.0033562486 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00155       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 424          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060860496 |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0881       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.125       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | 0.0010151935 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000269     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009763582  |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.132       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.144       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    reward               | -0.009572149 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000285     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 418           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0042245984  |\n",
      "|    clip_fraction        | 0.0413        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.603        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.124        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00284      |\n",
      "|    reward               | 0.00057855365 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000454      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.29696154431891797\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_14\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 154          |\n",
      "|    time_elapsed    | 58           |\n",
      "|    total_timesteps | 9060         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -540         |\n",
      "|    critic_loss     | 287          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6795         |\n",
      "|    reward          | 0.0005528295 |\n",
      "-------------------------------------\n",
      "day: 2264, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 11320\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "======DDPG Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======Trading from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -0.786      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.00371     |\n",
      "|    reward             | 0.014478844 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.000122    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 0.0426       |\n",
      "|    reward             | -0.003100215 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.000101     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.079        |\n",
      "|    reward             | -0.0010098814 |\n",
      "|    std                | 1.1           |\n",
      "|    value_loss         | 0.000284      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.43        |\n",
      "|    reward             | -0.043945923 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.00107      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.075        |\n",
      "|    reward             | 0.0034152719 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 4.12e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0675      |\n",
      "|    reward             | 0.0007986474 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 4.16e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.0207      |\n",
      "|    reward             | 0.003368969 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 9.46e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.143       |\n",
      "|    reward             | 0.000548317 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 0.000126    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.055      |\n",
      "|    reward             | 0.010067221 |\n",
      "|    std                | 1.32        |\n",
      "|    value_loss         | 2.4e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.0363      |\n",
      "|    reward             | 0.0007767868 |\n",
      "|    std                | 1.37         |\n",
      "|    value_loss         | 8.49e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.208        |\n",
      "|    reward             | -0.0029276132 |\n",
      "|    std                | 1.44          |\n",
      "|    value_loss         | 0.000214      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 324            |\n",
      "|    iterations         | 1200           |\n",
      "|    time_elapsed       | 18             |\n",
      "|    total_timesteps    | 6000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1199           |\n",
      "|    policy_loss        | -0.121         |\n",
      "|    reward             | -0.00037218095 |\n",
      "|    std                | 1.52           |\n",
      "|    value_loss         | 5.59e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.0443        |\n",
      "|    reward             | 0.00012286224 |\n",
      "|    std                | 1.6           |\n",
      "|    value_loss         | 9.43e-06      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.025        |\n",
      "|    reward             | 0.0023521422 |\n",
      "|    std                | 1.68         |\n",
      "|    value_loss         | 1.05e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | -0.269        |\n",
      "|    reward             | 0.00020851745 |\n",
      "|    std                | 1.75          |\n",
      "|    value_loss         | 0.000234      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.152        |\n",
      "|    reward             | 0.0041999845 |\n",
      "|    std                | 1.84         |\n",
      "|    value_loss         | 0.000122     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.0683     |\n",
      "|    reward             | -0.00392654 |\n",
      "|    std                | 1.91        |\n",
      "|    value_loss         | 6.25e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.117        |\n",
      "|    reward             | -0.008811108 |\n",
      "|    std                | 1.97         |\n",
      "|    value_loss         | 7.22e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 0.0328      |\n",
      "|    reward             | 0.004565713 |\n",
      "|    std                | 2.02        |\n",
      "|    value_loss         | 9.71e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.121      |\n",
      "|    reward             | 0.001082987 |\n",
      "|    std                | 2.09        |\n",
      "|    value_loss         | 4.85e-05    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.3354107716002741\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_14\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 424           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0006613625 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 408          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066520544 |\n",
      "|    clip_fraction        | 0.0872       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -4.12        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.143       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    reward               | 0.0002003679 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000665     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007371242  |\n",
      "|    clip_fraction        | 0.072        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.612       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.131       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | 0.0043285373 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000462     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006911836  |\n",
      "|    clip_fraction        | 0.0566       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.137        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.141       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | 0.0014189541 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000229     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 401           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008777626   |\n",
      "|    clip_fraction        | 0.0923        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.349         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.154        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00892      |\n",
      "|    reward               | -0.0010170436 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000186      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.3106501657943436\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_14\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 148           |\n",
      "|    time_elapsed    | 62            |\n",
      "|    total_timesteps | 9312          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -142          |\n",
      "|    critic_loss     | 152           |\n",
      "|    learning_rate   | 0.0005        |\n",
      "|    n_updates       | 6984          |\n",
      "|    reward          | -0.0021728799 |\n",
      "--------------------------------------\n",
      "day: 2327, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.02\n",
      "total_reward: -9.98\n",
      "total_cost: 9.98\n",
      "total_trades: 11635\n",
      "Sharpe: 0.205\n",
      "=================================\n",
      "======DDPG Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======Trading from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 290           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | 0.117         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.0602       |\n",
      "|    reward             | -0.0055823503 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 3.65e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | 0.281        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.207       |\n",
      "|    reward             | -0.001528027 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.000309     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 302           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | 0.0992        |\n",
      "|    reward             | -0.0124205975 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.000172      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.00431    |\n",
      "|    reward             | 0.002799403 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 8.45e-07    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.0773      |\n",
      "|    reward             | 0.014130031 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 7.07e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 305            |\n",
      "|    iterations         | 600            |\n",
      "|    time_elapsed       | 9              |\n",
      "|    total_timesteps    | 3000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.5          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 599            |\n",
      "|    policy_loss        | 0.0933         |\n",
      "|    reward             | -0.00015370917 |\n",
      "|    std                | 1.21           |\n",
      "|    value_loss         | 6.77e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 305           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.161         |\n",
      "|    reward             | 0.00012756478 |\n",
      "|    std                | 1.26          |\n",
      "|    value_loss         | 0.000122      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.262        |\n",
      "|    reward             | 0.00055422296 |\n",
      "|    std                | 1.32          |\n",
      "|    value_loss         | 0.000324      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.118       |\n",
      "|    reward             | 0.011153956 |\n",
      "|    std                | 1.37        |\n",
      "|    value_loss         | 0.000135    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.0593       |\n",
      "|    reward             | -0.004784335 |\n",
      "|    std                | 1.41         |\n",
      "|    value_loss         | 1.48e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.2         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.0538        |\n",
      "|    reward             | -0.0019257882 |\n",
      "|    std                | 1.47          |\n",
      "|    value_loss         | 1.3e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.102         |\n",
      "|    reward             | -0.0015862302 |\n",
      "|    std                | 1.54          |\n",
      "|    value_loss         | 4.38e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.0113        |\n",
      "|    reward             | 0.00029114273 |\n",
      "|    std                | 1.63          |\n",
      "|    value_loss         | 6e-06         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.0722      |\n",
      "|    reward             | 0.010035471 |\n",
      "|    std                | 1.71        |\n",
      "|    value_loss         | 5.83e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0567      |\n",
      "|    reward             | 0.0036078242 |\n",
      "|    std                | 1.79         |\n",
      "|    value_loss         | 2.61e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.00374     |\n",
      "|    reward             | 0.0024612735 |\n",
      "|    std                | 1.87         |\n",
      "|    value_loss         | 1.68e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.0973      |\n",
      "|    reward             | 0.0025655925 |\n",
      "|    std                | 1.97         |\n",
      "|    value_loss         | 3.39e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.201       |\n",
      "|    reward             | -0.001303415 |\n",
      "|    std                | 2.06         |\n",
      "|    value_loss         | 0.000127     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0249      |\n",
      "|    reward             | -0.004764693 |\n",
      "|    std                | 2.14         |\n",
      "|    value_loss         | 0.000108     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 33           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.154        |\n",
      "|    reward             | 0.0022123528 |\n",
      "|    std                | 2.21         |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.066772732800913\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_13\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 375          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 5            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.009867439 |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005905303  |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -2.14        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.133       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0072      |\n",
      "|    reward               | -0.003139344 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000811     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 333           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0058143595  |\n",
      "|    clip_fraction        | 0.0774        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.069         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.133        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00445      |\n",
      "|    reward               | -0.0007744817 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000535      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 315           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005615983   |\n",
      "|    clip_fraction        | 0.0525        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.497         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.143        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00325      |\n",
      "|    reward               | 0.00015467091 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000268      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 321           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 31            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0061884965  |\n",
      "|    clip_fraction        | 0.069         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.13         |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00457      |\n",
      "|    reward               | -0.0007547532 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000158      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.03534415884920519\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_13\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 137        |\n",
      "|    time_elapsed    | 69         |\n",
      "|    total_timesteps | 9564       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -173       |\n",
      "|    critic_loss     | 62.8       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 7173       |\n",
      "|    reward          | 0.00864421 |\n",
      "-----------------------------------\n",
      "day: 2390, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10011.70\n",
      "total_reward: 11.70\n",
      "total_cost: 9.99\n",
      "total_trades: 14340\n",
      "Sharpe: 0.254\n",
      "=================================\n",
      "======DDPG Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======Trading from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_567_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.0253     |\n",
      "|    reward             | 0.003405759 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 2.44e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.3         |\n",
      "|    explained_variance | -0.0991       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.102        |\n",
      "|    reward             | -0.0019512329 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.000461      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 2.38e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.0848      |\n",
      "|    reward             | -0.009883964 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.000313     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.203       |\n",
      "|    reward             | -0.018774023 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.000292     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.00926     |\n",
      "|    reward             | 0.0007700381 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 8.72e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.0183       |\n",
      "|    reward             | -0.002169101 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 7.85e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.0894        |\n",
      "|    reward             | -0.0068034204 |\n",
      "|    std                | 1.19          |\n",
      "|    value_loss         | 4.45e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.159        |\n",
      "|    reward             | 0.0071422816 |\n",
      "|    std                | 1.24         |\n",
      "|    value_loss         | 0.000195     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.394        |\n",
      "|    reward             | -0.011430777 |\n",
      "|    std                | 1.28         |\n",
      "|    value_loss         | 0.000902     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.0338      |\n",
      "|    reward             | 0.0026870784 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 5.57e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.0396       |\n",
      "|    reward             | -0.0015527046 |\n",
      "|    std                | 1.37          |\n",
      "|    value_loss         | 8.55e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.0786      |\n",
      "|    reward             | 0.0074293893 |\n",
      "|    std                | 1.43         |\n",
      "|    value_loss         | 2.92e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -0.305      |\n",
      "|    reward             | 0.008435479 |\n",
      "|    std                | 1.49        |\n",
      "|    value_loss         | 0.000626    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.263       |\n",
      "|    reward             | 0.009643095 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 0.000379    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0206       |\n",
      "|    reward             | 0.0043509942 |\n",
      "|    std                | 1.61         |\n",
      "|    value_loss         | 2.87e-06     |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 323             |\n",
      "|    iterations         | 1600            |\n",
      "|    time_elapsed       | 24              |\n",
      "|    total_timesteps    | 8000            |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -17.4           |\n",
      "|    explained_variance | 1.79e-07        |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 1599            |\n",
      "|    policy_loss        | -0.00581        |\n",
      "|    reward             | -0.000119395445 |\n",
      "|    std                | 1.67            |\n",
      "|    value_loss         | 1.87e-06        |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 26            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.0806       |\n",
      "|    reward             | -0.0030558472 |\n",
      "|    std                | 1.76          |\n",
      "|    value_loss         | 4.04e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0788       |\n",
      "|    reward             | -0.008961951 |\n",
      "|    std                | 1.85         |\n",
      "|    value_loss         | 3.08e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 0.226       |\n",
      "|    reward             | 0.005367996 |\n",
      "|    std                | 1.95        |\n",
      "|    value_loss         | 0.000175    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.2         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.0279        |\n",
      "|    reward             | -0.0027723939 |\n",
      "|    std                | 2.05          |\n",
      "|    value_loss         | 4.02e-06      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.1032869467470738\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_567_13\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 413          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0012664861 |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 393          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005090408  |\n",
      "|    clip_fraction        | 0.0487       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -1.9         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.128       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | 0.0012318577 |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.000987     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 390          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006903679  |\n",
      "|    clip_fraction        | 0.0669       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.123       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    reward               | 0.0021165065 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000368     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 388            |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 21             |\n",
      "|    total_timesteps      | 8192           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0049320916   |\n",
      "|    clip_fraction        | 0.0503         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | 0.31           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.125         |\n",
      "|    n_updates            | 30             |\n",
      "|    policy_gradient_loss | -0.00437       |\n",
      "|    reward               | -0.00041135165 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.000242       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 386           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 26            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0055047246  |\n",
      "|    clip_fraction        | 0.0377        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.42          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.133        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00312      |\n",
      "|    reward               | -0.0027876145 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000266      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.11022751159492544\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_567_13\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 155          |\n",
      "|    time_elapsed    | 63           |\n",
      "|    total_timesteps | 9816         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 178          |\n",
      "|    critic_loss     | 72.4         |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 7362         |\n",
      "|    reward          | -0.024433248 |\n",
      "-------------------------------------\n",
      "day: 2453, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10034.34\n",
      "total_reward: 34.34\n",
      "total_cost: 9.99\n",
      "total_trades: 12265\n",
      "Sharpe: 0.240\n",
      "=================================\n",
      "======DDPG Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======Trading from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_630_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | 0.0256        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | 0.113         |\n",
      "|    reward             | -0.0060227816 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 0.00063       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 0.0422       |\n",
      "|    reward             | 0.0042142984 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 7.62e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.0865       |\n",
      "|    reward             | -0.031495452 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.00029      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 308           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 6             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.0247        |\n",
      "|    reward             | -0.0060132747 |\n",
      "|    std                | 1.1           |\n",
      "|    value_loss         | 4.68e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | -0.336        |\n",
      "|    reward             | -0.0020609333 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 0.000538      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.161        |\n",
      "|    reward             | -0.0025719705 |\n",
      "|    std                | 1.16          |\n",
      "|    value_loss         | 0.000181      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 312            |\n",
      "|    iterations         | 700            |\n",
      "|    time_elapsed       | 11             |\n",
      "|    total_timesteps    | 3500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 699            |\n",
      "|    policy_loss        | -0.11          |\n",
      "|    reward             | -0.00091746234 |\n",
      "|    std                | 1.2            |\n",
      "|    value_loss         | 6.64e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.0736      |\n",
      "|    reward             | 0.0002920456 |\n",
      "|    std                | 1.25         |\n",
      "|    value_loss         | 5.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.101       |\n",
      "|    reward             | 0.0028948765 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 7.77e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.0221      |\n",
      "|    reward             | 0.0031036937 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 7.19e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.056      |\n",
      "|    reward             | 0.001488489 |\n",
      "|    std                | 1.41        |\n",
      "|    value_loss         | 2.37e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0124       |\n",
      "|    reward             | 0.0005122753 |\n",
      "|    std                | 1.48         |\n",
      "|    value_loss         | 2.13e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.0186       |\n",
      "|    reward             | 0.0017458728 |\n",
      "|    std                | 1.57         |\n",
      "|    value_loss         | 4.2e-06      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.0402        |\n",
      "|    reward             | -0.0012203779 |\n",
      "|    std                | 1.66          |\n",
      "|    value_loss         | 1.2e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | -0.0158     |\n",
      "|    reward             | 0.003455955 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 3.1e-06     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.042        |\n",
      "|    reward             | -0.003426011 |\n",
      "|    std                | 1.85         |\n",
      "|    value_loss         | 1.6e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.0679      |\n",
      "|    reward             | 0.010135143 |\n",
      "|    std                | 1.94        |\n",
      "|    value_loss         | 1.78e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.00216       |\n",
      "|    reward             | 0.00020327764 |\n",
      "|    std                | 2.04          |\n",
      "|    value_loss         | 2.46e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0148      |\n",
      "|    reward             | 0.0014259401 |\n",
      "|    std                | 2.16         |\n",
      "|    value_loss         | 6.51e-07     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 31            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.2         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.0823       |\n",
      "|    reward             | -0.0005265794 |\n",
      "|    std                | 2.28          |\n",
      "|    value_loss         | 2.65e-05      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.3061137923689682\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_630_13\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 399           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 5             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0010708477 |\n",
      "--------------------------------------\n",
      "day: 2516, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 1847.46\n",
      "total_reward: -8152.54\n",
      "total_cost: 4368.22\n",
      "total_trades: 14350\n",
      "Sharpe: -0.247\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 390          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008713026  |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.162        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.138       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00764     |\n",
      "|    reward               | 0.0045060925 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000429     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 387          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069816746 |\n",
      "|    clip_fraction        | 0.0574       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.139       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 6.780031e-05 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000504     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 383           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0071335435  |\n",
      "|    clip_fraction        | 0.0774        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.402         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.121        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00582      |\n",
      "|    reward               | -0.0018378926 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000347      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 377          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071950955 |\n",
      "|    clip_fraction        | 0.0928       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.152       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    reward               | 0.0011460581 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000248     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.3290343846130804\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_630_13\n",
      "day: 2516, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 30653.42\n",
      "total_reward: 20653.42\n",
      "total_cost: 458.41\n",
      "total_trades: 10371\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 153          |\n",
      "|    time_elapsed    | 65           |\n",
      "|    total_timesteps | 10068        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 404          |\n",
      "|    critic_loss     | 199          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 7551         |\n",
      "|    reward          | -0.011896568 |\n",
      "-------------------------------------\n",
      "======DDPG Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======Trading from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_693_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 300         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.0225      |\n",
      "|    reward             | 0.010088916 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 3.48e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.121      |\n",
      "|    reward             | 0.001298847 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 7.31e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -0.0685    |\n",
      "|    reward             | 0.02517062 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 8.7e-05    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.143       |\n",
      "|    reward             | -0.017940797 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | -0.111        |\n",
      "|    reward             | -0.0077924123 |\n",
      "|    std                | 1.19          |\n",
      "|    value_loss         | 6.84e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 0.111       |\n",
      "|    reward             | -0.00525618 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 0.000122    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 313            |\n",
      "|    iterations         | 700            |\n",
      "|    time_elapsed       | 11             |\n",
      "|    total_timesteps    | 3500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15            |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 699            |\n",
      "|    policy_loss        | 0.0137         |\n",
      "|    reward             | -0.00065800134 |\n",
      "|    std                | 1.28           |\n",
      "|    value_loss         | 8.17e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.00998      |\n",
      "|    reward             | -0.0144526055 |\n",
      "|    std                | 1.34          |\n",
      "|    value_loss         | 3.02e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.164       |\n",
      "|    reward             | 0.0032994028 |\n",
      "|    std                | 1.4          |\n",
      "|    value_loss         | 0.000126     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.108        |\n",
      "|    reward             | 0.0018545034 |\n",
      "|    std                | 1.47         |\n",
      "|    value_loss         | 8.42e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.145        |\n",
      "|    reward             | 0.0044922717 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 9.34e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.07         |\n",
      "|    reward             | 0.0035616697 |\n",
      "|    std                | 1.58         |\n",
      "|    value_loss         | 1.72e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.019        |\n",
      "|    reward             | -0.002277075 |\n",
      "|    std                | 1.64         |\n",
      "|    value_loss         | 2.96e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.171       |\n",
      "|    reward             | 0.002754663 |\n",
      "|    std                | 1.7         |\n",
      "|    value_loss         | 0.000131    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.107       |\n",
      "|    reward             | 0.010150689 |\n",
      "|    std                | 1.74        |\n",
      "|    value_loss         | 0.000142    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -0.0394       |\n",
      "|    reward             | -0.0015625149 |\n",
      "|    std                | 1.78          |\n",
      "|    value_loss         | 1.05e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.177        |\n",
      "|    reward             | 0.0020633775 |\n",
      "|    std                | 1.83         |\n",
      "|    value_loss         | 0.000125     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0488       |\n",
      "|    reward             | -0.018646715 |\n",
      "|    std                | 1.91         |\n",
      "|    value_loss         | 1.87e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | -0.157        |\n",
      "|    reward             | -0.0072311335 |\n",
      "|    std                | 1.97          |\n",
      "|    value_loss         | 8.93e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.455      |\n",
      "|    reward             | 0.029576752 |\n",
      "|    std                | 2.03        |\n",
      "|    value_loss         | 0.000666    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.06347954520905136\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_693_13\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    fps             | 397            |\n",
      "|    iterations      | 1              |\n",
      "|    time_elapsed    | 5              |\n",
      "|    total_timesteps | 2048           |\n",
      "| train/             |                |\n",
      "|    reward          | -0.00064550096 |\n",
      "---------------------------------------\n",
      "day: 2579, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 1603.46\n",
      "total_reward: -8396.54\n",
      "total_cost: 7253.07\n",
      "total_trades: 15367\n",
      "Sharpe: -0.455\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 387           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0063832332  |\n",
      "|    clip_fraction        | 0.074         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -3.87         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.141        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00528      |\n",
      "|    reward               | -0.0023494547 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00765       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 371           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0060353978  |\n",
      "|    clip_fraction        | 0.0686        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.0125       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.142        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00547      |\n",
      "|    reward               | -0.0009861739 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000314      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 340          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005900155  |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.0722       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.129       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 0.0063434658 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00026      |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 325            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 31             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0067710746   |\n",
      "|    clip_fraction        | 0.0587         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.9          |\n",
      "|    explained_variance   | 0.0888         |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.124         |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.0042        |\n",
      "|    reward               | -0.00094537187 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.000306       |\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.13811925991317306\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_693_13\n",
      "day: 2579, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9994.04\n",
      "total_reward: -5.96\n",
      "total_cost: 9.99\n",
      "total_trades: 10316\n",
      "Sharpe: 0.231\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 146        |\n",
      "|    time_elapsed    | 70         |\n",
      "|    total_timesteps | 10320      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 310        |\n",
      "|    critic_loss     | 166        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 7740       |\n",
      "|    reward          | 0.03134072 |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-07-06T00:00:00.000000000\n",
      "======Trading from:  2020-07-06T00:00:00.000000000 to  2020-10-02T00:00:00.000000000\n",
      "Ensemble Strategy took:  24.884421416123708  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs, PPO_model_kwargs, DDPG_model_kwargs, timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.18881</td>\n",
       "      <td>-0.419753</td>\n",
       "      <td>-0.200898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.213949</td>\n",
       "      <td>-0.020959</td>\n",
       "      <td>0.197413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.163297</td>\n",
       "      <td>0.106038</td>\n",
       "      <td>0.400928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.165592</td>\n",
       "      <td>-0.116504</td>\n",
       "      <td>-0.216793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.48494</td>\n",
       "      <td>0.296962</td>\n",
       "      <td>0.69472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.335411</td>\n",
       "      <td>0.31065</td>\n",
       "      <td>0.406546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.066773</td>\n",
       "      <td>-0.035344</td>\n",
       "      <td>0.10168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.103287</td>\n",
       "      <td>0.110228</td>\n",
       "      <td>0.027765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.306114</td>\n",
       "      <td>-0.329034</td>\n",
       "      <td>-0.078555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.06348</td>\n",
       "      <td>0.138119</td>\n",
       "      <td>0.233644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter  Val Start    Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126 2018-01-02 2018-04-04        A2C   -0.18881  -0.419753   -0.200898\n",
       "1  189 2018-04-04 2018-07-03       DDPG  -0.213949  -0.020959    0.197413\n",
       "2  252 2018-07-03 2018-10-02       DDPG   0.163297   0.106038    0.400928\n",
       "3  315 2018-10-02 2019-01-03        A2C   0.165592  -0.116504   -0.216793\n",
       "4  378 2019-01-03 2019-04-04       DDPG    0.48494   0.296962     0.69472\n",
       "5  441 2019-04-04 2019-07-05       DDPG   0.335411    0.31065    0.406546\n",
       "6  504 2019-07-05 2019-10-03       DDPG   0.066773  -0.035344     0.10168\n",
       "7  567 2019-10-03 2020-01-03        PPO   0.103287   0.110228    0.027765\n",
       "8  630 2020-01-03 2020-04-03       DDPG  -0.306114  -0.329034   -0.078555\n",
       "9  693 2020-04-03 2020-07-06       DDPG    0.06348   0.138119    0.233644"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9998.908928</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>-0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9856.480908</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>-0.014244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9871.763478</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>0.001551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9923.765217</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>0.005268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>13268.863610</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>0.018593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>13419.964238</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>0.011388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>13358.774067</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>-0.004560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>13445.233043</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>0.006472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>13616.297390</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0.012723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     account_value        date  daily_return\n",
       "0     10000.000000  2018-04-04           NaN\n",
       "1      9998.908928  2018-04-05     -0.000109\n",
       "2      9856.480908  2018-04-06     -0.014244\n",
       "3      9871.763478  2018-04-09      0.001551\n",
       "4      9923.765217  2018-04-10      0.005268\n",
       "..             ...         ...           ...\n",
       "625   13268.863610  2020-09-25      0.018593\n",
       "626   13419.964238  2020-09-28      0.011388\n",
       "627   13358.774067  2020-09-29     -0.004560\n",
       "628   13445.233043  2020-09-30      0.006472\n",
       "629   13616.297390  2020-10-01      0.012723\n",
       "\n",
       "[630 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "# for every cycle (rebalance_window + validation_window) read the csv files into a dataframe\n",
    "for i in range(rebalance_window+validation_window, len(test_dates)+1,rebalance_window):\n",
    "     result_df = pd.read_csv(f'results/account_value_trade_ensemble_{i}.csv')\n",
    "     results_list.append(result_df)\n",
    "\n",
    "df_ensemble_results  = pd.concat(results_list, ignore_index=True)  # Create a dataframe to store execution results\n",
    "\n",
    "df_ensemble_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> - #### Step 6.1.2: Model with top voalatile 5 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-01-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_15\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 351           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.0432       |\n",
      "|    reward             | -0.0021420352 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 3.81e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0693      |\n",
      "|    reward             | 0.0041552307 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 5.35e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 349          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.18        |\n",
      "|    reward             | -0.013210306 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.000372     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 351           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 5             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.169         |\n",
      "|    reward             | 0.00044394642 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 0.000157      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 353         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.111       |\n",
      "|    reward             | 0.001483902 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 7.17e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 355           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.0855       |\n",
      "|    reward             | -0.0038064653 |\n",
      "|    std                | 1.2           |\n",
      "|    value_loss         | 3.61e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 352          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.172        |\n",
      "|    reward             | -0.003172609 |\n",
      "|    std                | 1.26         |\n",
      "|    value_loss         | 0.000192     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 354           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.161         |\n",
      "|    reward             | -0.0070364974 |\n",
      "|    std                | 1.31          |\n",
      "|    value_loss         | 0.00021       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 354           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.000371     |\n",
      "|    reward             | -0.0059488295 |\n",
      "|    std                | 1.37          |\n",
      "|    value_loss         | 1.16e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 353          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.027        |\n",
      "|    reward             | 0.0028925312 |\n",
      "|    std                | 1.44         |\n",
      "|    value_loss         | 3.37e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 353         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.22       |\n",
      "|    reward             | 0.004591012 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 0.00024     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 354          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0347       |\n",
      "|    reward             | 0.0027819928 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 1.52e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 355          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.199        |\n",
      "|    reward             | -0.009981338 |\n",
      "|    std                | 1.66         |\n",
      "|    value_loss         | 0.000161     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 353          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.11         |\n",
      "|    reward             | 0.0010098671 |\n",
      "|    std                | 1.74         |\n",
      "|    value_loss         | 5.77e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 355         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.0532      |\n",
      "|    reward             | 0.011582938 |\n",
      "|    std                | 1.84        |\n",
      "|    value_loss         | 2.26e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 355          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.000484     |\n",
      "|    reward             | 0.0006228899 |\n",
      "|    std                | 1.92         |\n",
      "|    value_loss         | 3.2e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 355         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.0488      |\n",
      "|    reward             | 0.003738687 |\n",
      "|    std                | 2           |\n",
      "|    value_loss         | 5.8e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 355          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.0553      |\n",
      "|    reward             | 0.0035775173 |\n",
      "|    std                | 2.1          |\n",
      "|    value_loss         | 1.07e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 355         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.211      |\n",
      "|    reward             | 0.007711441 |\n",
      "|    std                | 2.21        |\n",
      "|    value_loss         | 0.000115    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 355          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.0645      |\n",
      "|    reward             | 0.0010239758 |\n",
      "|    std                | 2.33         |\n",
      "|    value_loss         | 1.05e-05     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.1438177034745954\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_15\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 448          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0036949876 |\n",
      "-------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 431            |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0064464016   |\n",
      "|    clip_fraction        | 0.0628         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | -1             |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.127         |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | -0.00394       |\n",
      "|    reward               | -0.00040644527 |\n",
      "|    std                  | 0.996          |\n",
      "|    value_loss           | 0.000983       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 425          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070943153 |\n",
      "|    clip_fraction        | 0.0776       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.138       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    reward               | -0.016484823 |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 0.000322     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 424          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034082532 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.137       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    reward               | 0.0023589728 |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 0.000322     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2012, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 2538.84\n",
      "total_reward: -7461.16\n",
      "total_cost: 4138.05\n",
      "total_trades: 11485\n",
      "Sharpe: -0.243\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 421            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 24             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0073577063   |\n",
      "|    clip_fraction        | 0.07           |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.7          |\n",
      "|    explained_variance   | 0.593          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.139         |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00512       |\n",
      "|    reward               | -0.00047001176 |\n",
      "|    std                  | 0.998          |\n",
      "|    value_loss           | 0.000171       |\n",
      "--------------------------------------------\n",
      "======PPO Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.4030751246050501\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_15\n",
      "day: 2012, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 10060\n",
      "Sharpe: 0.214\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 153           |\n",
      "|    time_elapsed    | 52            |\n",
      "|    total_timesteps | 8052          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | 249           |\n",
      "|    critic_loss     | 151           |\n",
      "|    learning_rate   | 0.0005        |\n",
      "|    n_updates       | 6039          |\n",
      "|    reward          | -0.0037689263 |\n",
      "--------------------------------------\n",
      "======DDPG Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======Trading from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0.357       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.0283      |\n",
      "|    reward             | 0.018669223 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 5.51e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 2             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | -6.78         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.121        |\n",
      "|    reward             | -0.0030060133 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.000524      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 342          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | -4.67        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -1.08        |\n",
      "|    reward             | -0.015216103 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.0065       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 345          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0.255        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.0521      |\n",
      "|    reward             | -0.015671354 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 4.01e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 344           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14           |\n",
      "|    explained_variance | -0.0256       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.164         |\n",
      "|    reward             | -0.0018228213 |\n",
      "|    std                | 1.14          |\n",
      "|    value_loss         | 0.000173      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0654        |\n",
      "|    reward             | -0.0057897633 |\n",
      "|    std                | 1.17          |\n",
      "|    value_loss         | 5e-05         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 344          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -1.01        |\n",
      "|    reward             | -0.009163367 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 0.00487      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 346           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.0255        |\n",
      "|    reward             | -0.0014375165 |\n",
      "|    std                | 1.25          |\n",
      "|    value_loss         | 6.09e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 347           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | 0.00295       |\n",
      "|    reward             | -0.0009220849 |\n",
      "|    std                | 1.29          |\n",
      "|    value_loss         | 1.62e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 346          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.0964      |\n",
      "|    reward             | 0.0033783622 |\n",
      "|    std                | 1.35         |\n",
      "|    value_loss         | 4.77e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 347          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.0666      |\n",
      "|    reward             | -0.002898339 |\n",
      "|    std                | 1.42         |\n",
      "|    value_loss         | 2.98e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 347            |\n",
      "|    iterations         | 1200           |\n",
      "|    time_elapsed       | 17             |\n",
      "|    total_timesteps    | 6000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.4          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1199           |\n",
      "|    policy_loss        | -0.0453        |\n",
      "|    reward             | -0.00059616525 |\n",
      "|    std                | 1.5            |\n",
      "|    value_loss         | 7.35e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 346           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.000232     |\n",
      "|    reward             | 0.00016835904 |\n",
      "|    std                | 1.58          |\n",
      "|    value_loss         | 1.52e-06      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 347          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.076        |\n",
      "|    reward             | 0.0026351113 |\n",
      "|    std                | 1.65         |\n",
      "|    value_loss         | 2.4e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 348          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0427      |\n",
      "|    reward             | 0.0018352991 |\n",
      "|    std                | 1.75         |\n",
      "|    value_loss         | 8.66e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 348          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.104       |\n",
      "|    reward             | 0.0006307819 |\n",
      "|    std                | 1.85         |\n",
      "|    value_loss         | 3.57e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 347          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.0604       |\n",
      "|    reward             | 0.0015562437 |\n",
      "|    std                | 1.96         |\n",
      "|    value_loss         | 1.95e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 348            |\n",
      "|    iterations         | 1800           |\n",
      "|    time_elapsed       | 25             |\n",
      "|    total_timesteps    | 9000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -19.3          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1799           |\n",
      "|    policy_loss        | 0.0198         |\n",
      "|    reward             | -0.00047804366 |\n",
      "|    std                | 2.06           |\n",
      "|    value_loss         | 4.98e-06       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 348          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.113       |\n",
      "|    reward             | 0.0034772384 |\n",
      "|    std                | 2.17         |\n",
      "|    value_loss         | 5.09e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 347            |\n",
      "|    iterations         | 2000           |\n",
      "|    time_elapsed       | 28             |\n",
      "|    total_timesteps    | 10000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -20.2          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1999           |\n",
      "|    policy_loss        | 0.385          |\n",
      "|    reward             | -0.00051827414 |\n",
      "|    std                | 2.29           |\n",
      "|    value_loss         | 0.000377       |\n",
      "------------------------------------------\n",
      "======A2C Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.0653091714307401\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_15\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 456          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0034514526 |\n",
      "-------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 435            |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0072901864   |\n",
      "|    clip_fraction        | 0.0728         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.8          |\n",
      "|    explained_variance   | -8.98          |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.137         |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | -0.00445       |\n",
      "|    reward               | -0.00056660845 |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 0.00194        |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 430           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007941451   |\n",
      "|    clip_fraction        | 0.0768        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.149        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.13         |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00485      |\n",
      "|    reward               | -0.0001378726 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000902      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 426           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009569143   |\n",
      "|    clip_fraction        | 0.124         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.0831       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.145        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.0074       |\n",
      "|    reward               | -0.0038508405 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000744      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 424         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009047118 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | -1.66       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.115      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    reward               | 0.000321476 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.000717    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.07228942892935053\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_15\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 150         |\n",
      "|    time_elapsed    | 55          |\n",
      "|    total_timesteps | 8304        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -302        |\n",
      "|    critic_loss     | 193         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6228        |\n",
      "|    reward          | 0.012696555 |\n",
      "------------------------------------\n",
      "day: 2075, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10033.33\n",
      "total_reward: 33.33\n",
      "total_cost: 9.99\n",
      "total_trades: 8300\n",
      "Sharpe: 0.210\n",
      "=================================\n",
      "======DDPG Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======Trading from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.0637       |\n",
      "|    reward             | -0.0050037345 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 0.00064       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.3      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 0.0741     |\n",
      "|    reward             | 0.01221112 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.000125   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.079       |\n",
      "|    reward             | -0.048461914 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.000743     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.281       |\n",
      "|    reward             | 0.036292568 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00275     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.024       |\n",
      "|    reward             | 0.0026068112 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 7.9e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0578      |\n",
      "|    reward             | 0.0052218717 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 5.02e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.347       |\n",
      "|    reward             | -0.019122072 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 0.000418     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 338         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -0.288      |\n",
      "|    reward             | 0.025613707 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 0.000564    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.22       |\n",
      "|    reward             | 0.010951611 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 0.000272    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.0351      |\n",
      "|    reward             | -0.009462684 |\n",
      "|    std                | 1.27         |\n",
      "|    value_loss         | 6.63e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.137        |\n",
      "|    reward             | 0.0061195935 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 7.84e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.0104      |\n",
      "|    reward             | 0.0009752758 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 1.75e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 342          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.101       |\n",
      "|    reward             | -0.010613394 |\n",
      "|    std                | 1.44         |\n",
      "|    value_loss         | 4.59e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -0.0486     |\n",
      "|    reward             | 0.008014978 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 1.84e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.265        |\n",
      "|    reward             | 0.0014048567 |\n",
      "|    std                | 1.58         |\n",
      "|    value_loss         | 0.000299     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.2       |\n",
      "|    explained_variance | -3.54       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 0.337       |\n",
      "|    reward             | 0.012753316 |\n",
      "|    std                | 1.63        |\n",
      "|    value_loss         | 0.000457    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 341           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.166        |\n",
      "|    reward             | -0.0050446126 |\n",
      "|    std                | 1.69          |\n",
      "|    value_loss         | 0.00025       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.00834     |\n",
      "|    reward             | 0.007635916 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 2.74e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 342           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.00441       |\n",
      "|    reward             | -0.0028272483 |\n",
      "|    std                | 1.82          |\n",
      "|    value_loss         | 6.45e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 343           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.0796        |\n",
      "|    reward             | -0.0002528678 |\n",
      "|    std                | 1.91          |\n",
      "|    value_loss         | 3.66e-05      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.19188244394052031\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_15\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 433           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | 0.00037629053 |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 419           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00522283    |\n",
      "|    clip_fraction        | 0.0577        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -3.38         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.128        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00609      |\n",
      "|    reward               | 0.00014143104 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000802      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 414           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008289846   |\n",
      "|    clip_fraction        | 0.0859        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.514         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.125        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00515      |\n",
      "|    reward               | -0.0007403793 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000322      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 412           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007063088   |\n",
      "|    clip_fraction        | 0.0545        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -2.04         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.155        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00602      |\n",
      "|    reward               | -0.0019666532 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000896      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 411          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008874611  |\n",
      "|    clip_fraction        | 0.0787       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.138       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 0.0020480687 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000274     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.2181834911229897\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_15\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 148         |\n",
      "|    time_elapsed    | 57          |\n",
      "|    total_timesteps | 8556        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -271        |\n",
      "|    critic_loss     | 115         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6417        |\n",
      "|    reward          | 0.008427322 |\n",
      "------------------------------------\n",
      "day: 2138, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10017.29\n",
      "total_reward: 17.29\n",
      "total_cost: 9.99\n",
      "total_trades: 10690\n",
      "Sharpe: 0.191\n",
      "=================================\n",
      "======DDPG Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======Trading from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 287         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.0167      |\n",
      "|    reward             | 0.009977425 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 4.53e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.3      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -0.216     |\n",
      "|    reward             | -0.0117013 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.000319   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 0.0582      |\n",
      "|    reward             | -0.01744059 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.000505    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 0.403        |\n",
      "|    reward             | -0.010063516 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | -0.00813      |\n",
      "|    reward             | -0.0040589673 |\n",
      "|    std                | 1.14          |\n",
      "|    value_loss         | 2.14e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.101        |\n",
      "|    reward             | -0.0011277742 |\n",
      "|    std                | 1.18          |\n",
      "|    value_loss         | 7.73e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.6         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.0499        |\n",
      "|    reward             | -0.0022307578 |\n",
      "|    std                | 1.22          |\n",
      "|    value_loss         | 2.64e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.247        |\n",
      "|    reward             | -0.000804068 |\n",
      "|    std                | 1.27         |\n",
      "|    value_loss         | 0.000364     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.0883       |\n",
      "|    reward             | 0.0026017346 |\n",
      "|    std                | 1.33         |\n",
      "|    value_loss         | 0.000122     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.0579       |\n",
      "|    reward             | 0.0012503316 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 3.16e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.215        |\n",
      "|    reward             | -0.0011905988 |\n",
      "|    std                | 1.45          |\n",
      "|    value_loss         | 0.00021       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -0.135      |\n",
      "|    reward             | 0.006489006 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 0.000103    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.156       |\n",
      "|    reward             | -0.009714829 |\n",
      "|    std                | 1.56         |\n",
      "|    value_loss         | 0.000219     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0109       |\n",
      "|    reward             | -0.007916051 |\n",
      "|    std                | 1.63         |\n",
      "|    value_loss         | 1.4e-06      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | -0.191        |\n",
      "|    reward             | -0.0054525193 |\n",
      "|    std                | 1.69          |\n",
      "|    value_loss         | 0.000155      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.539        |\n",
      "|    reward             | -0.004673803 |\n",
      "|    std                | 1.74         |\n",
      "|    value_loss         | 0.00123      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.378       |\n",
      "|    reward             | 0.015303238 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 0.000579    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.086        |\n",
      "|    reward             | -0.004027961 |\n",
      "|    std                | 1.81         |\n",
      "|    value_loss         | 3.99e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | -0.0876       |\n",
      "|    reward             | -0.0016470926 |\n",
      "|    std                | 1.86          |\n",
      "|    value_loss         | 3.29e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.0374       |\n",
      "|    reward             | -0.0016190376 |\n",
      "|    std                | 1.91          |\n",
      "|    value_loss         | 6.22e-05      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.16276152217433784\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_15\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 426           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0019784279 |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 413           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0068111275  |\n",
      "|    clip_fraction        | 0.0757        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -2.29         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.132        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00568      |\n",
      "|    reward               | -0.0005625484 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00109       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010528123  |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.105       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.121       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | -0.007043416 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00167      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007040331  |\n",
      "|    clip_fraction        | 0.0909       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.0032      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.148       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    reward               | 0.0017687473 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00121      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 403           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0057920367  |\n",
      "|    clip_fraction        | 0.0616        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.112         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.136        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00316      |\n",
      "|    reward               | 0.00072529656 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000861      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.042390756065066024\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_15\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 149          |\n",
      "|    time_elapsed    | 59           |\n",
      "|    total_timesteps | 8808         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -357         |\n",
      "|    critic_loss     | 181          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6606         |\n",
      "|    reward          | 0.0035539498 |\n",
      "-------------------------------------\n",
      "day: 2201, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10072.71\n",
      "total_reward: 72.71\n",
      "total_cost: 9.99\n",
      "total_trades: 6603\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "======DDPG Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======Trading from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.047        |\n",
      "|    reward             | -0.0027271872 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 3.75e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.0439       |\n",
      "|    reward             | -0.0011838423 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 0.000151      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.191      |\n",
      "|    reward             | 0.028660404 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.000273    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.239       |\n",
      "|    reward             | -0.030325405 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.000309     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.185         |\n",
      "|    reward             | -0.0022653167 |\n",
      "|    std                | 1.16          |\n",
      "|    value_loss         | 0.000172      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0617        |\n",
      "|    reward             | -0.0012225555 |\n",
      "|    std                | 1.2           |\n",
      "|    value_loss         | 1.95e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -0.0938    |\n",
      "|    reward             | 0.00716575 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 5.3e-05    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.252       |\n",
      "|    reward             | 0.0077729663 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 0.00141      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.541        |\n",
      "|    reward             | 0.0135765765 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 0.0016       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.0481     |\n",
      "|    reward             | 0.005833278 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 3.11e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -0.0148    |\n",
      "|    reward             | 0.00875879 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 7.67e-06   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 1200           |\n",
      "|    time_elapsed       | 18             |\n",
      "|    total_timesteps    | 6000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.3          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1199           |\n",
      "|    policy_loss        | -0.066         |\n",
      "|    reward             | -0.00055527803 |\n",
      "|    std                | 1.48           |\n",
      "|    value_loss         | 8.53e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.189        |\n",
      "|    reward             | -0.0082341535 |\n",
      "|    std                | 1.54          |\n",
      "|    value_loss         | 0.000198      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | -0.0765       |\n",
      "|    reward             | -0.0040350407 |\n",
      "|    std                | 1.59          |\n",
      "|    value_loss         | 1.96e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.101       |\n",
      "|    reward             | 0.0030269613 |\n",
      "|    std                | 1.66         |\n",
      "|    value_loss         | 4.12e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.0235        |\n",
      "|    reward             | -0.0042524682 |\n",
      "|    std                | 1.74          |\n",
      "|    value_loss         | 1.63e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.1          |\n",
      "|    reward             | -0.0037008186 |\n",
      "|    std                | 1.83          |\n",
      "|    value_loss         | 3.68e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.000628    |\n",
      "|    reward             | 0.005453852 |\n",
      "|    std                | 1.92        |\n",
      "|    value_loss         | 5.6e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0474      |\n",
      "|    reward             | -0.004626813 |\n",
      "|    std                | 2            |\n",
      "|    value_loss         | 2.1e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.0556        |\n",
      "|    reward             | -0.0023754837 |\n",
      "|    std                | 2.09          |\n",
      "|    value_loss         | 4.42e-05      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.36563382038513137\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_15\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 419           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0002107789 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053091254 |\n",
      "|    clip_fraction        | 0.0547       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | -2.93        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.132       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | 0.0023837513 |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 0.00332      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 400          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009810415  |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.7        |\n",
      "|    explained_variance   | -0.225       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.122       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 0.0013239065 |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 0.00185      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 398           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007481402   |\n",
      "|    clip_fraction        | 0.0863        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.266        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.131        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00593      |\n",
      "|    reward               | -0.0035814887 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00115       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 398          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064550987 |\n",
      "|    clip_fraction        | 0.061        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.0176      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.125       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | 0.0012779869 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000909     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.7053334475731212\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_15\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 134          |\n",
      "|    time_elapsed    | 67           |\n",
      "|    total_timesteps | 9060         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 447          |\n",
      "|    critic_loss     | 211          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6795         |\n",
      "|    reward          | -0.010479815 |\n",
      "-------------------------------------\n",
      "day: 2264, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 13584\n",
      "Sharpe: 0.157\n",
      "=================================\n",
      "======DDPG Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======Trading from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 297        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | 0.0736     |\n",
      "|    reward             | 0.01678482 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 8.85e-05   |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 319             |\n",
      "|    iterations         | 200             |\n",
      "|    time_elapsed       | 3               |\n",
      "|    total_timesteps    | 1000            |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -13.5           |\n",
      "|    explained_variance | 0               |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 199             |\n",
      "|    policy_loss        | 0.0604          |\n",
      "|    reward             | -0.000106842424 |\n",
      "|    std                | 1.09            |\n",
      "|    value_loss         | 0.000105        |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.7         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.136        |\n",
      "|    reward             | -0.0010025364 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 0.000356      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.331       |\n",
      "|    reward             | -0.021162866 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 0.000703     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.118       |\n",
      "|    reward             | 0.001373465 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 7.02e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0748      |\n",
      "|    reward             | 0.0013155149 |\n",
      "|    std                | 1.19         |\n",
      "|    value_loss         | 4.69e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.041        |\n",
      "|    reward             | 0.0015129031 |\n",
      "|    std                | 1.24         |\n",
      "|    value_loss         | 1.83e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.0207        |\n",
      "|    reward             | -0.0016346748 |\n",
      "|    std                | 1.3           |\n",
      "|    value_loss         | 6.21e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.149       |\n",
      "|    reward             | 0.0016153534 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 9.52e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.0325       |\n",
      "|    reward             | -0.0006718174 |\n",
      "|    std                | 1.42          |\n",
      "|    value_loss         | 9.29e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.012        |\n",
      "|    reward             | -0.0024244245 |\n",
      "|    std                | 1.5           |\n",
      "|    value_loss         | 4.9e-06       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 333            |\n",
      "|    iterations         | 1200           |\n",
      "|    time_elapsed       | 18             |\n",
      "|    total_timesteps    | 6000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1199           |\n",
      "|    policy_loss        | -0.149         |\n",
      "|    reward             | -0.00042871476 |\n",
      "|    std                | 1.58           |\n",
      "|    value_loss         | 9.26e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.147         |\n",
      "|    reward             | 0.00019910965 |\n",
      "|    std                | 1.65          |\n",
      "|    value_loss         | 9.47e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0619       |\n",
      "|    reward             | 0.0015588186 |\n",
      "|    std                | 1.73         |\n",
      "|    value_loss         | 2.31e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0245       |\n",
      "|    reward             | 0.0016331704 |\n",
      "|    std                | 1.81         |\n",
      "|    value_loss         | 3.19e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.138        |\n",
      "|    reward             | 0.0036407833 |\n",
      "|    std                | 1.89         |\n",
      "|    value_loss         | 6.99e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.126       |\n",
      "|    reward             | 0.0040710624 |\n",
      "|    std                | 1.98         |\n",
      "|    value_loss         | 8.23e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0327       |\n",
      "|    reward             | 0.0020336744 |\n",
      "|    std                | 2.07         |\n",
      "|    value_loss         | 1.15e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.0439       |\n",
      "|    reward             | 0.0019906184 |\n",
      "|    std                | 2.15         |\n",
      "|    value_loss         | 9.22e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.0663       |\n",
      "|    reward             | -0.0027333056 |\n",
      "|    std                | 2.25          |\n",
      "|    value_loss         | 1.6e-05       |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.07963743715587333\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_15\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 433           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0012727713 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 424          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053742975 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -1.24        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.115       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    reward               | 0.0008637869 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000756     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008086126  |\n",
      "|    clip_fraction        | 0.0863       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0134       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.132       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.0028045382 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00192      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01016186   |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.0675       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.143       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    reward               | 0.0022123752 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00142      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 405           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00800921    |\n",
      "|    clip_fraction        | 0.0951        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.13          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.125        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00517      |\n",
      "|    reward               | 0.00023373187 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000977      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.1720669562045332\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_15\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 158         |\n",
      "|    time_elapsed    | 58          |\n",
      "|    total_timesteps | 9312        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -122        |\n",
      "|    critic_loss     | 144         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6984        |\n",
      "|    reward          | 0.012485239 |\n",
      "------------------------------------\n",
      "day: 2327, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10062.69\n",
      "total_reward: 62.69\n",
      "total_cost: 9.99\n",
      "total_trades: 9308\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "======DDPG Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======Trading from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0372      |\n",
      "|    reward             | -0.003240149 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 3.65e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.205       |\n",
      "|    reward             | 0.0045192945 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 0.000419     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 326            |\n",
      "|    iterations         | 300            |\n",
      "|    time_elapsed       | 4              |\n",
      "|    total_timesteps    | 1500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 299            |\n",
      "|    policy_loss        | -0.0507        |\n",
      "|    reward             | -0.00061996706 |\n",
      "|    std                | 1.12           |\n",
      "|    value_loss         | 0.000103       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.0834     |\n",
      "|    reward             | -0.01998565 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 3.85e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.134       |\n",
      "|    reward             | 0.011489674 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 0.000113    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.0697       |\n",
      "|    reward             | 0.0044298093 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 6.12e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.0497        |\n",
      "|    reward             | -0.0030231308 |\n",
      "|    std                | 1.25          |\n",
      "|    value_loss         | 2.88e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.849       |\n",
      "|    reward             | -0.006376003 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 0.00303      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.317       |\n",
      "|    reward             | -0.009834807 |\n",
      "|    std                | 1.33         |\n",
      "|    value_loss         | 0.00112      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.101         |\n",
      "|    reward             | -0.0021292344 |\n",
      "|    std                | 1.36          |\n",
      "|    value_loss         | 6.04e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.0539        |\n",
      "|    reward             | -0.0030381412 |\n",
      "|    std                | 1.4           |\n",
      "|    value_loss         | 1.69e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.0248        |\n",
      "|    reward             | -0.0038058804 |\n",
      "|    std                | 1.46          |\n",
      "|    value_loss         | 4.7e-06       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.0404      |\n",
      "|    reward             | 0.0035519695 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 1.57e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.111       |\n",
      "|    reward             | 0.009906265 |\n",
      "|    std                | 1.6         |\n",
      "|    value_loss         | 9.92e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0464      |\n",
      "|    reward             | 0.0042718225 |\n",
      "|    std                | 1.67         |\n",
      "|    value_loss         | 1.38e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.159        |\n",
      "|    reward             | 0.0021209102 |\n",
      "|    std                | 1.74         |\n",
      "|    value_loss         | 0.000107     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.0642      |\n",
      "|    reward             | 0.0023988078 |\n",
      "|    std                | 1.82         |\n",
      "|    value_loss         | 2e-05        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.17         |\n",
      "|    reward             | -0.0019469834 |\n",
      "|    std                | 1.92          |\n",
      "|    value_loss         | 9.43e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.0614        |\n",
      "|    reward             | -0.0020443304 |\n",
      "|    std                | 2             |\n",
      "|    value_loss         | 3.7e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.0501       |\n",
      "|    reward             | 0.0034977514 |\n",
      "|    std                | 2.1          |\n",
      "|    value_loss         | 3.71e-05     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -9.347407994829148e-05\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_14\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 425           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0013759867 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009033103  |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -4.85        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.142       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    reward               | -0.005484405 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0015       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 404           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0079275165  |\n",
      "|    clip_fraction        | 0.0918        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.0388       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.131        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00468      |\n",
      "|    reward               | -0.0024737483 |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 0.00138       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 402           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007207009   |\n",
      "|    clip_fraction        | 0.0938        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0985        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.117        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00456      |\n",
      "|    reward               | 0.00094204437 |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 0.000799      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065926258 |\n",
      "|    clip_fraction        | 0.0674       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.114       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | 0.0009968056 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000536     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.16927453279223525\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_14\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 157         |\n",
      "|    time_elapsed    | 60          |\n",
      "|    total_timesteps | 9564        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 92.3        |\n",
      "|    critic_loss     | 96.9        |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7173        |\n",
      "|    reward          | 0.008096231 |\n",
      "------------------------------------\n",
      "day: 2390, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10074.29\n",
      "total_reward: 74.29\n",
      "total_cost: 9.99\n",
      "total_trades: 7170\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "======DDPG Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======Trading from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_567_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 257         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.0157      |\n",
      "|    reward             | 0.011481466 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 9.88e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 244           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.3         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | 0.0568        |\n",
      "|    reward             | -0.0033113908 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.000117      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 241          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.584        |\n",
      "|    reward             | -0.015810886 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 0.00173      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 232           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.12          |\n",
      "|    reward             | 9.5494244e-05 |\n",
      "|    std                | 1.11          |\n",
      "|    value_loss         | 0.000103      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 229         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.0348      |\n",
      "|    reward             | 0.001830848 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 1.03e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 226          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.0324       |\n",
      "|    reward             | 0.0014794872 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 9.16e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 231           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.072         |\n",
      "|    reward             | -0.0031432668 |\n",
      "|    std                | 1.22          |\n",
      "|    value_loss         | 3.47e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 240         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.141       |\n",
      "|    reward             | 0.004596097 |\n",
      "|    std                | 1.28        |\n",
      "|    value_loss         | 0.000156    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 242           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | 0.0129        |\n",
      "|    reward             | -0.0063976105 |\n",
      "|    std                | 1.35          |\n",
      "|    value_loss         | 5.58e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 246          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.00666     |\n",
      "|    reward             | 0.0001642385 |\n",
      "|    std                | 1.42         |\n",
      "|    value_loss         | 6.58e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 252           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.0269        |\n",
      "|    reward             | -0.0025837796 |\n",
      "|    std                | 1.5           |\n",
      "|    value_loss         | 4.34e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 256          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0031       |\n",
      "|    reward             | 0.0021054987 |\n",
      "|    std                | 1.58         |\n",
      "|    value_loss         | 4.75e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.0511      |\n",
      "|    reward             | 0.0026342834 |\n",
      "|    std                | 1.67         |\n",
      "|    value_loss         | 1.05e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 265          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.0187      |\n",
      "|    reward             | 0.0035886078 |\n",
      "|    std                | 1.77         |\n",
      "|    value_loss         | 4.58e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 267         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.0606      |\n",
      "|    reward             | 0.006014672 |\n",
      "|    std                | 1.88        |\n",
      "|    value_loss         | 1.65e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 270            |\n",
      "|    iterations         | 1600           |\n",
      "|    time_elapsed       | 29             |\n",
      "|    total_timesteps    | 8000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.9          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1599           |\n",
      "|    policy_loss        | -0.104         |\n",
      "|    reward             | -0.00089354784 |\n",
      "|    std                | 1.98           |\n",
      "|    value_loss         | 3.76e-05       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 273            |\n",
      "|    iterations         | 1700           |\n",
      "|    time_elapsed       | 31             |\n",
      "|    total_timesteps    | 8500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -19.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1699           |\n",
      "|    policy_loss        | 0.115          |\n",
      "|    reward             | -0.00069188897 |\n",
      "|    std                | 2.08           |\n",
      "|    value_loss         | 4.52e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 275         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.0126      |\n",
      "|    reward             | 0.007378955 |\n",
      "|    std                | 2.19        |\n",
      "|    value_loss         | 4.41e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 277         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.242      |\n",
      "|    reward             | 0.001540947 |\n",
      "|    std                | 2.3         |\n",
      "|    value_loss         | 0.000161    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 279         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 0.0688      |\n",
      "|    reward             | -0.00160795 |\n",
      "|    std                | 2.4         |\n",
      "|    value_loss         | 1.28e-05    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.6144751343380854\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_567_14\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 410          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0014124785 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 386           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007009083   |\n",
      "|    clip_fraction        | 0.0842        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -2.35         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.116        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00532      |\n",
      "|    reward               | -0.0038381666 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00508       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 387          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065094046 |\n",
      "|    clip_fraction        | 0.0769       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.139       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | -0.00606329  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000327     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 387          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063442793 |\n",
      "|    clip_fraction        | 0.0632       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.143       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    reward               | 0.0023658306 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000337     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 388            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 26             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.005772397    |\n",
      "|    clip_fraction        | 0.0529         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.9          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.14          |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00417       |\n",
      "|    reward               | -0.00044880624 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.000318       |\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.29054166923509767\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_567_14\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 148          |\n",
      "|    time_elapsed    | 66           |\n",
      "|    total_timesteps | 9816         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -530         |\n",
      "|    critic_loss     | 282          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 7362         |\n",
      "|    reward          | -0.025566522 |\n",
      "-------------------------------------\n",
      "day: 2453, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10000.39\n",
      "total_reward: 0.39\n",
      "total_cost: 9.99\n",
      "total_trades: 12265\n",
      "Sharpe: 0.246\n",
      "=================================\n",
      "======DDPG Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======Trading from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_630_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.0128      |\n",
      "|    reward             | 0.004727418 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 3.04e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 312            |\n",
      "|    iterations         | 200            |\n",
      "|    time_elapsed       | 3              |\n",
      "|    total_timesteps    | 1000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.6          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 199            |\n",
      "|    policy_loss        | -0.227         |\n",
      "|    reward             | -0.00043277713 |\n",
      "|    std                | 1.09           |\n",
      "|    value_loss         | 0.000492       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.205      |\n",
      "|    reward             | 0.002466869 |\n",
      "|    std                | 1.13        |\n",
      "|    value_loss         | 0.000261    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | 0.253        |\n",
      "|    reward             | -0.010667046 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 0.000488     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.218       |\n",
      "|    reward             | 0.002740517 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 0.0003      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.237        |\n",
      "|    reward             | -0.0026265206 |\n",
      "|    std                | 1.21          |\n",
      "|    value_loss         | 0.000254      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.0292       |\n",
      "|    reward             | -0.0029469605 |\n",
      "|    std                | 1.26          |\n",
      "|    value_loss         | 9.23e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.00484      |\n",
      "|    reward             | 0.0007040908 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 1.47e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.0555       |\n",
      "|    reward             | 0.0039739595 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 1.46e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.101       |\n",
      "|    reward             | -0.00833508 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.058       |\n",
      "|    reward             | 0.0022301232 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 1.25e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.076       |\n",
      "|    reward             | 0.0037037195 |\n",
      "|    std                | 1.61         |\n",
      "|    value_loss         | 6.81e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.00814      |\n",
      "|    reward             | 0.0036208786 |\n",
      "|    std                | 1.67         |\n",
      "|    value_loss         | 7.79e-06     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -0.0307     |\n",
      "|    reward             | 0.014624862 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 6.94e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.228       |\n",
      "|    reward             | 0.014679265 |\n",
      "|    std                | 1.83        |\n",
      "|    value_loss         | 0.000256    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.223        |\n",
      "|    reward             | -0.005142788 |\n",
      "|    std                | 1.89         |\n",
      "|    value_loss         | 0.000189     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.0499     |\n",
      "|    reward             | 0.016145421 |\n",
      "|    std                | 1.96        |\n",
      "|    value_loss         | 1.48e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.0727        |\n",
      "|    reward             | 0.00051402475 |\n",
      "|    std                | 2.05          |\n",
      "|    value_loss         | 2.64e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.186        |\n",
      "|    reward             | 0.0011967659 |\n",
      "|    std                | 2.13         |\n",
      "|    value_loss         | 0.000131     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 2000           |\n",
      "|    time_elapsed       | 30             |\n",
      "|    total_timesteps    | 10000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -19.9          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1999           |\n",
      "|    policy_loss        | -0.0201        |\n",
      "|    reward             | -0.00055128173 |\n",
      "|    std                | 2.21           |\n",
      "|    value_loss         | 1.19e-05       |\n",
      "------------------------------------------\n",
      "======A2C Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.31978903625112354\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_630_14\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 413           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0005968628 |\n",
      "--------------------------------------\n",
      "day: 2516, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 2565.79\n",
      "total_reward: -7434.21\n",
      "total_cost: 5207.77\n",
      "total_trades: 14436\n",
      "Sharpe: -0.144\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 409           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0052802544  |\n",
      "|    clip_fraction        | 0.0672        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -3.95         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.143        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00551      |\n",
      "|    reward               | -0.0007415962 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00309       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 403           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009045275   |\n",
      "|    clip_fraction        | 0.0812        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.274        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.136        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00326      |\n",
      "|    reward               | -0.0014320896 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.004         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 398          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007635931  |\n",
      "|    clip_fraction        | 0.0751       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.254       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.129       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    reward               | 0.0003401018 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0027       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 397           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004980216   |\n",
      "|    clip_fraction        | 0.0938        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.262        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.112        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00487      |\n",
      "|    reward               | -0.0004971854 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00176       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.1750808309519843\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_630_14\n",
      "day: 2516, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 31866.49\n",
      "total_reward: 21866.49\n",
      "total_cost: 518.01\n",
      "total_trades: 15056\n",
      "Sharpe: 0.813\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 145         |\n",
      "|    time_elapsed    | 69          |\n",
      "|    total_timesteps | 10068       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 438         |\n",
      "|    critic_loss     | 181         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7551        |\n",
      "|    reward          | 0.009009726 |\n",
      "------------------------------------\n",
      "======DDPG Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======Trading from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_693_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | 0.0318     |\n",
      "|    reward             | 0.02084564 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 6.03e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.3         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | 0.0802        |\n",
      "|    reward             | -0.0038465385 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.000134      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 0.346        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.219       |\n",
      "|    reward             | -0.023535013 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.000417     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.1        |\n",
      "|    reward             | -0.00899846 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.000238    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -0.274      |\n",
      "|    reward             | -0.01372855 |\n",
      "|    std                | 1.13        |\n",
      "|    value_loss         | 0.000453    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.308         |\n",
      "|    reward             | -0.0065617473 |\n",
      "|    std                | 1.15          |\n",
      "|    value_loss         | 0.000568      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.132       |\n",
      "|    reward             | 0.003165578 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 0.000169    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.116        |\n",
      "|    reward             | -0.018126456 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 0.00017      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.619      |\n",
      "|    reward             | -0.00494301 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 0.00209     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.0084        |\n",
      "|    reward             | -0.0032922167 |\n",
      "|    std                | 1.27          |\n",
      "|    value_loss         | 0.000461      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.0537       |\n",
      "|    reward             | 0.0041956976 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 3.77e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0995       |\n",
      "|    reward             | 0.0038758179 |\n",
      "|    std                | 1.33         |\n",
      "|    value_loss         | 4.25e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 0.0538      |\n",
      "|    reward             | 0.008697284 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 2.4e-05     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.027         |\n",
      "|    reward             | -0.0015602554 |\n",
      "|    std                | 1.45          |\n",
      "|    value_loss         | 1e-05         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.00191      |\n",
      "|    reward             | 0.0010792977 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 9.12e-07     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.0425        |\n",
      "|    reward             | 0.00042194402 |\n",
      "|    std                | 1.59          |\n",
      "|    value_loss         | 1.05e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.323        |\n",
      "|    reward             | 0.0024719792 |\n",
      "|    std                | 1.67         |\n",
      "|    value_loss         | 0.000472     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.162         |\n",
      "|    reward             | -0.0041226256 |\n",
      "|    std                | 1.75          |\n",
      "|    value_loss         | 9.83e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.088        |\n",
      "|    reward             | -0.003904211 |\n",
      "|    std                | 1.83         |\n",
      "|    value_loss         | 3.94e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.354      |\n",
      "|    reward             | 0.008311289 |\n",
      "|    std                | 1.91        |\n",
      "|    value_loss         | 0.000495    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.03742851725541381\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_693_14\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    fps             | 408            |\n",
      "|    iterations      | 1              |\n",
      "|    time_elapsed    | 5              |\n",
      "|    total_timesteps | 2048           |\n",
      "| train/             |                |\n",
      "|    reward          | -0.00019607638 |\n",
      "---------------------------------------\n",
      "day: 2579, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 659.84\n",
      "total_reward: -9340.16\n",
      "total_cost: 4265.82\n",
      "total_trades: 14839\n",
      "Sharpe: -0.734\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008730681  |\n",
      "|    clip_fraction        | 0.0848       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -4.08        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.146       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    reward               | 0.0015296601 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000879     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 402           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009065293   |\n",
      "|    clip_fraction        | 0.123         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.00711      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.129        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00602      |\n",
      "|    reward               | -0.0038443336 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00216       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008955832 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | -0.0548     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.141      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | 0.007875287 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00158     |\n",
      "-----------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 389            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 26             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.006046256    |\n",
      "|    clip_fraction        | 0.0688         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.9          |\n",
      "|    explained_variance   | -0.162         |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.141         |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00651       |\n",
      "|    reward               | -1.9402314e-05 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 0.0016         |\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.14803458995079904\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_693_14\n",
      "day: 2579, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 20631\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 154         |\n",
      "|    time_elapsed    | 66          |\n",
      "|    total_timesteps | 10320       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -854        |\n",
      "|    critic_loss     | 589         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7740        |\n",
      "|    reward          | 0.031668276 |\n",
      "------------------------------------\n",
      "======DDPG Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-07-06T00:00:00.000000000\n",
      "======Trading from:  2020-07-06T00:00:00.000000000 to  2020-10-02T00:00:00.000000000\n",
      "Ensemble Strategy took:  24.502549465497335  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "df_summary_mv = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs, PPO_model_kwargs, DDPG_model_kwargs, timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.143818</td>\n",
       "      <td>-0.403075</td>\n",
       "      <td>-0.167419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.065309</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.165294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.191882</td>\n",
       "      <td>0.218183</td>\n",
       "      <td>0.09797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>-0.162762</td>\n",
       "      <td>0.042391</td>\n",
       "      <td>-0.333039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.365634</td>\n",
       "      <td>0.705333</td>\n",
       "      <td>0.532201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.079637</td>\n",
       "      <td>0.172067</td>\n",
       "      <td>0.287512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.169275</td>\n",
       "      <td>-0.075772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.614475</td>\n",
       "      <td>0.290542</td>\n",
       "      <td>-0.027333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>-0.319789</td>\n",
       "      <td>-0.175081</td>\n",
       "      <td>-0.300965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.037429</td>\n",
       "      <td>-0.148035</td>\n",
       "      <td>0.234329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter  Val Start    Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126 2018-01-02 2018-04-04        A2C  -0.143818  -0.403075   -0.167419\n",
       "1  189 2018-04-04 2018-07-03       DDPG   0.065309   0.072289    0.165294\n",
       "2  252 2018-07-03 2018-10-02        PPO   0.191882   0.218183     0.09797\n",
       "3  315 2018-10-02 2019-01-03        PPO  -0.162762   0.042391   -0.333039\n",
       "4  378 2019-01-03 2019-04-04        PPO   0.365634   0.705333    0.532201\n",
       "5  441 2019-04-04 2019-07-05       DDPG   0.079637   0.172067    0.287512\n",
       "6  504 2019-07-05 2019-10-03        A2C  -0.000093  -0.169275   -0.075772\n",
       "7  567 2019-10-03 2020-01-03        A2C   0.614475   0.290542   -0.027333\n",
       "8  630 2020-01-03 2020-04-03        PPO  -0.319789  -0.175081   -0.300965\n",
       "9  693 2020-04-03 2020-07-06       DDPG  -0.037429  -0.148035    0.234329"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9979.070997</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>-0.002093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9847.471965</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>-0.013188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9866.176620</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>0.001899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9909.565673</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>0.004398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>8493.444293</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>0.012248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>8660.852307</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>0.019710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>8558.712978</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>-0.011793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>8626.658921</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>0.007939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>8686.088159</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0.006889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     account_value        date  daily_return\n",
       "0     10000.000000  2018-04-04           NaN\n",
       "1      9979.070997  2018-04-05     -0.002093\n",
       "2      9847.471965  2018-04-06     -0.013188\n",
       "3      9866.176620  2018-04-09      0.001899\n",
       "4      9909.565673  2018-04-10      0.004398\n",
       "..             ...         ...           ...\n",
       "625    8493.444293  2020-09-25      0.012248\n",
       "626    8660.852307  2020-09-28      0.019710\n",
       "627    8558.712978  2020-09-29     -0.011793\n",
       "628    8626.658921  2020-09-30      0.007939\n",
       "629    8686.088159  2020-10-01      0.006889\n",
       "\n",
       "[630 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "# for every cycle (rebalance_window + validation_window) read the csv files into a dataframe\n",
    "for i in range(rebalance_window+validation_window, len(test_dates)+1,rebalance_window):\n",
    "     result_df = pd.read_csv(f'results/account_value_trade_ensemble_{i}.csv')\n",
    "     results_list.append(result_df)\n",
    "\n",
    "df_ensemble_results_mv  = pd.concat(results_list, ignore_index=True)  # Create a dataframe to store execution results\n",
    "\n",
    "df_ensemble_results_mv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> - #### Step 6.1.3: Model with least voalatile 5 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-01-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_126_16\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 350         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.00901     |\n",
      "|    reward             | 0.007895148 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 4.13e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 359         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 0.552       |\n",
      "|    reward             | 0.022816775 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.00132     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 353         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.172      |\n",
      "|    reward             | -0.05308663 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.000965    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.38       |\n",
      "|    reward             | -0.05159121 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.000856    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 276           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.333         |\n",
      "|    reward             | -0.0007389694 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 0.000686      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 274          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0491      |\n",
      "|    reward             | 0.0026599332 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 2.89e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.198         |\n",
      "|    reward             | -0.0020162181 |\n",
      "|    std                | 1.2           |\n",
      "|    value_loss         | 0.000292      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 289           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.0043       |\n",
      "|    reward             | -0.0056825867 |\n",
      "|    std                | 1.24          |\n",
      "|    value_loss         | 7.18e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 295           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.0151       |\n",
      "|    reward             | -0.0025424426 |\n",
      "|    std                | 1.28          |\n",
      "|    value_loss         | 1.52e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 300          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.0339      |\n",
      "|    reward             | 0.0036475384 |\n",
      "|    std                | 1.33         |\n",
      "|    value_loss         | 9.03e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.0207      |\n",
      "|    reward             | 0.0032387741 |\n",
      "|    std                | 1.39         |\n",
      "|    value_loss         | 2.21e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.0769      |\n",
      "|    reward             | 0.0063905385 |\n",
      "|    std                | 1.45         |\n",
      "|    value_loss         | 3.16e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.0893        |\n",
      "|    reward             | -0.0035741685 |\n",
      "|    std                | 1.52          |\n",
      "|    value_loss         | 6.66e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 315            |\n",
      "|    iterations         | 1400           |\n",
      "|    time_elapsed       | 22             |\n",
      "|    total_timesteps    | 7000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.9          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1399           |\n",
      "|    policy_loss        | 0.18           |\n",
      "|    reward             | -0.00048006204 |\n",
      "|    std                | 1.59           |\n",
      "|    value_loss         | 0.000165       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.213       |\n",
      "|    reward             | 0.014574559 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 0.000173    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 320       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -17.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 0.198     |\n",
      "|    reward             | 0.0062324 |\n",
      "|    std                | 1.7       |\n",
      "|    value_loss         | 0.000172  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.129       |\n",
      "|    reward             | 0.0010978099 |\n",
      "|    std                | 1.76         |\n",
      "|    value_loss         | 9.94e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.00361     |\n",
      "|    reward             | 0.0035655336 |\n",
      "|    std                | 1.83         |\n",
      "|    value_loss         | 4.1e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 0.092       |\n",
      "|    reward             | 0.003574489 |\n",
      "|    std                | 1.91        |\n",
      "|    value_loss         | 5.77e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | -0.313     |\n",
      "|    reward             | 0.00708044 |\n",
      "|    std                | 1.99       |\n",
      "|    value_loss         | 0.000385   |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.23745419155186973\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_126_16\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 480         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 4           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.002888208 |\n",
      "------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 458           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006176673   |\n",
      "|    clip_fraction        | 0.0573        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -2.33         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.125        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00348      |\n",
      "|    reward               | -0.0034242985 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00478       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 442          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068339556 |\n",
      "|    clip_fraction        | 0.0862       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.223       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.134       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | -0.02102458  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000448     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 445          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007859385  |\n",
      "|    clip_fraction        | 0.0762       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.216        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.125       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | 0.0029528446 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000191     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2012, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 2069.77\n",
      "total_reward: -7930.23\n",
      "total_cost: 3289.86\n",
      "total_trades: 11634\n",
      "Sharpe: -0.435\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 443          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053805    |\n",
      "|    clip_fraction        | 0.0634       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.142       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | 0.0017757318 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000166     |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.5236264190542631\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_16\n",
      "day: 2012, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10028.66\n",
      "total_reward: 28.66\n",
      "total_cost: 9.99\n",
      "total_trades: 14084\n",
      "Sharpe: 0.216\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 155           |\n",
      "|    time_elapsed    | 51            |\n",
      "|    total_timesteps | 8052          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -413          |\n",
      "|    critic_loss     | 240           |\n",
      "|    learning_rate   | 0.0005        |\n",
      "|    n_updates       | 6039          |\n",
      "|    reward          | -0.0037658156 |\n",
      "--------------------------------------\n",
      "======DDPG Validation from:  2018-01-02T00:00:00.000000000 to  2018-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======Trading from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_189_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.485       |\n",
      "|    reward             | -0.013178555 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.00163      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 349         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.304      |\n",
      "|    reward             | 0.007611967 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.00116     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 346         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.465      |\n",
      "|    reward             | -0.03786491 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.00202     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 344         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.596      |\n",
      "|    reward             | -0.03372852 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 347           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.0904        |\n",
      "|    reward             | -0.0024391816 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 4.99e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 351           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0675        |\n",
      "|    reward             | -0.0008918104 |\n",
      "|    std                | 1.16          |\n",
      "|    value_loss         | 4.54e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 348          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.865       |\n",
      "|    reward             | -0.005013851 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 0.00357      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 350            |\n",
      "|    iterations         | 800            |\n",
      "|    time_elapsed       | 11             |\n",
      "|    total_timesteps    | 4000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 799            |\n",
      "|    policy_loss        | -0.0739        |\n",
      "|    reward             | -0.00048560562 |\n",
      "|    std                | 1.25           |\n",
      "|    value_loss         | 5.16e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 349          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.104        |\n",
      "|    reward             | 0.0003439453 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 5.76e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.194       |\n",
      "|    reward             | 0.0051102624 |\n",
      "|    std                | 1.35         |\n",
      "|    value_loss         | 0.000239     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 353         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.181      |\n",
      "|    reward             | -0.00709485 |\n",
      "|    std                | 1.41        |\n",
      "|    value_loss         | 0.000129    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 353          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.139       |\n",
      "|    reward             | 0.0016814827 |\n",
      "|    std                | 1.47         |\n",
      "|    value_loss         | 7.74e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 351          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.0311       |\n",
      "|    reward             | 0.0053706435 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 7.28e-06     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 351         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.118       |\n",
      "|    reward             | 0.005731743 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 5.2e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 352         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.114       |\n",
      "|    reward             | 0.005059127 |\n",
      "|    std                | 1.66        |\n",
      "|    value_loss         | 8.39e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 352         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | -0.073      |\n",
      "|    reward             | 0.009551553 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 3.72e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 353          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.0358       |\n",
      "|    reward             | 0.0017076228 |\n",
      "|    std                | 1.8          |\n",
      "|    value_loss         | 1.06e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 352            |\n",
      "|    iterations         | 1800           |\n",
      "|    time_elapsed       | 25             |\n",
      "|    total_timesteps    | 9000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1799           |\n",
      "|    policy_loss        | 0.0743         |\n",
      "|    reward             | -0.00060810364 |\n",
      "|    std                | 1.88           |\n",
      "|    value_loss         | 2.05e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 352         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.186      |\n",
      "|    reward             | 0.004907196 |\n",
      "|    std                | 1.97        |\n",
      "|    value_loss         | 0.000115    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 352          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.563        |\n",
      "|    reward             | -0.002533464 |\n",
      "|    std                | 2.04         |\n",
      "|    value_loss         | 0.000932     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.041134176647447604\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_189_16\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    fps             | 481            |\n",
      "|    iterations      | 1              |\n",
      "|    time_elapsed    | 4              |\n",
      "|    total_timesteps | 2048           |\n",
      "| train/             |                |\n",
      "|    reward          | -0.00030380554 |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 455           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0058406135  |\n",
      "|    clip_fraction        | 0.0682        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -3.24         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.117        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00507      |\n",
      "|    reward               | -0.0030866961 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00103       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 445         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008400463 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | -0.771      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.144      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    reward               | 0.003630544 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.000691    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 438           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005217608   |\n",
      "|    clip_fraction        | 0.0468        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.00772       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.128        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.0035       |\n",
      "|    reward               | -0.0002214676 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00049       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 436          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064057065 |\n",
      "|    clip_fraction        | 0.0641       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.245        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.14        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    reward               | 0.0016641128 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000256     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.04612126451707716\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_16\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 163         |\n",
      "|    time_elapsed    | 50          |\n",
      "|    total_timesteps | 8304        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -51.8       |\n",
      "|    critic_loss     | 111         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 6228        |\n",
      "|    reward          | 0.012522047 |\n",
      "------------------------------------\n",
      "day: 2075, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10015.37\n",
      "total_reward: 15.37\n",
      "total_cost: 9.99\n",
      "total_trades: 10375\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "======DDPG Validation from:  2018-04-04T00:00:00.000000000 to  2018-07-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======Trading from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-07-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_252_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.00335    |\n",
      "|    reward             | 0.014935639 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 5.71e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 0.0991       |\n",
      "|    reward             | -0.004265497 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.000189     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.5         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.156        |\n",
      "|    reward             | -0.0011308471 |\n",
      "|    std                | 1.09          |\n",
      "|    value_loss         | 0.000432      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.534       |\n",
      "|    reward             | -0.052585486 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 337            |\n",
      "|    iterations         | 500            |\n",
      "|    time_elapsed       | 7              |\n",
      "|    total_timesteps    | 2500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.9          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 499            |\n",
      "|    policy_loss        | -0.0445        |\n",
      "|    reward             | -0.00049123465 |\n",
      "|    std                | 1.13           |\n",
      "|    value_loss         | 1.06e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0747      |\n",
      "|    reward             | 0.0067430506 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 6.28e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 343          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.171       |\n",
      "|    reward             | -0.012720965 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 0.000132     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 342        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.8      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -0.00657   |\n",
      "|    reward             | 0.01012199 |\n",
      "|    std                | 1.26       |\n",
      "|    value_loss         | 1.15e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.0339      |\n",
      "|    reward             | 0.0031556443 |\n",
      "|    std                | 1.31         |\n",
      "|    value_loss         | 8.44e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 343          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -0.23        |\n",
      "|    reward             | 0.0018483367 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 0.000299     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 344          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.127        |\n",
      "|    reward             | 0.0073467935 |\n",
      "|    std                | 1.43         |\n",
      "|    value_loss         | 9.23e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 343          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0282       |\n",
      "|    reward             | 0.0032724598 |\n",
      "|    std                | 1.49         |\n",
      "|    value_loss         | 2.31e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 344           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -0.0913       |\n",
      "|    reward             | -0.0067143333 |\n",
      "|    std                | 1.55          |\n",
      "|    value_loss         | 4.28e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 345          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0137       |\n",
      "|    reward             | 0.0004096757 |\n",
      "|    std                | 1.61         |\n",
      "|    value_loss         | 1.48e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 346          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.26         |\n",
      "|    reward             | 0.0039884807 |\n",
      "|    std                | 1.68         |\n",
      "|    value_loss         | 0.000303     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 346          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.0163      |\n",
      "|    reward             | 0.0005252426 |\n",
      "|    std                | 1.75         |\n",
      "|    value_loss         | 9.63e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 346         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.0705      |\n",
      "|    reward             | 0.011361482 |\n",
      "|    std                | 1.81        |\n",
      "|    value_loss         | 5.62e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 346         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.0385      |\n",
      "|    reward             | 0.011528282 |\n",
      "|    std                | 1.87        |\n",
      "|    value_loss         | 1.17e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 345           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.0696        |\n",
      "|    reward             | -0.0096975425 |\n",
      "|    std                | 1.95          |\n",
      "|    value_loss         | 2.18e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 345          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.114        |\n",
      "|    reward             | 0.0016307832 |\n",
      "|    std                | 2.03         |\n",
      "|    value_loss         | 0.000111     |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.030625749912628165\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_252_16\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 438          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.007666872 |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 428          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00711768   |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -6.07        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.129       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 0.0017017487 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00735      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 425          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008748938  |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.19        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.134       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | 0.0024283023 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00645      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 417          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011990277  |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.0181      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.139       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00983     |\n",
      "|    reward               | -0.000786577 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00435      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005853962 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.00839     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.142      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    reward               | 0.001732159 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00302     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.11150795937392827\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_16\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 163          |\n",
      "|    time_elapsed    | 52           |\n",
      "|    total_timesteps | 8556         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -535         |\n",
      "|    critic_loss     | 357          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6417         |\n",
      "|    reward          | 0.0024947198 |\n",
      "-------------------------------------\n",
      "day: 2138, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 12828\n",
      "Sharpe: 0.128\n",
      "=================================\n",
      "======DDPG Validation from:  2018-07-03T00:00:00.000000000 to  2018-10-02T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======Trading from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2018-10-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_315_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 305           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -0.128        |\n",
      "|    reward             | -0.0012011385 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 9.38e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.116        |\n",
      "|    reward             | 0.00029584407 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.000236      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.161       |\n",
      "|    reward             | 0.0060253246 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.000338     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.238       |\n",
      "|    reward             | -0.023649966 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 0.000293     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 338           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.177         |\n",
      "|    reward             | -0.0095916875 |\n",
      "|    std                | 1.19          |\n",
      "|    value_loss         | 0.000198      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.127        |\n",
      "|    reward             | 0.0014294125 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 6.5e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 338           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.136         |\n",
      "|    reward             | -0.0019091715 |\n",
      "|    std                | 1.29          |\n",
      "|    value_loss         | 0.000122      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.068        |\n",
      "|    reward             | 0.0061592413 |\n",
      "|    std                | 1.34         |\n",
      "|    value_loss         | 4.32e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | 0.118         |\n",
      "|    reward             | -0.0008088871 |\n",
      "|    std                | 1.4           |\n",
      "|    value_loss         | 0.000151      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.0484       |\n",
      "|    reward             | -0.0027467506 |\n",
      "|    std                | 1.47          |\n",
      "|    value_loss         | 1.73e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.103       |\n",
      "|    reward             | 0.0012506704 |\n",
      "|    std                | 1.54         |\n",
      "|    value_loss         | 6.43e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.196         |\n",
      "|    reward             | 0.00064318615 |\n",
      "|    std                | 1.63          |\n",
      "|    value_loss         | 0.000108      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.158       |\n",
      "|    reward             | -0.005114345 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 0.000122     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.0207        |\n",
      "|    reward             | -0.0016042067 |\n",
      "|    std                | 1.8           |\n",
      "|    value_loss         | 7.97e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0205       |\n",
      "|    reward             | -0.003307627 |\n",
      "|    std                | 1.89         |\n",
      "|    value_loss         | 8.85e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.287         |\n",
      "|    reward             | 0.00015281487 |\n",
      "|    std                | 1.99          |\n",
      "|    value_loss         | 0.00028       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 338           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.0175       |\n",
      "|    reward             | -0.0035902846 |\n",
      "|    std                | 2.09          |\n",
      "|    value_loss         | 4.04e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 26            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.0124       |\n",
      "|    reward             | -0.0005844763 |\n",
      "|    std                | 2.19          |\n",
      "|    value_loss         | 1.06e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.00795     |\n",
      "|    reward             | 0.0006800174 |\n",
      "|    std                | 2.3          |\n",
      "|    value_loss         | 3.96e-07     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 338           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.043        |\n",
      "|    reward             | -0.0013092989 |\n",
      "|    std                | 2.43          |\n",
      "|    value_loss         | 5.62e-06      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.45528414241391835\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_315_16\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 470         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 4           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.002229302 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 434          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058790343 |\n",
      "|    clip_fraction        | 0.0374       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -4.22        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.121       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | 0.0048004934 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00761      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 420           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0064406535  |\n",
      "|    clip_fraction        | 0.101         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0249        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.133        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00482      |\n",
      "|    reward               | -0.0074419947 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00337       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009257581  |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0354       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.126       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | 0.0022234274 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00239      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 354          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007215959  |\n",
      "|    clip_fraction        | 0.0719       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.063        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.13        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.0005154469 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00156      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.26177605494695044\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_16\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 140          |\n",
      "|    time_elapsed    | 62           |\n",
      "|    total_timesteps | 8808         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -448         |\n",
      "|    critic_loss     | 223          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6606         |\n",
      "|    reward          | 0.0010716327 |\n",
      "-------------------------------------\n",
      "day: 2201, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 11005\n",
      "Sharpe: 0.228\n",
      "=================================\n",
      "======DDPG Validation from:  2018-10-02T00:00:00.000000000 to  2019-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======Trading from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_378_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.12       |\n",
      "|    reward             | 0.014946676 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000138    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0094      |\n",
      "|    reward             | -0.005992318 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.000136     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -2.23e-05    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.127        |\n",
      "|    reward             | -0.012571315 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.000512     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.394       |\n",
      "|    reward             | -0.039619464 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 0.000738     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 0.0892        |\n",
      "|    reward             | -0.0008878112 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 4.72e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0813        |\n",
      "|    reward             | -0.0028051017 |\n",
      "|    std                | 1.15          |\n",
      "|    value_loss         | 3.14e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.025       |\n",
      "|    reward             | 0.005595727 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 6.69e-06    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 333            |\n",
      "|    iterations         | 800            |\n",
      "|    time_elapsed       | 11             |\n",
      "|    total_timesteps    | 4000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.7          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 799            |\n",
      "|    policy_loss        | -0.062         |\n",
      "|    reward             | -0.00016801807 |\n",
      "|    std                | 1.24           |\n",
      "|    value_loss         | 0.000183       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | 0.115         |\n",
      "|    reward             | -0.0033664783 |\n",
      "|    std                | 1.3           |\n",
      "|    value_loss         | 7.3e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.00431    |\n",
      "|    reward             | 0.007829845 |\n",
      "|    std                | 1.35        |\n",
      "|    value_loss         | 5.53e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 337         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.0794     |\n",
      "|    reward             | 0.008640254 |\n",
      "|    std                | 1.4         |\n",
      "|    value_loss         | 4.01e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.185        |\n",
      "|    reward             | 7.981491e-05 |\n",
      "|    std                | 1.46         |\n",
      "|    value_loss         | 0.000254     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.082        |\n",
      "|    reward             | -0.005701759 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 2.57e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.0488       |\n",
      "|    reward             | 0.0011059892 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 1.1e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | -0.0802       |\n",
      "|    reward             | 0.00017648678 |\n",
      "|    std                | 1.66          |\n",
      "|    value_loss         | 2.2e-05       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 0.0898     |\n",
      "|    reward             | 0.00601274 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 5.41e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.336        |\n",
      "|    reward             | -0.0049978225 |\n",
      "|    std                | 1.83          |\n",
      "|    value_loss         | 0.00042       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 26            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.0289       |\n",
      "|    reward             | 0.00045505303 |\n",
      "|    std                | 1.94          |\n",
      "|    value_loss         | 2.27e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.26        |\n",
      "|    reward             | -0.005585372 |\n",
      "|    std                | 2.03         |\n",
      "|    value_loss         | 0.000201     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.0385       |\n",
      "|    reward             | -0.0038858226 |\n",
      "|    std                | 2.13          |\n",
      "|    value_loss         | 8.55e-06      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.4117984430146725\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_378_16\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    fps             | 438            |\n",
      "|    iterations      | 1              |\n",
      "|    time_elapsed    | 4              |\n",
      "|    total_timesteps | 2048           |\n",
      "| train/             |                |\n",
      "|    reward          | -0.00078040943 |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 435         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007851714 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | -6.91       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.13       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    reward               | 0.001194905 |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.00258     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 419           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007697651   |\n",
      "|    clip_fraction        | 0.0996        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.177        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.136        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00769      |\n",
      "|    reward               | -0.0011110001 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000989      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 416           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004682281   |\n",
      "|    clip_fraction        | 0.0599        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -0.118        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.146        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00479      |\n",
      "|    reward               | -0.0026501482 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000699      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007392385  |\n",
      "|    clip_fraction        | 0.0927       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | -0.00144     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.142       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00778     |\n",
      "|    reward               | 0.0031164559 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000587     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.17851554513184323\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_16\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 159          |\n",
      "|    time_elapsed    | 56           |\n",
      "|    total_timesteps | 9060         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 72.4         |\n",
      "|    critic_loss     | 69           |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 6795         |\n",
      "|    reward          | 0.0006118675 |\n",
      "-------------------------------------\n",
      "day: 2264, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10069.46\n",
      "total_reward: 69.46\n",
      "total_cost: 9.99\n",
      "total_trades: 9056\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "======DDPG Validation from:  2019-01-03T00:00:00.000000000 to  2019-04-04T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======Trading from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-04-04T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_441_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0529      |\n",
      "|    reward             | 0.0025741917 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 4.68e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 299           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.198        |\n",
      "|    reward             | 0.00076406635 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.0004        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.195        |\n",
      "|    reward             | -0.012204398 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.000233     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.0109      |\n",
      "|    reward             | -0.012482129 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 1.57e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.0919      |\n",
      "|    reward             | 0.001763482 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 4.6e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0626      |\n",
      "|    reward             | 0.0011624875 |\n",
      "|    std                | 1.22         |\n",
      "|    value_loss         | 3.34e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.0126       |\n",
      "|    reward             | 0.0030405063 |\n",
      "|    std                | 1.28         |\n",
      "|    value_loss         | 5.29e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.018         |\n",
      "|    reward             | 0.00012994447 |\n",
      "|    std                | 1.34          |\n",
      "|    value_loss         | 2.84e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.011        |\n",
      "|    reward             | -0.000731205 |\n",
      "|    std                | 1.41         |\n",
      "|    value_loss         | 3.2e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.0462     |\n",
      "|    reward             | 0.000898415 |\n",
      "|    std                | 1.47        |\n",
      "|    value_loss         | 1.13e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.303        |\n",
      "|    reward             | -0.0037181368 |\n",
      "|    std                | 1.54          |\n",
      "|    value_loss         | 0.000316      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | -0.239        |\n",
      "|    reward             | 0.00015911652 |\n",
      "|    std                | 1.62          |\n",
      "|    value_loss         | 0.000202      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 1300           |\n",
      "|    time_elapsed       | 20             |\n",
      "|    total_timesteps    | 6500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -17.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1299           |\n",
      "|    policy_loss        | -0.00444       |\n",
      "|    reward             | -0.00071562355 |\n",
      "|    std                | 1.7            |\n",
      "|    value_loss         | 7.99e-06       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.00451     |\n",
      "|    reward             | 0.0017724904 |\n",
      "|    std                | 1.77         |\n",
      "|    value_loss         | 4.59e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.3         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | -0.239        |\n",
      "|    reward             | 0.00019351824 |\n",
      "|    std                | 1.85          |\n",
      "|    value_loss         | 0.000178      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 0.119       |\n",
      "|    reward             | 0.003656574 |\n",
      "|    std                | 1.94        |\n",
      "|    value_loss         | 5.84e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.0394      |\n",
      "|    reward             | -0.002918621 |\n",
      "|    std                | 2.03         |\n",
      "|    value_loss         | 3.44e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.5         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.0337       |\n",
      "|    reward             | -0.0067304424 |\n",
      "|    std                | 2.1           |\n",
      "|    value_loss         | 1.37e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.026        |\n",
      "|    reward             | 0.0017479783 |\n",
      "|    std                | 2.17         |\n",
      "|    value_loss         | 6.91e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.1         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.115        |\n",
      "|    reward             | -0.0003249922 |\n",
      "|    std                | 2.26          |\n",
      "|    value_loss         | 3.73e-05      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.40374149907343093\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_441_16\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 422           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0013503167 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072204517 |\n",
      "|    clip_fraction        | 0.0851       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -18.3        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.126       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00753     |\n",
      "|    reward               | 0.0019094605 |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.00454      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 416          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009334052  |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.00422      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.15        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    reward               | 0.0038994292 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00305      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 408           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007261455   |\n",
      "|    clip_fraction        | 0.0841        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.00562       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.109        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00272      |\n",
      "|    reward               | 0.00052996643 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00215       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 411            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 24             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.009150923    |\n",
      "|    clip_fraction        | 0.0928         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -12.9          |\n",
      "|    explained_variance   | 0.0491         |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | -0.14          |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -0.00533       |\n",
      "|    reward               | -0.00082530134 |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 0.00157        |\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.19650147861118075\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_16\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 4             |\n",
      "|    fps             | 156           |\n",
      "|    time_elapsed    | 59            |\n",
      "|    total_timesteps | 9312          |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -252          |\n",
      "|    critic_loss     | 118           |\n",
      "|    learning_rate   | 0.0005        |\n",
      "|    n_updates       | 6984          |\n",
      "|    reward          | 0.00054278946 |\n",
      "--------------------------------------\n",
      "day: 2327, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10036.15\n",
      "total_reward: 36.15\n",
      "total_cost: 9.99\n",
      "total_trades: 6981\n",
      "Sharpe: 0.169\n",
      "=================================\n",
      "======DDPG Validation from:  2019-04-04T00:00:00.000000000 to  2019-07-05T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======Trading from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-07-05T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_504_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 284           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | 0.0263        |\n",
      "|    reward             | -0.0025471356 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 0.00028       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 0.102       |\n",
      "|    reward             | -0.00710593 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 6.3e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | 0.122         |\n",
      "|    reward             | -0.0058400924 |\n",
      "|    std                | 1.09          |\n",
      "|    value_loss         | 0.000326      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.249       |\n",
      "|    reward             | -0.013787919 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.000334     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.192       |\n",
      "|    reward             | 0.009565661 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.000183    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0105        |\n",
      "|    reward             | -0.0013257142 |\n",
      "|    std                | 1.18          |\n",
      "|    value_loss         | 2.19e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.0237      |\n",
      "|    reward             | 0.008663275 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 5.48e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.281       |\n",
      "|    reward             | 0.0037694196 |\n",
      "|    std                | 1.27         |\n",
      "|    value_loss         | 0.000398     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.167       |\n",
      "|    reward             | 0.008581032 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 0.00027     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.073         |\n",
      "|    reward             | 0.00014504965 |\n",
      "|    std                | 1.35          |\n",
      "|    value_loss         | 3.56e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.0184       |\n",
      "|    reward             | -0.0038676942 |\n",
      "|    std                | 1.4           |\n",
      "|    value_loss         | 1.06e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0496       |\n",
      "|    reward             | -0.006753059 |\n",
      "|    std                | 1.46         |\n",
      "|    value_loss         | 1.62e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.000619     |\n",
      "|    reward             | 0.0018618008 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 9.98e-06     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.0384      |\n",
      "|    reward             | 0.014536758 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 6.82e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.128       |\n",
      "|    reward             | 0.0021581743 |\n",
      "|    std                | 1.64         |\n",
      "|    value_loss         | 6.5e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.0856       |\n",
      "|    reward             | -0.004394501 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 3.63e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | 0.0278        |\n",
      "|    reward             | -0.0020628865 |\n",
      "|    std                | 1.79          |\n",
      "|    value_loss         | 1.08e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.142         |\n",
      "|    reward             | -0.0027847206 |\n",
      "|    std                | 1.86          |\n",
      "|    value_loss         | 6.77e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.0718     |\n",
      "|    reward             | 0.007134646 |\n",
      "|    std                | 1.94        |\n",
      "|    value_loss         | 9.7e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 0.0481      |\n",
      "|    reward             | 0.010195281 |\n",
      "|    std                | 2.01        |\n",
      "|    value_loss         | 2.99e-05    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.028512720759339322\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_504_15\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0008492305 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 415           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0063718124  |\n",
      "|    clip_fraction        | 0.0853        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | -4.7          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.126        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00667      |\n",
      "|    reward               | -0.0031472235 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00513       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 412          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008151478  |\n",
      "|    clip_fraction        | 0.0955       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.649       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.139       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00835     |\n",
      "|    reward               | 4.393598e-06 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000916     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 407           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007999784   |\n",
      "|    clip_fraction        | 0.0978        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.168         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.145        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00677      |\n",
      "|    reward               | -0.0013671137 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000483      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 403           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008333722   |\n",
      "|    clip_fraction        | 0.0828        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.347         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.131        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00553      |\n",
      "|    reward               | -0.0026298466 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00038       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.03984178381758523\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_15\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 159         |\n",
      "|    time_elapsed    | 60          |\n",
      "|    total_timesteps | 9564        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -96.3       |\n",
      "|    critic_loss     | 101         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7173        |\n",
      "|    reward          | 0.007963677 |\n",
      "------------------------------------\n",
      "day: 2390, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 9990.01\n",
      "total_reward: -9.99\n",
      "total_cost: 9.99\n",
      "total_trades: 11950\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "======DDPG Validation from:  2019-07-05T00:00:00.000000000 to  2019-10-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======Trading from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2019-10-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_567_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.25        |\n",
      "|    reward             | -0.006940603 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.000432     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.374       |\n",
      "|    reward             | 0.0040362845 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.283       |\n",
      "|    reward             | -0.042374767 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.00102      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.139      |\n",
      "|    reward             | -0.02728939 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.000162    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.00101     |\n",
      "|    reward             | 0.0033794064 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 4.99e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.0395       |\n",
      "|    reward             | -0.0009602308 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 1.57e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.0345      |\n",
      "|    reward             | -0.007543375 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 1.42e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.0901       |\n",
      "|    reward             | 0.0053657205 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 8.02e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.36         |\n",
      "|    reward             | -0.013181568 |\n",
      "|    std                | 1.25         |\n",
      "|    value_loss         | 0.000659     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.0462        |\n",
      "|    reward             | -0.0021856022 |\n",
      "|    std                | 1.29          |\n",
      "|    value_loss         | 7.65e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.00266       |\n",
      "|    reward             | -0.0023737748 |\n",
      "|    std                | 1.34          |\n",
      "|    value_loss         | 2.69e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.0573      |\n",
      "|    reward             | 0.0038986201 |\n",
      "|    std                | 1.39         |\n",
      "|    value_loss         | 1.18e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.0453      |\n",
      "|    reward             | 0.0016362777 |\n",
      "|    std                | 1.46         |\n",
      "|    value_loss         | 2.89e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.0253      |\n",
      "|    reward             | 0.0044211373 |\n",
      "|    std                | 1.54         |\n",
      "|    value_loss         | 7.18e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.0519      |\n",
      "|    reward             | 0.003517568 |\n",
      "|    std                | 1.62        |\n",
      "|    value_loss         | 1.01e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -0.0048       |\n",
      "|    reward             | -0.0019350327 |\n",
      "|    std                | 1.71          |\n",
      "|    value_loss         | 9.68e-07      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.0144      |\n",
      "|    reward             | 0.0006453308 |\n",
      "|    std                | 1.82         |\n",
      "|    value_loss         | 1e-06        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.0352      |\n",
      "|    reward             | -6.73931e-05 |\n",
      "|    std                | 1.93         |\n",
      "|    value_loss         | 3.38e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.0716       |\n",
      "|    reward             | 0.0008458717 |\n",
      "|    std                | 2.06         |\n",
      "|    value_loss         | 1.26e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 9.79e-05      |\n",
      "|    reward             | -0.0010833616 |\n",
      "|    std                | 2.19          |\n",
      "|    value_loss         | 7.57e-07      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.11500555780992741\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_567_15\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 419          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 4            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0027175553 |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 411          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062424657 |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.114       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.12        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | 0.002309154  |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.000887     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075947    |\n",
      "|    clip_fraction        | 0.0856       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.00255     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.14        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 0.0017602188 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00118      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 401          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005688618  |\n",
      "|    clip_fraction        | 0.0576       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.0115       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.138       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | 0.0017533234 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000583     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 401           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007791381   |\n",
      "|    clip_fraction        | 0.0743        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.0469        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.136        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00432      |\n",
      "|    reward               | -0.0014501077 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000438      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.11253668211303067\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_567_15\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 157          |\n",
      "|    time_elapsed    | 62           |\n",
      "|    total_timesteps | 9816         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 585          |\n",
      "|    critic_loss     | 302          |\n",
      "|    learning_rate   | 0.0005       |\n",
      "|    n_updates       | 7362         |\n",
      "|    reward          | -0.025876293 |\n",
      "-------------------------------------\n",
      "day: 2453, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10111.34\n",
      "total_reward: 111.34\n",
      "total_cost: 9.99\n",
      "total_trades: 9812\n",
      "Sharpe: 0.208\n",
      "=================================\n",
      "======DDPG Validation from:  2019-10-03T00:00:00.000000000 to  2020-01-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======Trading from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-01-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_630_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.11        |\n",
      "|    reward             | 0.0024364365 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 0.049       |\n",
      "|    reward             | 0.003042297 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 4.97e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.5         |\n",
      "|    explained_variance | -2.38e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | -0.109        |\n",
      "|    reward             | -0.0032683858 |\n",
      "|    std                | 1.09          |\n",
      "|    value_loss         | 0.00038       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.479      |\n",
      "|    reward             | -0.04156739 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.193       |\n",
      "|    reward             | -0.015364506 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.000354     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.106        |\n",
      "|    reward             | -0.0011665191 |\n",
      "|    std                | 1.15          |\n",
      "|    value_loss         | 6.91e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.0961       |\n",
      "|    reward             | -0.0006288909 |\n",
      "|    std                | 1.19          |\n",
      "|    value_loss         | 4.07e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.00407       |\n",
      "|    reward             | -0.0021771393 |\n",
      "|    std                | 1.23          |\n",
      "|    value_loss         | 2.19e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.0839       |\n",
      "|    reward             | 0.0011886347 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 4.59e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.181      |\n",
      "|    reward             | 0.015335937 |\n",
      "|    std                | 1.35        |\n",
      "|    value_loss         | 0.000247    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.0103       |\n",
      "|    reward             | 0.0015344536 |\n",
      "|    std                | 1.41         |\n",
      "|    value_loss         | 1.22e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.3         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | -0.0352       |\n",
      "|    reward             | 9.0980146e-05 |\n",
      "|    std                | 1.49          |\n",
      "|    value_loss         | 5.31e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.00736      |\n",
      "|    reward             | -0.006716076 |\n",
      "|    std                | 1.57         |\n",
      "|    value_loss         | 8.12e-06     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.00552     |\n",
      "|    reward             | 0.0035751325 |\n",
      "|    std                | 1.65         |\n",
      "|    value_loss         | 2.16e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | -0.0564     |\n",
      "|    reward             | 0.006597298 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 1.93e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 319            |\n",
      "|    iterations         | 1600           |\n",
      "|    time_elapsed       | 25             |\n",
      "|    total_timesteps    | 8000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1599           |\n",
      "|    policy_loss        | 0.172          |\n",
      "|    reward             | -0.00066759245 |\n",
      "|    std                | 1.82           |\n",
      "|    value_loss         | 0.00012        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.0953     |\n",
      "|    reward             | 0.010733803 |\n",
      "|    std                | 1.91        |\n",
      "|    value_loss         | 2.14e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.195        |\n",
      "|    reward             | -0.0019193685 |\n",
      "|    std                | 2.01          |\n",
      "|    value_loss         | 0.000113      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.0834     |\n",
      "|    reward             | 0.002937249 |\n",
      "|    std                | 2.11        |\n",
      "|    value_loss         | 1.86e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 31            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.0175       |\n",
      "|    reward             | -0.0020265752 |\n",
      "|    std                | 2.2           |\n",
      "|    value_loss         | 3.58e-06      |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.1988719638648734\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_630_15\n",
      "---------------------------------------\n",
      "| time/              |                |\n",
      "|    fps             | 408            |\n",
      "|    iterations      | 1              |\n",
      "|    time_elapsed    | 5              |\n",
      "|    total_timesteps | 2048           |\n",
      "| train/             |                |\n",
      "|    reward          | 0.000112619724 |\n",
      "---------------------------------------\n",
      "day: 2516, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 901.76\n",
      "total_reward: -9098.24\n",
      "total_cost: 2956.40\n",
      "total_trades: 14075\n",
      "Sharpe: -0.430\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 398          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046151364 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.136       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | 0.002417893  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000574     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 392          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008089937  |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.144       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | 0.0021777449 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00152      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 392           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009077817   |\n",
      "|    clip_fraction        | 0.114         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.16          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.133        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00724      |\n",
      "|    reward               | -0.0008117718 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000998      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 393          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011772189  |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.131       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    reward               | 0.0014095831 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.000677     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.2118908377161466\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_630_15\n",
      "day: 2516, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 31513.96\n",
      "total_reward: 21513.96\n",
      "total_cost: 511.98\n",
      "total_trades: 10426\n",
      "Sharpe: 0.881\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 146         |\n",
      "|    time_elapsed    | 68          |\n",
      "|    total_timesteps | 10068       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 668         |\n",
      "|    critic_loss     | 396         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 7551        |\n",
      "|    reward          | 0.009009726 |\n",
      "------------------------------------\n",
      "======DDPG Validation from:  2020-01-03T00:00:00.000000000 to  2020-04-03T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======Trading from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  45.85564342289033\n",
      "======Model training from:  2010-01-01 to  2020-04-03T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_693_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 281         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.00422     |\n",
      "|    reward             | -0.00428438 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 2.21e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 292           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.196        |\n",
      "|    reward             | -0.0059328354 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 0.000575      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 294         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.291      |\n",
      "|    reward             | 0.046653934 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.00076     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 278         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.362      |\n",
      "|    reward             | -0.03692688 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.000713    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 270          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -0.234       |\n",
      "|    reward             | -0.009787941 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 0.000251     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 262           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0161        |\n",
      "|    reward             | -0.0035611512 |\n",
      "|    std                | 1.17          |\n",
      "|    value_loss         | 2.54e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 260           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.00924      |\n",
      "|    reward             | -0.0013389381 |\n",
      "|    std                | 1.2           |\n",
      "|    value_loss         | 1.55e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 261          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.00169     |\n",
      "|    reward             | -0.016400674 |\n",
      "|    std                | 1.25         |\n",
      "|    value_loss         | 4.49e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 265          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.0844      |\n",
      "|    reward             | 0.0022800644 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 4.82e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 269        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 0.161      |\n",
      "|    reward             | 0.01477132 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 0.000189   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 266          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.00522     |\n",
      "|    reward             | 0.0040619452 |\n",
      "|    std                | 1.41         |\n",
      "|    value_loss         | 1.5e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 265          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0557       |\n",
      "|    reward             | 0.0048212977 |\n",
      "|    std                | 1.47         |\n",
      "|    value_loss         | 1.33e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 268         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 0.0933      |\n",
      "|    reward             | 0.008479755 |\n",
      "|    std                | 1.54        |\n",
      "|    value_loss         | 3.33e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 271           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.109         |\n",
      "|    reward             | -0.0029331024 |\n",
      "|    std                | 1.61          |\n",
      "|    value_loss         | 5.36e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 273         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.11        |\n",
      "|    reward             | 0.003595533 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 4.25e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 276           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.7         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.077         |\n",
      "|    reward             | 0.00058955594 |\n",
      "|    std                | 1.73          |\n",
      "|    value_loss         | 2.11e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 279          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.148        |\n",
      "|    reward             | 0.0014139727 |\n",
      "|    std                | 1.81         |\n",
      "|    value_loss         | 8.36e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 281          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0527       |\n",
      "|    reward             | 0.0007752166 |\n",
      "|    std                | 1.9          |\n",
      "|    value_loss         | 1.52e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 282           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.017         |\n",
      "|    reward             | -0.0018566244 |\n",
      "|    std                | 2             |\n",
      "|    value_loss         | 1.53e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.048      |\n",
      "|    reward             | 0.008095545 |\n",
      "|    std                | 2.12        |\n",
      "|    value_loss         | 1.14e-05    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.2026330254693361\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo/ppo_693_15\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 433           |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 4             |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0011284745 |\n",
      "--------------------------------------\n",
      "day: 2579, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 1280.40\n",
      "total_reward: -8719.60\n",
      "total_cost: 6690.99\n",
      "total_trades: 15244\n",
      "Sharpe: -0.572\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 395           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007940432   |\n",
      "|    clip_fraction        | 0.0709        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.192         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.127        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00551      |\n",
      "|    reward               | -0.0009967879 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00032       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 399           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008852681   |\n",
      "|    clip_fraction        | 0.0939        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.8         |\n",
      "|    explained_variance   | 0.253         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.143        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00692      |\n",
      "|    reward               | -0.0009214124 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000376      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 389          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073766094 |\n",
      "|    clip_fraction        | 0.0958       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.128       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00842     |\n",
      "|    reward               | 0.00417326   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00032      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 387           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 26            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0072686877  |\n",
      "|    clip_fraction        | 0.0757        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -12.9         |\n",
      "|    explained_variance   | 0.419         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.134        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00476      |\n",
      "|    reward               | -0.0017792579 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.000296      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.16441777210099162\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_693_15\n",
      "day: 2579, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 10061.80\n",
      "total_reward: 61.80\n",
      "total_cost: 9.95\n",
      "total_trades: 2579\n",
      "Sharpe: 0.193\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 145        |\n",
      "|    time_elapsed    | 70         |\n",
      "|    total_timesteps | 10320      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 179        |\n",
      "|    critic_loss     | 95.4       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 7740       |\n",
      "|    reward          | 0.04644546 |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2020-04-03T00:00:00.000000000 to  2020-07-06T00:00:00.000000000\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-07-06T00:00:00.000000000\n",
      "======Trading from:  2020-07-06T00:00:00.000000000 to  2020-10-02T00:00:00.000000000\n",
      "Ensemble Strategy took:  24.06088953415553  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "df_summary_lv = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs, PPO_model_kwargs, DDPG_model_kwargs, timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "Op7jyI7lm4hm",
    "outputId": "d8356c0f-673d-4ab1-879e-972e5bf32871"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.237454</td>\n",
       "      <td>-0.523626</td>\n",
       "      <td>-0.16785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.041134</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>0.003083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.030626</td>\n",
       "      <td>-0.111508</td>\n",
       "      <td>0.25826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.455284</td>\n",
       "      <td>-0.261776</td>\n",
       "      <td>-0.223047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.411798</td>\n",
       "      <td>-0.178516</td>\n",
       "      <td>0.693379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.403741</td>\n",
       "      <td>0.196501</td>\n",
       "      <td>0.335418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.028513</td>\n",
       "      <td>-0.039842</td>\n",
       "      <td>-0.075401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>PPO</td>\n",
       "      <td>-0.115006</td>\n",
       "      <td>0.112537</td>\n",
       "      <td>-0.043428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.198872</td>\n",
       "      <td>-0.211891</td>\n",
       "      <td>-0.296564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.202633</td>\n",
       "      <td>0.164418</td>\n",
       "      <td>0.085229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter  Val Start    Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126 2018-01-02 2018-04-04       DDPG  -0.237454  -0.523626    -0.16785\n",
       "1  189 2018-04-04 2018-07-03        PPO   0.041134   0.046121    0.003083\n",
       "2  252 2018-07-03 2018-10-02       DDPG   0.030626  -0.111508     0.25826\n",
       "3  315 2018-10-02 2019-01-03       DDPG  -0.455284  -0.261776   -0.223047\n",
       "4  378 2019-01-03 2019-04-04       DDPG   0.411798  -0.178516    0.693379\n",
       "5  441 2019-04-04 2019-07-05        A2C   0.403741   0.196501    0.335418\n",
       "6  504 2019-07-05 2019-10-03        A2C  -0.028513  -0.039842   -0.075401\n",
       "7  567 2019-10-03 2020-01-03        PPO  -0.115006   0.112537   -0.043428\n",
       "8  630 2020-01-03 2020-04-03        A2C  -0.198872  -0.211891   -0.296564\n",
       "9  693 2020-04-03 2020-07-06        A2C   0.202633   0.164418    0.085229"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10068.749172</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>0.006875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9845.059572</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>-0.022216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9893.360330</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>0.004906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10049.709796</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>0.015803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>14001.630524</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>0.022628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>14641.455319</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>0.045696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>14373.378171</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>-0.018309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>14406.006117</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>14609.933983</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0.014156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     account_value        date  daily_return\n",
       "0     10000.000000  2018-04-04           NaN\n",
       "1     10068.749172  2018-04-05      0.006875\n",
       "2      9845.059572  2018-04-06     -0.022216\n",
       "3      9893.360330  2018-04-09      0.004906\n",
       "4     10049.709796  2018-04-10      0.015803\n",
       "..             ...         ...           ...\n",
       "625   14001.630524  2020-09-25      0.022628\n",
       "626   14641.455319  2020-09-28      0.045696\n",
       "627   14373.378171  2020-09-29     -0.018309\n",
       "628   14406.006117  2020-09-30      0.002270\n",
       "629   14609.933983  2020-10-01      0.014156\n",
       "\n",
       "[630 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "# for every cycle (rebalance_window + validation_window) read the csv files into a dataframe\n",
    "for i in range(rebalance_window+validation_window, len(test_dates)+1,rebalance_window):\n",
    "     result_df = pd.read_csv(f'results/account_value_trade_ensemble_{i}.csv')\n",
    "     results_list.append(result_df)\n",
    "\n",
    "df_ensemble_results_lv  = pd.concat(results_list, ignore_index=True)  # Create a dataframe to store execution results\n",
    "\n",
    "df_ensemble_results_lv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQNioH9UxmEC"
   },
   "source": [
    "#### Step 7: Analyze Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - #### Step 7.0: Baseline Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = df.loc[df['tic'] == 'SPY'].sort_values(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_index['date'] > df_ensemble_results.loc[0,'date']) & (df_index['date'] <= df_ensemble_results.loc[len(df_ensemble_results)-1,'date'])\n",
    "df_index_masked = df_index.loc[mask].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return          0.121354\n",
      "Cumulative returns     0.330942\n",
      "Annual volatility      0.236552\n",
      "Sharpe ratio           0.604095\n",
      "Calmar ratio           0.359916\n",
      "Stability              0.554521\n",
      "Max drawdown          -0.337173\n",
      "Omega ratio            1.137069\n",
      "Sortino ratio          0.825409\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.702057\n",
      "Daily value at risk   -0.029236\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "index_stats = backtest_stats(df_index_masked, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - #### Step 7.1: Model with Most-Volatile and Least-Volatile Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bi0NhRExrSz"
   },
   "source": [
    ">> - #### Step 7.1.1: Calcualte Sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcGN6S1PzjpU",
    "outputId": "20f8a9a8-941c-472a-8ab0-18449a668319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  0.8387482275095949\n"
     ]
    }
   ],
   "source": [
    "# Calculate Sharpe ratio\n",
    "sharpe=(252**0.5)*df_ensemble_results.account_value.pct_change(1).mean()/df_ensemble_results.account_value.pct_change(1).std()\n",
    "\n",
    "print('Sharpe Ratio: ',sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "bhQeQ969zvRa"
   },
   "outputs": [],
   "source": [
    "df_validation_dates = trade_date_df[validation_window:].reset_index(drop=True) # Get the stock market dates from historical data\n",
    "df_ensemble_results = df_ensemble_results.join(df_validation_dates) # Mask the results with the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "4RYlDJUDm4an",
    "outputId": "97f6cffc-d76a-48ad-8f5c-974d112cd8c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_ensemble_results.account_value.plot()     # plot the chance in the amount value with time during test period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zsjiQs0xuA4"
   },
   "source": [
    ">> - #### Step 7.1.2: Backtest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOtqFrge0PaS",
    "outputId": "57b6fa4d-2ed6-4814-f533-cffec36c254a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return          0.131419\n",
      "Cumulative returns     0.361630\n",
      "Annual volatility      0.163439\n",
      "Sharpe ratio           0.838748\n",
      "Calmar ratio           0.904645\n",
      "Stability              0.788096\n",
      "Max drawdown          -0.145272\n",
      "Omega ratio            1.171603\n",
      "Sortino ratio          1.169260\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.823937\n",
      "Daily value at risk   -0.020047\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "stats = backtest_stats(account_value=df_ensemble_results)\n",
    "stats_df = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JlN8dyDxwvB"
   },
   "source": [
    ">> - #### Step 7.1.3: Compare with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "TtxmLvb44SfI"
   },
   "outputs": [],
   "source": [
    "# Rescale index stocks with begining as 10000\n",
    "\n",
    "df_index_scaled = pd.DataFrame()\n",
    "\n",
    "df_index_scaled[\"date\"] = df_ensemble_results[\"date\"]\n",
    "\n",
    "df_index_scaled[\"spy\"] = df_index_masked['close'] / df_index_masked.iloc[0]['close'] * 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "DCRq62Rq9wBC",
    "outputId": "9f66278a-ee2e-4d31-d157-7aa7a778eb1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>spy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>9777.141321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>9825.327421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>9981.552869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>9929.227721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>13196.873815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>13125.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>13224.516675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>13309.419390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date           spy\n",
       "0    2018-04-04  10000.000000\n",
       "1    2018-04-05   9777.141321\n",
       "2    2018-04-06   9825.327421\n",
       "3    2018-04-09   9981.552869\n",
       "4    2018-04-10   9929.227721\n",
       "..          ...           ...\n",
       "625  2020-09-25  13196.873815\n",
       "626  2020-09-28  13125.003128\n",
       "627  2020-09-29  13224.516675\n",
       "628  2020-09-30  13309.419390\n",
       "629  2020-10-01           NaN\n",
       "\n",
       "[630 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "tmq__tq19v62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>spy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>9998.908928</td>\n",
       "      <td>9777.141321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>9856.480908</td>\n",
       "      <td>9825.327421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>9871.763478</td>\n",
       "      <td>9981.552869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>9923.765217</td>\n",
       "      <td>9929.227721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>13268.863610</td>\n",
       "      <td>13196.873815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>13419.964238</td>\n",
       "      <td>13125.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>13358.774067</td>\n",
       "      <td>13224.516675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>13445.233043</td>\n",
       "      <td>13309.419390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>13616.297390</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            account_value           spy\n",
       "date                                   \n",
       "2018-04-04   10000.000000  10000.000000\n",
       "2018-04-05    9998.908928   9777.141321\n",
       "2018-04-06    9856.480908   9825.327421\n",
       "2018-04-09    9871.763478   9981.552869\n",
       "2018-04-10    9923.765217   9929.227721\n",
       "...                   ...           ...\n",
       "2020-09-25   13268.863610  13196.873815\n",
       "2020-09-28   13419.964238  13125.003128\n",
       "2020-09-29   13358.774067  13224.516675\n",
       "2020-09-30   13445.233043  13309.419390\n",
       "2020-10-01   13616.297390           NaN\n",
       "\n",
       "[630 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.merge(df_ensemble_results, df_index_scaled, on =\"date\", how = \"left\")[[\"date\",\"account_value\",\"spy\"]]\n",
    "final_results.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFNgSamJxyv3"
   },
   "source": [
    ">> - #### Step 7.1.4: Vizualise the comparision with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "KjlrtpRk9mc_",
    "outputId": "d8314657-6f9d-4600-f2e9-bf633538a358"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACth0lEQVR4nOydd3hUZfr3v2d62qRXUugdAtIEAUEQBBsWVhA74rorrivK7quriH3XXnDXn31dYXUtIAqiKCoISA8dpAQC6X3Spp/3j+fUKclMMun357pynfacc57JJHO+c1eO53keBEEQBEEQXQxNe0+AIAiCIAiiNSCRQxAEQRBEl4REDkEQBEEQXRISOQRBEARBdElI5BAEQRAE0SUhkUMQBEEQRJeERA5BEARBEF0SEjkEQRAEQXRJdO09gfbE7XajoKAAUVFR4DiuvadDEARBEEQA8DyPmpoapKWlQaPxb6/p1iKnoKAAGRkZ7T0NgiAIgiCawblz55Cenu73eLcWOVFRUQDYL8lsNrfzbAiCIAiCCASLxYKMjAzpOe6Pbi1yRBeV2WwmkUMQBEEQnYymQk0o8JggCIIgiC4JiRyCIAiCILokJHIIgiAIguiSdOuYnEBwuVxwOBztPQ2iC6DVaqHT6ahcAUEQRBtBIqcRamtrcf78efA8395TIboI4eHhSE1NhcFgaO+pEARBdHlI5PjB5XLh/PnzCA8PR2JiIn37JloEz/Ow2+0oLS1Fbm4u+vXr12gBK4IgCKLlkMjxg8PhAM/zSExMRFhYWHtPh+gChIWFQa/X4+zZs7Db7TCZTO09JYIgiC4NfZVsArLgEKGErDcEQRBtB33iEgRBEATRJSGRQxAEQRBEl4REDkEILF++HCNGjGjvaRAEQRAhgkQO0SHp2bMnXnnllfaeBkEQBNGJIZFDEARBEIRPeJ7HR7+exa4zFe09lWZBIidAeJ5Hvd3ZLj/BFiPcsGEDJk6ciJiYGMTHx+OKK67AqVOnpOPnz5/H/PnzERcXh4iICIwePRo7duyQjn/11VcYM2YMTCYTEhIScM0110jHKisrccsttyA2Nhbh4eGYNWsWTpw4IR335fJ55ZVX0LNnT2n7tttuw5w5c/DCCy8gNTUV8fHxuOeee6TK0lOmTMHZs2dx//33g+O4JjPcLBYLwsLC8M0336j2r169GlFRUaivrwcA/PWvf0X//v0RHh6O3r1749FHH220mvWUKVPw5z//WbVvzpw5uO2226Rtm82GBx98ED169EBERATGjRuHn376qdH5EgRBdBb27M/Bp1+uwdw3t7f3VJoF1ckJkAaHC4OXfdsu9z7yxEyEGwJ/q+rq6rBkyRIMHz4ctbW1WLZsGa655hrk5OSgvr4eF198MXr06IG1a9ciJSUFe/fuhdvtBgCsW7cO11xzDf72t7/hww8/hN1ux/r166Vr33bbbThx4gTWrl0Ls9mMv/71r5g9ezaOHDkCvV4f8Bx//PFHpKam4scff8TJkydxww03YMSIEVi0aBG++OILZGdn46677sKiRYuavJbZbMYVV1yBVatWYdasWdL+lStXYs6cOQgPDwcAREVF4YMPPkBaWhoOHjyIRYsWISoqCn/5y18CnrcnixcvxpEjR/Dxxx8jLS0Nq1evxmWXXYaDBw+iX79+zb4uQRBER2D0min40ghMtr3c3lNpFkFbcjZv3owrr7wSaWlp4DgOa9as8Tv27rvvBsdxXrEVFRUVWLBgAcxmM2JiYrBw4ULU1taqxhw4cACTJk2CyWRCRkYGnnvuOa/rf/rppxg4cCBMJhOGDRumehh3Z6677jpce+216Nu3L0aMGIH33nsPBw8exJEjR7Bq1SqUlpZizZo1mDhxIvr27Yvf/e53GD9+PADg6aefxrx58/D4449j0KBByM7OxkMPPQQAkrh55513MGnSJGRnZ2PlypXIz89v9O/AF7GxsVixYgUGDhyIK664Apdffjl++OEHAEBcXBy0Wi2ioqKQkpKClJSUJq+3YMECrFmzRrLaWCwWrFu3DgsWLJDGPPLII5gwYQJ69uyJK6+8Eg8++CD+97//BTVvJXl5eXj//ffx6aefYtKkSejTpw8efPBBTJw4Ee+//36zr0sQBNHR6M+db+8pNIugLTl1dXXIzs7GHXfcgWuvvdbvuNWrV+PXX39FWlqa17EFCxagsLAQGzduhMPhwO2334677roLq1atAsAeUDNmzMD06dPx5ptv4uDBg7jjjjsQExODu+66CwCwbds2zJ8/H88++6z0LX7OnDnYu3cvhg4dGuzLapIwvRZHnpgZ8usGeu9gOHHiBJYtW4YdO3agrKxMstLk5eUhJycHI0eORFxcnM9zc3Jy/FpPjh49Cp1Oh3Hjxkn74uPjMWDAABw9ejSoOQ4ZMgRarfy6UlNTcfDgwaCuoWT27NnQ6/VYu3Yt5s2bh88//xxmsxnTp0+XxnzyySd47bXXcOrUKdTW1sLpdMJsNjf7ngcPHoTL5UL//v1V+202G+Lj45t9XYIgiA6B0yatWtE5++0FLXJmzZqlcgn4Ij8/H/feey++/fZbXH755apjR48exYYNG7Br1y6MHj0aAPD6669j9uzZeOGFF5CWloaVK1fCbrfjvffeg8FgwJAhQ5CTk4OXXnpJEjmvvvoqLrvsMixduhQA8OSTT2Ljxo1YsWIF3nzzzWBfVpNwHBeUy6g9ufLKK5GVlYW3334baWlpcLvdGDp0KOx2e5MtKlrawkKj0XjFEPmKe/F0bXEcJ4mx5mAwGHD99ddj1apVmDdvHlatWoUbbrgBOh17z7Zv344FCxbg8ccfx8yZMxEdHY2PP/4YL774YrNfS21tLbRaLfbs2aMSbAAQGRnZ7NdCEATRIbBapFU7r4PD5YZe27lCeUM+W7fbjZtvvhlLly7FkCFDvI5v374dMTExksABgOnTp0Oj0UjBr9u3b8fkyZNVnZpnzpyJ48ePo7KyUhqj/JYujtm+3X9wlM1mg8ViUf10NcrLy3H8+HE88sgjmDZtGgYNGiT9zgBg+PDhyMnJQUWF70j54cOHS24jTwYNGgSn06kKUhbvN3jwYABAYmIiioqKVOIgJycn6NdhMBjgcrmCOmfBggXYsGEDDh8+jE2bNqlcVdu2bUNWVhb+9re/YfTo0ejXrx/Onj3b6PUSExNRWFgobbtcLhw6dEjaHjlyJFwuF0pKStC3b1/VTyAuNoIgiA6NTX5Gajk3rI7gPpM7AiEXOf/4xz+g0+nwpz/9yefxoqIiJCUlqfbpdDrExcWhqKhIGpOcnKwaI243NUY87otnn30W0dHR0k9GRkZwL64TEBsbi/j4eLz11ls4efIkNm3ahCVLlkjH58+fj5SUFMyZMwdbt27F6dOn8fnnn0vi8LHHHsN///tfPPbYYzh69CgOHjyIf/zjHwCAfv364eqrr8aiRYvwyy+/YP/+/bjpppvQo0cPXH311QBYRlJpaSmee+45nDp1Cm+88YZX1lMg9OzZE5s3b0Z+fj7KysoCOmfy5MlISUnBggUL0KtXL5VbrV+/fsjLy8PHH3+MU6dO4bXXXsPq1asbvd4ll1yCdevWYd26dTh27Bj+8Ic/oKqqSjrev39/LFiwALfccgu++OIL5ObmYufOnXj22Wexbt26oF8zQRBEh0IhcvRwwuZsvrW9vQipyNmzZw9effVVfPDBBx2yseVDDz2E6upq6efcuXPtPaWQo9Fo8PHHH2PPnj0YOnQo7r//fjz//PPScYPBgO+++w5JSUmYPXs2hg0bhr///e+Su2XKlCn49NNPsXbtWowYMQKXXHIJdu7cKZ3//vvvY9SoUbjiiiswfvx48DyP9evXS+6nQYMG4Z///CfeeOMNZGdnY+fOnXjwwQeDfh1PPPEEzpw5gz59+iAxMTGgcziOw/z587F//36VFQcArrrqKtx///1YvHgxRowYgW3btuHRRx9t9Hp33HEHbr31Vtxyyy24+OKL0bt3b0ydOlU15v3338ctt9yCBx54AAMGDMCcOXOwa9cuZGZmBveCCYIgOhpWtcjpjJYc8C0AAL969Wpp++WXX+Y5juO1Wq30A4DXaDR8VlYWz/M8/+677/IxMTGq6zgcDl6r1fJffPEFz/M8f/PNN/NXX321asymTZt4AHxFRQXP8zyfkZHBv/zyy6oxy5Yt44cPHx7w/Kurq3kAfHV1tdexhoYG/siRI3xDQ0PA1yOIpqC/K4IgOg1HvuL5x8w8/5iZ//1Dy/gTxTXtPSOJxp7fSkJqybn55ptx4MAB5OTkSD9paWlYunQpvv2W1ZgZP348qqqqsGfPHum8TZs2we12S+6F8ePHY/Pmzaogz40bN2LAgAGIjY2VxnjGjmzcuFFKhSYIgiAIogUo3FWGTmrJCVrk1NbWSgIGAHJzc5GTk4O8vDzEx8dj6NChqh+9Xo+UlBQMGDAAAHNnXHbZZVi0aBF27tyJrVu3YvHixZg3b56Ubn7jjTfCYDBg4cKFOHz4MD755BO8+uqrqtiS++67Dxs2bMCLL76IY8eOYfny5di9ezcWL14cgl8L0dGYNWsWIiMjff4888wz7T09giCIroetRlplMTmdT+QEnRO9e/duVVyCKDxuvfVWfPDBBwFdY+XKlVi8eDGmTZsGjUaD6667Dq+99pp0PDo6Gt999x3uuecejBo1CgkJCVi2bJmUPg4AEyZMwKpVq/DII4/g4YcfRr9+/bBmzZpWqZFDtD/vvPMOGhoafB7zV/OHIAiCaAHKmBzOCauj8wUeBy1ypkyZElQvpTNnznjti4uLkwr/+WP48OHYsmVLo2Pmzp2LuXPnBjwXovPSo0eP9p4CQRBE98Iru6rzWXI6V1UfgiAIgiDaBq+YnM5nySGRQxAEQRCENw1V0mpnTSEnkUMQBEEQhDd1pdKqniw5BEEQBEF0GZQihyNLDkEQBEEQXYXaEmnVABe1dSAIgiAIoguw4WHAWiVtUkwOQRAEQRCdn6pzwK9vqHbp4YSVUsgJgiAIgujUVJ312qWHEzYKPO7C8Dxgr2ufnyCKLwLAZ599hmHDhiEsLAzx8fGYPn066urqcNttt2HOnDl4/PHHkZiYCLPZjLvvvht2ux0A8OGHHyI+Ph42m011vTlz5uDmm28O2a+SIAiC6MBUeoscA+dErc3ZDpNpGUFXPO62OOqBZ9La594PFwCGiICGFhYWYv78+XjuuedwzTXXoKamBlu2bJGqVP/www8wmUz46aefcObMGdx+++2Ij4/H008/jblz5+JPf/oT1q5dK1WSLikpwbp16/Ddd9+12ssjCIIg2garw4V3f8nFzCHJ6JsU5XuQH0tOscXayrMLPWTJ6WIUFhbC6XTi2muvRc+ePTFs2DD88Y9/RGRkJADAYDDgvffew5AhQ3D55ZfjiSeewGuvvQa3242wsDDceOONeP/996XrffTRR8jMzMSUKVPa6RURBEEQoWLpZwfw/LfH8YeP9vofJFhyzoYPxUuO6wEwkVNisfk/p4NClpxA0Yczi0p73TtAsrOzMW3aNAwbNgwzZ87EjBkzcP311yM2NlY6Hh4uX2/8+PGora3FuXPnkJWVhUWLFmHMmDHIz89Hjx498MEHH+C2224Dx3Ehf1kEQRBE2/LVfvYcO1FS639Q2W8AgBeqpsDEsXAGPZwo8rDkHDhfhe+PluDeS/pCr+2YNpOOOauOCMcxl1F7/AQhMLRaLTZu3IhvvvkGgwcPxuuvv44BAwYgNzc3oPNHjhyJ7OxsfPjhh9izZw8OHz6M2267rZm/NIIgCKKjUFqjtsRsOFSk2na7eby95jugYC94ToOd7oGw88wWYoAT1Q0OKY3c7nTjqhVb8doPJ7yu05EgkdMF4TgOF110ER5//HHs27cPBoMBq1evBgDs378fDQ0N0thff/0VkZGRyMjIkPbdeeed+OCDD/D+++9j+vTpqmMEQRBE56S6wa7avvujPdhztlLa/u5IMSp2fQ4AKE6cgGLEoUdCNADApGFBx2JczvqDhdJ5FqujVefdEkjkdDF27NiBZ555Brt370ZeXh6++OILlJaWYtCgQQAAu92OhQsX4siRI1i/fj0ee+wxLF68GBqN/Kdw44034vz583j77bdxxx13tNdLIQiCIEJIjdU7O+rrA3IYRkmNFalcOQDgEN8bANA7mYU6hGtZ+viJ4lrwPI+jhXKHcrc7uAzgtoRicroYZrMZmzdvxiuvvAKLxYKsrCy8+OKLmDVrFj755BNMmzYN/fr1w+TJk2Gz2TB//nwsX75cdY3o6Ghcd911WLduHebMmdMur4MgCIIILXU272J+20+VS+taDYdojomXXSVaAEDf1FjgBBCmYSLnzg9349oLeqiETYOfSsh2pxt6LdeuMZ0kcroYgwYNwoYNGxod8/jjj+Pxxx9vdEx+fj4WLFgAo9EYyukRBEEQ7YSvOjfHi2tQ3eBAdJgeNVYn+ggip8DBypb0TY0HwBp0inyxNx8X9o6TthvsvosEXv7aFpytqMdHC8dhbK84n2NaG3JXESoqKyuxevVq/PTTT7jnnnvaezoEQRBEiPAlcnge2CvE5VTW2REPJnLKEI302DBEhocBYIHHSpTp5P4sOVUNDtidboQbtCGZf3MgSw6hYuTIkaisrMQ//vEPDBgwoL2nQxBEN8TqcMHS4ECS2dTeU+lS1PmpWPzr6XJMHZiEyno74gRLTgUfhf7JUYCWuZr0UAcXK9PJ/TXurG5g50SH6Vs89+ZCIqcb8cEHHzQ55syZM60+D4IgiMa44f+2Y//5amz5y1RkxAVeJ4xoHH9tGdYfKsT/mzUQVXVWxILVzynnozElKRIwModPuFtdV6feLgubBru3yLE6XLA7mRsrOrz9RA65qwiCIIgOg8vNY//5agDAD0eL23k2XQtPkRMXYUCYXotzFQ14e8tpuGrLoeF4uHkOlYhEn6RIICoFABDmqoUJvise+3JXiVYcrYZDlLH97CkkcpqAD7I5JkE0Bv09EUTj5FXUS+uRpvazAHRFPN1VEUYt7pjYEwDw/LfHYbcwUVmriUKf5GhMHZAEGM2AngUhJ3OV8EVjIsds0rVrdhWJHD9otSxQSuzQTRChoL6efYDr9fThTRC++K24RlqvbnB06BosnY1ajzo5Wo7DgzMGINKog8PFw1xzGgBgiM/Ed/dfjMQoI6u4L1hzkuFb5PiKyekI8TgAxeT4RafTITw8HKWlpdDr9apieQQRLDzPo76+HiUlJYiJiZFENEF0B8prbbjzw9343egMzB+b2ejYEwqR89yGY3jl+9/w8V0XYkhadGtPs8vj6a7SalgNm8FpZuzMrcAYzTEAAJc1Xn1iVCpQcQopXCXgQ3P6ismprieR06HhOA6pqanIzc3F2bPebecJojnExMQgJSWlvadBEG3KSxt/w768KuzLq/IrcracKMWqHXn4RtEHyeZ0w+Z0Y/naw/j07gltNd0uS51dLXL6JUUBAPonR2JnbgXGCSLH2Hui+kTBkpPk4a4y6jSwOd2Nu6tI5HRcDAYD+vXrRy4rIiTo9Xqy4BDdkmKL74BVEZebx//7/CDyqxp8HvdsLEk0D9Fd9fvJvVFQbcWjV7B2PwOSowDw6M0JLR7SRqpPNKcCAFK4CtXuxCgjzlc2+BQ5VeSu6hxoNBqYTFSrgSAIorn4q6MisuVEqV+BA6jTlYnmU1bLvrBfOjgZo3vKFYgn9E1AFBpgFKsaRyapTwxj/auioH6PkgSRY/XlruogIocCTQiCIIhWxV9FXJF9eVWNHi+psfktZEcERr3dKQnJ3omRqmN9EiMRz7G0fSsXBujD1Cfr2Bd9I6f2aiRGsbY/Pt1V9WwsiRyCIAiiS1JZZ8dL3x3H8aKaRsedq6xv9DgAVNRR2EBLOF1aB4DVxomLMHgdf35WGgBAG5XkdQw6JmaMHlWPk6KY+PEUOR/9ehb/3s5iWVOj29cTQu4qgiAIolV45MtDWHegULXP5eah1ch1U8prbdh0rAQAEG7QSq4pjmN9lUT8VeslAuNkCatY3NfDiiMyJpFVJ9ZHJXofFC05HiJHtORYHW643Tw0Gg5WhwuPrDkkjWnvitVkySEIgiBahZ8E8aJE+a3f6nDh+je3o0pIN77jol4AgCiTDv++fSy++OMEZAoPyXo7iZyWcLSI9aTqkxThe0BdKVtGBCZytHAhOVK2k1id7H0V30uR9hY5ZMkhCIIg2ox6uxORQpn/j3fmIbesTjp220U9MTw9GoNSzdLDMUIYW2ej4OPmwvM8vjnIUvMv7B3ve1BdGVtGJHgfE9xVcZwF4bDCAAc2GpeC2z8KHLcIPM/en3CDzsut2CMmzPt6bQhZcgiCIIg2o14hVnaeUackx0cYMGNIiurbf4SBlV0gS07zOVxgQV5FPcINWlw6ONn3oPrGRA6z5AzSnMN+4yJM1+5FImdBQsGPSDYwUSMGhlfVq0WOSd++ZTNI5BAEQRBthjIdXAyGvahvPN68aZTPHkfhgiWnliw5zeac0A9sYEoUwg1+HDjV59kywn/gMQDoORf6ceel7dF61gpCjJmqVLirpg/yI6jaEBI5BEEQRMhxuXlYnW6v/aJFxu3mJVfVM9cMw2VDfVcCjzSSJaellAkupIRIo/fBujLg3C4gbzvb7nGB9xit+rxbMsul9ZGaUwBkkVMhWHIGpkRhxY0eRQXbARI5BEEQRMgpr7XB5aO5pmjJKbRYYXO6oddyjcZtiJYHislpPhVCEcB4T5HD88D7s4B3pwP15azbeJoPkaNTnxdWtEda78vlA1C4qwRBdXf4JphWXg3s+yhUL6NZkMghCIIgQo6/CsaiyMkVXFUZceHQaf0/isSYHCoG2HzK61hbjHjP+jj5e4Cy3+TtrPGAzruGjhiTI+GWXVIJPOtn5WnJ6e04AZzZAljUJQTaGhI5BEEQRMgRXVGp0Sb8/dphuKgvy+oR3U75VSxOJLOJFGMxJsezuSQROOWSJUcQMA2VwMkfgIOfqgf2muz7Ajofbi6BOEHkiJY2MYU83iE0Wo1pvOt8a0Mp5ARBEETIEYOKpw5MwryxmfjxOKuZU293ged5/FbMitOlNZFiLKab15O7qtlIlhzRXfXDE8Du97wH+hU5/qsWx7hYhlytjYmbSrGdg51EDkEQBNFFOV3GREzvBFZ8Toytqbc78cz6o3j3l1wATddRCRfcVbVkyWk2kiVHdFd5Chx9BBCdDqQM932BRiw5Ye5aGGGXst9qrU5o4EZ4A4kcgiAIoosiWnJ6JzKREybVu3Hh7S250rimehtFiOKIYnKajVigT3JXJQ8FioXWC/1mANe9C3AaQOOnpo0vS05UKtBQBTgbkMRVSjFTdXYXklEJDe8ENDogynfWXFtBIocgCIIIOecrWeBxZhwTOWIAcYNd7XZqyl0lVTy2k7uqOWz+rRTldXbotZz8u3YIDVEvfwm44FZA24QU8GXJMcWw/ZVnkIQqSeTU251I54QWEdHp/oVTG0GBxwRBEERAVDc4wCu6ZuaV1+O8jw7itTanlG2TIlhqwgy+A4jToptwVxkpu6olvL+VWc1uvrAnzAYt8N2jQAUr4IfM8U0LHMC3UDFFA5HMSpPIVaNGeH/6Wg/hXcMLbEw7u6oAEjkEQRBEAOzNq8TIJ77Ds98cQ2mNDUs/3Y/Jz/+Iq1Zs9RIgJRYrAGa9EQOHIxTuKoOQMt47MQI9YhsROTyPKKniMYmcYHG7eew5y7KfrhnZA8j9Gdj2mjzAFN38i4fFAOEsYy6Oq5H+Bt51PQIzJwjfDiByyF1FEARBNMmjaw7BzQNvbT6NvPJ6bDjMAksr6uz4YNsZzBicjH7JUQCAYgvL5kk2y7EcYgBxZZ0ddherhPzlPRdBq/Fu5QB7HfDP8UBsT5gvWwkAsDQ4vMcRXjhdbqnu0PKvDsNidcKo02BgahTw0xb14LCY5t/IFANo9QCAWNTguNUJt5tXW06i21/kkCWHIAiCaJJKRXdpUeCIPP/tcVz+2i84W86CjUtqmCUnySzHcojuqsJqdkzDyUHFKtxuYPsbQNVZIPdnxDhZirLF6lS5yghv3vjxJIYt/w6HC6pxvrIeH24/CwDITo+BvuIksOP/1CfoG69R1Cgelpw9Zyvx2NrD6jEdwJJDIocgCIJokuomLCl2lxtfHyiEzenCK9+fAACkKCw5orvqWFENAMAcpofG04rz7d+AJ2KBH5+WdkVXHgTAemHVU/Bxozz/7XE0OFz46+cHUCSISQC4/9L+wK53AHut+gQfDVEDxhQjiZwYjr2n//n1rHoMiRyCIAiio5Nf1eCV3fTApf1x5u+Xq+rcbDxSjL98dkCqdqzslSSmkItEmTysOFYLsH2F170Nxfug17KHscVKLqtAKLHYUFrDXIajsmIxvk88UHEqtDfJmgCExwEA4lDje0x0j9DesxmQyCEIgiAa5ev9BV77rh2VDgD49x1jcMXwVABAzrkqfJkjjx2RESOti6ngIpV1HoKl8ozPe3MlR2E2sdgPSwMFHwdCaa0NZbVM5CSItXEqchs5Iwh0YcDi3UDviyVLTqxgydFCIYR7TgJiskJzzxZAIocgCIJoFKVwAYCBKVGSBadvUhRW3HgBesbL8R1PzRmKn5dOkcQPAITp1ZYcr2ypSuEhnDwMmPqIvL+uFOYwJnKacpkRDJ6HZMlJjDICbhdQlccONjejavQdbHnXT0BCP7YuihwwN1gEFE1Zb17dMndYiCCRQxAEQfjlZEkNjhRaoNNwWHXnONw6Pgsf3TnOa9ztF/UCAFwxPBU3XZiFrPgIcIqHnKclxwvR0pA0ELh4KXD7BrZdVwqz4NqiDKvAEYsxJkaaAEs+6xyu0QPzP2bVjS/+a3AXvPwl4OFC9v6IhDF3lWjJiRJEjhVGKfOqvaEUcoIgCMIv6w6wTKrJ/RMxoW8CJvRN8Dnu5guzMLSHGdnpMT6Ph3vE5Dw1Z6h6gOiuimViCRHCferLYU4S3FUUk+MXnueh1XBwuVkG2t48Vh8nIcogC8jYLBZL8//OAcbI4G7AcYDBIxtLiMkxcw0wwIFIThA5mjA03qyj7QjakrN582ZceeWVSEtLA8dxWLNmjer48uXLMXDgQERERCA2NhbTp0/Hjh07VGMqKiqwYMECmM1mxMTEYOHChaitVUd9HzhwAJMmTYLJZEJGRgaee+45r7l8+umnGDhwIEwmE4YNG4b169cH+3IIgiCIRvjpN9Y9fOaQ5EbHaTQcRmXFSTVaPFEGHi+c2As3XaiI13A5WaE6AIjvy5aiyLFZEGdgD26y5PjH5nRLAgcAzpSzgnyJkUbZFSgKyGAFjj9MMcwqBOA3062YqdnN5qJpQWp6iAla5NTV1SE7OxtvvPGGz+P9+/fHihUrcPDgQfzyyy/o2bMnZsyYgdLSUmnMggULcPjwYWzcuBFff/01Nm/ejLvuuks6brFYMGPGDGRlZWHPnj14/vnnsXz5crz11lvSmG3btmH+/PlYuHAh9u3bhzlz5mDOnDk4dOhQsC+JIAiC8EFVvR37z1UBYJaclhCuiMnxcl0d+5q1GgiLAwbOZvtMMazBI4AUPfsSbLFS4LE//KXXZ8SFy5acuF6hvalGA4TFSptL9J8BAGzaiNDepwUE7a6aNWsWZs2a5ff4jTfeqNp+6aWX8O677+LAgQOYNm0ajh49ig0bNmDXrl0YPXo0AOD111/H7Nmz8cILLyAtLQ0rV66E3W7He++9B4PBgCFDhiAnJwcvvfSSJIZeffVVXHbZZVi6dCkA4Mknn8TGjRuxYsUKvPnmm8G+LIIgCMKDwwUWuHmgZ3w4UpvoMdUUSguPKgi57CSw9VW2PvhqwMiqJoPjgPAEoLYIKbpaAHqpmzbhja/eXj1iwjAwJQoQu77H9gz9jcPjgfpy1S6nLkSWohDQqoHHdrsdb731FqKjo5GdnQ0A2L59O2JiYiSBAwDTp0+HRqOR3Frbt2/H5MmTYTAYpDEzZ87E8ePHUVlZKY2ZPn266n4zZ87E9u3b/c7HZrPBYrGofgiCIAjfiJWLG+0v1QxMeuHRw/PAilFAwV627Vk8LoJZj9J0zJIjZgwR3ng2PgWAGUOSWfB3hYe7KpQIGVZKOJM59PdpJq0icr7++mtERkbCZDLh5ZdfxsaNG5GQwPyrRUVFSEpKUo3X6XSIi4tDUVGRNCY5We3/FbebGiMe98Wzzz6L6Oho6ScjI6NlL5QgCKILUyL0oEpUFPVrCWJjzoli8LLYDVvES+SwB2iyIHKKLVYQvlFacgw6DYanR2Px1L5MSIpB3aF2VwFShpUSbVjHETmtkl01depU5OTkoKysDG+//TZ+97vfYceOHV7ipq156KGHsGTJEmnbYrGQ0CEIgvCDaDlJMocmV2br/7sEJTVWqZEnTv+kHhCdrt42MLdHrJ4FHBfXkMjxR52NxeQMSjXj07vHI8KgZVacshOAzQLoTEBcn9Df2EeTT2NEC7qbh5hWseRERESgb9++uPDCC/Huu+9Cp9Ph3XffBQCkpKSgpKRENd7pdKKiogIpKSnSmOLiYtUYcbupMeJxXxiNRpjNZtUPQRAE4ZuSmtBachKjjBiSpngAFh1QD/AUOTp2X7OOPcCLLTZq0ukH0ZITadQi0qiTaxTl/cqWaRcAOoOfs1uCd8G/sMiYVrhP82iTYoButxs2G/tnGT9+PKqqqrBnzx7p+KZNm+B2uzFu3DhpzObNm+FwyOmCGzduxIABAxAbGyuN+eGHH1T32bhxI8aPH9/aL4cgCKJbIFtymilyjn4FFOzzf7yuTL0dlare1rL7RundAAC7093qVY+r6u2dMsBZ7C0W7tnZ/ZxQwiXTu4BjSODdXrvCo2Ja517NIGiRU1tbi5ycHOTk5AAAcnNzkZOTg7y8PNTV1eHhhx/Gr7/+irNnz2LPnj244447kJ+fj7lz5wIABg0ahMsuuwyLFi3Czp07sXXrVixevBjz5s1DWloaAJahZTAYsHDhQhw+fBiffPIJXn31VZWr6b777sOGDRvw4osv4tixY1i+fDl2796NxYsXh+DXQhAEQYiBx82y5OTvAT65CXhrCvDBFcD/bmHxIUoaKuX1kTcBGnXBQNHyoHM7EBvOCgIWtWJcjsvNY8QTG3HBkxthdXSujudV9UyYRXqm55exjvBIGdY6N+a9f0+6sE7srtq9ezdGjhyJkSNHAgCWLFmCkSNHYtmyZdBqtTh27Biuu+469O/fH1deeSXKy8uxZcsWDBkyRLrGypUrMXDgQEybNg2zZ8/GxIkTVTVwoqOj8d133yE3NxejRo3CAw88gGXLlqlq6UyYMAGrVq3CW2+9hezsbHz22WdYs2YNhg71qKJJEARBNIuSllhyjn8jr5/ZAhz5EqhVhypIqce3rAWu9lF7TSfEArlsUkfzitrWs7I0KISN2OCys3C4gGUL90v2SN+uPseW0R5B3aFi5E3e+8QyAB2AoAOPp0yZ0qhP9IsvvmjyGnFxcVi1alWjY4YPH44tW7Y0Ombu3LmShYggCKKzUVDVgKWf7cegFDOWzOjv7WpoR6obHKgRiu81q0bOqU3e+2qLgChFVqwocnykIQMAtEIMidMGvZCZ5XS3XkyOw+nteuksiG0cRmbKxfngcgA1hWw9ppWSbHpNBi5/EVj3gLyvA4kcatBJEATRTnx/tBhbT5bjnV9y8b9d54I6N+dcFXKEasStwbkK1hYgIdLQdHNNT3geKDnK1m/9Sm7VUKMo8eF2A/UVbN2fyBECj5nIYQGuTnfrCRG7S762qxXFVKj5MicfeeW1GMadxohUhSC1FLCYGa0BiGjF7Oa0keptEjkEQRCEWIcGAPbkVQV8Xp3NiTlvbMWcN7a2WuxIniByMuOa0YfIWgU42PlIHyOnLitFjq1ajucI9661AkAKPIbLBq1GEDmu1hMfNocscmydyKrz8sbfcKN2E74yPoLo7x+UD0iuqnTWgqG10Hv8jZDIIQiC6N7szK3Aih9PSts55yobGa1GGXwbyqaVPM/jXEU9bE4XnlnPLDHNEjkWwUUSFgvow4AoobSHUuSIVhxDpGyx8URMeXbaoRNETmtaWOwuWTDaO5HIKbbY8Bfdx2xj/3/lA1UKkdOa6D3cmcaOU56l4ziACYIgugg8z8t1Svzwu/9Tt6A5V9GAgqoGpMU0Hf+irPxb1eAIWbG+VTvz8LfVhzCsRzTOVzYAEBo8BoulgC3NPdhSEjmF8hjJVeXHigOoAo91giXC0Yoix9oJLTkNdhcaHC5Em+q9D7Z20LGIzlPkdJPeVQRBEN2N5WsPY/LzP0opvb7wl7zx7i+5Ad1DKXJaUjfmUH41Pt19TprP31YfAgAczK+Wxozu2YgI8UeNIHLEujeiyKlVFHAVg459tAWQ0CosOVrRktN64kMpbDqLJaeikb8zVOWxZWsFHYt4WXLIXUUQBNEl+WDbGZyraMB/d/oPJLY0qJsp/ukSFpj747ES7M2rxOGCal+nSRRVy7E8VfXNFzlXv7EVSz87gNX78uH2YSF55pphuLh/YvAXliw5rPaZFPSqTCG3Cq/RR1sACSnw2Cq5qxytGJOjFDbKIOSOTGWdHSb4SHff8BCw7z9sPbqNRY5njE47QiKHIAgiRCiFQmOWnPyqBtW2mPZbUN2Aa/+5DZe/9gucjTxkQ2HJqbc7pfiWz/eex+myOq8xlw313ybHL7+8DPz0LFsXRY7YldpWw5YuJ+unBDQevyFaclx2aAV3VWvG5NicnS8mp7zOjskaj/YYLgfw6z/l7da25Gj16u0mXLVtCcXkEARBhIhKhbCpszv9jivwEDk9Ytk3YWVMSEmNzW98TlG1LHKKLVZc969tiA3X47ErhwQcQ3OypFZa33+uGp/sypO2+yRGYGLfBMRFBNnrqLYU+H65vN3rYrYU3Re2GtaUc+VcIEKwEJkaETliTI7TBp1RzK5iv6PKOjuiTDrotKH7rm5vI3fVqh15OFVai0cuH9Rk7FZTVNbZcZP2e/XOBo8g9tYOPFbi2ZqjnSGRQxAEESLKFT2PCqv8tx8oqJZFzrPXDvMuxQ9m7fEncs5XyUGmv54ux56z7KF2vLgGX987CdFhep/nKTleVCOt19qceHsLiwd6/7YxmDqwmTVVKs/I6/F9gcwL2bporbFWAR9ezdYt+cKxRloA6OQUcp1UJ4dHYXUDJj/3I3olRODTuycE9HoDQRmTo7TqhJqHVx8EAMwckoKxvZoR86Sgos6OyRqPWC7RXShibkORM/CKtrtXAJC7iiAIIkSU1cixEWKdGV+cLWfHbr+oJ+aPzYRJr/Ua42ntEXG5eZUVJlfhZjpX0YCfjpf4Os2LYwqRI8JxwEV9EwI63wtbDbBO7i+I330ouy1EkePw8TsxNSJytL5TyHNL6+Bw8fituBYfbD3TvPn6oC0sOUrxFIpmoxaLBXGc8PcgFlU89Lk8YOxdrdR93IML72H9saY+3Pr3CgKy5BAEQYSIUkW/o9yyOhRbrEj2kd69TyjBP6wHe8CH+RA5nnE7Iucq6lVuLTHVW6Sw2r8Fqdhixed7z2PG4BSpDYCSpCgjDLpmfvfd9DRQJMSGjFgAJMv9ChvNtmnUXaUIPBbcUg4XrwoKPlvhHUvUXGxtEHhcrQgUD0WmWG3ZWQCAXRMGQ2wvlrW27TV2MDwBmP18i+8REJc90zb3CRISOQRBECGiTNE80unmsXJHHpZc2l81xuZ04VA+C7q9QAg4NvoQFvmVvkXO8WJvC4ySYj9duqsbHLjy9V9QUmPDK9+fkCwVY3vFYWcuq1nTI4AaPX458Z287hmX4a/YHxBw4LFsyXGrMqwq6lresJPneTz/7XH8erpc2tdalpxKhcgJhSWnLJ+5qpyRaTBEeGTChcX6OKN7Qe4qgiCIECF2rhb7LB3xkQp+uMACu8uNuAgDsuJZkLBGw8GkV38c+7PInCplrgmzSf0dVRQBylYRSn48ViJ1FRcf4AmRRlzUR3ZP9YhtQeqvsv+UZ1p4Y8G1gQYea+UUcofCyhIKkbPrTCX++dMp7FW01mitYoDK4PTKFqT/A+zvTSvUJDLEZQCxPdUDOlCWU3tBIocgCCJEiGnjfZOihG3vh9heIUj4gswYVWaNZ1xOpZ8U9ErhoZ6dEaPaPyiViQVPS85TXx/BPav24u0tpwEAlyiCiueNycCITPk6UaYgjfv1FXK9myrmNkF0JjDq9sCv0VhMjhR4bJcqHrvcapFTXttykdPgo/9Xa1lyuLNb8ab+ZaShrEU1jsDzqPv0D3jR8CYAQBeTDsT1Vo9pqGr+9bsI5K4iCIIIEWKRv8y4MBwttKDKhztin2AtEGvjiITptaiCwpXh5wEoPhgHp5mx5USZtH9gShQO5ler+lrV2514R1FFmeOA+6f3x8X9E1FeZ8d90/pB+V1/YEoQlWodVuDFgUyILDkqVzP+/c/BlfUPxF3ltEoNOh0e7qryOt+Wq2AIN3jHRLWWJWfczzcDWiAK9fiqfmTTJ/jDVoOss4oA45hMb5FjrWr+9bsIJHIIgiBChMXKBIjY1NJXzMUeyZLjLXKU+IvXEIVTRmw4Io061NqYsBItOSUWm9Q7S2nlCDdo8dz1wzEsPRrD0tXWkx8fnIJ1Bwrwu9FBFI2rOgu4bOzn3A62zxgdfBxIIIHHLjvEsCWXh7vK6nCj3u5EuKH5jzOHjyBjT0uO3enGLydLMaFPgs9suGAZpsnFh421ZGgCe1U+VDlTfS7x7gMW08o9qzoB5K4iCIIIEWJH8Mz4CADMGqPsU1VQ1YAiC7NKZGeohYbng7O8zo41+/JxvlKddi1aeGLDDUiNljO3RCuM3eWWrD3Kuj2f3T0BVwxP8znvXgkRWHxJv+Ae3nWyFQk5K9kyvk/wcSCB1MkBYOSYmHN6uKuAlrusfLWKUHYkB4Cb3t2BOz7YjY935nmNbQ5hsLUoJqe65Lx6R49RalGTOAi4/v1mX7+rQCKHIAgiRIjWF9GSY3e5VfEeYtr2oNQoL8uDZ+AxAPz5kxzc9eEen/eICddLgc7smmapQnFxDXNZlQvHh6dHY3BaIxaT5lBbJK+LdVmSBwdwoocIaqwLuVYhciCKHLeXlaW8hcHHvuJvlPvOVdRLGWjfHw2sDlFT6DmX9P40h9pyhci5YSWg0bD2Cjd9Acz9N3DPr0Dq8BDMtHNDIocgCKKF8DyPm9/dgTNCkb9ks1HKsKqqd6DBzoTO3rNVALxdVQAQ5iMuBACOFFpU1qCqBvZAjw7T49YJPQEA903rh9gIg1ST57JXtuC34hrp4R90e4bGOL8H2P0eUHTI+1hSIyJn8lK2vOJl9f7GLD9aed4GQeSwwGO15cXSwlTsptxVyq7s6bEtSLP36D5/qrQWG48U+xncOPZKllX1k3EqMEhRZbjvNGDInObOsMtBMTkEQRAt5ERJrSoIODpMj+gwA8pqbXh/ay7e/SUXL98wAttOsTGjsnyInEZcRZX1DkmoiK6o6DA9/jilLy4bmoIBycxVlWw24mghO+f3/9kjxdjERzRSpyYYeB5YNZcVnPNFfF//5079G3DBraxZ5Nd/ZvtMMY3fT6MBNHrA7YCRY4LN4eK9mpe2tGmnT5HjJ029zt6Cdg/2WtVmDGrx0/ESXDo4OehLuarZG20zNaNLfDeCLDkEQRAtZPsp9UPfbNIjJpz1U3p7Sy7cPHDfxzk4VlQDDQdM7uf9YGosHqZQ6HVldbikrJ+YcD0MOg0GppilVPTkKDlGJ7esTnKHJESGyJJTfc6/wInOADLH+z+X47y7YTfmqhIR4nKMKktOaEWOr0wqpSWnUilybP4brzZJfYVqsxdXFFSq+v5zVZK7khPchc6I4AVSd4JEDkEQRAvxFDnhBq3fppEjMmIQ68N9ZNT5Fzli13HxAafVcD6beorCSkSM2QmZu6rkqO/9170L/Plg45lSvggLXOTohfR6h8sNu4e7ytkKlhyl8KlQZEHVtkTkNKhFTl9Nvs97+2LLiVJc/cZWzHvrV+w6U4HKEtbgVBNFIqcxSOQQBEG0ALebx6+5apHDcRxi/IicXgm+a8jkV/lv6ClWP1a6qjgfsSyeD+A1OSxuIyEyBO4qngd2veO9f+FGYNj1wWVV6YS4lgGzmh4rBB+L2VW+LDluvmUix5c1RSlylEX76u0tseSo/076cvkB98havY+JmqOFFry88TfECk059VHNbKjaTSCRQxAE0QKOFdX4rFwbHe5b5MT62X+6VG40eYMQSyMGL4vuKtEyE+/HMqOsZqxkUr8QPAj3/lvdn0qkx+jgr3X3FmDWc8BF9zU9VuigrefZ79hXCnmoLDlXj0jD89ezjCSbIitOFZNja0FMjkcF4n5cPuzOwOYutu0AAC73JwzSsFT2Ef16Nn8+3QASOQRBEC1gz1m1C0J8FsWE+RYini4lkYdnDwIAPDRrIJ66Zii+uW8Sls4cAIDF1wByywZfnc0BJnI+uH0Mdj48Df9v1kAAwJ0TeyHJz/iAcTQA3y9n63F9gMtfZOtXvsqCg4MloR8w7vcs5bkptGp3ldPl9squcrdY5LDzw/RaZAk1jixW2WKjbLHRopgcIfDYwjNLVk+uSCXYaqwOr6BqEc7thBYu9OYKsNLwrLQ/ISnV53iCQdlVBEEQLeB8FbOy3H5RTwxPj0Z2egwA+I3JiQ73LX7mjOyByf0TERvOXFGDUs1SkbujhazzuNhgMynKt/uJ4zhMGcCsOXdf3AdXj0hDUlQLBQ4AFOQADZVARBJwz05AqwNG3iJZWVoVISbHADsAk09LTqgCj/VajfS+VTc48MXe83j+2+OqZqktEjkO9rdSzpth5hpg4JySq6y81oaLn/8JIzNj8J+F49Tnud2458SdWGiw4RXndepj1Gm8UUjkEARBtIBi4QGYYjbhmpHp0n5/Fht/sTqAd4DwoFSWGn6mvA51NqdkyUk0BxZjkxrdgpouSs7vYsuMsUzgAG0jcABJ5OhEd5Ur9CJHvJ5S5FTU2bHkf/u9xtbZXXC7eWg0QVZ2BiSRUwv2vujgku695UQZam1ObDlRBpvTpQ5Et1Yh03Ea0AA9OY+6Oo31/iLIXUUQBNESxIaYKdFqi4lfkeNnvy/iI41INhvB88CxIotkyUkOhXUmGESRk96M+JuWIrmrGkkhb2HgsUOwphh0Gr8WOCW+upYHdiMmcup8iBylUBPdkxI2i7T6F/0n6mPBttHoZpDIIQiCaAHFFkF4eMS9+HtYxvpxV/lDjBEpqLKiRBBUSQFackJGvtBaIn1M294XkCxGOl4oBuh2ewXrttSSI2Y4GbQcTHoNDDrvR2OK2STFWzXXZWWzMvFSy7O/FR1Y3aOPfj2LBz6VrUbHi2pU5znqqkE0DxI5BEEQzYTneSnzKaURkSM2z/TcHwgxihgROSanDS05lgLAkg9wGiBtZNvdV0Sw5BgEkeNy83C6W89dxXGc6j0y6DTQaji8fMMIRAj9xppTK8fqcOGT7b+x8wVLjhZuOFxuPLJG3SLDU+SUljWv9QNBMTkEQRDNxtLghNXBHpDe7irZYjMo1YxjwoMrGHcVIIuiyjo7CquYJSc1uo1EjqUQ+HIxW08aAhgi2ua+SoSYHK279WJybAp3FcB+56WCoPzvogvRMz4c8ZFGRBh1qLE5Ud+M1g4nS2phEoRaHa90V3nPvUAIZhcpLyuD7/7xRFOQJYcgCKIZ1NmceOeX0wAAs0nn1ZZBGWA8rEe0tO6rUnFjiCLnaJEFdpcbBp0GaTEhCihuivdmAqd+YOsZY9vmnp54Bh673XAI7iqjIEpabslh5+u17HoNChEzJM2MeKGYoihQm9P1vKreAZPQf6tGsuS4fBYirFDUXdqbV4n3N3kHQAMAMicEPY/uBllyCIIgmsGN7+zA/nNVAACzDxeUOUwPrYaDy81jxpBkFFusSIk2+axU3BjigzUnj90rKy4c2uZk9gRLfQVQdZatj74DmPxg69/TF1p1TI7TzUsxNCa9FjanO6SBxwCQr7CkKMVremwYjhXV4FyF/+rU/iiyWGGGaMkRY3LcPts6VNTZpPW3fj6NFM7H/cYsAqY+HPQ8uhskcgiCIILE5eYlgQP4ts5oNRwenj0IFXU2pMeG4yGh2F+wiJacAiFVvVdCG7mMKs+wZWQKcMXLbXNPX4juKh8p5Ca9BtUNoQw8bty5kR4bDgA4V9kMkVPdgCRR5AiWHA3Hw+50QsMBypdQWSdbcpLMRkTB436zXwDG3EmZVQFA7iqCIIgg2X++SrUdZfL9fXHhxF5YOnNgi+7laSXqldhWIieXLWN7ts39/KETrB4uReCxokKxuC8Q6u1O8D6sPlLgsY6JhqevGQqOA9648QLVuPRYJk7OV6hjZgKhyGL1clcBgNVmlwTO1SNY5I2yjYTD5UYUp7jfxPuBsYtI4AQIiRyCIIgg+DInH9f+c5tqX7BxNsHgmY01Y3AbdZ2uEEROXK+2uZ8/BHeVRkwhd7kVlpzARc5vxTUY8fhG3Pnv3V5xMOK2Qcuut2BcFg4tn4nLh6tbJmTEMUvOuoOF+HhnXlAvo6jaijAwN5TorgJYXA4ARBl1eGrOUACsDo8YF1Rrc8EMoW7O1L8B05cHdd/uDokcgiCIILjv4xyvfZGm4DKmgkGZpXXzhVkYlRXXaveScDmB/f9l6+1uyRGzq2RLjuheMgYhcg4XVMPucuOHYyX4MidfdcwupZDL1pEIH8I1UxA5APDZnvPBvArkV1lhEvpv1SosOTpB5MRGGBBp1EkuswqhX1at1YEoMSaHWjgEDYkcgiCIFtJWlpyL+ye22n1UHP4CKD/J1vtd2jb39IdgyZFSyBUVj01idlUAgcdORaq2WG9IRHZXNf5IHJAcJXUD9yWC/OFy8zhVWguTEJNTy8siRwt279gIAziOw9Vhe/GqfgUqK0rZWJsT0aIlh1o4BA2JHIIgiADxVwTOX0xOKIhTWHIuyGqjb/KiwBlyDdBjVNvc0x+CJUfjYsJE2YVcdFcF0oXcqRjjz11lbCLwWKPh8OLvsgHAZ1aUP86W18HudMPEsddQDxN4MLEUxTXgQd0nGKVl5Qiedz6Hq7Xb8OW7z8Lt5lFjdaKnRigGGJ3u8/qEfyi7iiAIIkDyK30HnLaqJSdcj6evGQqTTuvVwLPVsAjunKQhbXO/xvDIrqqzu1AnxKuIgcfOQESOQpR4ChSpTk4TlhxArs3jq76NP34rrgUAyV01e2Rv4JgOcDtwk/Z73K37Cij6ErBdI52jAQ+L1QG3rQbpXBnbmdS8DL3uDFlyCIIgAkSsj2LQavDurXKzytYUOQALhL1uVIi/xVurgZ1vA7Za72OWArY0d4A6u0JbBxPnVBVVBGQLWiAxOcrKwp6iSA48DkTkMGFlC0LknCypwSTNASlL6t6ZQ8Fp2NzTRAEDAOd3Sqs1CMf2U+VIajjD5hyeDIS3QTxWF4MsOQRBEAFyXqiPcsnAJIzpJT9wArEAdDjW3gsc+RI4uw2Y+776WEcSOYIlh3PZ8P7tY/DPH0+hrNaG4enRsFiZ+9AdSEyOot+V0gpTWN2AAqH/WCDtMgzNsOSU1drxH8PfpW3OEA4IIsfCy8HM+I9syTHBjj+s3IvfaXMBPeBKGEAP7GZAvzOCIIgAKRYCVlOiTYg0KD4+W1hxt1048iVbHv6CiZy6cuDtqcCA2axnFQCYe7Tf/ESEwGM47UiINGLZlYOlQ69+f4IdCtqSIwuUdQcKwfPAmJ6xSDI3LXJEd5XNGXj/quoGh3qHLgzQMItQNFfn8xyTkG7emysCAHCJAwK+HyFDIocgCCJAygSRkxhlhEbRWqGFBXfbHqc6uwgNlcDRtayNw45/yfvN6jox7YJQDBBOq7zv278BlWegTVwGIMDAY4XIEXtfAcCPx0sAALOGBvZam2PJqar36HWlM0qWHLNnNWMBsXBgBseCjnUJvQO+HyFDIocgCCJASmtlkaMkKz7c1/COS0GO97bLw9oQlQYYo9pqRv7RCyLHViPv274CAJAWdh0AY2CBxwrrjcPtxr+3ncH7W3NxppyJjMkBpuc3Jyanvl4R97ToR1atWBA5/i057P3I5JgI07R3UcZOCokcgiCIACkVLTlCV+pVi8bhSIGl7erXhIqcleptSwFQU6jeN+jKtptPYyQJ7qnyE6xpqKIgnh4OAMaALDlKd5XDxePNn0+hUOgHlmI2oU+A7TKak13lrq8EAPCcFlzaSLZTsuQwkeOI7AF9rVykkFVH5pEliBzEkshpDp0wWo4gCKJ9KK1RW3Im9EnAnZN6B91ZvF1xu4GDn7H1OMEFYikAaooUgzgg+4Y2n5pPIpOARKH/15lfALdcq0gr/N4DKQboUlpynG4p/RwA/ji1T8DvoUGKyQlM5Bw8X41qobCfyxgt95zyiMnhkwarzjPBjmjUwSxWO47NCuh+hBoSOQRBEH6oszlxsoS5SdxuHuVC40RPd1WnorYIcNQBnJYV+wMAy3mgRsiomvUccPcv7V8EUEnmeLYs2Ae45PgWDcfETXMCj7VCTNWqO8fhlvE9A56KZMlxuQOyIF254hfEQHBXhSlSwD1icnQjbgDG3gUIlh4TZ0cPIb28gosB9HKVZCJwSOQQBEH44ZE1hzD9pc34MicflfV2uNw8OA5tV5QvlFir2bJKaCwZ3QOIyWTrSktO4gAgZWjbz68xwmLY0mlViRytIHICq3isSCF3yf2vDEGm/yvH25uoeiy6tGI5JnI04YqK1YLI0XMsS0tjigZmPw+Muh0AkMJVIJZjArtGGxPUHAkZEjkEQRBg3cUXfrALFqscgLt6H4uRuO/jHBwvYg+c2HAD9AEUjeswuN3A6ruBv2cC/zcZKD7E9kdnyinilWeAaiEeJKoDZFR5ohH6d7nsqgBp0eEUSDFAZXaV0+WWCwAGKXLEwGOgaZeVmFUVLYkcb0uOfOFIthQsNmM0v+Et/UsAgAZtZFBzJGQ60X8qQRBE63Hfxzn44VgJ3vzplLRPGbdx4zs7AACx4a3XcbxVOLVJ7iheuB/Y9R5bj8mQRU7Zb4C9BohI6pgBrmKtHJdDZcnRQ+5M3hTqwGNZ5ChFSyAoO5U3FXxcWc8EmeyuUlpyPO5rEISMTq7VEyH0urJqqTFncwla5GzevBlXXnkl0tLSwHEc1qxZIx1zOBz461//imHDhiEiIgJpaWm45ZZbUFBQoLpGRUUFFixYALPZjJiYGCxcuBC1terS4gcOHMCkSZNgMpmQkZGB5557zmsun376KQYOHAiTyYRhw4Zh/fr1wb4cgiAIFWW1cg0Z5QNNJCa8k7mqyn5Tb5ccZsuYTCZ0lFx0H6DrgK9PK1g9PESO2Jk8oC7kysBjFy9ZYYK15HAcJ8XlzH1zG8oVfy+nS2tx4HyVtF0pWHLiBLcTGrPkGITsLr13OQKbPtprHxEYQYucuro6ZGdn44033vA6Vl9fj7179+LRRx/F3r178cUXX+D48eO46qqrVOMWLFiAw4cPY+PGjfj666+xefNm3HXXXdJxi8WCGTNmICsrC3v27MHzzz+P5cuX46233pLGbNu2DfPnz8fChQuxb98+zJkzB3PmzMGhQ4eCfUkEQRASGiH7xe3mUeOj63ins+RUnmHLRI/mjjFZrA5ORJK8L2Ncm00rKER3VV0p8NV90m5DEJYcpx9LTrAiR8mZ8nrc/7/90vYlL/6Mq1ZsRUkNS00X3VV9DFVsgLKCtJe7SqhJpPeuumw3kMhpLkHXyZk1axZmzZrl81h0dDQ2btyo2rdixQqMHTsWeXl5yMzMxNGjR7Fhwwbs2rULo0ezBnevv/46Zs+ejRdeeAFpaWlYuXIl7HY73nvvPRgMBgwZMgQ5OTl46aWXJDH06quv4rLLLsPSpUsBAE8++SQ2btyIFStW4M033wz2ZREE0Y3hFZYAMZW41u702a2h01lyRJEzcgHw3SPy/v6XsWVkElAn1GJJ6NumUwsY0V11Uv18kSw5Abmr1L2rpMDjZsRXKWNxThbXeM0hv7IBSVEmVAnuqp76SsAGFuwt4mXJEd1V3llUThI5zabVY3Kqq6vBcRxiYmIAANu3b0dMTIwkcABg+vTp0Gg02LFjhzRm8uTJMBjkD5OZM2fi+PHjqKyslMZMnz5dda+ZM2di+/btfudis9lgsVhUPwRBEA0OuQ+R2K3B4tlvSCAmrJNZcqrOsmXyEOAqVikY4+4GIuLZOq+IK1HGjHQktL6/j+v5wEWOMs283i6/30Z9yx6DpbU28Dyv+hsS09PFmJwEF6uTg2iFe1D5mnQmOUXcR6q4y9hB35dOQKuKHKvVir/+9a+YP38+zGYWOFVUVISkpCTVOJ1Oh7i4OBQVFUljkpOTVWPE7abGiMd98eyzzyI6Olr6ycjI8DuWIIjuQ41VdkuJHa0tDWxfYpQRr84bIR2P7Uzp41aLbMmJyQIuuBm4bz8w42l5THh8u0wtKLS+f+daPpjAY1nM1dnl97s5lhz1dXlU1jtQr7gmByZyqurt0MKFaCerd+PXXRWVKhcJ9OGu4sUUeiJoWk3kOBwO/O53vwPP8/jXv/7V9AltwEMPPYTq6mrp59y5c+09JYIg2oEaq9pKo7Ta1NrYN3Ixldxs0mFERox0PKYzxOSc+B5Y9wDw1sWstkxsLyC2JzsW21NtRZj1D5ZOftXr7THTwND4/p3r3ILICSTwWBGTU2cLncgBgJIaKxoU1iG7i61X1tuRhCpo4GavIVLxxdxT5Ij4CDzmTWTJaS6t0rtKFDhnz57Fpk2bJCsOAKSkpKCkpEQ13ul0oqKiAikpKdKY4uJi1Rhxu6kx4nFfGI1GGI2duFIpQRAtZu3+Avzpv/vwzDXDcOM4VgxPWRtHfACK1h1zmB7xkfLnRrApx22OrRZYeZ28zWmAq9/wTlkWSR4C3H+wbebWXPy4q3RBWHI8s6sAJnCU3eSbS4nFhiSz/DcixuxUNzikBpswpwEahaBSiRzFc8uH1cpBMTnNJuSWHFHgnDhxAt9//z3i49Wm0PHjx6Oqqgp79uyR9m3atAlutxvjxo2TxmzevBkOh/zBs3HjRgwYMACxsbHSmB9++EF17Y0bN2L8+PGhfkkEQXQh/vTffQCAh1fLD3bRNQUAtYK4Ea07ZpMeEQZZIARSXbddObJGvX3rV0DPi9plKiHDj7tKE1TgsfeYlmRWKSmpsanifESRU293YYTmJNuZOlx9klJ0mtPk9bBYYMBs1VCHgerkNJeg3+Ha2lrk5OQgJycHAJCbm4ucnBzk5eXB4XDg+uuvx+7du7Fy5Uq4XC4UFRWhqKgIdjtT3IMGDcJll12GRYsWYefOndi6dSsWL16MefPmIS2NvdE33ngjDAYDFi5ciMOHD+OTTz7Bq6++iiVLlkjzuO+++7Bhwwa8+OKLOHbsGJYvX47du3dj8eLFIfi1EATRnVBacsS0ccldFaZXNW8ckRnTpnMLmiNr5fXxi4GeE9tvLqHCn7sqqMBj78J9oRM5Hu4qQeTU2pwYpRHqFHmm5/uz5HAcMP+/quNOQ0xI5tkdCdpdtXv3bkydOlXaFoXHrbfeiuXLl2PtWvYPNmLECNV5P/74I6ZMmQIAWLlyJRYvXoxp06ZBo9Hguuuuw2uvvSaNjY6OxnfffYd77rkHo0aNQkJCApYtW6aqpTNhwgSsWrUKjzzyCB5++GH069cPa9aswdChHaznCkEQHRJl02mLIvD4aKEFz64/KrVuELOpfvnrVBRbrOifHNWm8wyYw6uBvR+yCscA8Pst3taDzoofd5XWzQrxBVsnR8TYTJEzqV8CtpwoQ4rZhCKLFaUelhxR5NRbnbhAc4LtbFTk+Giloei27tJTW4fmErTImTJliqqmhCeNHROJi4vDqlWrGh0zfPhwbNmypdExc+fOxdy5c5u8H0EQBMBiJESijPLHn2e6+P9tPo1wwUWVEs2yXdJjw5Ee6x0U2mFYv5QVywNYgb/kLvSFz6+7KvDAY4ePZprNteS8fctonCypxfZT5Xh6/VFU1NlV2VV2pxtwu/C7+lVI4CxwawzQpGZ7TF7x+I1IbPR+0eEUS9pcqHcVQRDdhqOFcm0sq9MtfSlTtnIQEb+Zp8V4p/R2OGpLZYEDAOPvUQe5dnb8uKu0gsgJrAu5j5icZmZWmfRaDO0RjfhIJr4q6uwqd5XN6QaOrcNC58dsO3EYoPMQKsqYnIiERu936eDkRo8T/mmV7CqCIIiOhtPlxhs/npS27U436uwuRBp1KLZY/Z6XGu1dnK3DkbeNLRP6A3f/4v1A7ew0EXjsS8B44tNd1cJCgHFCzaSyWruHu8oFFOyTtvk4X01PFf7S8MZFjjYEGWDdlS4k9QmCIPzzjw3HsOVEmWrfmbI6AEBRNRM5f5zSB7OGqstQpHUGkVN8hC0zxnU9gQP4j8lxMQtcIJYcn+6qFtbIiY9gv+uKOpuq4rHd5YZLIWKc43wkxNgVTamVjTuJkEIihyCIbsHWk+UAgKuy0xCmZ66CK17/BW43j2ILe1hOG5SMsb3UD5zk6E4gGmoK2DK6i1Zx9+OuEmNyArHk+ApObml2VZzCXeUZk+OsqwIAvOacA1N6tvfJDVXyurYTFJjspJDIIQiiy2N3unGihDVSXDpzAIany8XVyupsUtfolGgTIhQByQmRxo5f/A8ALIVsafaRpdMVaCLw2N3MwOOWvrfxgrvK4eJRYpHjumxON1z1rM9iHRflW0xZqwK7iWcjTyIoSOQQBNGlsTvdmPTcJjhcPAw6DdJjw/DqvJHS8SMFFjhcPDgOSIoyqrKuEiI7SZ+qGkHkRKU1Pq6z4sddJWVXNTfwuIWWHJNeKxWKPF/ZIO23O93gG5jIser8lBywVgd2k676nrYRJHIIgujSbDlRKrmjxvSMBcdxSIk2IVuw5uzLqwLAvpXrtRqVJSe+M4ic9UuB4kNsvatacvy4qzgne1+bG3gcimKAosvqXGW9tM/mdEvuKJvOT7VipbvKFzf+j5UBmPdRi+fYnSGRQxBEl2bdgUJp/aFZg6R1MWvqUD77Rp0YxVLFI02yyImL6ODxODXFwM635G1fReW6Av7cVcEEHgsVj8V4LKD5xQCViH8jSkuOzekGZ2N/V06DH0tOdHrjF+4/E/jDVsCzvg4RFCRyCILokticLiz78hC+2JcPAFh15zgM7SHH4qQK9W8OCiJHdE0p3VVizEWHpKYYeLG/el9YF+1W7c9d5WAZSk1ZclxuHmLYzsOzB0r7s+IiWjw1X38j/92ZB06IuXH6a655/XvAgMuBRT+2eA6EfyiiiSCILkedzYmln+3H+oNF0r5BqWq3QapQybikhlkDxIeV0l0V15FFztG16u0h16p7VXQl/FhyOBsr7mgTCjtyfl6/Muj46pE9cHH/JBRZrLggBH3IfAthHhqbBeAAt9GPyEnoB8xvvPI/0XJI5BAE0eV4Zv1RlcABgFiPh1GGR4uG+EjmdlC6qyKNHfgjsuQoWyYNAX6/2a+1o0vgL4Xc2YBwnRv1Tg36/u0bVbd4JUo7j16jQWZ8ODLjQ9OiI85H3JYJdhg5llJuiIoPyX2I5kHuKoIguhxr9xc0OWZwmtqyIwYZRxhksRCqLtWtQolQAHDin7u2wAEarSPz2IxM6DQcXG4eFqvT50+N0IC1T2JESOJwlPiy5ESDFZl08hpkJTfel4poXbr4fwZBEN0Ro06DGsX2pH7eZfMz48IRZdJJD8AEwZKjLKHfYUUOz8siJ2lw+86lLeA4Vi9G0Zlb5IahZlw6ahCq6u1NXqZHbBg0IW6R4Cs4PZ5jbrRKRKF/qp/sKqJNIJFDEESXwupwoayWPfB+XjoFX+0vwPyxmV7jOI7DkDQzfj1dAUBdE8eg1cDucuPCXh3U1VCZy+qsaA0stqM7oNH7FDmwWRAX16vd4qeUlpyBKVE4VlSDWI5J7HLejAHJfrKriDahg35NIQiCaB75VSyVN8KgRWZcOBZf0k+Kt/Hk0sEp6M0VYBR3XOpDBADbH7oE3y+ZHLK4jZBzVmjImXZB1+xV5Quly+qenawZKQBYLb7HtxFKcSUGt8cLdsRqLgqZcR30b6ibQJYcgiC6FPlCvZIesWF+s21Ebh2fhSt/fAFJriJY67MBTAPAgpD9CaMOgShyssa37zzaEqXI0eoBo+AGsrWvyEk2m6T14enR2J2zF+lcKQDAYYwLuXuMCA4SOQRBdClOlLDaKemxTXyDLjsB3b8uQpJQUM700+PAgGmhnYzTDnz/GJA8BBixACg/CejDmi4E54+fnwOOfQ0U7mfbvaeEbKodHmWGldYAmASR086WnJRoE/654ALERRiQbSrC7cb7pWOaCO9YMKJtIZFDEESXYsMhVuF4Qh9FPI21Gji3E0gfLRfM27gMcMlNFVG4Hyg+zARJqDi6Fvj1n2z9y3vk/TevAfpMDe5a1mrgx6fl7V4Xs5/ugtZD5HQQSw4AzB4mVJr+5T+q/cbopHaYDaGEYnIIgugyVNbZsesMa4woPXjs9cCKMcDK64Gv/iwPriv1vsCBT0I7oRPf+dm/MfBruF1s/N89gqcv/GPXLf7nE8Vr1eo7jCVHRXicajM2sYu22ehEkCWHIIguw9kK1iQxxWxCWgzrTYX83UBtMVv/bQNgrwP04UDlGe8L+NrXXHgeOPmD72MFewO/zto/ATk+mjT2uaR58+qsKPWcypITYDfvtsBpU232yvTO6iPaFrLkEATRKeF5Hk98dQRv/HhS2lcoZFaJfakAAOd3yetOK3DqR6CmSG3Jie3JlrU+rDvNpa4MqC8DwAH9Z7GH8jyhjH/edjl4uCl8CZzb1gO6DtxyojWI7yuvaw1yqweXj7Ty9qDyLLDlJdUurqs2TO1EkCWHIIhOyanSOry3NRcAkBZjwjUj01FQbRW2w+SB53apTyw6IMfl6MOBGU8Bcb2A/1wD1JWEboIVp9kyOh2Yt5J9y9cZAV0Y4GwAvl4C3PUToDf5vwbvo/Fk4iCg50Whm2dnocco4NQmtq7RsR/Ad+2c9uDdGUCtupUIMi9sn7kQEmTJIQiiU1JY3SCtP7L6EPKrGlBY1YBI1OOW6v9j4qauTH4wDr2OLX/+B7DtNbaeMQ4YsxAw92DbobTkVDIBhtiegEYLGMLZ8gYhOLX0KPBCP7kHlS9sirrNlz4BcBrg8hdDN8fORM9J8jrHsd8lAPCu9pmPJ54C545v5TkS7QaJHIIgOiVFgtUGAOrsLvxwtBiF1VZcrd2GccUfA+9OB358hmVQpY1kXbpFftvAlnG92TJC6C9kqwYc8nWbDc8Dp39S30Ok9xQmVgCWGfT5IhZc7AsxlshoBib8CVhW0T2tOADQazIweSkw63m2zQkCwt/vrj2Z+SxZcToIJHIIguiUFFvUYqSo2oqC6gb05grlnbvfZcuh1wPxfbwvEteLLcNi5TosvrKugqH6PPDvK4H9/xXu4SFytHpZ5ABA8UHgyURvtxoA1AivJSqFWS+6VTaVBxwHXPIIMO4utq0RfodtYclxOVjNo0AxUb+qjgKJHIIgQk6N1YGSGitqbU7kltW1yj2KBJEjNtQsqrbiZHEtUrhy78Hpo4HYXt774wThw3GyNaelcTlr/gic2cLWjWag3wzvMZ5xJLwL+Pnv6n0OKxNLABCZ3LI5dUWkmJxWFjk8D7x9CfDaCK/sKb8YSeR0FCjwmCCIkFJSY8VVr29FjdWBYenR+PV0BT6560KM6x3aZpdF1eyBk50ejb15Vdh9thI1NicyjWXqgZwWSBnOAnxH3gzsUxRs66WI84hMBGoKgNoWipyig2y54DOg7/TArS9Gj0aO53fK67pGgpO7K23lrnLaWLA6wIpF9riArddXAHm/soDoKA8RSpacDgNZcgiCCBl2pxt//GgviixW1NldUofv1zadCPm9iiws8Dg7IwYAkCfUyMnUeIicpMEs6BcArl7B4iUAIPtGtbAwC60Wqs83f1JuF9DAihEidYR/gXPFK977tB69smqK5fWRC5o/p65KWwUeO+rldWuVvP7GWODj+cDq33uf4ylYiXaDRA5BECFj3cEC7D5b6bX/TFm9j9HN51xFPQ4XsEq3k/snSvvDYUU0L1TANfcADJFM2CgZuwi4eTVw1Wvq/TFC4baqvOZPrL4CAA+A86p+q2LUbcCfDwJzP1Cc6yHOxGydodcDQ65p/py6Km1lyXHIWXxS9p3DKsduiVYeg1LYdOPYqQ4GuasIgmgxx4oseOrroyiv8x2cmV/VAJebl+JnWsrqffngeeCivvEY01MWE1M1OWzFnA7cs4O5GiI83GRave9qwTEZbFl9rvkTEx984XGNpw9zHBNVMZlA0SFgywss3d3tAhqq2JxrBJETldL8+XRlxN9va9fJUYocSz5bWhVVlsVaRqJFyRQDpAxr3TkRAUOWHIIgWswrG0/gl5NlOFrIrCiiC0lJrTV0D6NTpazT+OR+iYg06mA2se9r12k3swHZ8wBjpLfAaYyQWHIEa0x4EN2nB8xmy7oy5vp4vg8TPmJsEAUd+0ZyV7lb9z5Kd5WY7aYUOY56JnScQrbfH39VNxMl2hUSOQRBtJham1rAXJWd5jXGYnWE7H5i+nhKNAvI/ddNo2DQajDSIFhhBswK/qLRgiWnKgSWnIggRI4oxOrLgIOfAuCBTU/J7iqy5PimPdxVlgK2VHY+d1oFoSOIrcYqWBNtDokcgiBajFLAzB2Vjsn9vB/yoRQ5JRaWWZUUwSw4F/VNwNalkxDjYoHOkmAJBtGSU1eifrAFQ52Qvh6UyBFiipyKuj9lx+XAY7Lk+KatAo+dir8F0YWoDEAG1LWVdGEgOg4kcgiCaDEFVewB/fW9E/H83Gz0S/bOLrE0hM5dVWyx4h+6tzD2i/FAIQv8TEQlOPCsqF9EYhNX8EFYLAtUBpqfYSXF5AQhcgwR3g/GitPqQoCEN23Vu0opeO1CzSerR+fzOkXQuM4jS45oV0jkEATRImxOF8pqmWUlNVo21X93/2RMG5gEvZYFG4fKklNrc6LO7sINup+gbSgH/m8SYLXIQaHmNLkabjCIwcAAUHWWLe1BFjIUY3KCFVmmaO99NgsADojJCu5a3QWxanSru6vqvdetFvUYUdzqTN27KnUHhEQOQRBBs+VEKZavPYw1+/JxtJA1kTTqNIiLMEhj+idH4d3bxmB8H2bVqAlB4PGxIgv+8tl+GOAhmH7+h2x9EZttNgdlXM5v3wLPpgPb/xn4+eI3+mDcVYD/uioxGRTj4Y82CzxWWHJEl6KnJUcMEicrToeDUsgJggiax9YexulStZUjKz4cnI9vsWLmk6Wh5ZacR9ccwq4zlUjnqtQHig7IsSvRLRA5ygyrzS+wB+i3DwHj/xjY+c0VOf4q5Mb3De463Yn2CDwW173cVaIlh+JxOhokcgiC8MkD/9uPqno73rx5FPRa2ehrd7q9BA4APHblELZyZC1wdisreLfn38jUTgPQMnfVs98cxfqDhThXwR4yvQweDxlLIVCZy9aj05t9H1WtnLBYwCJYh3a8xbpgJw1k6cI1RUB9OZA8hLknCvYBh1cDedvY+GBicgD/vY7i+zXvdXQH2iwmx4e7yubprhLELVlyOhwkcgiC8KKo2orP97IH/I7TFZjYLwFuNw+H2y0JjXCDFqOyYrHlRBn+OKUPLuqbAOx+D/j6fnaRHW8CABbr/ot/4p/NdldZHS7838+nVfs+vD4d+Bws9qWulImOwv3sYPLQZt0HgOzqqili/YiKhT5U3yxly4UbgVW/k1s3jL0LmP08sOlp4ORG+Tqhcld5djAnZNqsrYPCkuN2so7kXpYcwV2lJ0tOR4NEDkEQXuScq5LWb3p3B3olRKCo2gqXm8fvL2YP3l4JEXhxbjY2nyjD1SPSWJDud8u8rhXurALAw9LgQInFCnOYHiZ9I9WAPTiUr36gzBuTAa5GKPqXdgFw4lvAXgPk7xH2jQzmparRCz2uHA3MkuPJ2ntlgQOwBo2AnAklEnTgsR9LTkusUl2dNnNXebQkcTSwqtRKlIHHRIeCAo8JgvBi//kq1XZuWR0aHC7YXW68vukkAKB3YiSSzCZcPywW+v9cBfx3HhMbPsjkSnAwvxpjn/kBN7+7Aw6XG//ZfgYnS2qbnMuuM0xUXDo4GR/eMRYPXz4IKD3GDib0U/cMMkQBsb2Cf8EiorvBafWdWeW0eWwLgaj1Fer9vgRSY/hzV5lTg7tOd0LMoKsvB2y+/+5aTP5eYOur6n2OBjmLTgxUl9xVJHI6GiRyCILwQmk96Rkf7nPMhb2FnlGnfgTObAFyBeuKj+J1A7k8HCtiD6JdZyrxv93n8OiXh3Hpyz83OZcTxey8ERkxmNw/EWZ3DXDoc3aw3wx1HZn0Uc1LHxcR3Q2OBsDuQ4CJdXREHA0sRsezuWZjfat84VfktCCIuqsjxuRY8lkWXCjY/k/g5WFA5Rm2/cMT3mMc9bKoie3JlmJ2FWXCdThI5BAE4cWJYvaA//wP4/HlPRPRIyYMJr38cfG70elYME6o3yLGI4gMm+t1vZ6R6nic3YJ1hucBXmxw6IfCamYt6REjCJC8X9mDJr4fCwZWWjv6zWjytTWKZMmx+bYOeAaWOuqZGHL5bkwaMMqYHKWQak5Rw+4C5yEkm/g7CohvHwKq84CNgtvVl2XmP9fITVzjBKthPVlyOiokcgiCUFFjdaBI6A3VNzEK0eF6bP7LVOx/TBYQiyYpAmKV1YE1OmDkTV7XvLS3OiBTGZNz9Rtb8cK3x/3OR5yLVGhQjH9J6M8ym4bPkwe3WOQI83Q2ADYflhzPgFNHg7rabWo2MOPp4O+rjMkJVzQVDdYi1J3w/N24Qtc2RHrvfbkdxSw+wDswnGKoOhwUeEwQhITD5caEZzcBAGLD9YgOZ92UtRoOWo0Wn909HjU2p7ptQ7VQaXjqI8DoO1jDyaTBQMkRacjQOPV9CqvljJUD56tx4Hw1bhyXibQYtRjieR4FVWxsarRwrFbo6RQluMVGLmCtERwNLEanJYjuBqfNd0Crp1vKUc9iQgAWn/H7zc27r0bxURyTKVdcJvzjaclxOwAYfA4NGrcgmJRB5r7wdM2mjw3N/YmQQZYcgiAkfiuuQY3QUTwh0rvmx+iecZg6IEm9U2ynENtT7qh91ety2X0AYe46PH/9cGk7t8w7qHf1vnyvfVX1DticrKJtklmYj9gkMVIRizNkDjBifiOvLEBEd4O/mBzxoTfpQXmfaMlSWmCCRWkhmv08YIoBpj3W/Ot1B7wsOS10GaquJbhXG4SA8gn3AinDvcd5pv5njAndHIiQQCKHIAgJsbs3ANx9cR/fgxxW4MT3QN4OoCJXznRSVhpOHw3ctx+YuIRtW6sxd3QGjDr2kXO23CMtF8CRQovXPjEeJz7CILu4RJET5R3g3GJEkcO7/BeZ4zTAxX+Vt8X4jJaInEFXsmXmeCBpEPCXXGDSkuZfrzvgJXJCWBRQtOSIWXP9ZsrlBZQYQ5jZR7QK5K4iiG5MYXUDIo06hOm1eGvLaanQ39QBibhulJ/4gu0rgE1PqvdxWiDOQxTFZMrCx8YsFeEGrWSZ8aS81ua1T3RVpSgaf6LWhyUnVAQSOBoWB+gMgNbArAcVQoxGZFLj5zVGdDoTNuJDsyUZYt0Fn+6qECEKXNFyFx7nu9CfUuREJlFzzg4IiRyi42OtZj9iXyEiJJTUWDH+2U1IjDLi/un98dwGOfg3KaqRh33BPu99M570bVkxCt21raLI0aGy3vfDqKzW291wqpS5jHolRLCKxh/fxLJfgNa15DRGuBBgpA9nImf3u2y7pdWJw+OaHkPIhNJdtX4pkLtFcS0ny9YSRU5YrLclZ86b6hpNlAnXIaGvC0TH58M5wKvZwN4P23smXYo9Qhp3aY0NO3LLVceSzT568IiBuOWsGCB6jGLLjAuBC/00sDSJIoe5osIM8oNpSJq6NowvS87JklrEoAbXOdcDX90nCxygdWrIaDSAVvHaffWgEjNuPB968X7ce0TroPH4jt4Sd9XOt4DSo/K2W2jdILaMEK13IretZzFgSktOsK08iDaBRA7RsXE5gIK9rBv02nvlirNfLwGeTgWezQD2f9y+c+ykuBR1RUS3kEii2cOisfU14JkewJYXgfJTbN/17wFz/w3MW+nfTG/ytOTIImdkZgxGZ8kpupX1DjhdalfWydJa/Fn3Oaaefl5tQZrxVMvcQ42htOZMegD4w3b1cUnkePyOPN11ROvCeTy+QumucjnkoGN9OHuvz++Wj4sCXyly/PUfI9oVEjlEx0ZZgwVgVXXrypmLwFHPugEf+qJ95tbJKVe4h8TWCSLJUQprRsVpYOOjrHbMD0+wh4nOBERnsqymxr7BivVfrNVA2UmMdMtp5YNTo7Fy0TjsffRSaASNtDNXbo/A8zxOltTiQs1RqHjwJMt2aS2U8TAj5gPJg+Xy/YAscjzrspAlp21pzewqR73CVSW4EXtfzJap2bLANUTI51AH8g5J0CJn8+bNuPLKK5GWlgaO47BmzRrV8S+++AIzZsxAfHw8OI5DTk6O1zWsVivuuecexMfHIzIyEtdddx2Ki4tVY/Ly8nD55ZcjPDwcSUlJWLp0KZxOtTnyp59+wgUXXACj0Yi+ffvigw8+CPblEB0dj3oh/LcPAx9dox4jlmAngqK0xts9JJIeq3DFnNvpPSBleGDBsUpLzopReLxiKdK5UozijmM4foNRp0VchAFuwah04zs7YHUwF0F1gwOctRr9OUHoRmcCIxYAka0c+6DsOi3GFCkfYKLIsSmywVKG0Tf5tsYz8Li57ipf51ktQL0iHgcApi0HZj4L3LZOMQeFBVNHHcg7IkGLnLq6OmRnZ+ONN97we3zixIn4xz/+4fca999/P7766it8+umn+Pnnn1FQUIBrr71WOu5yuXD55ZfDbrdj27Zt+Pe//40PPvgAy5bJHY5zc3Nx+eWXY+rUqcjJycGf//xn3Hnnnfj222+DfUlEe+C0AaX+q9xKVDKRc9adhCo+AlzZbywAFUBVXyZ23JVnQlPSvZtRUmP1e2xQquKBrTTTi1z/XmA3iUgCotLk2AYAvbhCfG58HEO/uQ6we6eSFwlp4/lVDRimOQ0Nx7MaPPcfBOb8M7D7tgSn4vciCjnlA0z8Zq9s+3DL2tafF6HGKyanmZYcZ4P3Pked3Fk8XBA5kYnA+D/6F7NkyemQBC1yZs2ahaeeegrXXHONz+M333wzli1bhunTp/s8Xl1djXfffRcvvfQSLrnkEowaNQrvv/8+tm3bhl9//RUA8N133+HIkSP46KOPMGLECMyaNQtPPvkk3njjDdjt7A/5zTffRK9evfDiiy9i0KBBWLx4Ma6//nq8/PLLwb4koj348WngjbFNu5rKfgMAbHYPxyvO66TdtoQhmHZkNlw8B43Lhl2Hjvq7AuEHT0uO2cQeGndO7AVO+Q313K/qEy+8B4jJQEBodcAV6v/JDK5U3hCCmOcq0tXFNg4FVVakc0KF4fgWVjJuKcr4m7AYtuQV8UOUGdX2eLqrmhuT4/Aj9quEIPewAN/brIuad3+iVWnzmJw9e/bA4XCoRNDAgQORmZmJ7dtZgN/27dsxbNgwJCfLKaIzZ86ExWLB4cOHpTGeQmrmzJnSNXxhs9lgsVhUP0Q7sfVVtvzyHu9jFaeB/1zLMqq2rwAA/Man42vXeGnIf/s+j3J3BArBCrCdO00iJ1hKFdlMf5s9CDv/Nh3/XXQhHp49SB5UfBgoOsi+Nd/xHXDpk8D05cHdqN+lqs3eXIG8secDYN9KPDlnqNSAs1gQOYXVDUiG4DJQNuFsD5TByL76GRFtj5e7qrkix9uaCACoEf5OmxKw9+xklk2Pv3OiY9DmdXKKiopgMBgQExOj2p+cnIyioiJpjFLgiMfFY42NsVgsaGhoQFiYt3/02WefxeOPPx6ql0I0F+U3J0c9c4ekj5b37fkAOPWDtFlszMKn1othhRG/sz0KDsCOn6oAAIWaVKTzZXCVnmiTqXcVduZW4EgBE/lf3zsRQ9LM4DgO4/soqvbyPPCz4HYeMBvIHMd+gkWjZcLo++UAgN5coXxs97vA7ndhMkVjTM8eyM9pULmrsjghEDkqLfj7hhISOR0Pz5iw5oocpx9LjkX4O23q/U4cwH6IDkm3yq566KGHUF1dLf2cO3euvafUPTm+XrXJ//sqoFbhwig+rDq+1TAJVhhxz9Q+OKgbih08szQYdRqE9RgKAAivPNa6c+5ifLbnHNw8cPWINAztEa12T4l8fCNw5EuWqjvx/pbd8KI/s3o6APooLTkihz5HslDVWHRXFVZZkcx1EEuOMv5D/GY/8xm2vLoN4oQIbzxjcprtrvIRkwMAFuHvNFB3FdEhaXORk5KSArvdjqqqKtX+4uJipKSkSGM8s63E7abGmM1mn1YcADAajTCbzaofoo2x1wFr/qDaxTnqgF8UcRseIuebclYPZVK/RIzuKX+r+ua+SYjsORIAkFJPlpxgKBHicS7q4yf929Egi9Hpy4EeF7TshhwnpZpnaUq8j5/fhRShNo/oriqpsSKlPS05yqKAp3+S15OZsMb4e1grhpEL2nRahECo3FX+LDmBuquIDk2bi5xRo0ZBr9fjhx9kd8Tx48eRl5eH8eNZzMX48eNx8OBBlJTIH4YbN26E2WzG4MGDpTHKa4hjxGsQHZTyk9KHyiW2F3C7fSnbf+AT9iF19CugplB1ymF3T6THhmFERgz+IDSNnDogEb0TIxHdixXlGsUfgv0QZbgEihh0nCjWw7EUyoGWAFAr/O9pDcCEP4Xmpr4aHIrUFCJVqLKcX8X+PupsLtmSE9UKfar8IaaN95os7xt5E1sOuhLQ6uX99ABsP7zq5ITYklMvVAEnS06nJuiYnNraWpw8eVLazs3NRU5ODuLi4pCZmYmKigrk5eWhoICp4OPHWZpwSkoKUlJSEB0djYULF2LJkiWIi4uD2WzGvffei/Hjx+PCC5k5e8aMGRg8eDBuvvlmPPfccygqKsIjjzyCe+65B0Yj+yC8++67sWLFCvzlL3/BHXfcgU2bNuF///sf1q1bB6IDI9S0KY0ejtPFaTjLJ6OUNyOxvoxZDtaw9gC5fAq2uobACS0KEI8P5gyFSa/FhL4JWP+nSUiPY9a6mMyhqEE4olAP3eo7geRfgMT+7fXqOg0qkeN2AS8NZAceLmAFzuqErKaIEDYdNDQictxO9Ipi9UrOlNWB53nYrfVI4ITkAHMbWnIWfsdaiChddFMfBjIvBAZf3XbzIBonVA06/Ykckdauy0S0KkFbcnbv3o2RI0di5EjmJliyZAlGjhwp1bBZu3YtRo4cicsvvxwAMG/ePIwcORJvvvmmdI2XX34ZV1xxBa677jpMnjwZKSkp+OILOZVYq9Xi66+/hlarxfjx43HTTTfhlltuwRNPPCGN6dWrF9atW4eNGzciOzsbL774It555x3MnDmzeb8Jom0QOjb/WslqTbigxZculnrpWv0HwM4aMt5pfwCPOBdiufM2ABwuUJT/H5xmhtnEvk1zehOeS3kRBXwcNC4bcHh1272WTorLzaO8jpViSIwyAvVylWHUCi7gOsGSE8oP+MYsOQCyjOxhU93gwIfbzyLBxixLTmM0EB7f2KmhJWkgcNkz6tceHgcMu15txSHal1BZckoO+z+mCwPSWuiqJdqVoC05U6ZMAd9I4bXbbrsNt912W6PXMJlMeOONN/wWFASArKwsrF+/3u9xcS779vnoiEx0XARLzmk3i7P5avFEfPN9HXDmG2gddQCAX2KuxqkidfNFUdT4Iqb3KHx9fjzu0q1DRVUF2sK4nF/VgK/3F2D+uMxG59YelNfaUGdzITPet6iorLfD5ebBcUBchAEoVcS2iZlvorsqlJ2VlSInJlPuLi9gslcgPsKA8jo7Hlt7GFdqcgED4IztB12orElE18Hzb6I5IufsNmDTU+p9Gh3gFqogz3w6dJZMol3oVtlVRAdAEDnn+CTcOj4Lw9KjcfXMy7DP3Vca8mwxS1OePigJg1LNeOLqIY1ecnTPONjAhMamQ+ektgCtyQ3/tx3PfnMMT3/d8erzzH5tCyY//6OUiu2J6KqKCzdAr9XI1htAruIrVnuNCGETTL0iISB5KHDHt8DY37NqxsI9RQsTAPTVMJc3nzgwdHMgui7NcVft/dB7n5AFCIBadXQBSOQQbYtQ4faMOxn9ktkHyIBUMz6Mvw/FfAxedV6Dw3xPxITr8cw1w/DNfZNwy/iejV5ycr8ETBrEKuY6rPU4XFDd6PhQcL6SuVa2nChtYmTb8c3BQnz061kUW5iI2Xmmwue4Es+g41pFtpPdQ+SE0l2lbGYY3wdIGgTMfg5IEkTstw/jz5f0kob0FXpW6ZKoBgkRAM2x5Hi6UC+6T65oDaj/ZolOCYkcom1wu5lroprVJvqNT0eWwp0yYsxkjLP9Ey875wIAXpybjSSzyeelPOE4DiN6sewbI+eA1eFu4ozQYTJomx7UBlQ3OPCHlXvxyJpD0r7XfziByjrvfj5HC1kwb1Z8OLDvI2DN3fJB0ZIjuatCaclRPFCiM+V1sdha9Tn8MfEgegp/F1kcm4MuUbbyEYRfmiVyFNbFgVcAlz6hLvxoiGz5vIh2hUQO0fq4XcAHs4G/swdbIR8HCyLRM17+lnTtBXIMjkmvwaR+QVoQhA8mE+xt4q4SCdN3DJHjS8ycKKnFPzZ4F0ncc5alZc+MK/FuqyGKHDGdPJRZTSqRI/eqEoPNAcBQnYupA5mw6iH0reJis0I3B6Lr0hx3lTKzSkwZ15PI6UqQyCFCR1WeutaKyNGvgDy5p1gpHw29lkNqtPxhEmXS46k5QxEbrsd7t46BQRfkn6YgcoxwwOZsXUuOwyVfv6OInKoG3x/wH+9SV/XmeR57BZEzzrnL+wRbDWvnUCqIo1DGwxj8iJzxCqFVX474CAMi0IBYThA/0QE2AyW6N83pQt5QKa+LIkdlySF3VWenzXtXEV2UmiLgn+PZt/IpDwNT/sr28zzwy0uqoetd49A3KQo6rVrI3HRhFm66sJnf2gWzswl2VLeyJadM0dhSq+kYmRdV9b4/4HsnqD+kqxscUnBvaslm7xNOfMcCke21gEbPYmdCBad4v5UiJ2MsMPsFYP2DQHU+4uKNkhXHgkiYTVSZnAiA5rirlCJHtOooRY6RLDmdHbLkEKHh6Fey2+GnZ4C8X9l67magcD94XRhuif8vrrA9hXdcszEwJcRZCzoWRNsWMTlidhIA1NmdrXqvpvjpeAn+/s0xbD9drtr/rwWstkexxaoq+SAKtASTG5rCHLZz0SYgXoh7Of2T3CE+vm9o68JYLfK6Z9NDUfRY8hEXYZBETpkuhDFBRNfG3Yz/RaXIuXoFWyrr75Alp9NDlhwiNBz1aKmQu5lViBWK8+2JmYHN53kAvQEAA0IucmRLjs3ZupacEosscmqt7Sty/rhyL+rt6tc7sW8Cpgxg4qDO7oKlwYnTZbU4W16PZCGY+zLTEcDqBCKTWbGz7Hne9UKSBoV2sv0uZSXysyZ41x4xCzFZlnwkRMoip0KXLPzFEEQTtMRddfsGIEtoCeRW/D9RTE6nh0QOERw1xazP1KhbAZPQ48deB5xlMTdfaqbjavf3qD93AOHndwPHvgYAvFmsju3ITo8J7bxESw7awJKjcFfVtKPIqbE6vAROdno0/nXTBQgzaBEXYUBFnR3Hi2uw8N+7UGN1YnL/RAzk8vCUVeig3WM0ExxGHy6h3heHdsLhccADx1g/LE9ES05dKTKjNYgBswrmWcMxOrSzILoqzXJXVbFlhKJRrVLkUIXrTg+5q4jg+OFxYOOjwH+ukfed3Qa4HajQp+Jr63AAQPjJr4B3pgF1pXByBmxxDMLYnnHY9MDFeG3+SFzYO8R1iRUxOa2dXaW05NTY2k/kiN26lUzom4AooQJzWgyz2jz/7TFJjG3+rRTjNIoChr0msaWvomd9poV2wgATo74qyIbFSqI5yZ6PfjFsd1KCny7pBOFJsO4qlxOwCTW1lO5Tvu2yM4nWh0QOERyCZQb5e4BaoWDcqR8BAD85h+Ak38PrlHNIgg0GLJrcG70TI3FVdhq4UJdKV8TktHZ2VWmtLC7sTrdUd6atKfRR0TgmTP7mmd3DjDf0r+CO/GXgIP9O+glF9pB2ATDmTrbuKXKGXgfEtGFWE8cBCULRvzV/wBVCTcARfdP9n0MQSoJ1VwltZACo3VLNie0hOiwkcojgiEyW188LKcinmcj53jYYlcY02KE28Z52JiJMr8Wkfq34rVzXdpYcZeAxAMx9c7ufka2Lr7YNMeHy735WDxsu1+7ELO0uDOXOoE8iC6IU2yVg3N2yOT5zgnyRSx4Frn+v1ebtlwShe3zhfmgPfQoAiIyKaft5EJ2TYN1VTvH/mJO+JAEgkdPFIJFDBA7Pq+rg1OYfYanjJUfAg8M29xBMHpCK/HB1wOo5PhHj+8TD1Jo1ZRQxOUEHHttqgP2fsNiiACjxEDm1NmejTWtbC1/uqpgwPfDzc8Cnt2Nsg5wifolmH35/MUsH78vls52J/eUTI+KBJUeBK14Bxt7VmtP2T3is9z7KbiECJVhxokwZV1qWlb2riE4PBR4TgVNXCjjlB+uu3TswNYU9OE9qeqEKUbh0cDIaagcA9QekcfUwoW9SK2cpCDE5Rs4Bu93JBFlDJfO1N+Ua2/UO8P1yYHM/4N7djQ49XlSDfXlVXvtrbU5YrE6s2ZePBeMyERPuI7g2xIjuqmkDk1BcY0VWfAQutm4CfnwaAGDAF9LY34dvgqnfU9jT142E8xbwnBZcQn/1Bc1pwOjbW33efhl4JbDtdfU+apBIBEpzLTlKKw4AZM9ny4xxLZ8T0e6QJYcInMqzqs24upNwH98AANhpZ0EUk/oloHrMfTjPy66pUj4aGXEejfBCjeKDyumwAh9dCzzXC/jqvqbPPf0zW5afAAoPNDr00S/l3lAb758srVfU2THvre14/tvjeHpd63UmL7ZYUScEO+eWMcvTzCEp+PreSXhj7iCYjvzP53nhjkpo9v0Hfx/OOo5zGeM6npUkcxxzoSmhFF6iMf74K9BTCJ4PNmDY6aP4HwBoNMDIBUAC9UzrCpDIIRqH54F9K1ndm1L28C7jWbpxtuY0NAc+BgAc4ntiYEoUYsINGDZoECbaXsNSx13Y4BqD/7ouQVarixz5g0pjqwFObWIbx79p+lxlnJHYzsAPO3Plzt4ZceHoEcMsSOV1dpyrYB+a206V+zy3pZwpq8OEv2/C5a9twYZDRTgiBDwPTjMD9RXAijGsmB8A3LYeSB/L1ocImXDFB8EJ8VPoN71V5thi+nrMiyrOEo2RNAi44Fa27g5W5AiWHL2p8XFEp4ZEDtE4R9cCX/4R+PeVUi2c1a6JsPHq4OJD7l4Y05OlhUcamRf0U9cU3O24H1YYkdnaIkerh5tjMT9GhyxElO41vygaRL73zVb8b/c5VNXb8dbmUyislhv48TwPvZYDwOODSdUw2SsRH8ncUm9vPi2NE/eFms/3nofLzeNMeT3u/mgPquod0Gk45gr86VmpwzsAIHkwcMuXwB+2yQ+B4iPymOShrTLHFhPuUVqALDlEU2iExxgfZFal+NngackhuhQkcojG+eUVeX3/KgDAbvcAlEEuHndK1xdH+UyMzIyR9r19i7qEW5pg8WhN3Boh+NiuKNVuq2n6G57YeRuApqYAf/nsAP7+zTE8s/4Yxj+7CRYr8/VX1jvgcPG4TrMFU3b9AXhnOuIimKD55lCRdA2zqXUKiFXVe8cc9E2KhKnyBLDrXfWBsFjWEDN5CPsBgIrTQLWQPh4e3ypzbDGe8yKRQzQF10yR4xBFjrHxcUSnhkQO4R9LAVCw12v3PndfWHnZWjGt9gk4ocOwHtHSvksHJ+PM3y/HA5f2x7PXDgu+q3gzcAsfVhFKSw54wFrd+IkKS04qx85Vdu/+7jCLYympYR+Kcw1b2YHKXJ+CprUKBPqqxzM41Qwc+lwdjzB8nnpQZBIQngCAlzste/aO6iiEe5QZIHcV0RSCBTd4d5Uoclr/CxjRfpDIIXyz90PgJe/eRduME1GCWKzN+AvcPId/OOQHau9E7wfSvdP6Yf7YzFadqgivZWbncEeV+oCyCZ8vbEqR4x1PszePnS9WOo7WykXHfiuu8RrvryN4Szle5H2vwWlmJkYB4JJHmHvq8he8T47rpd72dAt1FDyDocmSQzSF2FAz6MBjP9lVRJeCRA6hxu0Ccv4LrL1X2vWm80rca1+ML10TsLRuAQDgwkuuxmDbe/iX60oAwIzBydBqQlzFOEh4IY3c7KpQH6iv8DFacZ7CXdUvzNtasvesIHKE+jhRnBznc7dQe+baC3rg+yWs11NlXehFTo3V4dNCNDjVDNQKrrKoVOaa8pV2HZMlr3MawBjtPaYjwHHqb9YdLQOM6Hg025IjxNvpyZLTlaE6OYSa7x4Ffn1D2jw75B68tWcYKmDGV25WFTcmXI8Le8fBCvYNKCHSgNfmj2yX6Srh9eyBGOPysNw0NCFy7LUQ5VmYrRx3T87Cm5vldPnjxTWwOlxS8b1whci5KjsNvRIiMCTNjOoGFjNjsTrhdLmh04buO4R47yiTDl8tnogpL/wEABiUamYFGQEgKsX/BWIVIicsVg7W7Ij0mQocX8/WNa1YQJLoGpAlh2iEDvxJR7QLCoFTEdkPF++5CBVQd6ie0j8RHMdhyoBEAMCyK4e0bjXjQBHiN+LcQVhyeB6cIiYHAC5Kl7MtwvRa8DwrvHeuoh4AEM7LGVcaDYfsjBjotBpEK/pGVTU0oyNyIxRVsw/kFLMJWfHhuHFcJu6+uA9iIwyyyIlsROQoLTkdNehYZPrj7Ns5FWMjAkEMPHZTdhXhDVlyujKHVzPXRa+L5R5FjSE23BTYWy3HQzw0ayD+ve0M3Dzw0GwWq/PqvJE4XlSDsb06RnyHRhQ5fCWg9JyVNlKcz9EAziMrY2KGHv+4bhgGppjx4Kf7caKkFucr63FaKL5ncNX7vJQodKobHKiqtyMhMnTfEIsES05KtAkcx+GZa4axA1/eA9SXsfWoVP8XiO0pr4d1jPfLL4n9WYsJclURgdBcS46DRE53gEROV2XPv4Gv/iRvz3kTGDG/8XM8xEAtmK96+qAk3DqhJ+6Y2AsOlxvhBvZnEx2m7zACBwA0JmZxGqxRV2bG1ldZJV1zmvdJCitONWdGNG8BZ6/FDWNY2nV6bBhOlNQiv7IBZwSRo+H9Z0+Zw3SobnCgxhraDKsioV5PslnxgVx5Btj3kbzdWDCxsi5OyZGQzq1ViEpuegxBALIlp+QI+9wbdWtg55Elp1tA7qquyLldwLol6n1r7gbKTjR+nqL5JgAY4MSdE3vhnVvHwKTXQq/VSAKnI6IzeWTiDLwCEOJ0cOI73ycJQce1vAlWrRCwa5WDj3vEMqF3rKgGJTU2cPAwiXuYyCOE30+9PbSd0CVLjlLkHF4jr2v0jffoioiXe/IE+hAgiM4Ap3CVf/UnoPhwYOeJIocqHndpSOR0RX55mXXk1Xq4S358pvHzqs6pNn92ZyM9tvNkHnCeWUVJg4AL/8DWz+30fZJgyamDCXadIJJssshJj2WVmredYi6hgeEencpd6o7k4Qb2gVsb4lo5ZTUsYyvJrHhP84VmonG9gVvXNn2Rq98AbvwfMHlpSOdGEO2KZ3B6TZHvcZ6QJadbQCKnq7H6D8DxdQAA2y3rcKT37Sib8hw7dvgL1nGb532fK5T8/9g5BUvsd+NT18XoEdvK7RhCiUdNlbxKK3a5+gEAbKe3+T6noQoAUMuHwaUXzldYcjKE1/9bMRNDk8PPqM93NKg2I4yiJSe0IkcUTX0tO4CKXLazTojFmfYYkDWh6YtotED/mYCpg6aPE0Rz4DxETmMWTSWSyKHsqq4MiZyuhNMG7P8vAIBPzcaSX7SYfeRSjN7QA9UQ3DbrHgBO/uD7fMFd9at7ML5wT4Ybmk5lyfEMVN2dsw8LN7EPPKMlFz/t9RGAXML2neLTACGmBza5QnKvBPma0zR78FDts+rzPXpjiZacOlto3VU1NieyuZOYsP0u4F8XMaFTJwSKRySG9F4E0alobjkEKfC4E33GEUFDIqcrUXUOALPSvNFzBdYdLBQOcNjoGiWPO+/HdSNYcvJ5ubR+j84kcjxaAHzvugAWROI3dw8AwNYfv/Y+p+ggAOAonwVduGDhEC05Tjt6JsiWrLnazd7ne4gcOSYnxJYcqwNTtTlsw1EH7HyLRA5BAD4sOQE+1siS0y0gkdOVqDoDAHAnDsKb2wpVh150zJU3fv6HZMGQcDml5o3n+ET89bKB+PCOsa3WbLJVULir1kbNwzfusQCAPe7+AID4yhwUVQsfbLYa4MdngYOfAgCOuLNgjIiVjx36HHg6BeFHP0NaNPPZF/E++j05PCw5xtax5NTanJigUQRUlv0m9+SKSPB9EkF0B7wKRgbqrhKLAVJMTleGRE5XovIMAODnknDU2pzoEROGb+6bhDsu6oVFV0zCbfa/SEP5dQ+oz7WcB9xO2HgdihGL+WMzMLl/J7MQKETO165x4IU/7yM8K4TXiyvCj8dL2IBfXgF+/rsUOHyYz0K4WRAx1mrgsztY3Y0fn0GvROayioAgaPpfBpjT2XobWXIarDZkc6fkHYX72VKjA0wxIb0XQXQqPC03gcTk2GqA87vYOmVXdWlI5HQlig4BAHJdTJzMH5uBQalmLLtyMK4fnY6jbrlRJnd2q/pcQSCd5xMRaTKoqvd2GhQxOSdqZRN0Pc8+xEyw46EvDuKZ9UflDzgAFj4MxZokhEUJIufMFvma8X2QnR4DQNHOoe90+YPRKyaHiZy6EKaQu9w84hyFMHIK4SS6qsITOnaLBoJobTzdVYFYcvZ/DFirAK0ByJrYGrMiOgj06dgFOFxQjXUbvwP2vA+ABdGmx4bhD1P6SmPMJj0uGjkMnzonAwCsRo/S/oLIOcsnIys+HFygGQodCUXF0wK7HEtjhQEAYOJYGvZbm0+jzCULolI+BinRYdCECSKn7Df5mm4XbhiTAQCIFC05hkjZxO1pyRHcVfUhTCGvszvRh2Odxt3RHh3dKR6H6O54uqsC+ewSW70MvZ4KT3ZxSOR0AS5/7Rfk/fwhAKDU1BOfuSZj1tAUr67gz8/Nxo6erG6MzlqJn44VywcFkZPHJyErrpOW01e4bWyCsLmobzwuGcbcVSbI3cGPnVHXBEqLDgP6TgP0Hinz1mpkxUfgoVkDkRUlpN4bImSR4xmT0wqWnDqbE30FkcOlj1YfpA9oorvjFWgcgMhxC73lPJIViK4HiZwuwigNsz58FTEXNhiQGedd30ar4ZCZwSwBOs6NzQdPygeF2ivn+CRk+Di3U5A2Elsz7sKf7PdIu67O7oHrxjGLVg+FdkuC3LTzNec1SIsJY20fht+gvqYQ3Pv7i/ugpyhyjAFYckIYk2MtPYOH9Kw0AJc4QI4H4rTAlIdDdh+C6JQ0p1O9W/j/1HTcCu5EaCCR09moPAOc2gQcWwc0VMLhcsMAB7K50wCAfxewJo3+hMplI7JQw7O08AiXXA9GZcmJ76Qih+NwsO/dWOu+SNplDtNJdTDijHILhmSuEgCw1HEXvnRfhFQhgwrJQ9TXtCp+R2KfK0Nk0zE5Lcyu+vpAAT7cfgYAoDvxjXxgwGzgsmeB7BuBB44D6aN8X4AgugueMTl8AN3IXYIlh0ROl4fe4Y5OVR5w8nug/yzAnAp8fBNQzGq77NFm4xHz08jgSmDkHKjhw3CWZ+6L3gm+zbD9k6NgCY8HGs6DtxSx6sc//wMozAEgxOR0VksOgLG94sBxclHnKJNeEiScswEaDjDwNkRzrJP4BtdYAByz5ABA4gD1Ba3V7GIcB9gUIsefJccQGkvO4lX7AADZ6TGIr2INR780XIGrU4cDqcOBwVe16PoE0WXwtOQEInLcwpcQEjldHrLkdGRqS4BXhgFf3w98/xj7xxQEDgCMcu1H/+L1WKF/HYBYxI/DDaMzkNmINcYtxK48WHA/qwfzk1zF9xyf2HndVQAuyIzFLRdmSdtmk16Ks+FqizHZeBIpHHNVWTkTaoRO65IlJ8FD5PAuwC70qxKXypgce71qeFgIKh7zirYbu85UQFfD6heVGjP9nUIQ3RfPmBw+gP89MSZH2wmzSImgIJHTkTnwP8X6J8DK672GvGr4JwZpWDuGQj4OAPDw5YMavWx0paKo3OcLVcec2jDZqtFJmTk0RVqPMulUxb4+wDIM5c4AAOpNSRCDFM1iynxkkvcFrdWsWKJT6FNliARiBMGx8y3AKQc0J0ax1PUiixXFFqvnlQLC6ZZFzm/FNTDWsCDpmrC0Zl2PILo0nu4qtx9LTs4q4MCnwhiKyekukMjpyBz+Qr19apO0utD+AJy8+u0r5OMRF9F0jZuqkXf73F/DhyE9NtwrK6uzMSpLrkycGGUE9GrRdoHmBADAGZ6M60elY2zPOIzIiGEHOQ740z5g0SZWgwZg9TQciu7jxkjgovsAoxmoOguUytWj02PDMaZnLFxuHv/bpc7gChSHS/6QPl5Ug/D6fAAA75k+ThBE0+4qqwXY8iKw5g/AF3cy66uLRE53gd7hjgrPA6W/+TxUzMfA2nsG6ktXwWyT2zcU8nHoGUDQsGbyX3Biz1r007CH56qoO5BXUY8t7uGy26YTY9Rp8fPSKbA53awrOKcWOT04oXt3VBpemJvtfYG43mxpigbqy5glR0xP1+hYATGdkVl9bBbZjSUwa2gqdp2pxJFCC5qDwylbcsrLSmEEiwUyJPRq1vUIokvTlLvq6/uBQ5/J2w2VZMnpRpAlp6NirQbsNT4Pfey6BCnmMJgT01X7tZwb/ZOjmry0OSYWH7umSttry9PwpusqHOZ7oqTG1rJ5dxCy4iPk34VHl+G+HBN30UlNWEZMYsPOakU8TqRcbEyssCwGJAskmZnLqrzWjuZgV1hyDDYmyCx8GBLjYpp1PYLo0jRlyTm6Vr3dUEExOd0IEjlticsJHN8A1BQ1Oszt5uGoYBk15XwUHnHcjvN8Aq6wPYUl9rvxf84rmMUlUl0IbptrCLJFt0sjcByH6Fi54vFhd09p/d5L+vo4o5Pj0fagj4ZZv4xx6b5GyyhFTq3wnhnN8nGDIKLsapETHyGInLpmCMajX4HL2yZtxghWnCo+Esnmzm9lI4iQ4xWT42HJ8bTW1FeQJacbQe9wW8HzwKq5LK6mzzTgZjneZsfpcjz7zTH8/bphGJAchave+AUZJT/jX1qWMfWR61J85LoUAHCIZ66U1BgT4JBFzl8ci7CTH4TH0qMDms5tN90KvPkqzvMJqEE4fnxwCupsTgxJMzd9clfBnNr4caXIKchh61nj5eOiJcfDXZUQyaotl9cFacmpPAN8chNYJNBKAByiOXbtKkQiNbpzB4QTRKvQlCXHU8g0VFBMTjeC3uG2oq5UDhw+9QPLABAsDDe89SsA4N5V+7By0TgcyrfgAm0JoAUK+AT0TojA6TL1gzQu3AAY5Pibta4JABCQuwoAzCl9cL3uNZwUGln27Kz9qlpCZBMtEZQi5/h6tj54jnzcj8iJj2S/06p6BxwuN/TaAA2mVXKgciKq8Jr+DZhFkcNHIrsLxEsRRMhpKibHUwTVl5MlpxtB73BbYSlQb5efBBL7q2qinCqtxbkKlqacxpUDYJacC7Ji4XTzKLJYcfuEnjhUUI2LByQCRfI/70d3T0GEURf4AxVAsSEDVWD363YCB5Czp/whipyGKsDC4niQqghUFvveeMROxYTpoeEANw9U1tmRFKibySHX3Pmjbi3Ga4/IhwwxMJvo35UgvPCqeMyrtzUecTf1lRST042gT822wkPkVJ3agZjE/shVWGjcPEsZBoB0IQOogI9HWkwYVv9xAhwuHinKb/NhMdLq6J5xQU/pmWuG4ff/2YPlVw1penBXJLyJ35kociz58je/MDk9HQZR5KgtORoNh7gIA8pq7SirDULk1JVJq2LXcZGJw/t1TyFKEE3hEXPnFZPjKWQaKCanO0GBx21FjfqhdXT/TgDAsSK1FeDh1ayicZogcs7zCUiLNiE+0qgWOAAw+g4g7QLgkkebNaVJ/RJxaPlM/G50RrPO79RwGlnE+EM8Xsmal0LrUXPHj7sKaGbwcV2ptNqLUwenG6OasDoRBMHwisnxdFcpY3Ka0dyT6FSQjG0rLIWqTWc5e3D6q4rbQ7LkJCDVXwViUzRw148tmpamkxf+azZhsU1/wIm1cYTmpQiPk9PHAbXIKdzPrHV9pgE6A5LMRhwvrpHcjwGhEDkZmlL1MaUFiSAI/3jF5DRmySF3VVeHLDltRQ0TOTlulh1ltuajss6OUqEuza3js6RKvQY4kMxVAWAxOUO7U8ZTWxEWgHtPGXgMeAsN0V1VUwi8Nwv47zzgqz8BAIYLWW578yoDn5PCXeU9XxI5BBEQTWVX2evkmBxyV3V5SOS0FUJMzi73QABAFleMfecqpeJ7SWYT5oxgvYlmJ1cBABp4A9LSekjZOkQLuPxF9bYinskvnu4sfyLn9M9y24cSFiw8OouJqD1ngxE5pf6PNRU/RBAEo6k6OU6bbMnRksjp6gQtcjZv3owrr7wSaWlp4DgOa9asUR3neR7Lli1DamoqwsLCMH36dJw4cUI1pqKiAgsWLIDZbEZMTAwWLlyI2lp1QbUDBw5g0qRJMJlMyMjIwHPPPec1l08//RQDBw6EyWTCsGHDsH79+mBfTpvBCy6P7e7BAIAYrg65B7ehxGLFWO4oehjrceO4LLy1YBheqb4PAGCNSMOqu8b7uyQRDGPuBJZVyNv1Ff7HijQpcgR3ldI8bmWtHC7IZGNzy+pQY3UENse6EtXmh1GLgCkPA1kXAVkTArsGQXR3PN1VnkLGZac6Od2IoEVOXV0dsrOz8cYbb/g8/txzz+G1117Dm2++iR07diAiIgIzZ86E1SrHnixYsACHDx/Gxo0b8fXXX2Pz5s246667pOMWiwUzZsxAVlYW9uzZg+effx7Lly/HW2+9JY3Ztm0b5s+fj4ULF2Lfvn2YM2cO5syZg0OHDgX7kloflxOoZjVQjriz0KCPAQDMPrQEs3Ofwf+MT2LSoUeg1XCYYTounRY7ZTHMJvIZhwxlDE7V2abHe1p7PD8QxRRyJYJrKzpcj3ADu19FIEUBeR6ozJM2P3ZOwcaYucCUvwK3rweMgdU/IohuT1Mp5C47xeR0I4IWObNmzcJTTz2Fa665xusYz/N45ZVX8Mgjj+Dqq6/G8OHD8eGHH6KgoECy+Bw9ehQbNmzAO++8g3HjxmHixIl4/fXX8fHHH6OggLl0Vq5cCbvdjvfeew9DhgzBvHnz8Kc//QkvvfSSdK9XX30Vl112GZYuXYpBgwbhySefxAUXXIAVK1Y081cROk6fPIq8Q9tgr60EnHbgnUvAuZ2w8Xq4I1NQOvb/AQBSuQrM0/0EAIgv+JmdfGQNW45ZBIxd1PaT7+r0m8GW2fOaHhuZzN4HkVq1pQX6CHld7I9ls0gfsrHhrPJxQCKnrgywVQPg8PXU7/D/nIuCqnlEEIRAU+4qlcghS05XJ6Sform5uSgqKsL06dOlfdHR0Rg3bhy2b98OANi+fTtiYmIwevRoacz06dOh0WiwY8cOaczkyZNhMBikMTNnzsTx48dRWVkpjVHeRxwj3scXNpsNFotF9dMa8J/cjMzPZuHJf74H95mtLPMGgA069IiLQMaU232f2FAldx7vNalV5tbtufZt4KrXgZnPND2W44DLX5C3PettJPRjvazSLgAeOMb2uZ1SUb/YCDa+qt4Bp8uNn38rxZJPclBrc3rfq1xw6cZkoMqYAoCDXttNM98IoiV4Bh57uq9cDorJ6UaE9B0uKmK1PZKT1eXyk5OTpWNFRUVISkpST0KnQ1xcnGpMr169vK4hHouNjUVRUVGj9/HFs88+i8cff7wZryw4bBrWbuGSmi+h+egJab8JdvSICQOnN4E3msHZPETW13+W4zKaajlANI+wGOCCW4I7Z+4HwE9/9xZG4XFM3Gj0TABxWvaBarUAhgjJknO2vA5/+fyAlEmXGGXEQ7MHqa9VJoic+H5wCF3IyZJDEM3Al6hR4rTJrmuy5HR5utWn6EMPPYTq6mrp59y5c02f1AwGZ7Esqana/er7OxYhPZYJIC4i0fvEw6vlmiy+jhPtw5BrgHt2AClDvY8ZIgCdgVl9TEKqvyBeRZHz4/FSSeAAwMmSWny+5zzWHyyUs6/yd7NlgixyDLpu9e9JEKHB05LjKXJcdnkfxeR0eUIqY1NSUgAAxcXFSE2VOzwXFxdjxIgR0piSEnVsg9PpREVFhXR+SkoKiouLVWPE7abGiMd9YTQaYTS2QTq2jyDRT+LuxucFk/FkrBC7EZEAVJzyf43IJP/HiI6J0Qw0VErBx3ERTOQcLlBb7H44VoIfjsn/A2ceGQPs/4RtDLoSjlwW02MgSw5BBI9nTI7bh8gRIUtOlyekn6K9evVCSkoKfvjhB2mfxWLBjh07MH48S4UeP348qqqqsGfPHmnMpk2b4Ha7MW7cOGnM5s2b4XDIf5wbN27EgAEDEBsbK41R3kccI96nXfGRdbOzjImrwamCAFJaasbcqR6sC5NrsBCdB6l4IBM1MeHsW2JZbeOtHRxndwIuG5A4CHUp4/D8tyzDjtxVBNEMArHkUExOtyHoT9Ha2lrk5OQgJycHAAs2zsnJQV5eHjiOw5///Gc89dRTWLt2LQ4ePIhbbrkFaWlpmDNnDgBg0KBBuOyyy7Bo0SLs3LkTW7duxeLFizFv3jykpTE3z4033giDwYCFCxfi8OHD+OSTT/Dqq69iyZIl0jzuu+8+bNiwAS+++CKOHTuG5cuXY/fu3Vi8eHHLfystxYdA+dXeG70TIqT6KQiPlw+mjwWu+T95OzJR3T6A6ByIIsemtuSIaP200LBWnAcAHHUk4v7/yS5OEjkE0Qw8RY7b6b0tWnPIktPlCfpTdPfu3Rg5ciRGjhwJAFiyZAlGjhyJZcuWAQD+8pe/4N5778Vdd92FMWPGoLa2Fhs2bIDJJDeXXLlyJQYOHIhp06Zh9uzZmDhxoqoGTnR0NL777jvk5uZi1KhReOCBB7Bs2TJVLZ0JEyZg1apVeOutt5CdnY3PPvsMa9aswdChPuIm2hoPd9Ud9geRj0TcfXEfuZO02CoAAPpOB5IUgahaqnDcKTEKMTnCexsTrhY5z1033OuU2ZpfEfnj3wAAu8sM+O6I7ILV60joEkTQ+LPkpCj+/ySRQzE5XZ2gZeyUKVPAexZbUsBxHJ544gk88cQTfsfExcVh1apVjd5n+PDh2LJlS6Nj5s6di7lz5zY+4fbAw5Kz2z0AT1w9BL8bo+j2PfImVhNn0oNARLy6mm5DANV4iY6Hh7sqyqj+9+qXHAmTXgOrg30IX6vZjJcMbwLCZ3Ixr66obCRLDkEEj2dMjihornodeOti9TGy5HR56FO0NVDE5Dh5Da65cBBuGd9TPabfpcDS08Alj7BtjQa49Wvmxpre+mnuRCtgUltyjB7ZUSa9FnEK6851WrWILwY14SSIFuOZQi66qwwR3mMpJqfLQ+9wa6Cw5FQjArOHp/keFxGv3u41CVh6iuJxOitSTA6z5Bj1WvVhnRaxEQYUVFsRgxpcqD2qOl7iYcmpqA+gUjJBEGrKfgPcbvbFEZDdVVo9s9woY3TIktPlIUtOa6CIydFGxGNc7/hGBntAAqfzIsXkCCLHw5Jj1GukYOQLNUehhRs2Xv6QLePNqvEBtYMgCELN0a+AjY/K225FTRzPeEcSOV0eEjmtgULkxMRT5eJug4e7yqT3cFfptIgwsA/VCzVHAACfuKZKx8/yyRiVJVtzymtJ5BBEs9gu9DDkeUW6uAHgPB55FHjc5SGR0xooA48T+rffPIi2xdNdpVO7q4x6DXRCP6qxGlYLZ7t7MMZY/4mJtlcxcUhvfP6HCbhtQk8AwJJL6W+HIFqE0jWl1XkXBtSo/0eJrgfZ6loDZTHArAntNw+ibfFIITd6WHKMOo1Q+4ZHT471WDvKZ6IUMdj18HSpeOBjVw7G/Zf2R3QYfcskiBahqm6sZ32rlFB4QJeHRE5rYFDUyckY137zINoWkzomx+QReMxxrLN4HGoQzrEP2+umXoirRvVCYpRRNY4EDkGEAGW1Y60egP/yJ0TXhEROaxAeBwy/gfmA43q392yItsIUw5Y234HHAKDTapDOlbKNqFTcO6MDFK8kiK6KKpOKvjh0RygmpzXgOODat4CrV5A5tDthVHQhd7t8Nti8a1JvZGgEkROT2YaTI4huiGjJ4bRySjnRraB3nSBChUmRAm6rkVt4KOiZEIGXZ8axjZisNpoYQXRT3IoaOUS3hEQOQYQKnRHQCT3alL3JoDboGSzn2EpMBgiCaEVciho5RLeERA5BhJIwwUqTs9L/mPKTbBnft/XnQxDdGanasY/w04Xft+1ciHaBRA5BhJJRt7Llrnf9j5FETr/Wnw9BdGfcjVhyMsa07VyIdoFEDkGEktF3sGV9uXc3ZACw1wGWfLYe36ft5kUQ3RGXn5gcrcF7LNElIZFDEKEkTGzLwAMNVd7Hy0+xZXg8KzVAEETL6X+Z7/1COQdlqx0A3j2siC4LiRyCCCVaPWAU2jvUl3sftxSwJaWPE0To+N1/gFG3ee8X/wfDhSbJYt2ygZe3ybSI9oeKARJEqAmPA2zVQEOF9zFHPVvqI9p2TgTRldEZgJTh3vvrPETOrV8DR74ERt7UdnMj2hWy5BBEqBHdUL4sOU4rW+pNbTcfgugOeHYYB+T/wYgEtozuAYz/o7qmFdGlIZFDEKFG/NZY35glJ6zt5kMQ3QFfHcXry9hS/J8kuh0kcggi1Ii1cjzdVWUngZ1vs3UdiRyCCCm+LDl1oshJaNu5EB0GiskhiFCjclexgn8XRpUDK0bJY8hdRRChhfNlyfGIySG6HWTJIYhQI4mcCvzv9+MxtlccXht+Rj1GH97m0yKILo2nJYfnFTE5JHK6KyRyCCLUhMkiZ2yvOPzv9+ORaM9Xj9GRJYcgQsr/b+/+g6Iq/z2Av3dZdsEfu4siLCgipUFl+lVIWrWaue6o5a3sOo0ZzZiZjoZT3mlMrUltynBypkaa0rEm7ao3p5rsh6nIBcNsEJUkRRvEpCQUqJBfpgjs5/4BHDgIfOv73bMnz3m/ZnZ22edx5zkf4PD2Oc+z231NTmszZ3KIIYco4DpOqF3X5FwqU/fhTA5RYHX9FFwAaL0GNLfvZrQPCP546G+BIYco0LpvIf+tFCgvUPfhmhyiwOp+uar1GuBv6bmNTIPfeaJA676FfNvD1/fh7iqiwOr+WXGtzZ0hx8o9NmbFkEMUaF23kF+7DNSVX9+H75NDFFjiV3/deg2Q9uDDkGNaDDlEgdZxuUr8QEVh5/OT/7vzMUMOUWBdN5PT5XJVT28USKbAkEMUaDZH50LH84fb7uPuAmLHdenDNTlEAdURaDq0NHU+5kyOaTHkEGmhYzbnfH7b/ZBb1Ds8OJNDFFjSbSan5UrnY87kmBZDDpEWOtblVP/Qdu+KY8gh0lL3mZzmLiGnp3dDJlNgyCHSQsdMTmNV273NATi6hBxeriIKLH+3hccdv3sAL1eZGEMOkRYczrb7jh0fIfZuMzl8M0CigOp+ueqTJzsfM+SYFkMOkRbCnOqvQ0IBx0D110QUON13V3XFNTmmxZBDpAVH95DjUM/kdH8LeiL698T+o+fnLVb+vpkY5/CItBDmUn8dYgdsdiBlPnDlEhCRoM+4iIxqxGTg0f8FBo8E3p7Q+TwvVZkav/tEWugecmz2tvv/fCP4YyEyi6QZbfch9rY3AwS4s8rkeLmKSAvXXa6y6zMOIjMKcXQ+5kyOqTHkEGnhuoXHjp77EVHg2br8p4KLjk2NIYdIC9fN5HA3FVHQcCaH2jHkEGmh+0yOjTM5REHT9feNMzmmxpBDpIXrdldxJocoaGycyaE2DDlEWujpfXKIKDhCuCaH2jDkEGmBu6uI9NN1JodbyE2NIYdICyE29Ydw2hhyiIKGC4+pHUMOkVbs/TsfcyaHKHi4JofaMeQQaaXrJ40z5BAFD3dXUTuGHCKtdN1RxZBDFDxceEztGHKItNL1RMuQQxQ8vFxF7RhyiLRi5UwOkS64u4raMeQQaaXr5Sorf9WIgoa7q6idJmfehoYGLF26FPHx8QgPD8fEiRNx9OhRpV1EsGrVKsTExCA8PBw+nw+lpaWq16ipqUFaWhqcTifcbjfmz5+PxsZGVZ8TJ07g7rvvRlhYGOLi4vD6669rcThE/xrO3hDpgwuPqZ0mIeepp55CdnY2tm3bhpMnT2Lq1Knw+XyoqKgAALz++uvIzMzEpk2bUFBQgP79+2PatGm4evWq8hppaWk4deoUsrOzsXv3bhw8eBALFy5U2uvr6zF16lTEx8ejsLAQ69evx5o1a7B582YtDonor+NHORDpQ7XwmDM5piYB9scff0hISIjs3r1b9fz48ePlxRdfFL/fLx6PR9avX6+01dbWisPhkA8//FBERE6fPi0A5OjRo0qfvXv3isVikYqKChEReeeddyQiIkKampqUPsuXL5fExMQ/Pda6ujoBIHV1df/SsRL16X9miqx2tt2IKHgOZHT+7m37L71HQxr4s3+/Az6T09LSgtbWVoSFhameDw8Px6FDh1BWVobKykr4fD6lzeVyITU1Ffn5+QCA/Px8uN1upKSkKH18Ph+sVisKCgqUPvfccw/s9s7EPm3aNJSUlODSpUuBPiyiv87KmRwiXXB3FbULeMgZOHAgvF4vXnnlFVy4cAGtra3Yvn078vPzcfHiRVRWVgIAoqOjVf8uOjpaaausrERUVJSq3WazYdCgQao+Pb1GR1tPmpqaUF9fr7oRaYaXq4j0wYXH1E6TNTnbtm2DiGDo0KFwOBzIzMzEnDlzYNV5h0lGRgZcLpdyi4uL03U8ZHAMOUT66PpZcRbubDQzTb77N998M/Ly8tDY2Ijy8nIcOXIEzc3NuOmmm+DxeAAAVVVVqn9TVVWltHk8HlRXV6vaW1paUFNTo+rT02t0tPVk5cqVqKurU27l5eX//sES9Ya7q4j0wZkcaqdpxO3fvz9iYmJw6dIlZGVl4aGHHkJCQgI8Hg9ycnKUfvX19SgoKIDX6wUAeL1e1NbWorCwUOmTm5sLv9+P1NRUpc/BgwfR3Nys9MnOzkZiYiIiIiJ6HI/D4YDT6VTdiDQTN0HvERCZU2h452OGHFPT5LuflZUFEUFiYiLOnj2LZcuWISkpCfPmzYPFYsHSpUvx6quvYtSoUUhISMBLL72E2NhYzJw5EwBw6623Yvr06ViwYAE2bdqE5uZmLFmyBI8++ihiY2MBAI899hhefvllzJ8/H8uXL0dxcTE2bNiAN998U4tDIvrrkucBfj8wYrLeIyEyF/uAzsd8nxxT0yTk1NXVYeXKlfjll18waNAgzJo1C2vXrkVoaNsaheeffx6XL1/GwoULUVtbi8mTJ2Pfvn2qHVk7duzAkiVLMGXKFFitVsyaNQuZmZlKu8vlwv79+5Geno7k5GRERkZi1apVqvfSIdKVNQRI5c8jUdA5GHKojUVERO9B6KW+vh4ulwt1dXW8dEVEZBQXioDN97Y9Tn4CeGCDnqMhDfzZv99cdk5ERMbiGNj5mB/QaWoMOUREZCxck0PtGHKIiMhY7P07H7de028cpDuGHCIiMpauIaf5au/9yPAYcoiIyFgsls7HLVf0GwfpjiGHiIiMq5khx8wYcoiIyLgYckyNIYeIiIyrhWtyzIwhh4iIjIsLj02NIYeIiIyLC49NjSGHiIiMZ2Dbhznj5v/QdxykK34GPRERGc9T/weU7AH+8ZjeIyEdMeQQEZHxuIYCExboPQrSGS9XERERkSEx5BAREZEhMeQQERGRITHkEBERkSEx5BAREZEhMeQQERGRITHkEBERkSEx5BAREZEhMeQQERGRITHkEBERkSEx5BAREZEhMeQQERGRITHkEBERkSGZ+lPIRQQAUF9fr/NIiIiI6M/q+Lvd8Xe8N6YOOQ0NDQCAuLg4nUdCREREf1VDQwNcLlev7Rb5ZzHIwPx+Py5cuICBAwfCYrEE7HXr6+sRFxeH8vJyOJ3OgL2uUbA+fWN9esfa9I316Rvr07sbrTYigoaGBsTGxsJq7X3ljalncqxWK4YNG6bZ6zudzhvih0UvrE/fWJ/esTZ9Y336xvr07kaqTV8zOB248JiIiIgMiSGHiIiIDIkhRwMOhwOrV6+Gw+HQeyh/S6xP31if3rE2fWN9+sb69M6otTH1wmMiIiIyLs7kEBERkSEx5BAREZEhMeQQERGRITHkEBERkSEx5Gjg7bffxogRIxAWFobU1FQcOXJE7yFp7uDBg3jggQcQGxsLi8WCzz77TNUuIli1ahViYmIQHh4On8+H0tJSVZ+amhqkpaXB6XTC7XZj/vz5aGxsDOJRaCcjIwN33nknBg4ciKioKMycORMlJSWqPlevXkV6ejoGDx6MAQMGYNasWaiqqlL1OX/+PGbMmIF+/fohKioKy5YtQ0tLSzAPJeA2btyIMWPGKG9C5vV6sXfvXqXdrHXpzbp162CxWLB06VLlOTPXaM2aNbBYLKpbUlKS0m7m2gBARUUFHn/8cQwePBjh4eG44447cOzYMaXd8OdmoYDauXOn2O12ef/99+XUqVOyYMECcbvdUlVVpffQNLVnzx558cUX5dNPPxUAsmvXLlX7unXrxOVyyWeffSbff/+9PPjgg5KQkCBXrlxR+kyfPl3Gjh0rhw8flm+++UZGjhwpc+bMCfKRaGPatGmyZcsWKS4ulqKiIrn//vtl+PDh0tjYqPRZtGiRxMXFSU5Ojhw7dkzuuusumThxotLe0tIio0ePFp/PJ8ePH5c9e/ZIZGSkrFy5Uo9DCpgvvvhCvvrqKzlz5oyUlJTICy+8IKGhoVJcXCwi5q1LT44cOSIjRoyQMWPGyLPPPqs8b+YarV69Wm6//Xa5ePGicvv111+VdjPXpqamRuLj4+WJJ56QgoICOXfunGRlZcnZs2eVPkY/NzPkBNiECRMkPT1d+bq1tVViY2MlIyNDx1EFV/eQ4/f7xePxyPr165XnamtrxeFwyIcffigiIqdPnxYAcvToUaXP3r17xWKxSEVFRdDGHizV1dUCQPLy8kSkrR6hoaHy8ccfK31++OEHASD5+fki0hYkrVarVFZWKn02btwoTqdTmpqagnsAGouIiJD33nuPdemioaFBRo0aJdnZ2XLvvfcqIcfsNVq9erWMHTu2xzaz12b58uUyefLkXtvNcG7m5aoAunbtGgoLC+Hz+ZTnrFYrfD4f8vPzdRyZvsrKylBZWamqi8vlQmpqqlKX/Px8uN1upKSkKH18Ph+sVisKCgqCPmat1dXVAQAGDRoEACgsLERzc7OqRklJSRg+fLiqRnfccQeio6OVPtOmTUN9fT1OnToVxNFrp7W1FTt37sTly5fh9XpZly7S09MxY8YMVS0A/uwAQGlpKWJjY3HTTTchLS0N58+fB8DafPHFF0hJScEjjzyCqKgojBs3Du+++67SboZzM0NOAP32229obW1V/bIAQHR0NCorK3Ualf46jr2vulRWViIqKkrVbrPZMGjQIMPVzu/3Y+nSpZg0aRJGjx4NoO347XY73G63qm/3GvVUw462G9nJkycxYMAAOBwOLFq0CLt27cJtt91m+rp02LlzJ7777jtkZGRc12b2GqWmpmLr1q3Yt28fNm7ciLKyMtx9991oaGgwfW3OnTuHjRs3YtSoUcjKysLixYvxzDPP4IMPPgBgjnOzqT+FnEgP6enpKC4uxqFDh/Qeyt9GYmIiioqKUFdXh08++QRz585FXl6e3sP6WygvL8ezzz6L7OxshIWF6T2cv5377rtPeTxmzBikpqYiPj4eH330EcLDw3Ucmf78fj9SUlLw2muvAQDGjRuH4uJibNq0CXPnztV5dMHBmZwAioyMREhIyHUr96uqquDxeHQalf46jr2vung8HlRXV6vaW1paUFNTY6jaLVmyBLt378aBAwcwbNgw5XmPx4Nr166htrZW1b97jXqqYUfbjcxut2PkyJFITk5GRkYGxo4diw0bNpi+LkDbJZfq6mqMHz8eNpsNNpsNeXl5yMzMhM1mQ3R0tOlr1JXb7cYtt9yCs2fPmv7nJyYmBrfddpvquVtvvVW5nGeGczNDTgDZ7XYkJycjJydHec7v9yMnJwder1fHkekrISEBHo9HVZf6+noUFBQodfF6vaitrUVhYaHSJzc3F36/H6mpqUEfc6CJCJYsWYJdu3YhNzcXCQkJqvbk5GSEhoaqalRSUoLz58+ranTy5EnVCSc7OxtOp/O6E9mNzu/3o6mpiXUBMGXKFJw8eRJFRUXKLSUlBWlpacpjs9eoq8bGRvz444+IiYkx/c/PpEmTrnurijNnziA+Ph6ASc7Neq98NpqdO3eKw+GQrVu3yunTp2XhwoXidrtVK/eNqKGhQY4fPy7Hjx8XAPLGG2/I8ePH5eeffxaRtm2KbrdbPv/8czlx4oQ89NBDPW5THDdunBQUFMihQ4dk1KhRN8w2xX9m8eLF4nK55Ouvv1Ztdf3jjz+UPosWLZLhw4dLbm6uHDt2TLxer3i9XqW9Y6vr1KlTpaioSPbt2ydDhgy54be6rlixQvLy8qSsrExOnDghK1asEIvFIvv37xcR89alL113V4mYu0bPPfecfP3111JWVibffvut+Hw+iYyMlOrqahExd22OHDkiNptN1q5dK6WlpbJjxw7p16+fbN++Xelj9HMzQ44G3nrrLRk+fLjY7XaZMGGCHD58WO8hae7AgQMC4Lrb3LlzRaRtq+JLL70k0dHR4nA4ZMqUKVJSUqJ6jd9//13mzJkjAwYMEKfTKfPmzZOGhgYdjibweqoNANmyZYvS58qVK/L0009LRESE9OvXTx5++GG5ePGi6nV++uknue+++yQ8PFwiIyPlueeek+bm5iAfTWA9+eSTEh8fL3a7XYYMGSJTpkxRAo6IeevSl+4hx8w1mj17tsTExIjdbpehQ4fK7NmzVe8DY+baiIh8+eWXMnr0aHE4HJKUlCSbN29WtRv93GwREdFnDomIiIhIO1yTQ0RERIbEkENERESGxJBDREREhsSQQ0RERIbEkENERESGxJBDREREhsSQQ0RERIbEkENERESGxJBDREREhsSQQ0RERIbEkENERESGxJBDREREhvT/FcOFX4KPP5oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - #### Step 7.2: Model with Most-Volatile Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bi0NhRExrSz"
   },
   "source": [
    ">> - #### Step 7.2.1: Calcualte Sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcGN6S1PzjpU",
    "outputId": "20f8a9a8-941c-472a-8ab0-18449a668319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  -0.17807157040087887\n"
     ]
    }
   ],
   "source": [
    "# Calculate Sharpe ratio\n",
    "sharpe=(252**0.5)*df_ensemble_results_mv.account_value.pct_change(1).mean()/df_ensemble_results_mv.account_value.pct_change(1).std()\n",
    "\n",
    "print('Sharpe Ratio: ',sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "bhQeQ969zvRa"
   },
   "outputs": [],
   "source": [
    "df_ensemble_results_mv = df_ensemble_results_mv.join(df_validation_dates) # Mask the results with the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "4RYlDJUDm4an",
    "outputId": "97f6cffc-d76a-48ad-8f5c-974d112cd8c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_ensemble_results_mv.account_value.plot()     # plot the chance in the amount value with time during test period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zsjiQs0xuA4"
   },
   "source": [
    ">> - #### Step 7.2.2: Backtest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOtqFrge0PaS",
    "outputId": "57b6fa4d-2ed6-4814-f533-cffec36c254a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return         -0.054787\n",
      "Cumulative returns    -0.131391\n",
      "Annual volatility      0.201965\n",
      "Sharpe ratio          -0.178072\n",
      "Calmar ratio          -0.183176\n",
      "Stability              0.560536\n",
      "Max drawdown          -0.299095\n",
      "Omega ratio            0.964220\n",
      "Sortino ratio         -0.238092\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.797461\n",
      "Daily value at risk   -0.025588\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "stats = backtest_stats(account_value=df_ensemble_results_mv)\n",
    "stats_df = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JlN8dyDxwvB"
   },
   "source": [
    ">> - #### Step 7.2.3: Compare with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "tmq__tq19v62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>spy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>9979.070997</td>\n",
       "      <td>9777.141321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>9847.471965</td>\n",
       "      <td>9825.327421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>9866.176620</td>\n",
       "      <td>9981.552869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>9909.565673</td>\n",
       "      <td>9929.227721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>8493.444293</td>\n",
       "      <td>13196.873815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>8660.852307</td>\n",
       "      <td>13125.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>8558.712978</td>\n",
       "      <td>13224.516675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>8626.658921</td>\n",
       "      <td>13309.419390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>8686.088159</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            account_value           spy\n",
       "date                                   \n",
       "2018-04-04   10000.000000  10000.000000\n",
       "2018-04-05    9979.070997   9777.141321\n",
       "2018-04-06    9847.471965   9825.327421\n",
       "2018-04-09    9866.176620   9981.552869\n",
       "2018-04-10    9909.565673   9929.227721\n",
       "...                   ...           ...\n",
       "2020-09-25    8493.444293  13196.873815\n",
       "2020-09-28    8660.852307  13125.003128\n",
       "2020-09-29    8558.712978  13224.516675\n",
       "2020-09-30    8626.658921  13309.419390\n",
       "2020-10-01    8686.088159           NaN\n",
       "\n",
       "[630 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_mv = pd.merge(df_ensemble_results_mv, df_index_scaled, on =\"date\", how = \"left\")[[\"date\",\"account_value\",\"spy\"]]\n",
    "final_results_mv.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFNgSamJxyv3"
   },
   "source": [
    ">> - #### Step 7.2.4: Vizualise the comparision with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "KjlrtpRk9mc_",
    "outputId": "d8314657-6f9d-4600-f2e9-bf633538a358"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results_mv.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - #### Step 7.3: Model with Least-Volatile Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bi0NhRExrSz"
   },
   "source": [
    ">> - #### Step 7.3.1: Calcualte Sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcGN6S1PzjpU",
    "outputId": "20f8a9a8-941c-472a-8ab0-18449a668319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  0.9357006490234189\n"
     ]
    }
   ],
   "source": [
    "# Calculate Sharpe ratio\n",
    "sharpe=(252**0.5)*df_ensemble_results_lv.account_value.pct_change(1).mean()/df_ensemble_results_lv.account_value.pct_change(1).std()\n",
    "\n",
    "print('Sharpe Ratio: ',sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "bhQeQ969zvRa"
   },
   "outputs": [],
   "source": [
    "df_ensemble_results_lv = df_ensemble_results_lv.join(df_validation_dates) # Mask the results with the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "4RYlDJUDm4an",
    "outputId": "97f6cffc-d76a-48ad-8f5c-974d112cd8c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_ensemble_results_lv.account_value.plot()     # plot the chance in the amount value with time during test period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zsjiQs0xuA4"
   },
   "source": [
    ">> - #### Step 7.3.2: Backtest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOtqFrge0PaS",
    "outputId": "57b6fa4d-2ed6-4814-f533-cffec36c254a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return          0.163749\n",
      "Cumulative returns     0.460993\n",
      "Annual volatility      0.179541\n",
      "Sharpe ratio           0.935701\n",
      "Calmar ratio           0.873037\n",
      "Stability              0.687687\n",
      "Max drawdown          -0.187562\n",
      "Omega ratio            1.198907\n",
      "Sortino ratio          1.377872\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.968116\n",
      "Daily value at risk   -0.021953\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "stats = backtest_stats(account_value=df_ensemble_results_lv)\n",
    "stats_df = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JlN8dyDxwvB"
   },
   "source": [
    ">> - #### Step 7.3.3: Compare with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "tmq__tq19v62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>spy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>10068.749172</td>\n",
       "      <td>9777.141321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>9845.059572</td>\n",
       "      <td>9825.327421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>9893.360330</td>\n",
       "      <td>9981.552869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>10049.709796</td>\n",
       "      <td>9929.227721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>14001.630524</td>\n",
       "      <td>13196.873815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>14641.455319</td>\n",
       "      <td>13125.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>14373.378171</td>\n",
       "      <td>13224.516675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>14406.006117</td>\n",
       "      <td>13309.419390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>14609.933983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            account_value           spy\n",
       "date                                   \n",
       "2018-04-04   10000.000000  10000.000000\n",
       "2018-04-05   10068.749172   9777.141321\n",
       "2018-04-06    9845.059572   9825.327421\n",
       "2018-04-09    9893.360330   9981.552869\n",
       "2018-04-10   10049.709796   9929.227721\n",
       "...                   ...           ...\n",
       "2020-09-25   14001.630524  13196.873815\n",
       "2020-09-28   14641.455319  13125.003128\n",
       "2020-09-29   14373.378171  13224.516675\n",
       "2020-09-30   14406.006117  13309.419390\n",
       "2020-10-01   14609.933983           NaN\n",
       "\n",
       "[630 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_lv = pd.merge(df_ensemble_results_lv, df_index_scaled, on =\"date\", how = \"left\")[[\"date\",\"account_value\",\"spy\"]]\n",
    "final_results_lv.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFNgSamJxyv3"
   },
   "source": [
    ">> - #### Step 7.3.4: Vizualise the comparision with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "KjlrtpRk9mc_",
    "outputId": "d8314657-6f9d-4600-f2e9-bf633538a358"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results_lv.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
